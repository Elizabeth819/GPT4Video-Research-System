#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Gemini 2.0 Flash Promptæ”¹è¿›æ•ˆæœåˆ†æ
å¯¹æ¯”ä½¿ç”¨å¹³è¡¡ç‰ˆpromptå‰åçš„æ€§èƒ½å˜åŒ–
"""

import os
import json
import pandas as pd
from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

def load_gemini_balanced_results():
    """åŠ è½½ä½¿ç”¨å¹³è¡¡ç‰ˆpromptçš„Gemini 2.0 Flashç»“æœ"""
    gemini_dir = "result/gemini-balanced-full"
    results = {}
    
    print("ğŸ“Š åŠ è½½Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPromptç»“æœ...")
    for filename in os.listdir(gemini_dir):
        if filename.startswith("actionSummary_") and filename.endswith(".json"):
            video_id = filename.replace("actionSummary_", "").replace(".json", "")
            # æ ‡å‡†åŒ–ä¸ºimages_æ ¼å¼
            if video_id.startswith("dada_"):
                video_id = video_id.replace("dada_", "images_")
            
            with open(os.path.join(gemini_dir, filename), 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # æå–key_actions
            key_actions = []
            for segment in data:
                if isinstance(segment, dict) and 'key_actions' in segment:
                    key_actions.append(segment['key_actions'])
            
            results[video_id] = key_actions
    
    print(f"âœ… åŠ è½½äº† {len(results)} ä¸ªå¹³è¡¡ç‰ˆPromptç»“æœ")
    return results

def load_gemini_original_results():
    """å°è¯•åŠ è½½åŸå§‹promptçš„Geminiç»“æœ"""
    # æ£€æŸ¥å¯èƒ½çš„åŸå§‹ç»“æœç›®å½•
    possible_dirs = [
        "result/gemini-1.5-flash",
        "result/gemini-2.0-flash-original", 
        "result/gemini-original",
        "result/gemini-baseline"
    ]
    
    results = {}
    found_dir = None
    
    for dir_path in possible_dirs:
        if os.path.exists(dir_path):
            print(f"ğŸ“Š æ£€æŸ¥ç›®å½•: {dir_path}")
            file_count = len([f for f in os.listdir(dir_path) if f.startswith("actionSummary_") and f.endswith(".json")])
            print(f"  æ‰¾åˆ° {file_count} ä¸ªç»“æœæ–‡ä»¶")
            
            if file_count > 10:  # å¦‚æœæœ‰è¶³å¤Ÿå¤šçš„æ–‡ä»¶
                found_dir = dir_path
                break
    
    if not found_dir:
        print("âŒ æœªæ‰¾åˆ°åŸå§‹promptçš„Geminiç»“æœ")
        return None, None
    
    print(f"ğŸ“Š åŠ è½½åŸå§‹Promptç»“æœä»: {found_dir}")
    
    # ç¡®å®šæ¨¡å‹ç±»å‹
    model_type = "Gemini 1.5 Flash" if "1.5" in found_dir else "Gemini 2.0 Flash"
    
    for filename in os.listdir(found_dir):
        if filename.startswith("actionSummary_") and filename.endswith(".json"):
            video_id = filename.replace("actionSummary_", "").replace(".json", "")
            
            try:
                with open(os.path.join(found_dir, filename), 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # æå–key_actions
                key_actions = []
                for segment in data:
                    if isinstance(segment, dict) and 'key_actions' in segment:
                        key_actions.append(segment['key_actions'])
                
                results[video_id] = key_actions
            except Exception as e:
                continue
    
    print(f"âœ… åŠ è½½äº† {len(results)} ä¸ªåŸå§‹Promptç»“æœ ({model_type})")
    return results, model_type

def load_ground_truth():
    """åŠ è½½Ground Truthæ ‡ç­¾"""
    df = pd.read_csv('result/groundtruth_labels.csv', sep='\t')
    
    ground_truth = {}
    for _, row in df.iterrows():
        video_id = row['video_id'].replace('.avi', '')
        label = row['ground_truth_label']
        
        # è½¬æ¢æ ‡ç­¾
        if label == 'none':
            ground_truth[video_id] = 'none'
        else:
            ground_truth[video_id] = 'ghost probing'
    
    return ground_truth

def evaluate_model_results(results, ground_truth, model_name):
    """è¯„ä¼°æ¨¡å‹ç»“æœ"""
    y_true = []
    y_pred = []
    details = []
    
    for video_id in sorted(results.keys()):
        if video_id in ground_truth:
            # Ground truth
            gt_label = ground_truth[video_id]
            y_true.append(gt_label)
            
            # æ¨¡å‹é¢„æµ‹ - any segmentç­–ç•¥
            predictions = results[video_id]
            has_ghost_probing = any('ghost probing' in str(pred).lower() for pred in predictions)
            
            if has_ghost_probing:
                pred_label = 'ghost probing'
            else:
                pred_label = 'none'
            
            y_pred.append(pred_label)
            
            details.append({
                'video_id': video_id,
                'ground_truth': gt_label,
                'prediction': pred_label,
                'correct': gt_label == pred_label,
                'raw_predictions': predictions
            })
    
    return y_true, y_pred, details

def calculate_metrics(y_true, y_pred):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    # è½¬æ¢ä¸ºäºŒå…ƒåˆ†ç±»
    y_true_binary = [1 if label == 'ghost probing' else 0 for label in y_true]
    y_pred_binary = [1 if label == 'ghost probing' else 0 for label in y_pred]
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true_binary, y_pred_binary)
    tn, fp, fn, tp = cm.ravel()
    
    # è®¡ç®—æŒ‡æ ‡
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'accuracy': accuracy,
        'specificity': specificity,
        'confusion_matrix': cm,
        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn
    }

def create_improvement_comparison_plot(metrics_original, metrics_balanced, original_model_type, save_path):
    """åˆ›å»ºpromptæ”¹è¿›æ•ˆæœå¯¹æ¯”å›¾"""
    metrics = ['precision', 'recall', 'f1', 'accuracy', 'specificity']
    original_values = [metrics_original[m] for m in metrics]
    balanced_values = [metrics_balanced[m] for m in metrics]
    
    x = np.arange(len(metrics))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars1 = ax.bar(x - width/2, original_values, width, label=f'{original_model_type} (åŸå§‹Prompt)', alpha=0.8, color='lightcoral')
    bars2 = ax.bar(x + width/2, balanced_values, width, label='Gemini 2.0 Flash (å¹³è¡¡ç‰ˆPrompt)', alpha=0.8, color='skyblue')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.3f}',
                       xy=(bar.get_x() + bar.get_width() / 2, height),
                       xytext=(0, 3),
                       textcoords="offset points",
                       ha='center', va='bottom')
    
    # æ·»åŠ æ”¹è¿›ç®­å¤´å’Œç™¾åˆ†æ¯”
    for i, (orig, bal) in enumerate(zip(original_values, balanced_values)):
        improvement = ((bal - orig) / orig * 100) if orig > 0 else 0
        if abs(improvement) > 1:  # åªæ˜¾ç¤ºæ˜¾è‘—æ”¹è¿›
            color = 'green' if improvement > 0 else 'red'
            ax.annotate(f'{improvement:+.1f}%', 
                       xy=(i, max(orig, bal) + 0.05),
                       ha='center', va='bottom',
                       color=color, fontweight='bold')
    
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Score')
    ax.set_title('Gemini Promptæ”¹è¿›æ•ˆæœå¯¹æ¯”')
    ax.set_xticks(x)
    ax.set_xticklabels([m.capitalize() for m in metrics])
    ax.legend()
    ax.set_ylim(0, 1.1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š æ”¹è¿›æ•ˆæœå¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")

def main():
    print("ğŸ” Gemini 2.0 Flash Promptæ”¹è¿›æ•ˆæœåˆ†æ")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    gemini_balanced = load_gemini_balanced_results()
    gemini_original, original_model_type = load_gemini_original_results()
    
    if not gemini_original:
        print("âŒ æ— æ³•æ‰¾åˆ°åŸå§‹promptçš„ç»“æœè¿›è¡Œå¯¹æ¯”")
        print("ğŸ’¡ å»ºè®®: å¦‚æœæœ‰åŸå§‹ç»“æœï¼Œè¯·ç¡®ä¿æ”¾åœ¨ä»¥ä¸‹ç›®å½•ä¹‹ä¸€:")
        print("  - result/gemini-2.0-flash-original/")
        print("  - result/gemini-original/") 
        print("  - result/gemini-baseline/")
        return
    
    ground_truth = load_ground_truth()
    
    # æ‰¾åˆ°å…±åŒè§†é¢‘
    common_videos = set(gemini_balanced.keys()) & set(gemini_original.keys()) & set(ground_truth.keys())
    print(f"ğŸ“¹ å¯å¯¹æ¯”çš„å…±åŒè§†é¢‘: {len(common_videos)} ä¸ª")
    
    if len(common_videos) < 5:
        print("âŒ å…±åŒè§†é¢‘å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆå¯¹æ¯”")
        return
    
    # åˆ›å»ºå­é›†æ•°æ®
    balanced_subset = {vid: gemini_balanced[vid] for vid in common_videos}
    original_subset = {vid: gemini_original[vid] for vid in common_videos}
    gt_subset = {vid: ground_truth[vid] for vid in common_videos}
    
    print(f"\nğŸ¯ å¯¹æ¯”åˆ†æ ({len(common_videos)} ä¸ªè§†é¢‘):")
    print("-" * 50)
    
    # è¯„ä¼°ä¸¤ä¸ªç‰ˆæœ¬
    y_true_original, y_pred_original, details_original = evaluate_model_results(original_subset, gt_subset, original_model_type)
    y_true_balanced, y_pred_balanced, details_balanced = evaluate_model_results(balanced_subset, gt_subset, "Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics_original = calculate_metrics(y_true_original, y_pred_original)
    metrics_balanced = calculate_metrics(y_true_balanced, y_pred_balanced)
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    print(f"ğŸ¤– {original_model_type} + åŸå§‹Prompt:")
    print(f"  ğŸ“Š ç²¾ç¡®åº¦ (Precision): {metrics_original['precision']:.3f}")
    print(f"  ğŸ“Š å¬å›ç‡ (Recall): {metrics_original['recall']:.3f}")
    print(f"  ğŸ“Š F1åˆ†æ•°: {metrics_original['f1']:.3f}")
    print(f"  ğŸ“Š å‡†ç¡®ç‡ (Accuracy): {metrics_original['accuracy']:.3f}")
    print(f"  ğŸ“Š ç‰¹å¼‚æ€§ (Specificity): {metrics_original['specificity']:.3f}")
    print(f"  ğŸ“Š æ··æ·†çŸ©é˜µ: TP={metrics_original['tp']}, FP={metrics_original['fp']}, FN={metrics_original['fn']}, TN={metrics_original['tn']}")
    
    print(f"\nğŸ¤– Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt:")
    print(f"  ğŸ“Š ç²¾ç¡®åº¦ (Precision): {metrics_balanced['precision']:.3f}")
    print(f"  ğŸ“Š å¬å›ç‡ (Recall): {metrics_balanced['recall']:.3f}")
    print(f"  ğŸ“Š F1åˆ†æ•°: {metrics_balanced['f1']:.3f}")
    print(f"  ğŸ“Š å‡†ç¡®ç‡ (Accuracy): {metrics_balanced['accuracy']:.3f}")
    print(f"  ğŸ“Š ç‰¹å¼‚æ€§ (Specificity): {metrics_balanced['specificity']:.3f}")
    print(f"  ğŸ“Š æ··æ·†çŸ©é˜µ: TP={metrics_balanced['tp']}, FP={metrics_balanced['fp']}, FN={metrics_balanced['fn']}, TN={metrics_balanced['tn']}")
    
    # æ”¹è¿›åˆ†æ
    print(f"\nğŸ“ˆ Promptæ”¹è¿›æ•ˆæœ:")
    improvements = {}
    for metric in ['precision', 'recall', 'f1', 'accuracy', 'specificity']:
        old_val = metrics_original[metric]
        new_val = metrics_balanced[metric]
        change = new_val - old_val
        pct_change = (change / old_val * 100) if old_val > 0 else 0
        improvements[metric] = {
            'absolute': change,
            'percentage': pct_change,
            'improved': change > 0
        }
        
        status = "ğŸ“ˆ æ”¹è¿›" if change > 0 else "ğŸ“‰ ä¸‹é™" if change < 0 else "â¡ï¸ æŒå¹³"
        print(f"  {metric.capitalize()}: {old_val:.3f} â†’ {new_val:.3f} ({change:+.3f}, {pct_change:+.1f}%) {status}")
    
    # æ€»ä½“è¯„ä¼°
    improved_count = sum(1 for imp in improvements.values() if imp['improved'])
    total_metrics = len(improvements)
    
    print(f"\nğŸ¯ æ€»ä½“æ”¹è¿›æ•ˆæœ:")
    print(f"  ğŸ“Š æ”¹è¿›æŒ‡æ ‡: {improved_count}/{total_metrics}")
    print(f"  ğŸ“ˆ æ”¹è¿›ç‡: {improved_count/total_metrics*100:.1f}%")
    
    if improved_count > total_metrics / 2:
        print(f"  ğŸ‰ æ€»ä½“è¯„ä»·: å¹³è¡¡ç‰ˆPromptæ˜¾è‘—æ”¹è¿›äº†æ€§èƒ½")
    elif improved_count == total_metrics / 2:
        print(f"  ğŸ¤ æ€»ä½“è¯„ä»·: å¹³è¡¡ç‰ˆPromptæ•ˆæœæŒå¹³")
    else:
        print(f"  ğŸ“‰ æ€»ä½“è¯„ä»·: å¹³è¡¡ç‰ˆPromptå¯¹æŸäº›æŒ‡æ ‡æœ‰è´Ÿé¢å½±å“")
    
    # åˆ›å»ºå¯è§†åŒ–
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    plot_path = f"result/gemini_prompt_improvement_{timestamp}.png"
    create_improvement_comparison_plot(metrics_original, metrics_balanced, original_model_type, plot_path)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    comparison_results = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'common_videos': len(common_videos),
        'original_model': original_model_type,
        'metrics_original': {k: float(v) if isinstance(v, (np.integer, np.floating)) else v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics_original.items()},
        'metrics_balanced': {k: float(v) if isinstance(v, (np.integer, np.floating)) else v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics_balanced.items()},
        'improvements': improvements,
        'summary': {
            'improved_metrics': improved_count,
            'total_metrics': total_metrics,
            'improvement_rate': improved_count/total_metrics*100
        }
    }
    
    output_file = f"result/gemini_prompt_improvement_analysis_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(comparison_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ”¹è¿›åˆ†æç»“æœå·²ä¿å­˜:")
    print(f"  ğŸ“Š è¯¦ç»†æ•°æ®: {output_file}")
    print(f"  ğŸ“ˆ å¯¹æ¯”å›¾è¡¨: {plot_path}")
    
    print(f"\nâœ… Promptæ”¹è¿›æ•ˆæœåˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()