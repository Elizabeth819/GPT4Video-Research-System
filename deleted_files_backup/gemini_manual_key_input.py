#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æ‰‹åŠ¨è¾“å…¥Gemini API Keyå®Œæˆå‰©ä½™50ä¸ªè§†é¢‘
"""

import os
import json
import cv2
from moviepy.editor import VideoFileClip
import google.generativeai as genai
import time
import pandas as pd
from tqdm import tqdm
import shutil
import getpass

def get_balanced_prompt():
    """è·å–å¹³è¡¡ç‰ˆprompt - ä¸GPT-4.1å®Œå…¨ç›¸åŒ"""
    return """You are an expert AI system analyzing sequential video frames from a moving vehicle's dashboard camera. Your task is to detect and analyze "ghost probing" (é¬¼æ¢å¤´) behavior - when objects (vehicles, pedestrians, cyclists, etc.) suddenly appear from concealed positions and potentially create collision risks.

**LAYERED DETECTION STRATEGY:**

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing" in key_actions)**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters)
- Object was completely hidden/concealed and suddenly becomes visible
- Creates IMMEDIATE collision risk requiring emergency response
- Appearance is sudden and unexpected from the ego vehicle's perspective

**2. POTENTIAL Ghost Probing (use "potential ghost probing" in key_actions)**:
- Object appears from partially concealed position
- Creates moderate collision risk but allows reaction time
- Object was somewhat predictable but still poses safety concern
- Distance allows for controlled response

**ANALYSIS REQUIREMENTS:**

For each 10-second interval, provide a JSON object with these fields:
- "timestamp": Time range (e.g., "0-10s")
- "summary": Brief scene description focusing on vehicle movement and object interactions
- "actions": Current actions of ego vehicle and other traffic participants
- "characters": People visible in the scene (if any)
- "key_objects": Important objects, vehicles, or infrastructure
- "key_actions": **CRITICAL FIELD** - Use "ghost probing" for high-confidence cases, "potential ghost probing" for moderate cases, or describe other significant actions
- "next_action": Predicted immediate next action of ego vehicle

**DETECTION GUIDELINES:**
- Focus on concealment and sudden appearance
- Consider collision risk and reaction time available
- Prioritize safety-critical situations
- Be specific about object types (vehicle, pedestrian, cyclist, etc.)
- Consider the ego vehicle's perspective and available sight lines

Analyze the provided frames and return a JSON array of interval analyses."""

def setup_gemini_with_manual_key():
    """æ‰‹åŠ¨è¾“å…¥API Keyè®¾ç½®Gemini"""
    print("ğŸ”‘ å½“å‰API Keyé…é¢å·²ç”¨å®Œï¼Œè¯·è¾“å…¥å¦ä¸€ä¸ªå¯ç”¨çš„Gemini API Key")
    print("ğŸ’¡ æ‚¨å¯ä»¥ä»Google AI Studioè·å–æ–°çš„API Key: https://aistudio.google.com/app/apikey")
    
    api_key = getpass.getpass("è¯·è¾“å…¥Gemini API Key (è¾“å…¥æ—¶ä¸ä¼šæ˜¾ç¤º): ").strip()
    
    if not api_key:
        print("âŒ æœªè¾“å…¥API Key")
        return None
    
    print(f"ğŸ”‘ æµ‹è¯•API Key: {api_key[:15]}...")
    genai.configure(api_key=api_key)
    
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # æµ‹è¯•APIè°ƒç”¨
        test_response = model.generate_content(
            "Test message - return just 'OK'",
            generation_config={"temperature": 0.1, "max_output_tokens": 10}
        )
        
        if test_response and test_response.text:
            print(f"âœ… API Key å¯ç”¨ï¼å“åº”: {test_response.text.strip()}")
            return model
        else:
            print("âŒ API Key å“åº”ä¸ºç©º")
            return None
            
    except Exception as e:
        if "429" in str(e) or "quota" in str(e).lower():
            print("âš ï¸ è¯¥API Keyé…é¢å·²ç”¨å®Œ")
        else:
            print(f"âŒ API Key é”™è¯¯: {str(e)}")
        return None

def extract_frames(video_path, output_dir, interval=10, frames_per_interval=10):
    """æå–è§†é¢‘å¸§"""
    if not os.path.exists(video_path):
        return []
    
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if fps <= 0 or total_frames <= 0:
            return []
        
        duration = total_frames / fps
        intervals = int(duration // interval) + (1 if duration % interval > 0 else 0)
        
        frame_paths = []
        
        for i in range(intervals):
            start_time = i * interval
            end_time = min((i + 1) * interval, duration)
            interval_duration = end_time - start_time
            
            if interval_duration <= 0:
                continue
            
            frames_to_extract = min(frames_per_interval, max(1, int(interval_duration * fps)))
            
            for j in range(frames_to_extract):
                timestamp = start_time + (j * interval_duration / frames_to_extract)
                frame_number = int(timestamp * fps)
                
                if frame_number >= total_frames:
                    break
                
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
                ret, frame = cap.read()
                
                if ret:
                    frame_filename = f"frame_{i:03d}_{j:03d}_{timestamp:.2f}s.jpg"
                    frame_path = os.path.join(output_dir, frame_filename)
                    cv2.imwrite(frame_path, frame)
                    frame_paths.append(frame_path)
        
        cap.release()
        return frame_paths
        
    except Exception as e:
        print(f"å¸§æå–é”™è¯¯: {e}")
        return []

def process_single_video(video_path, model, output_dir):
    """å¤„ç†å•ä¸ªè§†é¢‘"""
    try:
        video_id = os.path.basename(video_path).replace('.avi', '')
        video_id_formatted = video_id.replace('images_', 'dada_')
        output_file = os.path.join(output_dir, f"actionSummary_{video_id_formatted}.json")
        
        if os.path.exists(output_file):
            print(f"â­ï¸ è·³è¿‡å·²å¤„ç†çš„è§†é¢‘: {video_id}")
            return True
        
        print(f"ğŸ¬ å¤„ç†è§†é¢‘: {video_id}")
        
        # æå–å¸§
        temp_frames_dir = f"frames_temp_{hash(video_path) % 100000}"
        frame_paths = extract_frames(video_path, temp_frames_dir)
        
        if not frame_paths:
            print(f"âŒ æ— æ³•æå–å¸§: {video_id}")
            return False
        
        # å‡†å¤‡å›¾åƒ
        images = []
        for frame_path in frame_paths:
            if os.path.exists(frame_path):
                with open(frame_path, 'rb') as f:
                    images.append({
                        'mime_type': 'image/jpeg',
                        'data': f.read()
                    })
        
        if not images:
            print(f"âŒ æ²¡æœ‰æœ‰æ•ˆå›¾åƒ: {video_id}")
            return False
        
        # è°ƒç”¨Gemini
        prompt = get_balanced_prompt()
        
        response = model.generate_content(
            [prompt] + images,
            generation_config={
                "temperature": 0.3,
                "max_output_tokens": 8192,
            }
        )
        
        if not response or not response.text:
            print(f"âŒ APIå“åº”ä¸ºç©º: {video_id}")
            return False
        
        # è§£æJSONå“åº”
        response_text = response.text.strip()
        if response_text.startswith('```json'):
            response_text = response_text[7:]
        if response_text.endswith('```'):
            response_text = response_text[:-3]
        
        try:
            result = json.loads(response_text)
            
            # ä¿å­˜ç»“æœ
            os.makedirs(output_dir, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… æˆåŠŸå¤„ç†: {video_id}")
            return True
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æé”™è¯¯ {video_id}: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ å¤„ç†è§†é¢‘é”™è¯¯ {video_id}: {e}")
        return False
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if 'temp_frames_dir' in locals() and os.path.exists(temp_frames_dir):
            shutil.rmtree(temp_frames_dir, ignore_errors=True)

def get_remaining_videos():
    """è·å–å‰©ä½™æœªå¤„ç†çš„è§†é¢‘"""
    df = pd.read_csv('result/groundtruth_labels.csv', sep='\t')
    all_videos = df['video_id'].str.replace('.avi', '').tolist()
    
    output_dir = "result/gemini-balanced-full"
    remaining = []
    
    for vid in all_videos:
        if vid and isinstance(vid, str):
            video_path = f"DADA-2000-videos/{vid}.avi"
            video_id_formatted = vid.replace('images_', 'dada_')
            output_file = os.path.join(output_dir, f"actionSummary_{video_id_formatted}.json")
            
            if os.path.exists(video_path) and not os.path.exists(output_file):
                remaining.append(video_path)
    
    return remaining

def main():
    print("ğŸš€ Gemini æ‰‹åŠ¨API Keyè¾“å…¥ - å®Œæˆå‰©ä½™50ä¸ªè§†é¢‘")
    print("=" * 60)
    
    # æ£€æŸ¥å‰©ä½™è§†é¢‘
    remaining_videos = get_remaining_videos()
    print(f"ğŸ“‹ å‰©ä½™æœªå¤„ç†è§†é¢‘: {len(remaining_videos)} ä¸ª")
    
    if len(remaining_videos) == 0:
        print("ğŸ‰ æ‰€æœ‰è§†é¢‘å·²å¤„ç†å®Œæˆï¼")
        return
    
    # æ‰‹åŠ¨è¾“å…¥API Keyè®¾ç½®Gemini
    model = setup_gemini_with_manual_key()
    if not model:
        print("âŒ æ— æ³•åˆå§‹åŒ–Geminiæ¨¡å‹")
        return
    
    print(f"ğŸ¯ å¼€å§‹å¤„ç† {len(remaining_videos)} ä¸ªè§†é¢‘")
    print(f"ğŸ“Š é…é¢é™åˆ¶: 200 RPD (åº”è¯¥è¶³å¤Ÿå¤„ç†æ‰€æœ‰å‰©ä½™è§†é¢‘)")
    
    # å¤„ç†è§†é¢‘
    output_dir = "result/gemini-balanced-full"
    os.makedirs(output_dir, exist_ok=True)
    
    success_count = 0
    failed_videos = []
    
    for i, video_path in enumerate(tqdm(remaining_videos, desc="å¤„ç†è§†é¢‘"), 1):
        print(f"\n[{i}/{len(remaining_videos)}] å¤„ç†: {os.path.basename(video_path)}")
        
        if process_single_video(video_path, model, output_dir):
            success_count += 1
        else:
            failed_videos.append(video_path)
        
        # æ¯10ä¸ªè§†é¢‘æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
        if i % 10 == 0:
            print(f"ğŸ“Š è¿›åº¦æ›´æ–°: {success_count}/{i} æˆåŠŸ ({success_count/i*100:.1f}%)")
        
        # æ·»åŠ å»¶è¿Ÿä»¥é¿å…APIé™åˆ¶
        time.sleep(2)
    
    # æœ€ç»ˆç»Ÿè®¡
    total_processed = 49 + success_count  # ä¹‹å‰49ä¸ª + æ–°å¤„ç†çš„
    
    print(f"\nğŸ¯ å¤„ç†å®Œæˆ!")
    print(f"  ğŸ“Š æœ¬æ¬¡æˆåŠŸ: {success_count}/{len(remaining_videos)}")
    print(f"  ğŸ“Š æ€»ä½“è¿›åº¦: {total_processed}/99 ({total_processed/99*100:.1f}%)")
    
    if failed_videos:
        print(f"  âŒ å¤±è´¥è§†é¢‘: {len(failed_videos)} ä¸ª")
        for vid in failed_videos:
            print(f"    - {os.path.basename(vid)}")
    
    if total_processed >= 99:
        print("ğŸ‰ æ­å–œï¼å·²å®Œæˆå…¨éƒ¨99ä¸ªè§†é¢‘çš„Geminiå¤„ç†ï¼")
        print("ğŸ“Š ç°åœ¨å¯ä»¥è¿›è¡Œå®Œæ•´çš„99è§†é¢‘å¯¹æ¯”åˆ†æ")
        
        # è‡ªåŠ¨å¯åŠ¨å®Œæ•´å¯¹æ¯”åˆ†æ
        print("\nğŸ”„ è‡ªåŠ¨å¯åŠ¨å®Œæ•´99è§†é¢‘å¯¹æ¯”åˆ†æ...")
        try:
            import subprocess
            subprocess.run(["python", "create_final_99_video_comparison.py"], check=False)
        except:
            print("ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: python create_final_99_video_comparison.py")
    else:
        print(f"â³ è¿˜éœ€å¤„ç† {99 - total_processed} ä¸ªè§†é¢‘")

if __name__ == "__main__":
    main()