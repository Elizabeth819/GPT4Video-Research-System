#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Gemini 2.0 Flash + GPT-4.1å¹³è¡¡ç‰ˆPrompt å…¬å¹³å¯¹æ¯”å®éªŒ
åŸºäºActionSummary-gemini.pyï¼Œä½¿ç”¨GPT-4.1çš„å¹³è¡¡ç‰ˆpromptè¿›è¡Œå…¬å¹³å¯¹æ¯”
"""

import cv2
import os
import base64
import requests
from moviepy.editor import VideoFileClip
import logging
import json
import sys
import threading
from retrying import retry
logging.getLogger('moviepy').setLevel(logging.ERROR)
import time
from functools import wraps
from dotenv import load_dotenv
import time
import video_utilities as vu
from jinja2 import Environment, FileSystemLoader
import numpy as np
import tqdm
import traceback
import datetime
import multiprocessing
from functools import partial
import re

# Geminiç›¸å…³åº“
import google.generativeai as genai

def process_video_wrapper(video_path, args):
    """è§†é¢‘å¤„ç†çš„åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹è°ƒç”¨"""
    try:
        video_name = os.path.basename(video_path)
        result_filename = f'actionSummary_{video_name.split(".")[0]}.json'
        result_path = os.path.join(args.output_dir, result_filename)
        
        if os.path.exists(result_path) and not args.no_skip and not args.retry_failed:
            print(f"è§†é¢‘ {video_name} å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡")
            return (video_path, "skipped", None, 0)
        
        processor = GeminiVideoProcessor(args)
        result = processor.process_video(video_path)
        
        if result is None:
            return (video_path, "failed", None, 0)
        
        # ä¿å­˜ç»“æœ
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        return (video_path, "success", result, len(result))
        
    except Exception as e:
        print(f"å¤„ç†è§†é¢‘ {video_path} æ—¶å‡ºé”™: {str(e)}")
        return (video_path, "failed", str(e), 0)

class GeminiVideoProcessor:
    def __init__(self, args):
        self.frame_interval = args.interval
        self.frames_per_interval = args.frames
        self.output_dir = args.output_dir
        self.max_retries = getattr(args, 'max_retries', 3)
        
        # åˆå§‹åŒ–Gemini
        load_dotenv()
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')
        
        # è®¾ç½®æ—¥å¿—
        self.setup_logging()
    
    def setup_logging(self):
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"logs/gemini_balanced_processing_{timestamp}.log"
        os.makedirs("logs", exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_filename, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def get_balanced_prompt(self, video_id, segment_id_str, frame_interval, frames_per_interval):
        """
        ä½¿ç”¨GPT-4.1å¹³è¡¡ç‰ˆçš„åˆ†å±‚æ£€æµ‹ç­–ç•¥prompt
        """
        system_prompt = f"""You are an expert AI system analyzing sequential video frames from autonomous driving scenarios. Your primary task is to detect "ghost probing" events using a balanced layered detection strategy.

**DEFINITION: Ghost Probing**
A dangerous traffic scenario where pedestrians, cyclists, or objects suddenly appear from concealed positions (behind parked cars, walls, blind spots) creating immediate collision risk requiring emergency braking or avoidance.

**LAYERED DETECTION STRATEGY:**

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing" in key_actions)**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters) 
- Appearance is SUDDEN and from blind spots (behind parked cars, walls, obstacles)
- Occurs in HIGH-RISK environments: highways, rural roads, parking lots
- Creates IMMEDIATE danger requiring emergency response
- Object was previously completely hidden and suddenly emerges

**2. POTENTIAL Ghost Probing (use "potential ghost probing" in key_actions)**:
- Object appears suddenly but at moderate distance (3-5 meters)
- Sudden movement in environments where some unpredictability exists
- Appears from partially concealed positions
- Creates heightened caution but not immediate emergency

**3. Normal Traffic (use "none" in key_actions)**:
- Predictable pedestrian crossings at crosswalks
- Cyclists in designated bike lanes
- Normal traffic flow and lane changes
- Expected movements in urban environments

**ANALYSIS FRAMEWORK:**
1. **Concealment Assessment**: Was the object previously hidden behind obstacles?
2. **Distance Evaluation**: How close is the object when first detected?
3. **Environment Context**: Is this a high-risk scenario location?
4. **Predictability**: Was this movement expected or sudden?
5. **Emergency Level**: Does this require immediate evasive action?

Your job is to analyze {frames_per_interval} frames spanning {frame_interval} seconds and provide detailed analysis.

**TASKS:**
1. **Ghost Probing Detection**: Apply the layered detection strategy
2. **Current Action Analysis**: Describe what's happening in the video
3. **Next Action Prediction**: Predict required vehicle response
4. **Object-Action Consistency**: Ensure key_objects match key_actions

Always return a single JSON object with these fields:
- video_id: "{video_id}"
- segment_id: "{segment_id_str}"
- Start_Timestamp and End_Timestamp: derived from frame names
- summary: detailed description of the scenario
- actions: current vehicle actions and reasoning
- key_objects: important objects affecting driving decisions
- key_actions: classification using layered strategy ("ghost probing", "potential ghost probing", or "none")
- next_action: JSON object with speed_control, direction_control, and lane_control

**IMPORTANT**: Use the layered detection strategy to maintain high recall (detect real dangers) while improving precision (reduce false positives). When in doubt between categories, prefer the more conservative classification.

All text must be in English. Return only valid JSON."""

        return system_prompt.replace("{video_id}", video_id).replace("{segment_id_str}", segment_id_str)
    
    def process_video_segment(self, video_path, start_time, end_time, video_id, segment_id):
        """å¤„ç†è§†é¢‘ç‰‡æ®µ"""
        try:
            # æå–å¸§
            image_paths = vu.extract_frames_at_intervals(
                video_path, start_time, end_time, self.frames_per_interval
            )
            
            if not image_paths:
                self.logger.error(f"æœªèƒ½æå–å¸§: {video_path}")
                return None
            
            # æå–éŸ³é¢‘è½¬å½•ï¼ˆç®€åŒ–ç‰ˆï¼‰
            trans = ""  # Geminiä¸»è¦ä¾é è§†è§‰åˆ†æ
            
            # æ„å»ºåˆ†æè¯·æ±‚
            return self.analyze_with_gemini(image_paths, trans, video_id, f"segment_{segment_id:03d}")
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
            return None
    
    def analyze_with_gemini(self, image_paths, trans, video_id, segment_id_str):
        """ä½¿ç”¨Geminiè¿›è¡Œåˆ†æ"""
        try:
            # è·å–å¹³è¡¡ç‰ˆprompt
            system_prompt = self.get_balanced_prompt(
                video_id, segment_id_str, self.frame_interval, self.frames_per_interval
            )
            
            # å‡†å¤‡å›¾åƒæ•°æ®
            prompt_parts = []
            if trans:
                prompt_parts.append(f"Audio Transcription: {trans}")
            
            prompt_parts.append(f"Analyzing {len(image_paths)} frames from {self.frame_interval} seconds:")
            
            # æ·»åŠ å›¾åƒ
            images = []
            for img_path in image_paths:
                try:
                    # è¯»å–å¹¶ç¼–ç å›¾åƒ
                    with open(img_path, 'rb') as f:
                        image_data = f.read()
                    
                    # Geminiå›¾åƒæ ¼å¼
                    images.append({
                        'mime_type': 'image/jpeg',
                        'data': image_data
                    })
                    
                    prompt_parts.append(f"Frame: {os.path.basename(img_path)}")
                    
                except Exception as e:
                    self.logger.warning(f"æ— æ³•åŠ è½½å›¾åƒ {img_path}: {str(e)}")
                    continue
            
            if not images:
                self.logger.error("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å›¾åƒ")
                return None
            
            # æ„å»ºè¯·æ±‚å†…å®¹
            content = [system_prompt] + [{"text": part} for part in prompt_parts] + images
            
            # å®‰å…¨è®¾ç½®
            safety_settings = [
                {"category": "harassment", "threshold": "block_only_high"},
                {"category": "hate_speech", "threshold": "block_only_high"},
                {"category": "sexually_explicit", "threshold": "block_only_high"},
                {"category": "dangerous_content", "threshold": "block_only_high"}
            ]
            
            # ç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": 0.2,  # ä¸GPT-4.1ä¿æŒä¸€è‡´
                "top_p": 0.95,
                "max_output_tokens": 2048,
            }
            
            # APIè°ƒç”¨
            self.logger.info(f"è°ƒç”¨Gemini APIåˆ†æ {len(images)} ä¸ªå›¾åƒ")
            
            response = self.model.generate_content(
                content,
                safety_settings=safety_settings,
                generation_config=generation_config
            )
            
            if not response.text:
                self.logger.error("Gemini APIè¿”å›ç©ºå“åº”")
                return None
            
            # è§£æJSONå“åº”
            try:
                result = json.loads(response.text)
                self.logger.info("æˆåŠŸè§£æGeminiå“åº”JSON")
                return result
                
            except json.JSONDecodeError as e:
                self.logger.error(f"JSONè§£æå¤±è´¥: {str(e)}")
                self.logger.error(f"åŸå§‹å“åº”: {response.text[:500]}...")
                return None
                
        except Exception as e:
            self.logger.error(f"Gemini APIè°ƒç”¨å¤±è´¥: {str(e)}")
            return None
    
    def process_video(self, video_path):
        """å¤„ç†æ•´ä¸ªè§†é¢‘"""
        try:
            self.logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
            
            # è·å–è§†é¢‘ä¿¡æ¯
            with VideoFileClip(video_path) as clip:
                duration = clip.duration
            
            video_name = os.path.basename(video_path)
            video_id = video_name.split('.')[0].replace('images_', 'dada_')
            
            # è®¡ç®—åˆ†æ®µ
            total_segments = int(duration // self.frame_interval)
            if duration % self.frame_interval > 0:
                total_segments += 1
            
            results = []
            
            for segment_id in range(total_segments):
                start_time = segment_id * self.frame_interval
                end_time = min((segment_id + 1) * self.frame_interval, duration)
                
                self.logger.info(f"å¤„ç†ç‰‡æ®µ {segment_id + 1}/{total_segments}: {start_time:.1f}s - {end_time:.1f}s")
                
                result = self.process_video_segment(
                    video_path, start_time, end_time, video_id, segment_id
                )
                
                if result:
                    results.append(result)
                    self.logger.info(f"ç‰‡æ®µ {segment_id + 1} å¤„ç†æˆåŠŸ")
                else:
                    self.logger.warning(f"ç‰‡æ®µ {segment_id + 1} å¤„ç†å¤±è´¥")
                
                # è¿›åº¦æŠ¥å‘Š
                progress = (segment_id + 1) / total_segments * 100
                print(f"è¿›åº¦: {progress:.1f}% [{segment_id + 1}/{total_segments}]")
            
            self.logger.info(f"è§†é¢‘å¤„ç†å®Œæˆ: {len(results)}/{total_segments} ç‰‡æ®µæˆåŠŸ")
            return results
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
            return None

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt è§†é¢‘åˆ†æ')
    parser.add_argument('--folder', default='DADA-2000-videos', help='è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--single', help='å¤„ç†å•ä¸ªè§†é¢‘æ–‡ä»¶')
    parser.add_argument('--output-dir', default='result/gemini-balanced-prompt', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--interval', type=int, default=10, help='æ—¶é—´é—´éš”(ç§’)')
    parser.add_argument('--frames', type=int, default=10, help='æ¯ä¸ªé—´éš”çš„å¸§æ•°')
    parser.add_argument('--limit', type=int, help='é™åˆ¶å¤„ç†çš„è§†é¢‘æ•°é‡')
    parser.add_argument('--no-skip', action='store_true', help='ä¸è·³è¿‡å·²å¤„ç†çš„è§†é¢‘')
    parser.add_argument('--retry-failed', action='store_true', help='é‡æ–°å¤„ç†å¤±è´¥çš„è§†é¢‘')
    parser.add_argument('--start-at', type=int, default=0, help='ä»ç¬¬å‡ ä¸ªè§†é¢‘å¼€å§‹')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è·å–è§†é¢‘åˆ—è¡¨
    if args.single:
        video_files = [args.single]
    else:
        video_files = []
        for filename in sorted(os.listdir(args.folder)):
            if filename.endswith('.avi') and filename.startswith('images_'):
                video_files.append(os.path.join(args.folder, filename))
    
    # è¿‡æ»¤å’Œé™åˆ¶
    if args.start_at > 0:
        video_files = video_files[args.start_at:]
    
    if args.limit:
        video_files = video_files[:args.limit]
    
    print(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(video_files)} ä¸ªè§†é¢‘")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ”§ é…ç½®: {args.interval}ç§’é—´éš”, {args.frames}å¸§/é—´éš”")
    print("ğŸš€ ä½¿ç”¨Gemini 2.0 Flash + GPT-4.1å¹³è¡¡ç‰ˆPrompt")
    
    # å¤„ç†è§†é¢‘
    successful = 0
    failed = 0
    skipped = 0
    
    for i, video_path in enumerate(video_files, 1):
        print(f"\nå¤„ç†è§†é¢‘ {i}/{len(video_files)}: {os.path.basename(video_path)}")
        
        result = process_video_wrapper(video_path, args)
        video_path, status, data, segments = result
        
        if status == "success":
            successful += 1
            print(f"âœ… æˆåŠŸå¤„ç† {segments} ä¸ªç‰‡æ®µ")
        elif status == "skipped":
            skipped += 1
            print(f"â­ï¸ è·³è¿‡å·²å¤„ç†")
        else:
            failed += 1
            print(f"âŒ å¤„ç†å¤±è´¥: {data}")
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\nğŸ¯ å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸ: {successful}")
    print(f"  â­ï¸ è·³è¿‡: {skipped}")
    print(f"  âŒ å¤±è´¥: {failed}")
    print(f"  ğŸ“Š æˆåŠŸç‡: {successful/(successful+failed)*100:.1f}%")

if __name__ == "__main__":
    main()