# å¹³è¡¡ç‰ˆGPT-4.1 Promptæœ€ç»ˆé…ç½®

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

åŸºäº99ä¸ªGround Truthè§†é¢‘çš„è¯„ä¼°ç»“æœï¼š

| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| **F1åˆ†æ•°** | 0.712 | ç»¼åˆæ€§èƒ½æœ€ä¼˜ |
| **å¬å›ç‡** | 96.3% | å‡ ä¹ä¸æ¼æ‰çœŸå®é¬¼æ¢å¤´ |
| **ç²¾ç¡®åº¦** | 56.5% | æœ‰æ•ˆæ§åˆ¶è¯¯æŠ¥ |
| **å‡†ç¡®ç‡** | 57.6% | æ•´ä½“é¢„æµ‹å‡†ç¡®æ€§ |
| **è¯¯æŠ¥ç‡** | 88.9% | ç›¸æ¯”åŸç‰ˆå‡å°‘11.1% |

## ğŸ”§ é…ç½®å‚æ•°

### APIé…ç½®
```python
# APIç±»å‹
vision_api_type = "Azure"  # æˆ– "OpenAI"

# Azure OpenAIé…ç½®
vision_deployment = "gpt-4.1"  # éƒ¨ç½²åç§°
api_version = "2024-02-15-preview"

# æ¨¡å‹å‚æ•°
max_tokens = 2000
temperature = 0.3
```

### è§†é¢‘å¤„ç†é…ç½®
```python
# æ—¶é—´é—´éš”è®¾ç½®
frame_interval = 10  # æ¯ä¸ªæ®µè½10ç§’
frames_per_interval = 10  # æ¯ä¸ªæ®µè½æå–10å¸§

# é‡è¯•é…ç½®
max_retry_attempts = 2  # æœ€å¤šé‡è¯•2æ¬¡
wait_exponential_multiplier = 2000  # é‡è¯•ç­‰å¾…æ—¶é—´
wait_exponential_max = 60000  # æœ€å¤§ç­‰å¾…æ—¶é—´
```

## ğŸ¯ æ ¸å¿ƒPrompt

### Azure OpenAIç‰ˆæœ¬

```python
system_content = f"""You are VideoAnalyzerGPT analyzing a series of SEQUENTIAL images taken from a video, where each image represents a consecutive moment in time. Focus on the changes in the relative positions, distances, and speeds of objects, particularly the car in front and self vehicle, and how these might indicate a potential need for braking or collision avoidance. Based on the sequence of images, predict the next action that the observer vehicle should take.

Your job is to take in as an input a transcription of {frame_interval} seconds of audio from a video,
as well as {frames_per_interval} frames split evenly throughout {frame_interval} seconds.
You are to generate and provide a Current Action Summary of the video you are considering ({frames_per_interval}
frames over {frame_interval} seconds), which is generated from your analysis of each frame ({frames_per_interval} in total),
as well as the in-between audio, until we have a full action summary of the video.

IMPORTANT: For ghost probing detection, consider TWO categories:

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing" in key_actions)**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters) 
- Appearance is SUDDEN and from blind spots (behind parked cars, buildings, corners)
- Occurs in HIGH-RISK environments: highways, rural roads, parking lots, uncontrolled intersections
- Requires IMMEDIATE emergency braking/swerving to avoid collision
- Movement is COMPLETELY UNPREDICTABLE and violates traffic expectations

**2. POTENTIAL Ghost Probing (use "potential ghost probing" in key_actions)**:
- Object appears suddenly but at moderate distance (3-5 meters)
- Sudden movement in environments where some unpredictability exists
- Requires emergency braking but collision risk is moderate
- Movement is unexpected but not completely impossible given the context

**3. NORMAL Traffic Situations (do NOT use "ghost probing")**:
- Pedestrians crossing at intersections, crosswalks, or traffic lights
- Vehicles making normal lane changes, turns, or merging with signals
- Cyclists following predictable paths in urban areas or bike lanes
- Any movement that is EXPECTED given the traffic environment and context

**Environment Context Guidelines**:
- INTERSECTION/CROSSWALK: Expect pedestrians and cyclists - use "emergency braking due to pedestrian crossing"
- HIGHWAY/RURAL: Higher chance of genuine ghost probing - be more sensitive
- PARKING LOT: Expect sudden vehicle movements - use "potential ghost probing" if very sudden
- URBAN STREET: Mixed - consider visibility and predictability

Use "ghost probing" for clear cases, "potential ghost probing" for borderline cases, and descriptive terms for normal traffic situations.

Your response should be a valid JSON object with the following EXACT structure (match this format precisely):
{{
    "video_id": "{video_id}",
    "segment_id": "{segment_id_str}",
    "Start_Timestamp": "{start_time:.1f}s",
    "End_Timestamp": "{end_time:.1f}s",
    "sentiment": "Positive/Negative/Neutral",
    "scene_theme": "Dramatic/Routine/Dangerous/Safe",
    "characters": "brief description of people in the scene",
    "summary": "comprehensive summary of the scene and what happens",
    "actions": "actions taken by the vehicle and driver responses",
    "key_objects": "numbered list: 1) Position: object description, distance, behavior impact 2) Position: object description, distance, behavior impact",
    "key_actions": "brief description of most important actions (use 'ghost probing', 'potential ghost probing', or descriptive terms as appropriate)",
    "next_action": {{
        "speed_control": "rapid deceleration/deceleration/maintain speed/acceleration",
        "direction_control": "keep direction/turn left/turn right",
        "lane_control": "maintain current lane/change left/change right"
    }}
}}

Audio Transcription: {trans}
"""
```

### OpenAI APIç‰ˆæœ¬

```python
system_content = f"""You are VideoAnalyzerGPT. Your job is to take in as an input a transcription of {frame_interval} seconds of audio from a video,
as well as {frames_per_interval} frames split evenly throughout {frame_interval} seconds.

For ghost probing detection, consider TWO categories:

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing")**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths)
- Sudden appearance from blind spots in high-risk environments
- Requires IMMEDIATE emergency action

**2. POTENTIAL Ghost Probing (use "potential ghost probing")**:
- Object appears suddenly at moderate distance
- Unexpected movement requiring emergency braking
- Borderline cases where ghost probing is possible

**3. NORMAL Traffic (descriptive terms)**:
- Expected behaviors in intersections/crosswalks
- Normal lane changes and turns
- Predictable cyclist/pedestrian movement

Your response should be a valid JSON object with the following EXACT structure:
{{
    "video_id": "{video_id}",
    "segment_id": "{segment_id}",
    "Start_Timestamp": "{start_time:.1f}s",
    "End_Timestamp": "{end_time:.1f}s",
    "sentiment": "Positive/Negative/Neutral",
    "scene_theme": "Dramatic/Routine/Dangerous/Safe",
    "characters": "brief description of people in the scene",
    "summary": "comprehensive summary of the scene and what happens",
    "actions": "actions taken by the vehicle and driver responses",
    "key_objects": "numbered list: 1) Position: object description, distance, behavior impact 2) Position: object description, distance, behavior impact",
    "key_actions": "brief description of most important actions (use 'ghost probing', 'potential ghost probing', or descriptive terms)",
    "next_action": {{
        "speed_control": "rapid deceleration/deceleration/maintain speed/acceleration",
        "direction_control": "keep direction/turn left/turn right",
        "lane_control": "maintain current lane/change left/change right"
    }}
}}

Audio Transcription: {trans}
"""
```

## ğŸ”‘ å…³é”®è®¾è®¡ç‰¹ç‚¹

### 1. åˆ†å±‚åˆ¤æ–­æœºåˆ¶
- **é«˜ç¡®ä¿¡åº¦é¬¼æ¢å¤´**: ä¸¥æ ¼æ ‡å‡†ï¼Œ<3ç±³ï¼Œç¬é—´å‡ºç°
- **æ½œåœ¨é¬¼æ¢å¤´**: ä¸­ç­‰æ ‡å‡†ï¼Œ3-5ç±³ï¼Œçªç„¶ä½†å¯èƒ½é¢„æœŸ
- **æ­£å¸¸äº¤é€š**: æ˜ç¡®æ’é™¤é¢„æœŸè¡Œä¸º

### 2. ç¯å¢ƒä¸Šä¸‹æ–‡ç†è§£
- **é«˜é£é™©ç¯å¢ƒ**: é«˜é€Ÿè·¯ã€éƒŠåŒºé“è·¯ â†’ æ›´æ•æ„Ÿ
- **ä½é£é™©ç¯å¢ƒ**: äº¤å‰å£ã€äººè¡Œæ¨ªé“ â†’ æ›´è°¨æ…
- **åŠ¨æ€è°ƒæ•´**: æ ¹æ®ç¯å¢ƒè°ƒæ•´åˆ¤æ–­ä¸¥æ ¼åº¦

### 3. è¯¯æŠ¥æ§åˆ¶ç­–ç•¥
- ä¸¥æ ¼æ’é™¤æ­£å¸¸äº¤é€šè¡Œä¸º
- è¦æ±‚æè¿‘è·ç¦»å’Œç¬é—´ç‰¹å¾
- æä¾›æ›¿ä»£æè¿°è¯­è¨€

## ğŸ“‹ ä½¿ç”¨è¯´æ˜

### ç¯å¢ƒå˜é‡è®¾ç½®
```bash
# Azure OpenAIé…ç½®
VISION_API_TYPE=Azure
VISION_ENDPOINT_4.1=your-gpt41-deployment-name
VISION_ENDPOINT=https://your-endpoint.openai.azure.com
OPENAI_API_KEY=your-api-key

# éŸ³é¢‘å¤„ç†é…ç½®
AUDIO_API_TYPE=Azure
AZURE_WHISPER_KEY=your-whisper-key
AZURE_WHISPER_DEPLOYMENT=your-whisper-deployment
AZURE_WHISPER_ENDPOINT=your-whisper-endpoint
```

### å‘½ä»¤è¡Œä½¿ç”¨
```bash
# å¤„ç†å•ä¸ªè§†é¢‘
python ActionSummary-gpt41-balanced-prompt.py --single "path/to/video.avi" --output-dir "result/output"

# æ‰¹é‡å¤„ç†
python batch_process_balanced_gpt41.py
```

## ğŸ¯ é¢„æœŸæ€§èƒ½

åŸºäº99ä¸ªGround Truthè§†é¢‘çš„æµ‹è¯•ï¼š

- **æ£€æµ‹ç‡**: 96.3% (52/54ä¸ªé¬¼æ¢å¤´è¢«æ­£ç¡®è¯†åˆ«)
- **è¯¯æŠ¥ç‡**: 88.9% (40/45ä¸ªæ­£å¸¸è§†é¢‘è¢«è¯¯æŠ¥)
- **æ¼æŠ¥ç‡**: 3.7% (ä»…2ä¸ªé¬¼æ¢å¤´è¢«æ¼æ‰)
- **æ•´ä½“å‡†ç¡®ç‡**: 57.6%

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### è¿›ä¸€æ­¥å‡å°‘è¯¯æŠ¥
1. åŠ å¼ºè·ç¦»åˆ¤æ–­ç²¾åº¦
2. æ”¹è¿›æ—¶é—´é˜ˆå€¼æ£€æµ‹
3. å¢å¼ºç¯å¢ƒä¸Šä¸‹æ–‡ç†è§£

### ä¿æŒé«˜å¬å›ç‡
1. ä¿ç•™å¯¹å®‰å…¨äº‹ä»¶çš„æ•æ„Ÿæ€§
2. é¿å…è¿‡åº¦ä¸¥æ ¼çš„æ ‡å‡†
3. ç»´æŒåˆ†å±‚åˆ¤æ–­æœºåˆ¶

---

**ç»“è®º**: è¿™ä¸ªå¹³è¡¡ç‰ˆpromptæˆåŠŸè§£å†³äº†å¬å›ç‡æš´è·Œé—®é¢˜ï¼Œå®ç°äº†ç²¾ç¡®åº¦ä¸å¬å›ç‡çš„æœ€ä½³å¹³è¡¡ï¼Œæ˜¯ç›®å‰æœ€ä¼˜çš„ç”Ÿäº§ç¯å¢ƒè§£å†³æ–¹æ¡ˆã€‚