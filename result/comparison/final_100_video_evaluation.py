#!/usr/bin/env python3
"""
åŸºäº99ä¸ªæˆåŠŸå¤„ç†çš„è§†é¢‘ç”Ÿæˆå®Œæ•´çš„100è§†é¢‘è¯„ä¼°æŠ¥å‘Š
"""

import os
import json
import pandas as pd
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix
import numpy as np

def load_processed_videos():
    """åŠ è½½æ‰€æœ‰æˆåŠŸå¤„ç†çš„è§†é¢‘"""
    output_dir = "result/gpt41-balanced-full"
    processed_videos = []
    
    if os.path.exists(output_dir):
        for file in os.listdir(output_dir):
            if file.startswith("actionSummary_") and file.endswith(".json"):
                video_id = file.replace("actionSummary_", "").replace(".json", "")
                processed_videos.append(video_id)
    
    return sorted(processed_videos)

def load_ground_truth_for_processed():
    """åªåŠ è½½å·²å¤„ç†è§†é¢‘çš„Ground Truth"""
    labels_file = "result/groundtruth_labels.csv"
    df = pd.read_csv(labels_file, sep='\t')
    
    # æ¸…ç†æ•°æ®
    df = df.dropna()
    df = df[df['video_id'] != '']
    
    processed_videos = load_processed_videos()
    
    ground_truth = {}
    for _, row in df.iterrows():
        video_id = row['video_id'].replace('.avi', '')
        if video_id in processed_videos:
            label = row['ground_truth_label']
            has_ghost_probing = 0 if label == 'none' else 1
            ground_truth[video_id] = has_ghost_probing
    
    return ground_truth

def extract_predictions(video_list, result_dir):
    """æå–é¢„æµ‹ç»“æœ"""
    predictions = []
    
    for video_id in video_list:
        result_file = os.path.join(result_dir, f"actionSummary_{video_id}.json")
        
        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                segments = json.load(f)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ghost probing
            has_ghost_probing = False
            for segment in segments:
                if isinstance(segment, dict):
                    key_actions = segment.get('key_actions', '').lower()
                    if 'ghost probing' in key_actions:
                        has_ghost_probing = True
                        break
            
            predictions.append(1 if has_ghost_probing else 0)
        except:
            predictions.append(0)  # é»˜è®¤ä¸ºæ— é¬¼æ¢å¤´
    
    return predictions

def generate_final_report():
    """ç”Ÿæˆæœ€ç»ˆçš„100è§†é¢‘è¯„ä¼°æŠ¥å‘Š"""
    print("ğŸ”§ ç”ŸæˆåŸºäºå·²å¤„ç†è§†é¢‘çš„å®Œæ•´è¯„ä¼°æŠ¥å‘Š")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    processed_videos = load_processed_videos()
    ground_truth = load_ground_truth_for_processed()
    
    print(f"ğŸ“Š æˆåŠŸå¤„ç†çš„è§†é¢‘æ•°é‡: {len(processed_videos)}")
    print(f"ğŸ“Š æœ‰Ground Truthçš„è§†é¢‘æ•°é‡: {len(ground_truth)}")
    
    # å¯¹é½æ•°æ®
    valid_videos = [vid for vid in processed_videos if vid in ground_truth]
    true_labels = [ground_truth[vid] for vid in valid_videos]
    
    print(f"ğŸ“Š æœ€ç»ˆè¯„ä¼°è§†é¢‘æ•°é‡: {len(valid_videos)}")
    print(f"ğŸ“Š é¬¼æ¢å¤´è§†é¢‘æ•°é‡: {sum(true_labels)}")
    print(f"ğŸ“Š æ­£å¸¸è§†é¢‘æ•°é‡: {len(true_labels) - sum(true_labels)}")
    
    # å¤šæ¨¡å‹å¯¹æ¯”
    models = {
        "åŸç‰ˆGPT-4.1": "result/gpt41-gt-final",
        "å¹³è¡¡ç‰ˆGPT-4.1": "result/gpt41-balanced-full"
    }
    
    results = {}
    
    for model_name, model_dir in models.items():
        if os.path.exists(model_dir):
            predictions = extract_predictions(valid_videos, model_dir)
            
            # ç¡®ä¿é•¿åº¦ä¸€è‡´
            if len(predictions) == len(true_labels):
                metrics = {
                    'accuracy': float(accuracy_score(true_labels, predictions)),
                    'precision': float(precision_score(true_labels, predictions, zero_division=0)),
                    'recall': float(recall_score(true_labels, predictions, zero_division=0)),
                    'f1': float(f1_score(true_labels, predictions, zero_division=0))
                }
                
                # æ··æ·†çŸ©é˜µ
                cm = confusion_matrix(true_labels, predictions)
                if cm.shape == (2, 2):
                    tn, fp, fn, tp = cm.ravel()
                    metrics.update({
                        'true_positives': int(tp),
                        'false_positives': int(fp),
                        'true_negatives': int(tn),
                        'false_negatives': int(fn),
                        'specificity': float(tn / (tn + fp) if (tn + fp) > 0 else 0)
                    })
                
                results[model_name] = metrics
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ (åŸºäº {len(valid_videos)} ä¸ªè§†é¢‘)")
    print("=" * 80)
    
    print(f"{'æ¨¡å‹':<20} {'å‡†ç¡®ç‡':<10} {'ç²¾ç¡®åº¦':<10} {'å¬å›ç‡':<10} {'F1åˆ†æ•°':<10}")
    print("-" * 70)
    
    for model_name, metrics in results.items():
        print(f"{model_name:<20} {metrics['accuracy']:<10.3f} {metrics['precision']:<10.3f} "
              f"{metrics['recall']:<10.3f} {metrics['f1']:<10.3f}")
    
    # è¯¦ç»†æ··æ·†çŸ©é˜µ
    for model_name, metrics in results.items():
        if 'true_positives' in metrics:
            print(f"\nğŸ“ˆ {model_name} æ··æ·†çŸ©é˜µ:")
            tp, fp, tn, fn = metrics['true_positives'], metrics['false_positives'], metrics['true_negatives'], metrics['false_negatives']
            print(f"  TP: {tp:3d}  FP: {fp:3d}")
            print(f"  FN: {fn:3d}  TN: {tn:3d}")
            print(f"  è¯¯æŠ¥ç‡: {fp/(fp+tn)*100:5.1f}%  æ¼æŠ¥ç‡: {fn/(fn+tp)*100:5.1f}%")
    
    # ä¿å­˜ç»“æœ
    summary = {
        'evaluation_videos': len(valid_videos),
        'ghost_probing_videos': sum(true_labels),
        'normal_videos': len(true_labels) - sum(true_labels),
        'models': results
    }
    
    with open('result/final_evaluation_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: result/final_evaluation_summary.json")
    
    # ç”ŸæˆAAAI 2026è®ºæ–‡ç”¨çš„æ•°æ®
    print(f"\nğŸ“‹ AAAI 2026è®ºæ–‡æ•°æ®:")
    print(f"- è¯„ä¼°è§†é¢‘æ•°é‡: {len(valid_videos)} (è¿‘100ä¸ª)")
    print(f"- æ•°æ®å®Œæ•´æ€§: {len(valid_videos)/100*100:.1f}%")
    
    if "å¹³è¡¡ç‰ˆGPT-4.1" in results:
        balanced_metrics = results["å¹³è¡¡ç‰ˆGPT-4.1"]
        print(f"- æœ€ä½³F1åˆ†æ•°: {balanced_metrics['f1']:.3f}")
        print(f"- å¬å›ç‡: {balanced_metrics['recall']:.3f}")
        print(f"- ç²¾ç¡®åº¦: {balanced_metrics['precision']:.3f}")
    
    return results

if __name__ == "__main__":
    results = generate_final_report()