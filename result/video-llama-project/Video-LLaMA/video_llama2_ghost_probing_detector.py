#!/usr/bin/env python3
"""
Video-LLaMA2 Ghost Probing Detection System
ä½¿ç”¨Video-LLaMA2æ¨¡å‹è¿›è¡Œé¬¼æ¢å¤´æ£€æµ‹åˆ†æ
é’ˆå¯¹DADA-2000æ•°æ®é›†çš„100ä¸ªè§†é¢‘è¿›è¡Œåˆ†æ
"""

import os
import sys
import json
import logging
import argparse
import numpy as np
import torch
import torch.backends.cudnn as cudnn
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import pandas as pd
import cv2
from PIL import Image
import decord
from tqdm import tqdm

# æ·»åŠ Video-LLaMAè·¯å¾„
sys.path.append('/Users/wanmeng/repository/GPT4Video-cobra-auto/result/Video-LLaMA')

# Video-LLaMA2å¯¼å…¥
from video_llama.common.config import Config
from video_llama.common.dist_utils import get_rank
from video_llama.common.registry import registry
from video_llama.conversation.conversation_video import Chat, Conversation, default_conversation, conv_llava_llama_2
from video_llama.datasets.builders import *
from video_llama.models import *
from video_llama.processors import *
from video_llama.runners import *
from video_llama.tasks import *

# è®¾ç½®decordåç«¯
decord.bridge.set_bridge('torch')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('video_llama2_ghost_probing.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VideoLLaMA2GhostProbingDetector:
    def __init__(self, 
                 config_path: str = "eval_configs/video_llama_eval_withaudio.yaml",
                 model_type: str = "llama_v2",
                 gpu_id: int = 0,
                 device: str = "cuda:0"):
        """
        åˆå§‹åŒ–Video-LLaMA2é¬¼æ¢å¤´æ£€æµ‹å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            model_type: æ¨¡å‹ç±»å‹ (llama_v2 æˆ– vicuna)
            gpu_id: GPU ID
            device: è®¾å¤‡ç±»å‹
        """
        self.config_path = config_path
        self.model_type = model_type
        self.gpu_id = gpu_id
        self.device = device
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = None
        self.chat = None
        self.vis_processor = None
        
        # é¬¼æ¢å¤´æ£€æµ‹prompt
        self.ghost_probing_prompt = self._create_ghost_probing_prompt()
        
        logger.info(f"Video-LLaMA2 Ghost Probing Detector initialized")
        logger.info(f"Config: {config_path}")
        logger.info(f"Model Type: {model_type}")
        logger.info(f"Device: {device}")
    
    def _create_ghost_probing_prompt(self) -> str:
        """åˆ›å»ºé¬¼æ¢å¤´æ£€æµ‹ä¸“ç”¨prompt"""
        prompt = """You are VideoAnalyzerGPT analyzing a traffic video for dangerous driving scenarios, specifically "ghost probing" situations.

Your job is to analyze this video and provide a detailed segment-by-segment analysis in the exact JSON format specified below.

For ghost probing detection, consider:
- Objects that suddenly appear very close to the observer vehicle (< 3 meters)
- Minimal warning time for the driver
- Requires immediate emergency response
- Objects emerge from blind spots (behind parked cars, buildings, etc.)
- Situation is unexpected given the traffic context

IMPORTANT: For ghost probing detection, use "ghost probing" in key_actions field when:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters) 
- Appearance is SUDDEN and from blind spots
- Requires IMMEDIATE emergency braking/swerving
- Movement is COMPLETELY UNPREDICTABLE

For normal traffic situations, use descriptive terms like:
- "normal intersection start"
- "emergency braking due to pedestrian crossing"
- "maintain safe following distance"

Please respond with a JSON array containing segments of approximately 10-second intervals. Each segment should follow this EXACT format:

[
  {
    "video_id": "video_filename",
    "segment_id": "segment_000",
    "Start_Timestamp": "0.0s",
    "End_Timestamp": "10.0s",
    "sentiment": "Positive/Negative/Neutral",
    "scene_theme": "Dramatic/Routine/Dangerous/Safe",
    "characters": "brief description of people in the scene",
    "summary": "comprehensive summary of what happens in this segment",
    "actions": "actions taken by the vehicle and driver responses",
    "key_objects": "numbered list: 1) Position: object description, distance, behavior impact 2) Position: object description, distance, behavior impact",
    "key_actions": "brief description of most important actions (use 'ghost probing' if applicable)",
    "next_action": {
      "speed_control": "rapid deceleration/deceleration/maintain speed/acceleration",
      "direction_control": "keep direction/turn left/turn right",
      "lane_control": "maintain current lane/change left/change right"
    }
  }
]

Analyze the video carefully and provide the complete segment analysis."""
        
        return prompt
    
    def initialize_model(self):
        """åˆå§‹åŒ–Video-LLaMA2æ¨¡å‹"""
        try:
            logger.info("ğŸ”„ Initializing Video-LLaMA2 model...")
            
            # è§£æé…ç½®
            class Args:
                def __init__(self, config_path, model_type, gpu_id):
                    self.cfg_path = config_path
                    self.model_type = model_type
                    self.gpu_id = gpu_id
                    self.options = []
            
            args = Args(self.config_path, self.model_type, self.gpu_id)
            cfg = Config(args)
            
            # è®¾ç½®éšæœºç§å­
            seed = cfg.run_cfg.seed + get_rank()
            torch.manual_seed(seed)
            np.random.seed(seed)
            cudnn.benchmark = False
            cudnn.deterministic = True
            
            # åˆå§‹åŒ–æ¨¡å‹
            model_config = cfg.model_cfg
            model_config.device_8bit = args.gpu_id
            model_cls = registry.get_model_class(model_config.arch)
            self.model = model_cls.from_config(model_config).to(f'cuda:{args.gpu_id}')
            self.model.eval()
            
            # åˆå§‹åŒ–è§†è§‰å¤„ç†å™¨
            vis_processor_cfg = cfg.datasets_cfg.webvid.vis_processor.train
            self.vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)
            
            # åˆå§‹åŒ–Chat
            self.chat = Chat(self.model, self.vis_processor, device=f'cuda:{args.gpu_id}')
            
            logger.info("âœ… Video-LLaMA2 model initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize Video-LLaMA2 model: {e}")
            return False
    
    def analyze_video(self, video_path: str) -> Dict:
        """
        åˆ†æå•ä¸ªè§†é¢‘çš„é¬¼æ¢å¤´æƒ…å†µ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            logger.info(f"ğŸ“¹ Analyzing video: {video_path}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"Video file not found: {video_path}")
            
            # åˆ›å»ºå¯¹è¯çŠ¶æ€
            if self.model_type == 'vicuna':
                chat_state = default_conversation.copy()
            else:
                chat_state = conv_llava_llama_2.copy()
            
            # è®¾ç½®ç³»ç»Ÿprompt
            chat_state.system = self.ghost_probing_prompt
            
            # ä¸Šä¼ è§†é¢‘
            img_list = []
            try:
                # ä½¿ç”¨chat.upload_videoä¸Šä¼ è§†é¢‘
                llm_message = self.chat.upload_video(video_path, chat_state, img_list)
                logger.info(f"âœ… Video uploaded successfully")
            except Exception as e:
                logger.error(f"âŒ Failed to upload video: {e}")
                return {
                    "error": f"Failed to upload video: {e}",
                    "ghost_probing_detected": False,
                    "processing_status": "failed"
                }
            
            # è¯¢é—®é¬¼æ¢å¤´åˆ†æ
            question = "Please analyze this video for ghost probing situations as requested."
            self.chat.ask(question, chat_state)
            
            # è·å–å›ç­”
            try:
                response = self.chat.answer(
                    conv=chat_state,
                    img_list=img_list,
                    num_beams=1,
                    temperature=0.7,
                    max_new_tokens=500,
                    max_length=2000
                )[0]
                
                logger.info(f"âœ… Got response from Video-LLaMA2")
                
                # è§£æå›ç­”
                result = self._parse_response(response, video_name)
                result["video_path"] = video_path
                result["raw_response"] = response
                result["processing_status"] = "success"
                
                return result
                
            except Exception as e:
                logger.error(f"âŒ Failed to get response: {e}")
                return {
                    "error": f"Failed to get response: {e}",
                    "ghost_probing_detected": False,
                    "processing_status": "failed"
                }
        
        except Exception as e:
            logger.error(f"âŒ Error analyzing video {video_path}: {e}")
            return {
                "error": str(e),
                "ghost_probing_detected": False,
                "processing_status": "failed"
            }
    
    def _parse_response(self, response: str, video_id: str) -> Dict:
        """
        è§£æVideo-LLaMA2çš„å›ç­”
        
        Args:
            response: æ¨¡å‹çš„åŸå§‹å›ç­”
            video_id: è§†é¢‘ID
            
        Returns:
            è§£æåçš„ç»“æœå­—å…¸
        """
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSONæ•°ç»„
            import re
            
            # æŸ¥æ‰¾JSONæ•°ç»„æ ¼å¼çš„å“åº”
            json_match = re.search(r'\[.*\]', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    parsed_segments = json.loads(json_str)
                    if isinstance(parsed_segments, list) and len(parsed_segments) > 0:
                        # æ›´æ–°video_id
                        for segment in parsed_segments:
                            segment["video_id"] = video_id
                        
                        # æ£€æµ‹é¬¼æ¢å¤´
                        ghost_detected = False
                        ghost_timestamp = None
                        
                        for segment in parsed_segments:
                            key_actions = segment.get("key_actions", "").lower()
                            if "ghost probing" in key_actions:
                                ghost_detected = True
                                ghost_timestamp = segment.get("Start_Timestamp", "unknown")
                                break
                        
                        return {
                            "segments": parsed_segments,
                            "ghost_probing_detected": ghost_detected,
                            "time_of_occurrence": ghost_timestamp if ghost_detected else "none",
                            "total_segments": len(parsed_segments),
                            "parsing_success": True
                        }
                        
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON parsing error: {e}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONæ•°ç»„ï¼Œå°è¯•æŸ¥æ‰¾å•ä¸ªJSONå¯¹è±¡
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                try:
                    parsed = json.loads(json_str)
                    # è½¬æ¢ä¸ºsegmentæ ¼å¼
                    segment = {
                        "video_id": video_id,
                        "segment_id": "segment_000",
                        "Start_Timestamp": "0.0s",
                        "End_Timestamp": "unknown",
                        "sentiment": parsed.get("sentiment", "Neutral"),
                        "scene_theme": parsed.get("scene_theme", "Routine"),
                        "characters": parsed.get("characters", "Not specified"),
                        "summary": parsed.get("description", response[:200]),
                        "actions": parsed.get("actions", "Not specified"),
                        "key_objects": parsed.get("key_objects", "Not specified"),
                        "key_actions": parsed.get("key_actions", "Not specified"),
                        "next_action": parsed.get("next_action", {
                            "speed_control": "maintain speed",
                            "direction_control": "keep direction",
                            "lane_control": "maintain current lane"
                        })
                    }
                    
                    # æ£€æµ‹é¬¼æ¢å¤´
                    ghost_detected = "ghost probing" in segment["key_actions"].lower()
                    
                    return {
                        "segments": [segment],
                        "ghost_probing_detected": ghost_detected,
                        "time_of_occurrence": segment["Start_Timestamp"] if ghost_detected else "none",
                        "total_segments": 1,
                        "parsing_success": True
                    }
                    
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœæ— æ³•è§£æJSONï¼Œåˆ›å»ºåŸºäºæ–‡æœ¬çš„segment
            response_lower = response.lower()
            
            # æ£€æµ‹é¬¼æ¢å¤´ç›¸å…³å…³é”®è¯
            ghost_keywords = [
                "ghost probing", "sudden appearance", "emergency braking",
                "close distance", "blind spot", "dangerous", "immediate response"
            ]
            
            ghost_detected = any(keyword in response_lower for keyword in ghost_keywords)
            
            segment = {
                "video_id": video_id,
                "segment_id": "segment_000",
                "Start_Timestamp": "0.0s",
                "End_Timestamp": "unknown",
                "sentiment": "Negative" if ghost_detected else "Neutral",
                "scene_theme": "Dangerous" if ghost_detected else "Routine",
                "characters": "Not specified",
                "summary": response[:300] if len(response) > 300 else response,
                "actions": "Emergency response required" if ghost_detected else "Normal driving",
                "key_objects": "Not specified",
                "key_actions": "ghost probing" if ghost_detected else "normal traffic flow",
                "next_action": {
                    "speed_control": "rapid deceleration" if ghost_detected else "maintain speed",
                    "direction_control": "keep direction",
                    "lane_control": "maintain current lane"
                }
            }
            
            return {
                "segments": [segment],
                "ghost_probing_detected": ghost_detected,
                "time_of_occurrence": "0.0s" if ghost_detected else "none",
                "total_segments": 1,
                "parsing_success": False,
                "raw_response": response
            }
            
        except Exception as e:
            logger.error(f"âŒ Error parsing response: {e}")
            
            # åˆ›å»ºé”™è¯¯å¤„ç†çš„segment
            segment = {
                "video_id": video_id,
                "segment_id": "segment_000",
                "Start_Timestamp": "0.0s",
                "End_Timestamp": "unknown",
                "sentiment": "Neutral",
                "scene_theme": "Routine",
                "characters": "Processing error",
                "summary": f"Error parsing response: {str(e)}",
                "actions": "Processing failed",
                "key_objects": "Not available",
                "key_actions": "processing error",
                "next_action": {
                    "speed_control": "maintain speed",
                    "direction_control": "keep direction",
                    "lane_control": "maintain current lane"
                }
            }
            
            return {
                "segments": [segment],
                "ghost_probing_detected": False,
                "time_of_occurrence": "none",
                "total_segments": 1,
                "parsing_success": False,
                "error": str(e)
            }
    
    def batch_analyze(self, video_folder: str, max_videos: int = 100) -> List[Dict]:
        """
        æ‰¹é‡åˆ†æè§†é¢‘
        
        Args:
            video_folder: è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
            max_videos: æœ€å¤§å¤„ç†è§†é¢‘æ•°é‡
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        try:
            # è·å–ç›®æ ‡è§†é¢‘åˆ—è¡¨
            video_folder_path = Path(video_folder)
            target_videos = []
            
            # è·å–images_1_001åˆ°images_5_XXXçš„è§†é¢‘
            for i in range(1, 6):
                pattern = f"images_{i}_*.avi"
                videos = sorted(video_folder_path.glob(pattern))
                target_videos.extend(videos)
                if len(target_videos) >= max_videos:
                    break
            
            target_videos = target_videos[:max_videos]
            
            logger.info(f"ğŸ“Š Starting batch analysis of {len(target_videos)} videos")
            
            results = []
            
            with tqdm(total=len(target_videos), desc="Processing videos") as pbar:
                for i, video_path in enumerate(target_videos):
                    try:
                        video_name = video_path.name
                        logger.info(f"ğŸ¬ Processing {i+1}/{len(target_videos)}: {video_name}")
                        
                        # åˆ†æè§†é¢‘
                        result = self.analyze_video(str(video_path))
                        result["video_id"] = video_name
                        result["video_index"] = i + 1
                        
                        results.append(result)
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        pbar.set_postfix({
                            "current": video_name,
                            "ghost_detected": result.get("ghost_probing_detected", False)
                        })
                        pbar.update(1)
                        
                        # æ¯10ä¸ªè§†é¢‘ä¿å­˜ä¸€æ¬¡ä¸­é—´ç»“æœ
                        if (i + 1) % 10 == 0:
                            self._save_intermediate_results(results, i + 1)
                        
                    except Exception as e:
                        logger.error(f"âŒ Error processing video {video_path}: {e}")
                        results.append({
                            "video_id": video_path.name,
                            "video_index": i + 1,
                            "error": str(e),
                            "ghost_probing_detected": False,
                            "processing_status": "failed"
                        })
                        pbar.update(1)
            
            logger.info(f"âœ… Batch analysis completed: {len(results)} videos processed")
            return results
            
        except Exception as e:
            logger.error(f"âŒ Batch analysis failed: {e}")
            return []
    
    def _save_intermediate_results(self, results: List[Dict], count: int):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"intermediate_results_{count}_{timestamp}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info(f"ğŸ’¾ Intermediate results saved: {filename}")
        except Exception as e:
            logger.error(f"âŒ Failed to save intermediate results: {e}")
    
    def format_for_comparison(self, results: List[Dict], groundtruth_file: str) -> pd.DataFrame:
        """
        æ ¼å¼åŒ–ç»“æœä»¥ä¾¿ä¸ground truthæ¯”è¾ƒ
        
        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            groundtruth_file: Ground truthæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ ¼å¼åŒ–çš„DataFrame
        """
        try:
            # åŠ è½½ground truth
            gt_df = pd.read_csv(groundtruth_file, sep='\t')
            gt_dict = dict(zip(gt_df['video_id'], gt_df['ground_truth_label']))
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for result in results:
                video_id = result.get("video_id", "unknown")
                
                # æ ¼å¼åŒ–é¢„æµ‹æ ‡ç­¾
                if result.get("ghost_probing_detected", False):
                    time_str = result.get("time_of_occurrence", "unknown")
                    if time_str != "none" and time_str != "unknown":
                        predicted_label = f"{time_str}: ghost probing"
                    else:
                        predicted_label = "ghost probing"
                else:
                    predicted_label = "none"
                
                # è·å–ground truth
                ground_truth = gt_dict.get(video_id, "unknown")
                
                formatted_results.append({
                    "video_id": video_id,
                    "predicted_label": predicted_label,
                    "ground_truth_label": ground_truth,
                    "processing_status": result.get("processing_status", "unknown"),
                    "danger_level": result.get("danger_level", 0),
                    "object_type": result.get("object_type", "none"),
                    "description": result.get("description", ""),
                    "raw_response": result.get("raw_response", "")
                })
            
            return pd.DataFrame(formatted_results)
            
        except Exception as e:
            logger.error(f"âŒ Error formatting results: {e}")
            return pd.DataFrame()
    
    def calculate_metrics(self, df: pd.DataFrame) -> Dict:
        """
        è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        
        Args:
            df: åŒ…å«é¢„æµ‹å’Œground truthçš„DataFrame
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        try:
            # ç»Ÿè®¡å„ç§æƒ…å†µ
            tp = 0  # True Positive
            fp = 0  # False Positive
            tn = 0  # True Negative
            fn = 0  # False Negative
            
            successful_results = df[df['processing_status'] == 'success']
            
            for _, row in successful_results.iterrows():
                predicted = row['predicted_label']
                ground_truth = row['ground_truth_label']
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºé¬¼æ¢å¤´
                predicted_ghost = 'ghost probing' in predicted.lower() if predicted != 'none' else False
                ground_truth_ghost = 'ghost probing' in ground_truth.lower() if ground_truth != 'none' else False
                
                if predicted_ghost and ground_truth_ghost:
                    tp += 1
                elif predicted_ghost and not ground_truth_ghost:
                    fp += 1
                elif not predicted_ghost and ground_truth_ghost:
                    fn += 1
                else:
                    tn += 1
            
            # è®¡ç®—æŒ‡æ ‡
            precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            recall = tp / (tp + fn) if (tp + fn) > 0 else 0
            accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0
            f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
            
            metrics = {
                'total_videos': len(df),
                'successful_processing': len(successful_results),
                'failed_processing': len(df) - len(successful_results),
                'true_positive': tp,
                'false_positive': fp,
                'true_negative': tn,
                'false_negative': fn,
                'precision': precision,
                'recall': recall,
                'accuracy': accuracy,
                'f1_score': f1_score,
                'false_positive_rate': fp / (fp + tn) if (fp + tn) > 0 else 0
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ Error calculating metrics: {e}")
            return {}
    
    def save_results(self, results: List[Dict], df: pd.DataFrame, metrics: Dict):
        """
        ä¿å­˜åˆ†æç»“æœ
        
        Args:
            results: åŸå§‹ç»“æœåˆ—è¡¨
            df: æ ¼å¼åŒ–çš„DataFrame
            metrics: æ€§èƒ½æŒ‡æ ‡
        """
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # ä¿å­˜è¯¦ç»†JSONç»“æœ
            json_file = f"video_llama2_ghost_probing_results_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜åˆ†æ®µçº§åˆ«çš„è¯¦ç»†ç»“æœ (ç±»ä¼¼ActionSummaryæ ¼å¼)
            segments_file = f"video_llama2_segments_{timestamp}.json"
            all_segments = []
            
            for result in results:
                if "segments" in result and result["segments"]:
                    all_segments.extend(result["segments"])
            
            with open(segments_file, 'w', encoding='utf-8') as f:
                json.dump(all_segments, f, ensure_ascii=False, indent=2)
            
            # ä¸ºæ¯ä¸ªè§†é¢‘ä¿å­˜å•ç‹¬çš„ActionSummaryæ ¼å¼æ–‡ä»¶
            segments_dir = f"video_llama2_segments_{timestamp}"
            os.makedirs(segments_dir, exist_ok=True)
            
            for result in results:
                if "segments" in result and result["segments"]:
                    video_id = result.get("video_id", "unknown")
                    video_segments_file = os.path.join(segments_dir, f"actionSummary_{video_id}.json")
                    
                    with open(video_segments_file, 'w', encoding='utf-8') as f:
                        json.dump(result["segments"], f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜å¯¹æ¯”CSV
            csv_file = f"video_llama2_ghost_probing_comparison_{timestamp}.csv"
            df.to_csv(csv_file, sep='\t', index=False, encoding='utf-8')
            
            # ä¿å­˜æ€§èƒ½æŒ‡æ ‡
            metrics_file = f"video_llama2_ghost_probing_metrics_{timestamp}.json"
            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(metrics, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ’¾ Results saved:")
            logger.info(f"  - åŸå§‹ç»“æœJSON: {json_file}")
            logger.info(f"  - æ‰€æœ‰åˆ†æ®µJSON: {segments_file}")
            logger.info(f"  - å•è§†é¢‘åˆ†æ®µç›®å½•: {segments_dir}")
            logger.info(f"  - å¯¹æ¯”CSV: {csv_file}")
            logger.info(f"  - æ€§èƒ½æŒ‡æ ‡: {metrics_file}")
            
        except Exception as e:
            logger.error(f"âŒ Error saving results: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Video-LLaMA2 Ghost Probing Detection')
    parser.add_argument('--config', default='eval_configs/video_llama_eval_withaudio.yaml', 
                      help='Video-LLaMA2 config file path')
    parser.add_argument('--model-type', default='llama_v2', choices=['llama_v2', 'vicuna'],
                      help='Model type')
    parser.add_argument('--gpu-id', type=int, default=0, help='GPU ID')
    parser.add_argument('--video-folder', default='../../DADA-2000-videos', 
                      help='Video folder path')
    parser.add_argument('--groundtruth-file', default='../../result/groundtruth_labels.csv',
                      help='Ground truth file path')
    parser.add_argument('--max-videos', type=int, default=100, help='Maximum videos to process')
    parser.add_argument('--single-video', help='Process single video file')
    parser.add_argument('--dry-run', action='store_true', help='Preview videos without processing')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = VideoLLaMA2GhostProbingDetector(
        config_path=args.config,
        model_type=args.model_type,
        gpu_id=args.gpu_id
    )
    
    # åˆå§‹åŒ–æ¨¡å‹
    if not detector.initialize_model():
        logger.error("âŒ Failed to initialize model")
        return
    
    if args.dry_run:
        logger.info("ğŸ” Dry run mode - previewing videos")
        video_folder_path = Path(args.video_folder)
        target_videos = []
        for i in range(1, 6):
            pattern = f"images_{i}_*.avi"
            videos = sorted(video_folder_path.glob(pattern))
            target_videos.extend(videos)
            if len(target_videos) >= args.max_videos:
                break
        target_videos = target_videos[:args.max_videos]
        
        logger.info(f"Will process {len(target_videos)} videos:")
        for i, video in enumerate(target_videos):
            logger.info(f"  {i+1:3d}. {video.name}")
        return
    
    if args.single_video:
        logger.info(f"ğŸ¬ Processing single video: {args.single_video}")
        result = detector.analyze_video(args.single_video)
        print(json.dumps(result, indent=2, ensure_ascii=False))
        return
    
    # æ‰¹é‡å¤„ç†
    logger.info("ğŸš€ Starting batch processing")
    results = detector.batch_analyze(args.video_folder, args.max_videos)
    
    # æ ¼å¼åŒ–ç»“æœ
    logger.info("ğŸ“Š Formatting results for comparison")
    df = detector.format_for_comparison(results, args.groundtruth_file)
    
    # è®¡ç®—æŒ‡æ ‡
    logger.info("ğŸ“ˆ Calculating performance metrics")
    metrics = detector.calculate_metrics(df)
    
    # ä¿å­˜ç»“æœ
    logger.info("ğŸ’¾ Saving results")
    detector.save_results(results, df, metrics)
    
    # è¾“å‡ºæ€»ç»“
    logger.info("=" * 60)
    logger.info("ğŸ“‹ FINAL RESULTS SUMMARY")
    logger.info("=" * 60)
    logger.info(f"Total videos processed: {metrics.get('total_videos', 0)}")
    logger.info(f"Successful processing: {metrics.get('successful_processing', 0)}")
    logger.info(f"Failed processing: {metrics.get('failed_processing', 0)}")
    logger.info(f"Accuracy: {metrics.get('accuracy', 0):.3f}")
    logger.info(f"Precision: {metrics.get('precision', 0):.3f}")
    logger.info(f"Recall: {metrics.get('recall', 0):.3f}")
    logger.info(f"F1 Score: {metrics.get('f1_score', 0):.3f}")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()