#!/usr/bin/env python3
"""
Submit Video-LLaMA2 Ghost Probing Detection Job to Azure ML
ä½¿ç”¨æ‚¨ç°æœ‰çš„Azure MLç¯å¢ƒæäº¤Video-LLaMA2é¬¼æ¢å¤´æ£€æµ‹ä½œä¸š
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®Azure MLç¯å¢ƒå˜é‡
os.environ["AZURE_SUBSCRIPTION_ID"] = "0d3f39ba-7349-4bd7-8122-649ff18f0a4a"
os.environ["AZURE_RESOURCE_GROUP"] = "video-llama2-ghost-probing-rg"
os.environ["AZURE_WORKSPACE_NAME"] = "video-llama2-ghost-probing-ws"

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class VideoLLaMA2JobSubmitter:
    def __init__(self):
        self.subscription_id = "0d3f39ba-7349-4bd7-8122-649ff18f0a4a"
        self.resource_group = "video-llama2-ghost-probing-rg"
        self.workspace_name = "video-llama2-ghost-probing-ws"
        self.compute_name = "gpu-cluster-a100"
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        logger.info(f"ğŸš€ Video-LLaMA2 Ghost Probing Job Submitter")
        logger.info(f"   è®¢é˜…ID: {self.subscription_id}")
        logger.info(f"   èµ„æºç»„: {self.resource_group}")
        logger.info(f"   å·¥ä½œåŒº: {self.workspace_name}")
    
    def authenticate_azure_ml(self):
        """è®¤è¯Azure ML"""
        try:
            from azure.identity import DefaultAzureCredential
            from azure.ai.ml import MLClient
            
            credential = DefaultAzureCredential()
            ml_client = MLClient(
                credential=credential,
                subscription_id=self.subscription_id,
                resource_group_name=self.resource_group,
                workspace_name=self.workspace_name
            )
            
            # æµ‹è¯•è¿æ¥
            workspace = ml_client.workspaces.get(self.workspace_name)
            logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°Azure MLå·¥ä½œåŒº: {workspace.name}")
            
            return ml_client
            
        except Exception as e:
            logger.error(f"âŒ Azure MLè®¤è¯å¤±è´¥: {e}")
            return None
    
    def check_prerequisites(self):
        """æ£€æŸ¥å…ˆå†³æ¡ä»¶"""
        logger.info("ğŸ” æ£€æŸ¥å…ˆå†³æ¡ä»¶...")
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = [
            "video_llama2_ghost_probing_detector.py",
            "video_llama2_environment.yml",
            "azure_ml_videollama2_ghost_probing_job.yml",
            "eval_configs/video_llama_eval_withaudio.yaml"
        ]
        
        missing_files = []
        for file_path in required_files:
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
            return False
        
        logger.info("âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶å·²æ‰¾åˆ°")
        return True
    
    def upload_data_if_needed(self, ml_client):
        """å¦‚æœéœ€è¦ï¼Œä¸Šä¼ æ•°æ®"""
        logger.info("ğŸ“¤ æ£€æŸ¥æ•°æ®æ˜¯å¦éœ€è¦ä¸Šä¼ ...")
        
        try:
            from azure.ai.ml.entities import Data
            from azure.ai.ml.constants import AssetTypes
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è§†é¢‘æ•°æ®
            video_folder = Path("../../DADA-2000-videos")
            if video_folder.exists():
                logger.info("ğŸ“¹ æœ¬åœ°æ‰¾åˆ°DADA-2000è§†é¢‘æ•°æ®")
                
                # æ£€æŸ¥Azure MLä¸­æ˜¯å¦å·²å­˜åœ¨æ•°æ®
                try:
                    existing_data = ml_client.data.get("dada-2000-videos", version="latest")
                    logger.info(f"âœ… Azure MLä¸­å·²å­˜åœ¨è§†é¢‘æ•°æ®: {existing_data.name}")
                except:
                    logger.info("ğŸ“¤ ä¸Šä¼ è§†é¢‘æ•°æ®åˆ°Azure ML...")
                    video_data = Data(
                        name="dada-2000-videos",
                        version="1",
                        description="DADA-2000 video dataset for ghost probing detection",
                        type=AssetTypes.URI_FOLDER,
                        path=str(video_folder)
                    )
                    ml_client.data.create_or_update(video_data)
                    logger.info("âœ… è§†é¢‘æ•°æ®ä¸Šä¼ å®Œæˆ")
            
            # æ£€æŸ¥ground truthæ–‡ä»¶
            gt_file = Path("../../result/groundtruth_labels.csv")
            if gt_file.exists():
                logger.info("ğŸ“Š æœ¬åœ°æ‰¾åˆ°ground truthæ–‡ä»¶")
                
                try:
                    existing_gt = ml_client.data.get("groundtruth-labels", version="latest")
                    logger.info(f"âœ… Azure MLä¸­å·²å­˜åœ¨ground truthæ•°æ®: {existing_gt.name}")
                except:
                    logger.info("ğŸ“¤ ä¸Šä¼ ground truthæ•°æ®åˆ°Azure ML...")
                    gt_data = Data(
                        name="groundtruth-labels",
                        version="1",
                        description="Ground truth labels for ghost probing detection",
                        type=AssetTypes.URI_FILE,
                        path=str(gt_file)
                    )
                    ml_client.data.create_or_update(gt_data)
                    logger.info("âœ… Ground truthæ•°æ®ä¸Šä¼ å®Œæˆ")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ä¸Šä¼ å¤±è´¥: {e}")
            return False
    
    def create_environment(self, ml_client):
        """åˆ›å»ºæˆ–æ›´æ–°ç¯å¢ƒ"""
        logger.info("ğŸ åˆ›å»ºVideo-LLaMA2ç¯å¢ƒ...")
        
        try:
            from azure.ai.ml.entities import Environment
            
            environment = Environment(
                name=f"video-llama2-ghost-probing-{self.timestamp}",
                description="Video-LLaMA2 environment for ghost probing detection",
                conda_file="video_llama2_environment.yml",
                image="mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu20.04:latest"
            )
            
            environment = ml_client.environments.create_or_update(environment)
            logger.info(f"âœ… ç¯å¢ƒåˆ›å»ºå®Œæˆ: {environment.name}")
            
            return environment
            
        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
            return None
    
    def submit_job(self, ml_client, environment):
        """æäº¤Video-LLaMA2ä½œä¸š"""
        logger.info("ğŸš€ æäº¤Video-LLaMA2 Ghost Probingæ£€æµ‹ä½œä¸š...")
        
        try:
            from azure.ai.ml import command
            
            # åˆ›å»ºä½œä¸š
            job = command(
                name=f"video-llama2-ghost-probing-{self.timestamp}",
                display_name=f"Video-LLaMA2 Ghost Probing Detection - {self.timestamp}",
                description="Video-LLaMA2 model for ghost probing detection on 100 DADA videos",
                code=".",
                command="python video_llama2_ghost_probing_detector.py --config eval_configs/video_llama_eval_withaudio.yaml --model-type llama_v2 --gpu-id 0 --video-folder ./DADA-2000-videos --groundtruth-file ./result/groundtruth_labels.csv --max-videos 100",
                environment=environment,
                compute=self.compute_name,
                experiment_name="video_llama2_ghost_probing",
                tags={
                    "model": "video-llama2",
                    "task": "ghost_probing_detection",
                    "dataset": "DADA-2000",
                    "video_count": "100",
                    "framework": "pytorch",
                    "gpu": "a100",
                    "timestamp": self.timestamp
                }
            )
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            job.environment_variables = {
                "PYTHONPATH": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-cluster-a100/code",
                "OMP_NUM_THREADS": "4",
                "CUDA_VISIBLE_DEVICES": "0",
                "TORCH_CUDA_ARCH_LIST": "8.0",
                "FORCE_CUDA": "1"
            }
            
            # æäº¤ä½œä¸š
            submitted_job = ml_client.jobs.create_or_update(job)
            
            logger.info(f"ğŸ‰ ä½œä¸šæäº¤æˆåŠŸ!")
            logger.info(f"   ä½œä¸šåç§°: {submitted_job.name}")
            logger.info(f"   ä½œä¸šID: {submitted_job.id}")
            logger.info(f"   ä½œä¸šçŠ¶æ€: {submitted_job.status}")
            logger.info(f"   Studioé“¾æ¥: {submitted_job.studio_url}")
            
            # ä¿å­˜ä½œä¸šä¿¡æ¯
            job_info = {
                "job_name": submitted_job.name,
                "job_id": submitted_job.id,
                "status": submitted_job.status,
                "studio_url": submitted_job.studio_url,
                "timestamp": self.timestamp,
                "model": "video-llama2",
                "task": "ghost_probing_detection",
                "submission_time": datetime.now().isoformat()
            }
            
            job_info_file = f"video_llama2_job_info_{self.timestamp}.json"
            with open(job_info_file, "w") as f:
                json.dump(job_info, f, indent=2)
            
            logger.info(f"ğŸ“„ ä½œä¸šä¿¡æ¯å·²ä¿å­˜: {job_info_file}")
            
            return submitted_job
            
        except Exception as e:
            logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
            return None
    
    def monitor_job(self, ml_client, job_name):
        """ç›‘æ§ä½œä¸šçŠ¶æ€"""
        logger.info(f"ğŸ‘ï¸ å¼€å§‹ç›‘æ§ä½œä¸š: {job_name}")
        
        try:
            import time
            
            while True:
                job = ml_client.jobs.get(job_name)
                status = job.status
                
                logger.info(f"ğŸ“Š ä½œä¸šçŠ¶æ€: {status}")
                
                if status in ["Completed", "Failed", "Canceled"]:
                    if status == "Completed":
                        logger.info("ğŸ‰ ä½œä¸šæˆåŠŸå®Œæˆ!")
                        self.download_results(ml_client, job_name)
                    else:
                        logger.error(f"âŒ ä½œä¸šç»“æŸ: {status}")
                    break
                
                # ç­‰å¾…2åˆ†é’Ÿåå†æ£€æŸ¥
                time.sleep(120)
                
        except KeyboardInterrupt:
            logger.info("â¹ï¸ ç›‘æ§å·²ä¸­æ–­")
        except Exception as e:
            logger.error(f"âŒ ç›‘æ§å¤±è´¥: {e}")
    
    def download_results(self, ml_client, job_name):
        """ä¸‹è½½ä½œä¸šç»“æœ"""
        logger.info("ğŸ“¥ ä¸‹è½½ä½œä¸šç»“æœ...")
        
        try:
            output_dir = f"./video_llama2_outputs/{job_name}"
            os.makedirs(output_dir, exist_ok=True)
            
            ml_client.jobs.download(
                name=job_name,
                download_path=output_dir
            )
            
            logger.info(f"âœ… ç»“æœå·²ä¸‹è½½åˆ°: {output_dir}")
            
            # æŸ¥æ‰¾å¹¶æ˜¾ç¤ºç»“æœæ–‡ä»¶
            result_files = list(Path(output_dir).rglob("*.json")) + list(Path(output_dir).rglob("*.csv"))
            if result_files:
                logger.info("ğŸ“„ æ‰¾åˆ°ç»“æœæ–‡ä»¶:")
                for file in result_files:
                    logger.info(f"   ğŸ“„ {file.name}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ç»“æœå¤±è´¥: {e}")
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æäº¤æµæ°´çº¿"""
        logger.info("ğŸ”„ å¼€å§‹Video-LLaMA2 Ghost Probingæ£€æµ‹æµæ°´çº¿")
        
        try:
            # 1. æ£€æŸ¥å…ˆå†³æ¡ä»¶
            if not self.check_prerequisites():
                logger.error("âŒ å…ˆå†³æ¡ä»¶æ£€æŸ¥å¤±è´¥")
                return False
            
            # 2. è®¤è¯Azure ML
            ml_client = self.authenticate_azure_ml()
            if ml_client is None:
                logger.error("âŒ Azure MLè®¤è¯å¤±è´¥")
                return False
            
            # 3. ä¸Šä¼ æ•°æ®
            if not self.upload_data_if_needed(ml_client):
                logger.error("âŒ æ•°æ®ä¸Šä¼ å¤±è´¥")
                return False
            
            # 4. åˆ›å»ºç¯å¢ƒ
            environment = self.create_environment(ml_client)
            if environment is None:
                logger.error("âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥")
                return False
            
            # 5. æäº¤ä½œä¸š
            submitted_job = self.submit_job(ml_client, environment)
            if submitted_job is None:
                logger.error("âŒ ä½œä¸šæäº¤å¤±è´¥")
                return False
            
            # 6. ç›‘æ§ä½œä¸š
            self.monitor_job(ml_client, submitted_job.name)
            
            logger.info("âœ… æµæ°´çº¿æ‰§è¡Œå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Submit Video-LLaMA2 Ghost Probing Detection Job')
    parser.add_argument('--check-only', action='store_true', help='ä»…æ£€æŸ¥ç¯å¢ƒä¸æäº¤ä½œä¸š')
    parser.add_argument('--no-monitor', action='store_true', help='æäº¤ä½œä¸šä½†ä¸ç›‘æ§')
    parser.add_argument('--monitor-only', help='ä»…ç›‘æ§æŒ‡å®šä½œä¸š')
    parser.add_argument('--download-only', help='ä»…ä¸‹è½½æŒ‡å®šä½œä¸šç»“æœ')
    
    args = parser.parse_args()
    
    submitter = VideoLLaMA2JobSubmitter()
    
    if args.check_only:
        logger.info("ğŸ” ä»…æ£€æŸ¥ç¯å¢ƒ...")
        prereq_ok = submitter.check_prerequisites()
        ml_client = submitter.authenticate_azure_ml()
        
        if prereq_ok and ml_client:
            logger.info("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥æäº¤ä½œä¸š")
        else:
            logger.error("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        
    elif args.monitor_only:
        logger.info(f"ğŸ‘ï¸ ç›‘æ§ä½œä¸š: {args.monitor_only}")
        ml_client = submitter.authenticate_azure_ml()
        if ml_client:
            submitter.monitor_job(ml_client, args.monitor_only)
        
    elif args.download_only:
        logger.info(f"ğŸ“¥ ä¸‹è½½ä½œä¸šç»“æœ: {args.download_only}")
        ml_client = submitter.authenticate_azure_ml()
        if ml_client:
            submitter.download_results(ml_client, args.download_only)
        
    elif args.no_monitor:
        logger.info("ğŸš€ æäº¤ä½œä¸šä½†ä¸ç›‘æ§...")
        if submitter.check_prerequisites():
            ml_client = submitter.authenticate_azure_ml()
            if ml_client:
                submitter.upload_data_if_needed(ml_client)
                environment = submitter.create_environment(ml_client)
                if environment:
                    submitter.submit_job(ml_client, environment)
    else:
        # è¿è¡Œå®Œæ•´æµæ°´çº¿
        submitter.run_complete_pipeline()


if __name__ == "__main__":
    main()