# Simplified Azure ML Job for Video-LLaMA-2 (without large file uploads)

$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command
display_name: Video-LLaMA-2 Ghost Probing Detection (Simple)
description: Test Video-LLaMA-2 inference with minimal setup
experiment_name: video-llama2-test

# Use V100 cluster
compute: azureml:video-llama2-v100-cluster

# Simple environment
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Inline script (no file uploads)
command: >
  pip install transformers accelerate opencv-python &&
  python -c "
  import torch
  import json
  import cv2
  import numpy as np
  from datetime import datetime
  from pathlib import Path
  
  print('ðŸš€ Video-LLaMA-2 Inference Test Started')
  print(f'CUDA Available: {torch.cuda.is_available()}')
  if torch.cuda.is_available():
      print(f'GPU Count: {torch.cuda.device_count()}')
      for i in range(torch.cuda.device_count()):
          print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
  
  # Simulate inference results
  results = {
      'test_status': 'success',
      'cuda_available': torch.cuda.is_available(),
      'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0,
      'timestamp': datetime.now().isoformat(),
      'message': 'Video-LLaMA-2 environment test completed successfully'
  }
  
  # Save results
  with open('test_results.json', 'w') as f:
      json.dump(results, f, indent=2)
  
  print('âœ… Test completed successfully')
  print(json.dumps(results, indent=2))
  "

# Outputs
outputs:
  results:
    type: uri_folder

# Resource limits
limits:
  timeout: 1800  # 30 minutes

# Tags
tags:
  test: video-llama2-environment
  compute: v100-cluster