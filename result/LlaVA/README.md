# LLaVA-NeXT é¬¼æ¢å¤´è§†é¢‘æ‰“æ ‡ç³»ç»Ÿ

åŸºäºLLaVA-Video-7B-Qwen2æ¨¡å‹çš„é¬¼æ¢å¤´æ£€æµ‹ä¸è§†é¢‘æ‰“æ ‡ç³»ç»Ÿï¼Œä½¿ç”¨ä¸GPT-4.1ç›¸åŒçš„å¹³è¡¡æç¤ºè¯ç¡®ä¿è¯„ä¼°ä¸€è‡´æ€§ã€‚

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åˆ©ç”¨LLaVA-NeXTçš„å¤šæ¨¡æ€è§†é¢‘ç†è§£èƒ½åŠ›ï¼Œå¯¹DADA-100è§†é¢‘æ•°æ®é›†è¿›è¡Œé¬¼æ¢å¤´ï¼ˆGhost Probingï¼‰æ£€æµ‹å’Œæ‰“æ ‡ã€‚ç³»ç»Ÿè®¾è®¡éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

- **å®Œå…¨å¼€æº**ï¼šåŸºäºLLaVA-NeXTå¼€æºæ¨¡å‹ï¼Œå¯æœ¬åœ°éƒ¨ç½²
- **è¯„ä¼°ä¸€è‡´æ€§**ï¼šä½¿ç”¨ä¸GPT-4.1ç›¸åŒçš„å¹³è¡¡æç¤ºè¯
- **ç”Ÿäº§å°±ç»ª**ï¼šåŒ…å«å®Œæ•´çš„æ‰¹å¤„ç†ã€è¯„ä¼°å’Œéƒ¨ç½²ç³»ç»Ÿ
- **Azure MLé›†æˆ**ï¼šæ”¯æŒåœ¨Azure ML A100é›†ç¾¤ä¸Šè¿è¡Œ

## ğŸ“ é¡¹ç›®ç»“æ„

```
LlaVA/
â”œâ”€â”€ llava_ghost_probing_detector.py      # æ ¸å¿ƒæ£€æµ‹å™¨
â”œâ”€â”€ llava_ghost_probing_batch.py         # æ‰¹å¤„ç†è„šæœ¬
â”œâ”€â”€ llava_ghost_probing_evaluation.py    # è¯„ä¼°è„šæœ¬
â”œâ”€â”€ azure_ml_llava_ghost_probing.yml     # Azure MLé…ç½®
â”œâ”€â”€ submit_azure_llava_job.py            # Azure MLä½œä¸šæäº¤
â”œâ”€â”€ test_single_video.py                 # å•è§†é¢‘æµ‹è¯•
â”œâ”€â”€ requirements.txt                     # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ README.md                            # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ LLaVA-NeXT/                          # LLaVA-NeXTæºç 
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…PyTorch (CUDA 11.7ç‰ˆæœ¬)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117

# å®‰è£…è§†é¢‘å¤„ç†åº“
pip install decord
```

### 2. æµ‹è¯•å•ä¸ªè§†é¢‘

```bash
# æµ‹è¯•æ¨¡å‹åŠ è½½
python test_single_video.py --model-test-only

# æµ‹è¯•å•ä¸ªè§†é¢‘
python test_single_video.py --video /path/to/video.avi --output result.json

# è¿è¡Œç»¼åˆæµ‹è¯•
python test_single_video.py --comprehensive
```

### 3. æ‰¹é‡å¤„ç†

```bash
# æœ¬åœ°æ‰¹å¤„ç†
python llava_ghost_probing_batch.py \
    --video-folder /path/to/DADA-100-videos \
    --output-folder ./results \
    --limit 10 \
    --save-interval 5

# Azure MLæ‰¹å¤„ç†
python submit_azure_llava_job.py --action submit --limit 100
```

### 4. ç»“æœè¯„ä¼°

```bash
# è¯„ä¼°ä¸ground truthå¯¹æ¯”
python llava_ghost_probing_evaluation.py \
    --llava-results ./results/llava_ghost_probing_final_TIMESTAMP.json \
    --groundtruth-file /path/to/groundtruth_labels.csv \
    --output-folder ./evaluation_results
```

## ğŸ“Š ç³»ç»Ÿç‰¹æ€§

### æ ¸å¿ƒæ£€æµ‹åŠŸèƒ½

- **è§†é¢‘ç†è§£**ï¼šåŸºäºLLaVA-Video-7B-Qwen2çš„å¤šå¸§è§†é¢‘åˆ†æ
- **ä¸‰çº§åˆ†ç±»**ï¼šHIGH-CONFIDENCEã€POTENTIALã€NORMALé¬¼æ¢å¤´æ£€æµ‹
- **ç¯å¢ƒæ„ŸçŸ¥**ï¼šåŒºåˆ†é«˜é€Ÿå…¬è·¯ã€äº¤å‰å£ã€åœè½¦åœºç­‰ä¸åŒåœºæ™¯
- **è·ç¦»é˜ˆå€¼**ï¼š<3ç±³é«˜ä¿¡åº¦ï¼Œ3-5ç±³æ½œåœ¨é¬¼æ¢å¤´

### æŠ€æœ¯æ¶æ„

- **æ¨¡å‹**ï¼šLLaVA-Video-7B-Qwen2
- **æ¡†æ¶**ï¼šLLaVA-NeXT + PyTorch
- **è§†é¢‘å¤„ç†**ï¼šDecord + OpenCV
- **æ‰¹å¤„ç†**ï¼šæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé”™è¯¯æ¢å¤
- **è¯„ä¼°**ï¼šå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°

### Azure MLé›†æˆ

- **è®¡ç®—é›†ç¾¤**ï¼šllava-a100-low-priority (A100 GPU)
- **ç¯å¢ƒ**ï¼šAzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10
- **å­˜å‚¨**ï¼šAzure Blob Storageæ•°æ®é›†
- **ç›‘æ§**ï¼šAzure ML Studioå®æ—¶ç›‘æ§

## ğŸ­ æç¤ºè¯è®¾è®¡

ä½¿ç”¨ä¸GPT-4.1å®Œå…¨ç›¸åŒçš„å¹³è¡¡æç¤ºè¯ï¼š

```python
# ä¸‰çº§åˆ†ç±»ç³»ç»Ÿ
1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing")
   - <3ç±³æè¿‘è·ç¦»çªç„¶å‡ºç°
   - æ¥è‡ªç›²åŒº(åœè½¦ä½ã€å»ºç­‘ç‰©ã€è§’è½)
   - é«˜é£é™©ç¯å¢ƒ(é«˜é€Ÿå…¬è·¯ã€ä¹¡æ‘é“è·¯)

2. POTENTIAL Ghost Probing (use "potential ghost probing")  
   - 3-5ç±³ä¸­ç­‰è·ç¦»çªç„¶å‡ºç°
   - åœ¨å­˜åœ¨ä¸€å®šä¸å¯é¢„æµ‹æ€§çš„ç¯å¢ƒä¸­

3. NORMAL Traffic (descriptive terms)
   - é¢„æœŸçš„äº¤é€šè¡Œä¸º
   - äº¤å‰å£ã€äººè¡Œæ¨ªé“çš„æ­£å¸¸é€šè¡Œ
```

## ğŸ“ˆ æ€§èƒ½ç›®æ ‡

åŸºäºGPT-4.1 Balancedçš„åŸºå‡†æ€§èƒ½ï¼š

| æŒ‡æ ‡ | GPT-4.1 Balanced | LLaVAç›®æ ‡ |
|------|------------------|-----------|
| F1 Score | 0.712 | â‰¥0.650 |
| Recall | 96.3% | â‰¥90% |
| Precision | 56.5% | â‰¥50% |
| Accuracy | 57.6% | â‰¥55% |

## ğŸ”§ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡

```bash
# CUDAè®¾å¤‡
export CUDA_VISIBLE_DEVICES=0

# Hugging Faceç¼“å­˜
export HF_HOME=/tmp/huggingface
export TRANSFORMERS_CACHE=/tmp/transformers

# Pythonè·¯å¾„
export PYTHONPATH=/path/to/LlaVA:/path/to/LlaVA-NeXT
```

### Azure MLé…ç½®

```yaml
# azure_ml_llava_ghost_probing.yml
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10
inputs:
  video_data:
    path: azureml://datastores/workspaceblobstore/paths/DADA-100-videos/
outputs:
  results:
    path: azureml://datastores/workspaceblobstore/paths/llava-ghost-probing-results/
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å•è§†é¢‘æ£€æµ‹

```python
from llava_ghost_probing_detector import LLaVAGhostProbingDetector

# åˆå§‹åŒ–æ£€æµ‹å™¨
detector = LLaVAGhostProbingDetector()

# åˆ†æè§†é¢‘
result = detector.analyze_video("video.avi", "video_001")

# æå–æ ‡ç­¾
label, confidence = detector.extract_ghost_probing_label(result)
print(f"æ£€æµ‹ç»“æœ: {label} (ç½®ä¿¡åº¦: {confidence})")
```

### æ‰¹é‡å¤„ç†

```python
from llava_ghost_probing_batch import LLaVAGhostProbingBatchProcessor

# åˆ›å»ºæ‰¹å¤„ç†å™¨
processor = LLaVAGhostProbingBatchProcessor(
    video_folder="/path/to/videos",
    output_folder="/path/to/results"
)

# å¼€å§‹æ‰¹å¤„ç†
stats = processor.process_batch(limit=100, save_interval=10)
```

### ç»“æœè¯„ä¼°

```python
from llava_ghost_probing_evaluation import LLaVAGhostProbingEvaluator

# åˆ›å»ºè¯„ä¼°å™¨
evaluator = LLaVAGhostProbingEvaluator()

# è¯„ä¼°ç»“æœ
metrics = evaluator.evaluate_results("results.json")
print(f"F1 Score: {metrics['performance_metrics']['f1_score']}")
```

## ğŸ“Š è¾“å‡ºæ ¼å¼

### æ£€æµ‹ç»“æœJSON

```json
{
  "video_id": "images_1_001",
  "ghost_probing_label": "ghost_probing",
  "confidence": 0.9,
  "llava_analysis": {
    "summary": "è½¦è¾†ä»ç›²åŒºçªç„¶å‡ºç°...",
    "key_actions": "ghost probing",
    "key_objects": "1) å‰æ–¹: çªç„¶å‡ºç°çš„è½¦è¾†, 2ç±³, é«˜æ’å‡»é£é™©",
    "next_action": {
      "speed_control": "rapid deceleration",
      "direction_control": "turn left",
      "lane_control": "change left"
    }
  }
}
```

### è¯„ä¼°æŒ‡æ ‡

```json
{
  "performance_metrics": {
    "accuracy": 0.8750,
    "precision": 0.7500,
    "recall": 0.9000,
    "f1_score": 0.8182
  },
  "confusion_matrix": {
    "true_negatives": 45,
    "false_positives": 10,
    "false_negatives": 5,
    "true_positives": 40
  }
}
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘max_frameså‚æ•°
   detector = LLaVAGhostProbingDetector(max_frames=32)
   ```

2. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```bash
   # æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒHugging Faceè®¿é—®
   export HF_ENDPOINT=https://hf-mirror.com
   ```

3. **è§†é¢‘æ ¼å¼ä¸æ”¯æŒ**
   ```bash
   # è½¬æ¢è§†é¢‘æ ¼å¼
   ffmpeg -i input.mp4 -c:v libx264 output.avi
   ```

### Azure MLé—®é¢˜

1. **è®¡ç®—é›†ç¾¤ä¸å¯ç”¨**
   - æ£€æŸ¥é›†ç¾¤çŠ¶æ€å’Œé…é¢
   - å°è¯•å…¶ä»–å¯ç”¨é›†ç¾¤

2. **ä½œä¸šå¤±è´¥**
   ```bash
   # æ£€æŸ¥ä½œä¸šæ—¥å¿—
   python submit_azure_llava_job.py --action status --job-name JOB_NAME
   ```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. **ä»£ç è§„èŒƒ**ï¼šéµå¾ªPEP 8æ ‡å‡†
2. **æµ‹è¯•è¦æ±‚**ï¼šæ–°åŠŸèƒ½éœ€åŒ…å«å•å…ƒæµ‹è¯•
3. **æ–‡æ¡£æ›´æ–°**ï¼šæ›´æ–°ç›¸å…³æ–‡æ¡£å’ŒREADME
4. **æ€§èƒ½è¯„ä¼°**ï¼šç¡®ä¿ä¸é™ä½ç°æœ‰æ€§èƒ½æŒ‡æ ‡

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºåŸå§‹GPT4Video-cobra-autoé¡¹ç›®è®¸å¯è¯ã€‚LLaVA-NeXTç»„ä»¶éµå¾ªå…¶åŸå§‹Apache 2.0è®¸å¯è¯ã€‚

## ğŸ”— ç›¸å…³é“¾æ¥

- [LLaVA-NeXT GitHub](https://github.com/LLaVA-VL/LLaVA-NeXT)
- [LLaVA-Video Paper](http://arxiv.org/abs/2410.02713)
- [Azure ML Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/)
- [DADA-2000 Dataset](https://github.com/JWFangit/LOTVS-DADA)

## ğŸ“§ è”ç³»ä¿¡æ¯

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- é¡¹ç›®Issueï¼šGitHub Issues
- æŠ€æœ¯è®¨è®ºï¼šé¡¹ç›®Wiki
- æ¨¡å‹é—®é¢˜ï¼šLLaVA-NeXTå®˜æ–¹repo