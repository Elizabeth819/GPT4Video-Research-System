#!/usr/bin/env python3
"""
Azure ML LLaVA Ghost Probing Job Submission Script
æäº¤LLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸šåˆ°Azure ML
æ–‡ä»¶è·¯å¾„: /Users/wanmeng/repository/GPT4Video-cobra-auto/result/LlaVA/submit_azure_llava_job.py
"""

import os
import sys
import logging
import argparse
from datetime import datetime
from pathlib import Path

try:
    from azure.ai.ml import MLClient, command
    from azure.ai.ml.entities import Environment
    from azure.identity import DefaultAzureCredential
    from azure.core.exceptions import HttpResponseError
except ImportError:
    print("âŒ Azure ML SDKæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install azure-ai-ml")
    sys.exit(1)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AzureLLaVAJobSubmitter:
    """Azure ML LLaVAä½œä¸šæäº¤å™¨"""
    
    def __init__(self, 
                 subscription_id: str = "0d3f39ba-7349-4bd7-8122-649ff18f0a4a",
                 resource_group: str = "llava-resourcegroup", 
                 workspace_name: str = "llava-workspace"):
        """
        åˆå§‹åŒ–Azure MLå®¢æˆ·ç«¯
        
        Args:
            subscription_id: Azureè®¢é˜…ID
            resource_group: èµ„æºç»„åç§°
            workspace_name: å·¥ä½œåŒºåç§°
        """
        self.subscription_id = subscription_id
        self.resource_group = resource_group
        self.workspace_name = workspace_name
        
        try:
            # åˆå§‹åŒ–MLå®¢æˆ·ç«¯
            credential = DefaultAzureCredential()
            self.ml_client = MLClient(
                credential=credential,
                subscription_id=subscription_id,
                resource_group_name=resource_group,
                workspace_name=workspace_name
            )
            
            logger.info(f"âœ… Azure MLå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"ğŸ“‹ è®¢é˜…: {subscription_id}")
            logger.info(f"ğŸ“‹ èµ„æºç»„: {resource_group}")
            logger.info(f"ğŸ“‹ å·¥ä½œåŒº: {workspace_name}")
            
        except Exception as e:
            logger.error(f"âŒ Azure MLå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def submit_llava_ghost_probing_job(self, 
                                      job_name: str = None,
                                      compute_name: str = "llava-a100-low-priority",
                                      environment_name: str = "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10",
                                      video_limit: int = 100,
                                      save_interval: int = 5,
                                      dry_run: bool = False) -> str:
        """
        æäº¤LLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š
        
        Args:
            job_name: ä½œä¸šåç§°
            compute_name: è®¡ç®—é›†ç¾¤åç§°
            environment_name: ç¯å¢ƒåç§°
            video_limit: å¤„ç†è§†é¢‘æ•°é‡é™åˆ¶
            save_interval: ä¿å­˜é—´éš”
            dry_run: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
            
        Returns:
            ä½œä¸šID
        """
        try:
            # ç”Ÿæˆä½œä¸šåç§°
            if job_name is None:
                timestamp = datetime.now().strftime('%m%d_%H%M%S')
                job_name = f"llava-ghost-probing-{timestamp}"
            
            logger.info(f"ğŸš€ å‡†å¤‡æäº¤LLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š: {job_name}")
            
            # åˆ›å»ºä½œä¸šå‘½ä»¤ - ä½¿ç”¨å¹²å‡€çš„requirementsæ–‡ä»¶
            command_str = f"""pip install -r requirements_clean.txt && python llava_ghost_probing_batch.py --video-folder ./inputs/video_data --output-folder ./outputs/llava_ghost_probing_results --limit {video_limit} --save-interval {save_interval}"""
            
            # åˆ›å»ºå‘½ä»¤ä½œä¸š
            job = command(
                display_name=job_name,
                description=f"LLaVA-NeXT Ghost Probing Detection on {video_limit} DADA Videos",
                command=command_str,
                environment=f"azureml:{environment_name}",
                compute=compute_name,
                code=".",  # åŒ…å«å½“å‰ç›®å½•çš„æ‰€æœ‰æ–‡ä»¶
                inputs={
                    "video_data": {
                        "type": "uri_folder",
                        "path": "azureml:DADA-100-videos:20250721_150147",
                        "mode": "ro_mount"
                    }
                },
                outputs={
                    "results": {
                        "type": "uri_folder", 
                        "path": f"azureml://datastores/workspaceblobstore/paths/llava-ghost-probing-results/{job_name}/",
                        "mode": "rw_mount"
                    }
                },
                environment_variables={
                    "CUDA_VISIBLE_DEVICES": "0",
                    "PYTHONPATH": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/llava-a100-low-priority/code/Users/wanmeng/repository/GPT4Video-cobra-auto/result/LlaVA:/mnt/batch/tasks/shared/LS_root/mounts/clusters/llava-a100-low-priority/code/Users/wanmeng/repository/GPT4Video-cobra-auto/result/LlaVA/LLaVA-NeXT",
                    "HF_HOME": "/tmp/huggingface",
                    "TORCH_HOME": "/tmp/torch",
                    "TRANSFORMERS_CACHE": "/tmp/transformers"
                },
                tags={
                    "model": "LLaVA-Video-7B-Qwen2",
                    "task": "ghost_probing_detection", 
                    "dataset": "DADA-100-videos",
                    "prompt": "balanced_gpt41_compatible"
                },
                experiment_name="llava-ghost-probing-experiment"
            )
            
            if dry_run:
                logger.info("ğŸ§ª Dry Runæ¨¡å¼ - ä½œä¸šé…ç½®éªŒè¯")
                logger.info("âœ… ä½œä¸šé…ç½®éªŒè¯é€šè¿‡")
                logger.info(f"ğŸ“ ä½œä¸šåç§°: {job_name}")
                logger.info(f"ğŸ–¥ï¸  è®¡ç®—é›†ç¾¤: {compute_name}")
                logger.info(f"ğŸ¬ è§†é¢‘æ•°é‡: {video_limit}")
                logger.info("ğŸ’¡ ä½¿ç”¨ --no-dry-run æäº¤çœŸå®ä½œä¸š")
                return f"dry-run-{job_name}"
            
            # æäº¤ä½œä¸š
            logger.info("ğŸ“¤ æ­£åœ¨æäº¤ä½œä¸šåˆ°Azure ML...")
            submitted_job = self.ml_client.jobs.create_or_update(job)
            
            logger.info(f"âœ… ä½œä¸šæäº¤æˆåŠŸ!")
            logger.info(f"ğŸ†” ä½œä¸šID: {submitted_job.name}")
            logger.info(f"ğŸ“Š ä½œä¸šçŠ¶æ€: {submitted_job.status}")
            logger.info(f"ğŸ”— Azure ML Studioé“¾æ¥: {submitted_job.studio_url}")
            
            # æä¾›åç»­ç›‘æ§å»ºè®®
            logger.info("\nğŸ’¡ åç»­æ“ä½œå»ºè®®:")
            logger.info(f"   æ£€æŸ¥çŠ¶æ€: python {__file__} --action status --job-name {submitted_job.name}")
            logger.info(f"   ä¸‹è½½ç»“æœ: python {__file__} --action download --job-name {submitted_job.name}")
            
            return submitted_job.name
            
        except HttpResponseError as e:
            logger.error(f"âŒ Azure ML APIé”™è¯¯: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
            raise
    
    def check_job_status(self, job_name: str):
        """æ£€æŸ¥ä½œä¸šçŠ¶æ€"""
        try:
            job = self.ml_client.jobs.get(job_name)
            
            print(f"\nğŸ“Š ä½œä¸šçŠ¶æ€æŠ¥å‘Š: {job_name}")
            print("="*50)
            print(f"çŠ¶æ€: {job.status}")
            print(f"å¼€å§‹æ—¶é—´: {job.creation_context.created_at}")
            print(f"Studioé“¾æ¥: {job.studio_url}")
            
            if job.status == "Completed":
                print("âœ… ä½œä¸šå·²å®Œæˆ!")
            elif job.status == "Failed":
                print("âŒ ä½œä¸šå¤±è´¥!")
                if hasattr(job, 'error'):
                    print(f"é”™è¯¯ä¿¡æ¯: {job.error}")
            elif job.status in ["Running", "Preparing", "Starting"]:
                print("ğŸ”„ ä½œä¸šæ­£åœ¨è¿è¡Œä¸­...")
            else:
                print(f"ğŸ“‹ å½“å‰çŠ¶æ€: {job.status}")
            
            print("="*50)
            
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥ä½œä¸šçŠ¶æ€å¤±è´¥: {e}")
    
    def list_recent_jobs(self, limit: int = 10):
        """åˆ—å‡ºæœ€è¿‘çš„ä½œä¸š"""
        try:
            jobs = list(self.ml_client.jobs.list(max_results=limit))
            
            print(f"\nğŸ“‹ æœ€è¿‘{len(jobs)}ä¸ªä½œä¸š:")
            print("="*80)
            print(f"{'ä½œä¸šåç§°':<30} {'çŠ¶æ€':<12} {'åˆ›å»ºæ—¶é—´':<20}")
            print("-"*80)
            
            for job in jobs:
                created_at = job.creation_context.created_at.strftime('%Y-%m-%d %H:%M:%S')
                print(f"{job.name:<30} {job.status:<12} {created_at:<20}")
            
            print("="*80)
            
        except Exception as e:
            logger.error(f"âŒ åˆ—å‡ºä½œä¸šå¤±è´¥: {e}")
    
    def download_job_outputs(self, job_name: str, local_path: str = "./downloaded_results"):
        """ä¸‹è½½ä½œä¸šè¾“å‡º"""
        try:
            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ä½œä¸šè¾“å‡º: {job_name}")
            
            # åˆ›å»ºæœ¬åœ°ç›®å½•
            local_path = Path(local_path)
            local_path.mkdir(parents=True, exist_ok=True)
            
            # ä¸‹è½½è¾“å‡º
            self.ml_client.jobs.download(
                name=job_name,
                download_path=local_path,
                output_name="results"
            )
            
            logger.info(f"âœ… ä½œä¸šè¾“å‡ºä¸‹è½½å®Œæˆ: {local_path}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ä½œä¸šè¾“å‡ºå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Azure ML LLaVAä½œä¸šæäº¤å·¥å…·')
    parser.add_argument('--action', choices=['submit', 'status', 'list', 'download'], 
                       default='submit', help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--job-name', type=str, help='ä½œä¸šåç§°')
    parser.add_argument('--compute', type=str, default='llava-a100-low-priority',
                       help='è®¡ç®—é›†ç¾¤åç§°')
    parser.add_argument('--limit', type=int, default=100,
                       help='å¤„ç†è§†é¢‘æ•°é‡é™åˆ¶')
    parser.add_argument('--save-interval', type=int, default=5,
                       help='ä¿å­˜é—´éš”')
    parser.add_argument('--download-path', type=str, default='./downloaded_results',
                       help='ä¸‹è½½è·¯å¾„')
    parser.add_argument('--dry-run', action='store_true', default=True,
                       help='æµ‹è¯•æ¨¡å¼ï¼ŒéªŒè¯é…ç½®ä½†ä¸æäº¤ä½œä¸š')
    parser.add_argument('--no-dry-run', action='store_true',
                       help='å…³é—­æµ‹è¯•æ¨¡å¼ï¼Œæäº¤çœŸå®ä½œä¸š')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæäº¤å™¨
        submitter = AzureLLaVAJobSubmitter()
        
        if args.action == 'submit':
            # ç¡®å®šæ˜¯å¦ä¸ºdry runæ¨¡å¼
            is_dry_run = args.dry_run and not args.no_dry_run
            
            # æäº¤ä½œä¸š
            job_id = submitter.submit_llava_ghost_probing_job(
                job_name=args.job_name,
                compute_name=args.compute,
                video_limit=args.limit,
                save_interval=args.save_interval,
                dry_run=is_dry_run
            )
            print(f"\nâœ… ä½œä¸šæäº¤æˆåŠŸ: {job_id}")
            print(f"ğŸ’¡ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥çŠ¶æ€: python {__file__} --action status --job-name {job_id}")
            
        elif args.action == 'status':
            # æ£€æŸ¥ä½œä¸šçŠ¶æ€
            if not args.job_name:
                print("âŒ è¯·æŒ‡å®šä½œä¸šåç§°: --job-name JOB_NAME")
                sys.exit(1)
            submitter.check_job_status(args.job_name)
            
        elif args.action == 'list':
            # åˆ—å‡ºæœ€è¿‘ä½œä¸š
            submitter.list_recent_jobs()
            
        elif args.action == 'download':
            # ä¸‹è½½ä½œä¸šè¾“å‡º
            if not args.job_name:
                print("âŒ è¯·æŒ‡å®šä½œä¸šåç§°: --job-name JOB_NAME")
                sys.exit(1)
            submitter.download_job_outputs(args.job_name, args.download_path)
            
    except Exception as e:
        logger.error(f"âŒ æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()