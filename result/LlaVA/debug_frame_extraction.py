#!/usr/bin/env python3
"""
è°ƒè¯•ç‰ˆè§†é¢‘å¸§æå– - è¯¦ç»†æ—¥å¿—
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
from PIL import Image
import logging
import torch
from typing import List, Dict, Optional, Tuple
import numpy as np
import time

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s.%(msecs)03d - %(levelname)s - %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

def extract_frames_with_detailed_logging(video_path: str, num_frames: int = 8) -> List[Image.Image]:
    """ä½¿ç”¨decordæå–è§†é¢‘å¸§ - è¯¦ç»†æ—¥å¿—ç‰ˆæœ¬"""
    
    logger.info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {Path(video_path).name}")
    overall_start = time.time()
    
    try:
        import decord
        from decord import VideoReader
        
        # è®¾ç½®decordä½¿ç”¨native bridge
        decord.bridge.set_bridge('native')
        
        # è¯»å–è§†é¢‘
        logger.debug(f"ğŸ“‚ è§†é¢‘è·¯å¾„: {video_path}")
        logger.debug(f"ğŸ“‚ æ–‡ä»¶å­˜åœ¨: {Path(video_path).exists()}")
        logger.debug(f"ğŸ“‚ æ–‡ä»¶å¤§å°: {Path(video_path).stat().st_size / 1024 / 1024:.2f} MB")
        
        video_load_start = time.time()
        video_reader = VideoReader(str(video_path))
        video_load_time = time.time() - video_load_start
        
        total_frames = len(video_reader)
        logger.info(f"ğŸ“Š è§†é¢‘åŠ è½½æ—¶é—´: {video_load_time:.4f}ç§’")
        logger.info(f"ğŸ“Š æ€»å¸§æ•°: {total_frames}")
        
        if total_frames == 0:
            raise ValueError(f"è§†é¢‘æ–‡ä»¶æ²¡æœ‰å¸§: {video_path}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        try:
            fps = video_reader.get_avg_fps()
            duration = total_frames / fps if fps > 0 else 0
            logger.info(f"ğŸ“Š å¸§ç‡: {fps:.2f} fps")
            logger.info(f"ğŸ“Š æ—¶é•¿: {duration:.2f}ç§’")
        except:
            logger.warning("âš ï¸  æ— æ³•è·å–è§†é¢‘å¸§ç‡ä¿¡æ¯")
        
        # å‡åŒ€åˆ†å¸ƒé€‰æ‹©å¸§
        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
        logger.info(f"ğŸ“Š é€‰æ‹©å¸§ç´¢å¼•: {frame_indices.tolist()}")
        
        # æå–å¸§
        frames = []
        extraction_start = time.time()
        
        for i, idx in enumerate(frame_indices):
            frame_start = time.time()
            logger.debug(f"ğŸ” æ­£åœ¨æå–ç¬¬ {i+1}/{num_frames} å¸§ (ç´¢å¼•: {idx})")
            
            # è·å–å¸§
            frame_read_start = time.time()
            frame = video_reader[idx]
            frame_read_time = time.time() - frame_read_start
            
            logger.debug(f"  ğŸ“– å¸§è¯»å–æ—¶é—´: {frame_read_time:.4f}ç§’")
            logger.debug(f"  ğŸ“– å¸§ç±»å‹: {type(frame)}")
            logger.debug(f"  ğŸ“– å¸§shape: {getattr(frame, 'shape', 'N/A')}")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            convert_start = time.time()
            if hasattr(frame, 'asnumpy'):
                frame_array = frame.asnumpy()
                logger.debug(f"  ğŸ”„ ä½¿ç”¨asnumpy()è½¬æ¢")
            elif isinstance(frame, torch.Tensor):
                frame_array = frame.cpu().numpy()
                logger.debug(f"  ğŸ”„ ä½¿ç”¨tensor.cpu().numpy()è½¬æ¢")
            else:
                frame_array = np.array(frame)
                logger.debug(f"  ğŸ”„ ä½¿ç”¨np.array()è½¬æ¢")
            
            convert_time = time.time() - convert_start
            logger.debug(f"  ğŸ”„ æ•°ç»„è½¬æ¢æ—¶é—´: {convert_time:.4f}ç§’")
            logger.debug(f"  ğŸ”„ è½¬æ¢åshape: {frame_array.shape}")
            logger.debug(f"  ğŸ”„ è½¬æ¢ådtype: {frame_array.dtype}")
            
            # è½¬æ¢ä¸ºPIL Image
            pil_start = time.time()
            pil_image = Image.fromarray(frame_array.astype(np.uint8))
            pil_time = time.time() - pil_start
            
            logger.debug(f"  ğŸ–¼ï¸  PILè½¬æ¢æ—¶é—´: {pil_time:.4f}ç§’")
            logger.debug(f"  ğŸ–¼ï¸  PILå›¾åƒå¤§å°: {pil_image.size}")
            logger.debug(f"  ğŸ–¼ï¸  PILå›¾åƒæ¨¡å¼: {pil_image.mode}")
            
            frames.append(pil_image)
            
            frame_total_time = time.time() - frame_start
            logger.info(f"  âœ… å¸§ {i+1} å¤„ç†å®Œæˆ: {frame_total_time:.4f}ç§’")
        
        extraction_time = time.time() - extraction_start
        overall_time = time.time() - overall_start
        
        logger.info(f"âœ… æ‰€æœ‰å¸§æå–æ—¶é—´: {extraction_time:.4f}ç§’")
        logger.info(f"âœ… æ€»å¤„ç†æ—¶é—´: {overall_time:.4f}ç§’")
        logger.info(f"âœ… æˆåŠŸæå– {len(frames)} å¸§")
        
        return frames
        
    except Exception as e:
        overall_time = time.time() - overall_start
        logger.error(f"âŒ è§†é¢‘å¸§æå–å¤±è´¥ ({overall_time:.4f}ç§’): {e}")
        raise

def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ” è°ƒè¯•ç‰ˆè§†é¢‘å¸§æå–æµ‹è¯•")
    print("=" * 60)
    
    # è·å–è§†é¢‘æ•°æ®è·¯å¾„ï¼ˆæ¨¡æ‹ŸAzure MLç¯å¢ƒï¼‰
    test_videos = [
        "/Users/wanmeng/repository/GPT4Video-cobra-auto/result/DADA-100-videos/images_1_001.avi",
        "/Users/wanmeng/repository/GPT4Video-cobra-auto/result/DADA-100-videos/images_1_002.avi"
    ]
    
    for video_path in test_videos:
        if Path(video_path).exists():
            try:
                frames = extract_frames_with_detailed_logging(video_path)
                print(f"ğŸ‰ æˆåŠŸæå– {len(frames)} å¸§")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
            print("-" * 40)
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

if __name__ == "__main__":
    main()