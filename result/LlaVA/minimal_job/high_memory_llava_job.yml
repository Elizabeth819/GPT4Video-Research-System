# é«˜æ˜¾å­˜LLaVAæ£€æµ‹ä½œä¸š - å……åˆ†åˆ©ç”¨80GBæ˜¾å­˜æ‰¹é‡å¤„ç†
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

# Job metadata
display_name: high-memory-llava-batch-detection
description: "High Memory LLaVA - Batch processing 10 frames - Utilize full 80GB VRAM"

# Compute configuration  
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Resource requirements
resources:
  instance_count: 1

# Code source
code: .

# é«˜æ˜¾å­˜LLaVAæ‰¹é‡å¤„ç†ä½œä¸š
command: >
  echo "ğŸš€ å¼€å§‹é«˜æ˜¾å­˜LLaVAæ‰¹é‡æ£€æµ‹ - å……åˆ†åˆ©ç”¨80GBæ˜¾å­˜" &&
  python --version &&
  echo "ğŸ“‹ æ£€æŸ¥GPUå’Œæ˜¾å­˜ç¯å¢ƒ..." &&
  nvidia-smi &&
  python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB - è¶³å¤Ÿæ‰¹é‡å¤„ç†!' if torch.cuda.is_available() else 'No GPU')" &&
  echo "ğŸ”§ å®‰è£…ç³»ç»Ÿä¾èµ–..." &&
  apt-get update && apt-get install -y libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 git-lfs &&
  echo "ğŸ”§ å®‰è£…Pythonä¾èµ–..." &&
  pip install transformers>=4.37.0 accelerate Pillow numpy decord torch-audio torchaudio bitsandbytes &&
  echo "ğŸ“ æ£€æŸ¥è¾“å…¥æ•°æ®è·¯å¾„..." &&
  env | grep AZUREML_DATAREFERENCE_video_data &&
  echo "ğŸ“Š ç»Ÿè®¡è§†é¢‘æ–‡ä»¶..." &&
  find $AZUREML_DATAREFERENCE_video_data -name "images_[1-5]_*.avi" | head -10 &&
  find $AZUREML_DATAREFERENCE_video_data -name "images_[1-5]_*.avi" | wc -l &&
  echo "ğŸ”¥ è¿è¡Œé«˜æ˜¾å­˜LLaVAæ‰¹é‡æ£€æµ‹ - æ¯æ¬¡å¤„ç†10å¸§..." &&
  timeout 21600 python real_llava_gpt41_detector.py &&
  echo "ğŸ“Š æ£€æŸ¥è¾“å‡ºç»“æœ..." &&
  ls -la ./outputs/results/ &&
  echo "âœ… é«˜æ˜¾å­˜LLaVAæ‰¹é‡æ£€æµ‹å®Œæˆ"

# Input data  
inputs:
  video_data:
    type: uri_folder
    path: azureml:dada-100-videos-fixed:1
    mode: ro_mount

# Output data
outputs:
  results:
    type: uri_folder
    mode: rw_mount

# Environment variables
environment_variables:
  CUDA_VISIBLE_DEVICES: "0"
  TRANSFORMERS_CACHE: "/tmp/transformers"
  TORCH_CUDA_ARCH_LIST: "7.0;7.5;8.0;8.6"
  HF_HUB_CACHE: "/tmp/huggingface"
  
  # é«˜æ˜¾å­˜é…ç½®
  FRAME_INTERVAL: "10"
  FRAMES_PER_INTERVAL: "10"  # å……åˆ†åˆ©ç”¨80GBæ˜¾å­˜ï¼Œæ‰¹é‡å¤„ç†10å¸§
  DETECTION_METHOD: "High-Memory-Batch-LLaVA"
  
  # æ¨¡å‹ä¼˜åŒ–é…ç½®
  LLAVA_MODEL_CACHE: "/tmp/llava_models"
  TORCH_USE_CUDA_DSA: "1"
  PYTORCH_CUDA_ALLOC_CONF: "max_split_size_mb:512"

# Experiment settings
experiment_name: high-memory-llava-batch-experiment