# ç®€åŒ–ç‰ˆLLaVAæ£€æµ‹ä½œä¸š
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

# Job metadata
display_name: simple-llava-detection
description: "Simple LLaVA Ghost Probing Detection using CLIP and GPT2"

# Compute configuration  
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Resource requirements
resources:
  instance_count: 1

# Code source
code: .

# Simple detection job
command: >
  echo "ğŸš€ å¼€å§‹ç®€åŒ–ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š" &&
  python --version &&
  echo "ğŸ“‹ æ£€æŸ¥GPUå’ŒCUDAç¯å¢ƒ..." &&
  nvidia-smi &&
  python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')" &&
  echo "ğŸ”§ å®‰è£…ä¾èµ–åŒ…..." &&
  pip install decord transformers accelerate Pillow &&
  echo "ğŸ“ æ£€æŸ¥è¾“å…¥æ•°æ®è·¯å¾„..." &&
  env | grep AZUREML_DATAREFERENCE_video_data &&
  echo "ğŸ“Š è¿è¡Œç®€åŒ–ç‰ˆæ£€æµ‹..." &&
  timeout 7200 python simple_llava_detector.py &&
  echo "âœ… ç®€åŒ–ç‰ˆæ£€æµ‹ä½œä¸šå®Œæˆ"

# Input data  
inputs:
  video_data:
    type: uri_folder
    path: azureml:dada-100-videos-fixed:1
    mode: ro_mount

# Output data
outputs:
  results:
    type: uri_folder
    mode: rw_mount

# Environment variables
environment_variables:
  CUDA_VISIBLE_DEVICES: "0"
  TRANSFORMERS_CACHE: "/tmp/transformers"

# Experiment settings
experiment_name: simple-llava-experiment