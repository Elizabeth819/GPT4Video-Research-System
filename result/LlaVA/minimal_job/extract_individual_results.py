#!/usr/bin/env python3
"""
æå–LLaVAæ£€æµ‹ç»“æœï¼Œæ¯ä¸ªè§†é¢‘å•ç‹¬ä¿å­˜ä¸ºæ–‡ä»¶
ä¾¿äºç›´è§‚éªŒè¯æ£€æµ‹æ•ˆæœ
"""

import json
import os
from pathlib import Path
from datetime import datetime

def extract_individual_results():
    """æå–æ¯ä¸ªè§†é¢‘çš„æ£€æµ‹ç»“æœåˆ°å•ç‹¬æ–‡ä»¶"""
    
    # è¯»å–ç»“æœæ–‡ä»¶
    result_file = "./outputs/results/gpt41_balanced_100_videos_20250722_032034.json"
    
    if not Path(result_file).exists():
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
        return
    
    with open(result_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = data.get('results', [])
    metadata = data.get('metadata', {})
    
    print(f"ğŸš€ å¼€å§‹æå– {len(results)} ä¸ªè§†é¢‘çš„æ£€æµ‹ç»“æœ...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("./individual_results")
    output_dir.mkdir(exist_ok=True)
    
    # åŠ è½½ground truthç”¨äºå¯¹æ¯”
    gt_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result/groundtruth_labels.csv"
    ground_truth = {}
    
    if Path(gt_file).exists():
        import pandas as pd
        df = pd.read_csv(gt_file, sep='\t')
        for _, row in df.iterrows():
            video_id = str(row['video_id']).replace('.avi', '')
            label = str(row['ground_truth_label']).lower()
            has_ghost = (
                'ghost probing' in label or 
                'ghost' in label or
                ('s:' in label and 'none' not in label and 'cut-in' not in label)
            )
            ground_truth[video_id] = {
                'has_ghost_probing': has_ghost,
                'original_label': row['ground_truth_label']
            }
    
    # ç»Ÿè®¡ä¿¡æ¯
    ghost_detected_count = 0
    potential_detected_count = 0
    correct_detections = 0
    false_positives = 0
    missed_detections = 0
    
    # å¤„ç†æ¯ä¸ªè§†é¢‘
    for i, result in enumerate(results):
        video_id = result.get('video_id', f'video_{i}')
        
        # æ£€æµ‹åˆ†ç±»
        key_actions = result.get('key_actions', '').lower()
        
        if 'ghost probing' in key_actions and 'potential' not in key_actions:
            detection_type = "ğŸš¨ é«˜ç½®ä¿¡åº¦é¬¼æ¢å¤´"
            ghost_detected_count += 1
            detected = True
        elif 'potential ghost probing' in key_actions:
            detection_type = "âš ï¸ æ½œåœ¨é¬¼æ¢å¤´"
            potential_detected_count += 1
            detected = True
        elif 'emergency braking' in key_actions:
            detection_type = "ğŸŸ¡ ç´§æ€¥åˆ¶åŠ¨"
            detected = False
        else:
            detection_type = "âœ… æ­£å¸¸äº¤é€š"
            detected = False
        
        # Ground Truthå¯¹æ¯”
        gt_info = ground_truth.get(video_id, {})
        has_ground_truth_ghost = gt_info.get('has_ghost_probing', False)
        
        # å‡†ç¡®æ€§åˆ¤æ–­
        if has_ground_truth_ghost and detected:
            accuracy_status = "âœ… æ­£ç¡®æ£€æµ‹"
            correct_detections += 1
        elif not has_ground_truth_ghost and detected:
            accuracy_status = "âŒ è¯¯æŠ¥"
            false_positives += 1
        elif has_ground_truth_ghost and not detected:
            accuracy_status = "âš ï¸ æ¼æ£€"
            missed_detections += 1
        else:
            accuracy_status = "âœ… æ­£ç¡®åˆ¤æ–­ä¸ºæ­£å¸¸"
        
        # åˆ›å»ºè¯¦ç»†åˆ†ææŠ¥å‘Š
        analysis_report = {
            "è§†é¢‘ä¿¡æ¯": {
                "è§†é¢‘ID": video_id,
                "æ£€æµ‹ç±»å‹": detection_type,
                "å‡†ç¡®æ€§è¯„ä¼°": accuracy_status,
                "Ground Truth": gt_info.get('original_label', 'æœªçŸ¥'),
                "å¤„ç†æ—¶é—´": f"{result.get('processing_time', 0):.2f}ç§’"
            },
            
            "æ£€æµ‹ç»“æœè¯¦æƒ…": {
                "å…³é”®åŠ¨ä½œ": result.get('key_actions', ''),
                "åœºæ™¯æ¦‚è¿°": result.get('summary', ''),
                "åœºæ™¯ä¸»é¢˜": result.get('scene_theme', ''),
                "æƒ…æ„Ÿè‰²è°ƒ": result.get('sentiment', ''),
                "å…³é”®å¯¹è±¡": result.get('key_objects', ''),
                "ä¸‹ä¸€æ­¥åŠ¨ä½œ": result.get('next_action', {})
            },
            
            "æŠ€æœ¯åˆ†æ": {
                "æœ€å¤§å¸§å˜åŒ–": result.get('max_frame_change', 0),
                "å¹³å‡å¸§å˜åŒ–": result.get('avg_frame_change', 0),
                "å¸§å˜åŒ–åºåˆ—": result.get('feature_changes', []),
                "ç½®ä¿¡åº¦åˆ†æ•°": result.get('gpt41_analysis', {}).get('confidence_score', 0),
                "çªç„¶å˜åŒ–æ¬¡æ•°": result.get('gpt41_analysis', {}).get('sudden_changes', 0),
                "åˆ†ææ—¶é—´": f"{result.get('analysis_time', 0):.4f}ç§’",
                "æ£€æµ‹æ–¹æ³•": result.get('gpt41_analysis', {}).get('detection_method', '')
            },
            
            "æ¨¡å‹å…ƒæ•°æ®": {
                "æ¨¡å‹": result.get('model', ''),
                "æ—¶é—´æˆ³": result.get('timestamp', ''),
                "è®¾å¤‡": result.get('device', ''),
                "å¸§æ•°": result.get('frames_analyzed', 0)
            }
        }
        
        # ä¿å­˜åˆ°å•ç‹¬æ–‡ä»¶
        filename = f"{video_id}_analysis.json"
        filepath = output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(analysis_report, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°ç®€è¦ä¿¡æ¯
        confidence = result.get('gpt41_analysis', {}).get('confidence_score', 0)
        max_change = result.get('max_frame_change', 0)
        
        print(f"{i+1:3d}. {video_id:15s} | {detection_type:15s} | {accuracy_status:12s} | ç½®ä¿¡åº¦:{confidence:.3f} | æœ€å¤§å˜åŒ–:{max_change:.4f}")
    
    # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    summary_report = {
        "æ£€æµ‹æ±‡æ€»": {
            "æ€»è§†é¢‘æ•°": len(results),
            "é«˜ç½®ä¿¡åº¦é¬¼æ¢å¤´": ghost_detected_count,
            "æ½œåœ¨é¬¼æ¢å¤´": potential_detected_count,
            "æ­£å¸¸äº¤é€š": len(results) - ghost_detected_count - potential_detected_count,
            "æ£€æµ‹æ€»æ•°": ghost_detected_count + potential_detected_count
        },
        
        "å‡†ç¡®æ€§åˆ†æ": {
            "æ­£ç¡®æ£€æµ‹": correct_detections,
            "è¯¯æŠ¥": false_positives,
            "æ¼æ£€": missed_detections,
            "Ground Truthé¬¼æ¢å¤´æ€»æ•°": sum(1 for gt in ground_truth.values() if gt.get('has_ghost_probing', False)),
            "æ£€æµ‹å‡†ç¡®ç‡": f"{(correct_detections / len(results)) * 100:.1f}%" if results else "0%"
        },
        
        "æ€§èƒ½æŒ‡æ ‡": {
            "å¬å›ç‡": f"{(correct_detections / (correct_detections + missed_detections)) * 100:.1f}%" if (correct_detections + missed_detections) > 0 else "0%",
            "ç²¾ç¡®åº¦": f"{(correct_detections / (correct_detections + false_positives)) * 100:.1f}%" if (correct_detections + false_positives) > 0 else "0%",
            "è¯¯æŠ¥ç‡": f"{(false_positives / len(results)) * 100:.1f}%" if results else "0%"
        }
    }
    
    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    summary_file = output_dir / "detection_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*100)
    print("ğŸ“Š æ£€æµ‹ç»“æœæ±‡æ€»:")
    print("="*100)
    print(f"ğŸ“¹ æ€»è§†é¢‘æ•°: {len(results)}")
    print(f"ğŸš¨ é«˜ç½®ä¿¡åº¦é¬¼æ¢å¤´: {ghost_detected_count}")
    print(f"âš ï¸ æ½œåœ¨é¬¼æ¢å¤´: {potential_detected_count}")
    print(f"âœ… æ­£å¸¸äº¤é€š: {len(results) - ghost_detected_count - potential_detected_count}")
    print(f"ğŸ¯ æ£€æµ‹æ€»æ•°: {ghost_detected_count + potential_detected_count}")
    print()
    print(f"âœ… æ­£ç¡®æ£€æµ‹: {correct_detections}")
    print(f"âŒ è¯¯æŠ¥: {false_positives}")
    print(f"âš ï¸ æ¼æ£€: {missed_detections}")
    print()
    print(f"ğŸ“ å•ç‹¬ç»“æœæ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
    print(f"ğŸ“„ æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print("="*100)
    
    return output_dir

if __name__ == "__main__":
    output_dir = extract_individual_results()
    print(f"\nğŸ‰ æå–å®Œæˆ! è¯·æŸ¥çœ‹ {output_dir} ç›®å½•ä¸­çš„å•ä¸ªè§†é¢‘åˆ†ææ–‡ä»¶")