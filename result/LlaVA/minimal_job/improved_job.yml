# æ”¹è¿›ç‰ˆLLaVAæ£€æµ‹ä½œä¸š - é™ä½é˜ˆå€¼ + æ—¶åºåˆ†æ
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

# Job metadata
display_name: improved-llava-temporal-detection
description: "Improved LLaVA Ghost Probing Detection with lowered thresholds and temporal analysis"

# Compute configuration  
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Resource requirements
resources:
  instance_count: 1

# Code source
code: .

# æ”¹è¿›ç‰ˆæ£€æµ‹ä½œä¸š
command: >
  echo "ğŸš€ å¼€å§‹æ”¹è¿›ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š" &&
  python --version &&
  echo "ğŸ“‹ æ£€æŸ¥GPUå’ŒCUDAç¯å¢ƒ..." &&
  nvidia-smi &&
  python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 / 1024:.0f}MB' if torch.cuda.is_available() else 'CPUæ¨¡å¼')" &&
  echo "ğŸ”§ å®‰è£…ä¾èµ–åŒ…..." &&
  pip install decord transformers accelerate Pillow numpy &&
  echo "ğŸ“ æ£€æŸ¥è¾“å…¥æ•°æ®è·¯å¾„..." &&
  env | grep AZUREML_DATAREFERENCE_video_data &&
  echo "ğŸ” è¿è¡Œæ”¹è¿›ç‰ˆæ£€æµ‹ï¼ˆé™ä½é˜ˆå€¼+æ—¶åºåˆ†æï¼‰..." &&
  timeout 7200 python improved_llava_detector.py &&
  echo "âœ… æ”¹è¿›ç‰ˆæ£€æµ‹ä½œä¸šå®Œæˆ"

# Input data  
inputs:
  video_data:
    type: uri_folder
    path: azureml:dada-100-videos-fixed:1
    mode: ro_mount

# Output data
outputs:
  results:
    type: uri_folder
    mode: rw_mount

# Environment variables
environment_variables:
  CUDA_VISIBLE_DEVICES: "0"
  TRANSFORMERS_CACHE: "/tmp/transformers"
  TORCH_CUDA_ARCH_LIST: "7.0;7.5;8.0;8.6"

# Experiment settings
experiment_name: improved-llava-detection-experiment