# GPUåŠ é€Ÿçš„çœŸæ­£LLaVAæ£€æµ‹ä½œä¸š - ä¿®å¤ç‰ˆ
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

# Job metadata
display_name: real-llava-gpu-fixed
description: "Real LLaVA Ghost Probing Detection with GPU acceleration and decord fix"

# Compute configuration  
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Resource requirements
resources:
  instance_count: 1

# Code source
code: .

# GPU-accelerated LLaVA analysis
command: >
  echo "ğŸš€ å¼€å§‹GPUåŠ é€Ÿçš„çœŸæ­£LLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š" &&
  python --version &&
  echo "ğŸ“‹ æ£€æŸ¥GPUå’ŒCUDAç¯å¢ƒ..." &&
  nvidia-smi &&
  python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else \"N/A\"}')" &&
  echo "ğŸ”§ å®‰è£…ä¾èµ–åŒ…..." &&
  pip install decord transformers accelerate Pillow &&
  echo "ğŸ“ æ£€æŸ¥è¾“å…¥æ•°æ®è·¯å¾„..." &&
  env | grep AZUREML_DATAREFERENCE_video_data &&
  echo "ğŸ“Š è¿è¡ŒGPUåŠ é€Ÿçš„çœŸæ­£LLaVAæ£€æµ‹..." &&
  timeout 7200 python real_llava_gpu_fixed.py &&
  echo "âœ… GPUåŠ é€Ÿçš„LLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸šå®Œæˆ"

# Input data  
inputs:
  video_data:
    type: uri_folder
    path: azureml:dada-100-videos-fixed:1
    mode: ro_mount

# Output data
outputs:
  results:
    type: uri_folder
    mode: rw_mount

# Environment variables for GPU
environment_variables:
  CUDA_VISIBLE_DEVICES: "0"
  TORCH_CUDA_ARCH_LIST: "7.0;7.5;8.0;8.6"

# Experiment settings
experiment_name: real-llava-gpu-experiment