# LLaVAå…¼å®¹ç‰ˆæ£€æµ‹ä½œä¸š
$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
type: command

# Job metadata
display_name: real-llava-compatible
description: "Real LLaVA Ghost Probing Detection with compatible model loading"

# Compute configuration  
compute: azureml:llava-a100-low-priority
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10

# Resource requirements
resources:
  instance_count: 1

# Code source
code: .

# Compatible LLaVA analysis
command: >
  echo "ğŸš€ å¼€å§‹å…¼å®¹ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸š" &&
  python --version &&
  echo "ğŸ“‹ æ£€æŸ¥GPUå’ŒCUDAç¯å¢ƒ..." &&
  nvidia-smi &&
  python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')" &&
  echo "ğŸ”§ å®‰è£…ä¾èµ–åŒ…..." &&
  pip install decord transformers accelerate Pillow &&
  echo "ğŸ“ æ£€æŸ¥è¾“å…¥æ•°æ®è·¯å¾„..." &&
  env | grep AZUREML_DATAREFERENCE_video_data &&
  echo "ğŸ“Š è¿è¡Œå…¼å®¹ç‰ˆLLaVAæ£€æµ‹..." &&
  timeout 7200 python real_llava_compatible.py &&
  echo "âœ… å…¼å®¹ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹ä½œä¸šå®Œæˆ"

# Input data  
inputs:
  video_data:
    type: uri_folder
    path: azureml:dada-100-videos-fixed:1
    mode: ro_mount

# Output data
outputs:
  results:
    type: uri_folder
    mode: rw_mount

# Environment variables for GPU
environment_variables:
  CUDA_VISIBLE_DEVICES: "0"
  TRANSFORMERS_OFFLINE: "0"
  HF_HOME: "/tmp/huggingface"

# Experiment settings
experiment_name: real-llava-compatible-experiment