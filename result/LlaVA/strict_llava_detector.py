#!/usr/bin/env python3
"""
ä¸¥æ ¼ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹å™¨
å¼ºåˆ¶æ— ç¼“å­˜ï¼Œè¯¦ç»†éªŒè¯æ¯ä¸€æ­¥
"""

import json
import os
import sys
import gc
from pathlib import Path
from datetime import datetime
from PIL import Image
import logging
import torch
from typing import List, Dict, Optional, Tuple
import numpy as np
import time
import hashlib

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class StrictLLaVADetector:
    """ä¸¥æ ¼ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹å™¨ - æ— ç¼“å­˜éªŒè¯ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ£€æµ‹å™¨"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None
        self.processor = None
        self.processed_videos = []  # è®°å½•å¤„ç†è¿‡çš„è§†é¢‘
        
        # å¹³è¡¡ç‰ˆGPT-4.1é¬¼æ¢å¤´æ£€æµ‹prompt
        self.ghost_probing_prompt = """Analyze these sequential driving video frames for ghost probing detection."""
        
        self._initialize_model()
    
    def _initialize_model(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–ä¸¥æ ¼ç‰ˆæ¨¡å‹...")
            logger.info(f"ğŸ–¥ï¸  è®¾å¤‡: {self.device}")
            
            # ä½¿ç”¨CLIPè¿›è¡Œå›¾åƒç¼–ç 
            from transformers import CLIPProcessor, CLIPModel
            
            # åŠ è½½CLIPæ¨¡å‹
            logger.info("ğŸ“¥ åŠ è½½CLIPæ¨¡å‹...")
            self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
            self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            
            # ç§»åˆ°GPU
            if torch.cuda.is_available():
                self.clip_model = self.clip_model.cuda()
                logger.info(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ°GPU: {torch.cuda.get_device_name()}")
            else:
                logger.warning("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def extract_frames_strict(self, video_path: str, num_frames: int = 8) -> List[Image.Image]:
        """ä¸¥æ ¼æå–è§†é¢‘å¸§ - æ— ç¼“å­˜ç‰ˆæœ¬"""
        
        logger.info(f"ğŸ¬ ä¸¥æ ¼å¤„ç†è§†é¢‘: {Path(video_path).name}")
        overall_start = time.time()
        
        # éªŒè¯æ–‡ä»¶
        if not Path(video_path).exists():
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        file_size = Path(video_path).stat().st_size
        logger.info(f"ğŸ“‚ æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸ŒéªŒè¯çœŸå®æ€§
        hash_start = time.time()
        with open(video_path, 'rb') as f:
            file_hash = hashlib.md5(f.read(8192)).hexdigest()  # è¯»å–å‰8KBè®¡ç®—hash
        hash_time = time.time() - hash_start
        logger.info(f"ğŸ” æ–‡ä»¶hashéªŒè¯: {file_hash} ({hash_time:.3f}ç§’)")
        
        try:
            import decord
            from decord import VideoReader
            
            # å¼ºåˆ¶æ¸…é™¤ç¼“å­˜
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            
            # æ¯æ¬¡éƒ½é‡æ–°è®¾ç½®bridge
            decord.bridge.set_bridge('native')
            
            # è¯»å–è§†é¢‘ - æ·»åŠ è¯¦ç»†è®¡æ—¶
            logger.info("ğŸ“– å¼€å§‹è¯»å–è§†é¢‘...")
            video_load_start = time.time()
            
            # å¼ºåˆ¶é‡æ–°åˆ›å»ºVideoReaderå¯¹è±¡
            video_reader = VideoReader(str(video_path))
            total_frames = len(video_reader)
            
            video_load_time = time.time() - video_load_start
            logger.info(f"ğŸ“Š è§†é¢‘åŠ è½½æ—¶é—´: {video_load_time:.4f}ç§’")
            logger.info(f"ğŸ“Š æ€»å¸§æ•°: {total_frames}")
            
            if total_frames == 0:
                raise ValueError(f"è§†é¢‘æ–‡ä»¶æ²¡æœ‰å¸§: {video_path}")
            
            # è·å–è¯¦ç»†è§†é¢‘ä¿¡æ¯
            try:
                fps = video_reader.get_avg_fps()
                duration = total_frames / fps if fps > 0 else 0
                logger.info(f"ğŸ“Š å¸§ç‡: {fps:.2f} fps")
                logger.info(f"ğŸ“Š æ—¶é•¿: {duration:.2f}ç§’")
                
                # éªŒè¯è§†é¢‘åˆç†æ€§
                if duration < 1.0:
                    logger.warning(f"âš ï¸  è§†é¢‘æ—¶é•¿è¿‡çŸ­: {duration:.2f}ç§’")
                if fps < 10 or fps > 60:
                    logger.warning(f"âš ï¸  å¼‚å¸¸å¸§ç‡: {fps:.2f} fps")
                    
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {e}")
            
            # å‡åŒ€åˆ†å¸ƒé€‰æ‹©å¸§
            frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
            logger.info(f"ğŸ“Š é€‰æ‹©å¸§ç´¢å¼•: {frame_indices.tolist()}")
            
            # ä¸¥æ ¼æå–å¸§ - æ¯å¸§ç‹¬ç«‹è®¡æ—¶
            frames = []
            extraction_start = time.time()
            
            for i, idx in enumerate(frame_indices):
                frame_start = time.time()
                logger.info(f"ğŸ” æå–ç¬¬ {i+1}/{num_frames} å¸§ (ç´¢å¼•: {idx})")
                
                # å¼ºåˆ¶ç­‰å¾…ä¸€ç‚¹æ—¶é—´ç¡®ä¿ä¸æ˜¯ç¼“å­˜
                time.sleep(0.001)
                
                # è·å–å¸§
                frame_read_start = time.time()
                frame = video_reader[idx]
                frame_read_time = time.time() - frame_read_start
                
                logger.info(f"  ğŸ“– å¸§è¯»å–æ—¶é—´: {frame_read_time:.4f}ç§’")
                
                # éªŒè¯å¸§æ•°æ®
                if frame is None:
                    raise ValueError(f"å¸§ {idx} è¯»å–å¤±è´¥")
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                convert_start = time.time()
                if hasattr(frame, 'asnumpy'):
                    frame_array = frame.asnumpy()
                elif isinstance(frame, torch.Tensor):
                    frame_array = frame.cpu().numpy()
                else:
                    frame_array = np.array(frame)
                
                convert_time = time.time() - convert_start
                logger.info(f"  ğŸ”„ æ•°ç»„è½¬æ¢æ—¶é—´: {convert_time:.4f}ç§’")
                
                # éªŒè¯å¸§æ•°æ®åˆç†æ€§
                if frame_array.size == 0:
                    raise ValueError(f"å¸§ {idx} æ•°æ®ä¸ºç©º")
                
                logger.info(f"  ğŸ“Š å¸§å½¢çŠ¶: {frame_array.shape}")
                logger.info(f"  ğŸ“Š æ•°æ®èŒƒå›´: {frame_array.min()}-{frame_array.max()}")
                
                # è½¬æ¢ä¸ºPIL Image
                pil_start = time.time()
                pil_image = Image.fromarray(frame_array.astype(np.uint8))
                pil_time = time.time() - pil_start
                
                logger.info(f"  ğŸ–¼ï¸  PILè½¬æ¢æ—¶é—´: {pil_time:.4f}ç§’")
                logger.info(f"  ğŸ–¼ï¸  å›¾åƒå¤§å°: {pil_image.size}")
                
                # éªŒè¯å›¾åƒå†…å®¹ä¸æ˜¯å…¨é»‘æˆ–å…¨ç™½
                img_array = np.array(pil_image)
                pixel_variance = np.var(img_array)
                logger.info(f"  ğŸ¨ åƒç´ æ–¹å·®: {pixel_variance:.2f}")
                
                if pixel_variance < 100:
                    logger.warning(f"  âš ï¸  å¸§ {idx} å¯èƒ½æ˜¯çº¯è‰²å›¾åƒ")
                
                frames.append(pil_image)
                
                frame_total_time = time.time() - frame_start
                logger.info(f"  âœ… å¸§ {i+1} å®Œæˆ: {frame_total_time:.4f}ç§’")
                
                # å¼ºåˆ¶å†…å­˜æ¸…ç†
                del frame, frame_array
                gc.collect()
            
            extraction_time = time.time() - extraction_start
            overall_time = time.time() - overall_start
            
            logger.info(f"âœ… æ‰€æœ‰å¸§æå–æ—¶é—´: {extraction_time:.4f}ç§’")
            logger.info(f"âœ… æ€»å¤„ç†æ—¶é—´: {overall_time:.4f}ç§’")
            logger.info(f"âœ… å¹³å‡æ¯å¸§: {extraction_time/num_frames:.4f}ç§’")
            
            # è®°å½•å¤„ç†ä¿¡æ¯
            process_info = {
                'video_path': video_path,
                'file_size_mb': file_size / 1024 / 1024,
                'file_hash': file_hash,
                'total_frames': total_frames,
                'extraction_time': extraction_time,
                'avg_time_per_frame': extraction_time / num_frames,
                'overall_time': overall_time
            }
            self.processed_videos.append(process_info)
            
            return frames
            
        except Exception as e:
            overall_time = time.time() - overall_start
            logger.error(f"âŒ ä¸¥æ ¼æå–å¤±è´¥ ({overall_time:.4f}ç§’): {e}")
            raise
    
    def analyze_frames_simple(self, frames: List[Image.Image], video_path: str) -> Dict:
        """åˆ†æå¸§ï¼ˆä¿æŒåŸæ¥çš„é€»è¾‘ï¼‰"""
        if not frames:
            raise ValueError("æ²¡æœ‰å¸§å¯åˆ†æ")
        
        try:
            logger.info(f"ğŸ” ä¸¥æ ¼åˆ†æ{len(frames)}å¸§...")
            analysis_start = time.time()
            
            # ä½¿ç”¨CLIPæå–å›¾åƒç‰¹å¾
            inputs = self.clip_processor(images=frames, return_tensors="pt", padding=True)
            
            if torch.cuda.is_available():
                inputs = {k: v.cuda() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}
            
            with torch.no_grad():
                image_features = self.clip_model.get_image_features(**inputs)
            
            # åˆ†æå¸§é—´å˜åŒ–
            feature_changes = []
            for i in range(1, len(frames)):
                diff = torch.cosine_similarity(
                    image_features[i-1].unsqueeze(0),
                    image_features[i].unsqueeze(0)
                ).item()
                feature_changes.append(1 - diff)
            
            max_change = max(feature_changes) if feature_changes else 0
            avg_change = sum(feature_changes) / len(feature_changes) if feature_changes else 0
            
            analysis_time = time.time() - analysis_start
            logger.info(f"ğŸ§  CLIPåˆ†ææ—¶é—´: {analysis_time:.4f}ç§’")
            logger.info(f"ğŸ“Š æœ€å¤§ç‰¹å¾å˜åŒ–: {max_change:.4f}")
            logger.info(f"ğŸ“Š å¹³å‡ç‰¹å¾å˜åŒ–: {avg_change:.4f}")
            
            # åˆ¤æ–­é€»è¾‘
            if max_change > 0.5 and avg_change > 0.3:
                ghost_detected = "yes"
                confidence = min(0.9, max_change)
                ghost_type = "high_confidence" if max_change > 0.7 else "potential"
                risk_level = "high" if max_change > 0.7 else "medium"
            elif max_change > 0.3:
                ghost_detected = "yes"
                confidence = max_change * 0.7
                ghost_type = "potential"
                risk_level = "medium"
            else:
                ghost_detected = "no"
                confidence = 0.2
                ghost_type = "none"
                risk_level = "low"
            
            result = {
                "ghost_probing_detected": ghost_detected,
                "confidence": round(confidence, 3),
                "ghost_type": ghost_type,
                "summary": f"ä¸¥æ ¼åˆ†æå®Œæˆï¼Œæœ€å¤§å¸§é—´å˜åŒ–: {max_change:.4f}",
                "key_actions": f"ä¸¥æ ¼æ£€æµ‹{len(frames)}å¸§ï¼ŒCLIPç‰¹å¾åˆ†æ",
                "risk_level": risk_level,
                "distance_estimate": "åŸºäºä¸¥æ ¼ç‰¹å¾å˜åŒ–ä¼°ç®—",
                "emergency_action_needed": "yes" if ghost_detected == "yes" else "no",
                "max_frame_change": round(max_change, 4),
                "avg_frame_change": round(avg_change, 4),
                "analysis_time": round(analysis_time, 4)
            }
            
            logger.info(f"âœ… ä¸¥æ ¼åˆ†æå®Œæˆ - é¬¼æ¢å¤´: {ghost_detected} (ç½®ä¿¡åº¦: {confidence:.3f})")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä¸¥æ ¼åˆ†æå¤±è´¥: {e}")
            raise
    
    def process_video(self, video_path: str) -> Dict:
        """ä¸¥æ ¼å¤„ç†å•ä¸ªè§†é¢‘"""
        video_name = Path(video_path).stem
        logger.info(f"ğŸ¬ å¼€å§‹ä¸¥æ ¼å¤„ç†è§†é¢‘: {video_name}")
        
        start_time = datetime.now()
        
        try:
            # ä¸¥æ ¼æå–è§†é¢‘å¸§
            frames = self.extract_frames_strict(video_path, num_frames=8)
            
            if not frames:
                raise ValueError("ä¸¥æ ¼æå–å¤±è´¥ï¼šæ— æ³•æå–è§†é¢‘å¸§")
            
            # åˆ†æå¸§
            analysis_result = self.analyze_frames_simple(frames, video_path)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # æ„å»ºç»“æœ
            result = {
                "video_id": video_name,
                "video_path": str(video_path),
                "ghost_probing_label": analysis_result.get("ghost_probing_detected", "no"),
                "confidence": analysis_result.get("confidence", 0.5),
                "ghost_type": analysis_result.get("ghost_type", "none"),
                "summary": analysis_result.get("summary", ""),
                "key_actions": analysis_result.get("key_actions", ""),
                "risk_level": analysis_result.get("risk_level", "low"),
                "emergency_action_needed": analysis_result.get("emergency_action_needed", "no"),
                "model": "CLIP-Strict-NoCache",
                "timestamp": datetime.now().isoformat(),
                "processing_time": processing_time,
                "method": "strict_no_cache_analysis",
                "frames_analyzed": len(frames),
                "device": self.device,
                "max_frame_change": analysis_result.get("max_frame_change", 0),
                "avg_frame_change": analysis_result.get("avg_frame_change", 0),
                "analysis_time": analysis_result.get("analysis_time", 0)
            }
            
            logger.info(f"âœ… ä¸¥æ ¼å¤„ç†å®Œæˆ: {video_name} ({processing_time:.2f}s)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä¸¥æ ¼å¤„ç†å¤±è´¥: {video_name} - {e}")
            return {
                "video_id": video_name,
                "video_path": str(video_path),
                "error": str(e),
                "processing_time": (datetime.now() - start_time).total_seconds(),
                "method": "strict_no_cache_analysis"
            }

def main():
    """ä¸¥æ ¼ç‰ˆä¸»å‡½æ•° - ä»…å¤„ç†5ä¸ªè§†é¢‘è¿›è¡Œæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ä¸¥æ ¼ç‰ˆLLaVAé¬¼æ¢å¤´æ£€æµ‹...")
    print("âš ï¸  æ³¨æ„ï¼šè¿™æ˜¯æ— ç¼“å­˜ä¸¥æ ¼éªŒè¯ç‰ˆæœ¬")
    
    # æ£€æŸ¥GPU
    if torch.cuda.is_available():
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name()}")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    
    # è·å–è§†é¢‘è·¯å¾„
    azureml_data_path = os.environ.get('AZUREML_DATAREFERENCE_video_data')
    
    possible_paths = []
    if azureml_data_path:
        possible_paths.append(azureml_data_path)
        print(f"ğŸ”§ ä»ç¯å¢ƒå˜é‡æ‰¾åˆ°æ•°æ®è·¯å¾„: {azureml_data_path}")
    
    possible_paths.extend(["./inputs/video_data", "./inputs", "."])
    
    video_files = []
    video_folder = None
    
    for path in possible_paths:
        try:
            p = Path(path)
            if p.exists():
                found_videos = list(p.glob("**/*.avi"))
                if found_videos:
                    # ä»…å–å‰5ä¸ªè§†é¢‘è¿›è¡Œä¸¥æ ¼æµ‹è¯•
                    video_files = found_videos[:5]
                    video_folder = p
                    print(f"âœ… åœ¨ {path} æ‰¾åˆ° {len(found_videos)} ä¸ªè§†é¢‘ï¼Œä¸¥æ ¼æµ‹è¯•å‰ {len(video_files)} ä¸ª")
                    break
        except Exception as e:
            print(f"âŒ æ£€æŸ¥è·¯å¾„ {path} æ—¶å‡ºé”™: {e}")
    
    if not video_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("./outputs/results", exist_ok=True)
    
    # åˆå§‹åŒ–ä¸¥æ ¼æ£€æµ‹å™¨
    detector = StrictLLaVADetector()
    
    print(f"ğŸ¬ å¼€å§‹ä¸¥æ ¼å¤„ç† {len(video_files)} ä¸ªè§†é¢‘...")
    print("=" * 60)
    
    # å¤„ç†è§†é¢‘
    results = []
    failed_count = 0
    
    for i, video_file in enumerate(video_files):
        try:
            print(f"\nğŸ“¹ å¤„ç†è§†é¢‘ {i+1}/{len(video_files)}: {Path(video_file).name}")
            result = detector.process_video(str(video_file))
            results.append(result)
            
            if 'error' in result:
                failed_count += 1
                print(f"âŒ å¤„ç†å¤±è´¥: {result['error']}")
            else:
                print(f"âœ… å¤„ç†æˆåŠŸ: {result['processing_time']:.2f}ç§’")
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è§†é¢‘å¤±è´¥: {e}")
            failed_count += 1
            results.append({
                "video_id": Path(video_file).stem,
                "video_path": str(video_file),
                "error": str(e),
                "processing_time": 0
            })
    
    # ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜ä¸¥æ ¼æµ‹è¯•ç»“æœ...")
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    successful_results = [r for r in results if 'error' not in r]
    
    # ä¿å­˜è¯¦ç»†çš„ä¸¥æ ¼æµ‹è¯•ç»“æœ
    strict_result = {
        'metadata': {
            'model': 'CLIP-Strict-NoCache',
            'device': 'GPU' if torch.cuda.is_available() else 'CPU',
            'total_videos': len(video_files),
            'successful_videos': len(successful_results),
            'failed_videos': failed_count,
            'timestamp': timestamp,
            'test_type': 'strict_no_cache_validation'
        },
        'processed_videos_details': detector.processed_videos,
        'results': results
    }
    
    json_file = f"./outputs/results/strict_llava_results_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(strict_result, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    if successful_results:
        avg_time = sum(r['processing_time'] for r in successful_results) / len(successful_results)
        avg_extraction_time = sum(v['extraction_time'] for v in detector.processed_videos) / len(detector.processed_videos)
    else:
        avg_time = avg_extraction_time = 0
    
    print("=" * 60)
    print("ğŸ‰ ä¸¥æ ¼ç‰ˆæ£€æµ‹å®Œæˆ!")
    print("=" * 60)
    print(f"ğŸ“Š æµ‹è¯•è§†é¢‘æ•°: {len(video_files)}")
    print(f"âœ… æˆåŠŸå¤„ç†: {len(successful_results)}")
    print(f"âŒ å¤„ç†å¤±è´¥: {failed_count}")
    if successful_results:
        print(f"â±ï¸  å¹³å‡æ€»æ—¶é—´: {avg_time:.2f}ç§’/è§†é¢‘")
        print(f"â±ï¸  å¹³å‡æŠ½å¸§æ—¶é—´: {avg_extraction_time:.2f}ç§’/è§†é¢‘")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {json_file}")
    print("=" * 60)

if __name__ == "__main__":
    main()