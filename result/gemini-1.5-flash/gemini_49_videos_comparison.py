#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Gemini vs GPT-4.1 - 49ä¸ªè§†é¢‘å®Œæ•´å¯¹æ¯”åˆ†æ
åŸºäºå½“å‰å·²å¤„ç†çš„æ‰€æœ‰Geminiç»“æœ
"""

import os
import json
import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

def load_gemini_results():
    """åŠ è½½æ‰€æœ‰Geminiç»“æœ"""
    gemini_dir = "result/gemini-balanced-full"
    results = {}
    
    print("ğŸ“Š åŠ è½½Geminiç»“æœ...")
    for filename in os.listdir(gemini_dir):
        if filename.startswith("actionSummary_") and filename.endswith(".json"):
            video_id = filename.replace("actionSummary_", "").replace(".json", "")
            # æ ‡å‡†åŒ–ä¸ºimages_æ ¼å¼
            if video_id.startswith("dada_"):
                video_id = video_id.replace("dada_", "images_")
            
            with open(os.path.join(gemini_dir, filename), 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # æå–key_actions
            key_actions = []
            for segment in data:
                if isinstance(segment, dict) and 'key_actions' in segment:
                    key_actions.append(segment['key_actions'])
            
            results[video_id] = key_actions
    
    print(f"âœ… åŠ è½½äº† {len(results)} ä¸ªGeminiè§†é¢‘ç»“æœ")
    return results

def load_gpt41_results():
    """åŠ è½½GPT-4.1å¹³è¡¡ç‰ˆç»“æœ"""
    gpt41_dir = "result/gpt41-balanced-full"
    results = {}
    
    print("ğŸ“Š åŠ è½½GPT-4.1ç»“æœ...")
    for filename in os.listdir(gpt41_dir):
        if filename.startswith("actionSummary_") and filename.endswith(".json"):
            video_id = filename.replace("actionSummary_", "").replace(".json", "")
            
            with open(os.path.join(gpt41_dir, filename), 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # æå–key_actions
            key_actions = []
            for segment in data:
                if isinstance(segment, dict) and 'key_actions' in segment:
                    key_actions.append(segment['key_actions'])
            
            results[video_id] = key_actions
    
    print(f"âœ… åŠ è½½äº† {len(results)} ä¸ªGPT-4.1è§†é¢‘ç»“æœ")
    return results

def load_ground_truth():
    """åŠ è½½Ground Truthæ ‡ç­¾"""
    df = pd.read_csv('result/groundtruth_labels.csv', sep='\t')
    
    ground_truth = {}
    for _, row in df.iterrows():
        video_id = row['video_id'].replace('.avi', '')
        label = row['ground_truth_label']
        
        # è½¬æ¢æ ‡ç­¾
        if label == 'none':
            ground_truth[video_id] = 'none'
        else:
            ground_truth[video_id] = 'ghost probing'
    
    print(f"âœ… åŠ è½½äº† {len(ground_truth)} ä¸ªGround Truthæ ‡ç­¾")
    return ground_truth

def evaluate_model_results(results, ground_truth, model_name):
    """è¯„ä¼°æ¨¡å‹ç»“æœ"""
    y_true = []
    y_pred = []
    details = []
    
    for video_id in sorted(results.keys()):
        if video_id in ground_truth:
            # Ground truth
            gt_label = ground_truth[video_id]
            y_true.append(gt_label)
            
            # æ¨¡å‹é¢„æµ‹ - any segmentç­–ç•¥
            predictions = results[video_id]
            has_ghost_probing = any('ghost probing' in str(pred).lower() for pred in predictions)
            
            if has_ghost_probing:
                pred_label = 'ghost probing'
            else:
                pred_label = 'none'
            
            y_pred.append(pred_label)
            
            details.append({
                'video_id': video_id,
                'ground_truth': gt_label,
                'prediction': pred_label,
                'correct': gt_label == pred_label,
                'raw_predictions': predictions
            })
    
    return y_true, y_pred, details

def calculate_metrics(y_true, y_pred):
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
    # è½¬æ¢ä¸ºäºŒå…ƒåˆ†ç±»
    y_true_binary = [1 if label == 'ghost probing' else 0 for label in y_true]
    y_pred_binary = [1 if label == 'ghost probing' else 0 for label in y_pred]
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true_binary, y_pred_binary)
    tn, fp, fn, tp = cm.ravel()
    
    # è®¡ç®—æŒ‡æ ‡
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    
    return {
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'accuracy': accuracy,
        'specificity': specificity,
        'confusion_matrix': cm,
        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn
    }

def create_confusion_matrix_plot(cm_gemini, cm_gpt41, save_path):
    """åˆ›å»ºæ··æ·†çŸ©é˜µå¯¹æ¯”å›¾"""
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    # Geminiæ··æ·†çŸ©é˜µ
    sns.heatmap(cm_gemini, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Predicted None', 'Predicted Ghost Probing'],
                yticklabels=['Actual None', 'Actual Ghost Probing'],
                ax=axes[0])
    axes[0].set_title('Gemini 2.0 Flash')
    
    # GPT-4.1æ··æ·†çŸ©é˜µ
    sns.heatmap(cm_gpt41, annot=True, fmt='d', cmap='Oranges',
                xticklabels=['Predicted None', 'Predicted Ghost Probing'], 
                yticklabels=['Actual None', 'Actual Ghost Probing'],
                ax=axes[1])
    axes[1].set_title('GPT-4.1 Balanced')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜: {save_path}")

def create_metrics_comparison_plot(metrics_gemini, metrics_gpt41, save_path):
    """åˆ›å»ºæŒ‡æ ‡å¯¹æ¯”å›¾"""
    metrics = ['precision', 'recall', 'f1', 'accuracy', 'specificity']
    gemini_values = [metrics_gemini[m] for m in metrics]
    gpt41_values = [metrics_gpt41[m] for m in metrics]
    
    x = np.arange(len(metrics))
    width = 0.35
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars1 = ax.bar(x - width/2, gemini_values, width, label='Gemini 2.0 Flash', alpha=0.8, color='skyblue')
    bars2 = ax.bar(x + width/2, gpt41_values, width, label='GPT-4.1 Balanced', alpha=0.8, color='orange')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.3f}',
                       xy=(bar.get_x() + bar.get_width() / 2, height),
                       xytext=(0, 3),
                       textcoords="offset points",
                       ha='center', va='bottom')
    
    ax.set_xlabel('Metrics')
    ax.set_ylabel('Score')
    ax.set_title('Gemini vs GPT-4.1 Performance Comparison (49 Videos)')
    ax.set_xticks(x)
    ax.set_xticklabels([m.capitalize() for m in metrics])
    ax.legend()
    ax.set_ylim(0, 1.1)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“Š æŒ‡æ ‡å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")

def analyze_disagreements(details_gemini, details_gpt41):
    """åˆ†ææ¨¡å‹åˆ†æ­§æ¡ˆä¾‹"""
    disagreements = []
    
    for gem_detail, gpt_detail in zip(details_gemini, details_gpt41):
        if gem_detail['video_id'] == gpt_detail['video_id']:
            if gem_detail['prediction'] != gpt_detail['prediction']:
                disagreements.append({
                    'video_id': gem_detail['video_id'],
                    'ground_truth': gem_detail['ground_truth'],
                    'gemini_pred': gem_detail['prediction'],
                    'gpt41_pred': gpt_detail['prediction'],
                    'gemini_correct': gem_detail['correct'],
                    'gpt41_correct': gpt_detail['correct']
                })
    
    return disagreements

def main():
    print("ğŸ” Gemini vs GPT-4.1 å®Œæ•´å¯¹æ¯”åˆ†æ (49ä¸ªè§†é¢‘)")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    gemini_results = load_gemini_results()
    gpt41_results = load_gpt41_results()
    ground_truth = load_ground_truth()
    
    # æ‰¾åˆ°å…±åŒè§†é¢‘
    common_videos = set(gemini_results.keys()) & set(gpt41_results.keys()) & set(ground_truth.keys())
    print(f"ğŸ“¹ å…±åŒè§†é¢‘: {len(common_videos)} ä¸ª")
    
    if len(common_videos) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å…±åŒçš„è§†é¢‘è¿›è¡Œå¯¹æ¯”")
        return
    
    # åˆ›å»ºå­é›†æ•°æ®
    gemini_subset = {vid: gemini_results[vid] for vid in common_videos}
    gpt41_subset = {vid: gpt41_results[vid] for vid in common_videos}
    gt_subset = {vid: ground_truth[vid] for vid in common_videos}
    
    print(f"\nğŸ¯ å¯¹æ¯”åˆ†æ ({len(common_videos)} ä¸ªè§†é¢‘):")
    print("-" * 50)
    
    # è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹
    y_true_gemini, y_pred_gemini, details_gemini = evaluate_model_results(gemini_subset, gt_subset, "Gemini")
    y_true_gpt41, y_pred_gpt41, details_gpt41 = evaluate_model_results(gpt41_subset, gt_subset, "GPT-4.1")
    
    # è®¡ç®—æŒ‡æ ‡
    metrics_gemini = calculate_metrics(y_true_gemini, y_pred_gemini)
    metrics_gpt41 = calculate_metrics(y_true_gpt41, y_pred_gpt41)
    
    # æ‰“å°è¯¦ç»†ç»“æœ
    print("ğŸ¤– Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt:")
    print(f"  ğŸ“Š ç²¾ç¡®åº¦ (Precision): {metrics_gemini['precision']:.3f}")
    print(f"  ğŸ“Š å¬å›ç‡ (Recall): {metrics_gemini['recall']:.3f}")
    print(f"  ğŸ“Š F1åˆ†æ•°: {metrics_gemini['f1']:.3f}")
    print(f"  ğŸ“Š å‡†ç¡®ç‡ (Accuracy): {metrics_gemini['accuracy']:.3f}")
    print(f"  ğŸ“Š ç‰¹å¼‚æ€§ (Specificity): {metrics_gemini['specificity']:.3f}")
    print(f"  ğŸ“Š æ··æ·†çŸ©é˜µ: TP={metrics_gemini['tp']}, FP={metrics_gemini['fp']}, FN={metrics_gemini['fn']}, TN={metrics_gemini['tn']}")
    
    print("\nğŸ¤– GPT-4.1 + å¹³è¡¡ç‰ˆPrompt:")
    print(f"  ğŸ“Š ç²¾ç¡®åº¦ (Precision): {metrics_gpt41['precision']:.3f}")
    print(f"  ğŸ“Š å¬å›ç‡ (Recall): {metrics_gpt41['recall']:.3f}")
    print(f"  ğŸ“Š F1åˆ†æ•°: {metrics_gpt41['f1']:.3f}")
    print(f"  ğŸ“Š å‡†ç¡®ç‡ (Accuracy): {metrics_gpt41['accuracy']:.3f}")
    print(f"  ğŸ“Š ç‰¹å¼‚æ€§ (Specificity): {metrics_gpt41['specificity']:.3f}")
    print(f"  ğŸ“Š æ··æ·†çŸ©é˜µ: TP={metrics_gpt41['tp']}, FP={metrics_gpt41['fp']}, FN={metrics_gpt41['fn']}, TN={metrics_gpt41['tn']}")
    
    # å¯¹æ¯”åˆ†æ
    print(f"\nâš–ï¸ æ€§èƒ½å·®å¼‚åˆ†æ:")
    precision_diff = metrics_gemini['precision'] - metrics_gpt41['precision']
    recall_diff = metrics_gemini['recall'] - metrics_gpt41['recall']
    f1_diff = metrics_gemini['f1'] - metrics_gpt41['f1']
    accuracy_diff = metrics_gemini['accuracy'] - metrics_gpt41['accuracy']
    
    print(f"  ğŸ¯ ç²¾ç¡®åº¦å·®å¼‚: {precision_diff:+.3f} {'(Geminiæ›´å¥½)' if precision_diff > 0 else '(GPT-4.1æ›´å¥½)' if precision_diff < 0 else '(ç›¸ç­‰)'}")
    print(f"  ğŸ¯ å¬å›ç‡å·®å¼‚: {recall_diff:+.3f} {'(Geminiæ›´å¥½)' if recall_diff > 0 else '(GPT-4.1æ›´å¥½)' if recall_diff < 0 else '(ç›¸ç­‰)'}")
    print(f"  ğŸ¯ F1åˆ†æ•°å·®å¼‚: {f1_diff:+.3f} {'(Geminiæ›´å¥½)' if f1_diff > 0 else '(GPT-4.1æ›´å¥½)' if f1_diff < 0 else '(ç›¸ç­‰)'}")
    print(f"  ğŸ¯ å‡†ç¡®ç‡å·®å¼‚: {accuracy_diff:+.3f} {'(Geminiæ›´å¥½)' if accuracy_diff > 0 else '(GPT-4.1æ›´å¥½)' if accuracy_diff < 0 else '(ç›¸ç­‰)'}")
    
    # åˆ†æåˆ†æ­§æ¡ˆä¾‹
    disagreements = analyze_disagreements(details_gemini, details_gpt41)
    consistent_count = len(common_videos) - len(disagreements)
    consistency_rate = consistent_count / len(common_videos) * 100
    
    print(f"\nğŸ“‹ æ¨¡å‹ä¸€è‡´æ€§åˆ†æ:")
    print(f"  âœ… ä¸€è‡´é¢„æµ‹: {consistent_count}/{len(common_videos)} ({consistency_rate:.1f}%)")
    print(f"  âŒ åˆ†æ­§æ¡ˆä¾‹: {len(disagreements)} ä¸ª")
    
    # æ˜¾ç¤ºåˆ†æ­§æ¡ˆä¾‹è¯¦æƒ…
    if disagreements:
        print(f"\nğŸ” åˆ†æ­§æ¡ˆä¾‹è¯¦æƒ…:")
        print(f"{'Video ID':<15} {'Ground Truth':<15} {'Gemini':<20} {'GPT-4.1':<20} {'è°å¯¹äº†':<10}")
        print("-" * 85)
        
        for disagreement in disagreements:
            who_correct = ""
            if disagreement['gemini_correct'] and not disagreement['gpt41_correct']:
                who_correct = "Gemini"
            elif disagreement['gpt41_correct'] and not disagreement['gemini_correct']:
                who_correct = "GPT-4.1"
            elif disagreement['gemini_correct'] and disagreement['gpt41_correct']:
                who_correct = "éƒ½å¯¹"
            else:
                who_correct = "éƒ½é”™"
            
            print(f"{disagreement['video_id']:<15} {disagreement['ground_truth']:<15} {disagreement['gemini_pred']:<20} {disagreement['gpt41_pred']:<20} {who_correct:<10}")
    
    # åˆ›å»ºå¯è§†åŒ–
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # æ··æ·†çŸ©é˜µå›¾
    confusion_plot_path = f"result/gemini_vs_gpt41_confusion_matrix_{timestamp}.png"
    create_confusion_matrix_plot(metrics_gemini['confusion_matrix'], metrics_gpt41['confusion_matrix'], confusion_plot_path)
    
    # æŒ‡æ ‡å¯¹æ¯”å›¾
    metrics_plot_path = f"result/gemini_vs_gpt41_metrics_comparison_{timestamp}.png"
    create_metrics_comparison_plot(metrics_gemini, metrics_gpt41, metrics_plot_path)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    comparison_results = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_videos': len(common_videos),
        'gemini_metrics': {k: float(v) if isinstance(v, (np.integer, np.floating)) else v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics_gemini.items()},
        'gpt41_metrics': {k: float(v) if isinstance(v, (np.integer, np.floating)) else v.tolist() if isinstance(v, np.ndarray) else v for k, v in metrics_gpt41.items()},
        'consistency_rate': consistency_rate,
        'disagreements': disagreements,
        'common_videos': sorted(list(common_videos)),
        'summary': {
            'better_precision': 'Gemini' if precision_diff > 0 else 'GPT-4.1' if precision_diff < 0 else 'Tie',
            'better_recall': 'Gemini' if recall_diff > 0 else 'GPT-4.1' if recall_diff < 0 else 'Tie',
            'better_f1': 'Gemini' if f1_diff > 0 else 'GPT-4.1' if f1_diff < 0 else 'Tie',
            'better_accuracy': 'Gemini' if accuracy_diff > 0 else 'GPT-4.1' if accuracy_diff < 0 else 'Tie'
        }
    }
    
    output_file = f"result/gemini_vs_gpt41_49videos_comparison_{timestamp}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(comparison_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å®Œæ•´å¯¹æ¯”ç»“æœå·²ä¿å­˜:")
    print(f"  ğŸ“Š è¯¦ç»†æ•°æ®: {output_file}")
    print(f"  ğŸ“ˆ æ··æ·†çŸ©é˜µå›¾: {confusion_plot_path}")
    print(f"  ğŸ“Š æŒ‡æ ‡å¯¹æ¯”å›¾: {metrics_plot_path}")
    
    # æ€»ç»“
    print(f"\nğŸ¯ æ€»ç»“:")
    winner_count = {'Gemini': 0, 'GPT-4.1': 0, 'Tie': 0}
    for metric in ['better_precision', 'better_recall', 'better_f1', 'better_accuracy']:
        winner_count[comparison_results['summary'][metric]] += 1
    
    print(f"  ğŸ† å„æŒ‡æ ‡èƒœè´Ÿ: Gemini {winner_count['Gemini']} : {winner_count['GPT-4.1']} GPT-4.1 (å¹³å±€: {winner_count['Tie']})")
    
    if winner_count['Gemini'] > winner_count['GPT-4.1']:
        print(f"  ğŸ‰ æ€»ä½“è¡¨ç°: Gemini 2.0 Flash æ›´ä¼˜")
    elif winner_count['GPT-4.1'] > winner_count['Gemini']:
        print(f"  ğŸ‰ æ€»ä½“è¡¨ç°: GPT-4.1 æ›´ä¼˜")
    else:
        print(f"  ğŸ¤ æ€»ä½“è¡¨ç°: ä¸¤æ¨¡å‹è¡¨ç°ç›¸å½“")
    
    print(f"\nâœ… 49è§†é¢‘å¯¹æ¯”åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()