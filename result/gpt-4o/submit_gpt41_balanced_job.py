#!/usr/bin/env python3
"""
Azure ML GPT-4.1 Balanced Ghost Probing Job Submission
ä½¿ç”¨æ‚¨çš„Azure MLçŽ¯å¢ƒæäº¤GPT-4.1å¹³è¡¡ç‰ˆé¬¼æŽ¢å¤´æ£€æµ‹ä½œä¸š
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path

# è®¾ç½®Azure MLçŽ¯å¢ƒå˜é‡
os.environ["AZURE_SUBSCRIPTION_ID"] = "0d3f39ba-7349-4bd7-8122-649ff18f0a4a"
os.environ["AZURE_RESOURCE_GROUP"] = "video-llama2-ghost-probing-rg"
os.environ["AZURE_WORKSPACE_NAME"] = "video-llama2-ghost-probing-ws"

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GPT41BalancedJobSubmitter:
    def __init__(self):
        self.subscription_id = "0d3f39ba-7349-4bd7-8122-649ff18f0a4a"
        self.resource_group = "video-llama2-ghost-probing-rg"
        self.workspace_name = "video-llama2-ghost-probing-ws"
        self.compute_name = "gpu-cluster-a100"  # é»˜è®¤è®¡ç®—é›†ç¾¤å
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        logger.info(f"åˆå§‹åŒ–Azure MLå®¢æˆ·ç«¯:")
        logger.info(f"  è®¢é˜…ID: {self.subscription_id}")
        logger.info(f"  èµ„æºç»„: {self.resource_group}")
        logger.info(f"  å·¥ä½œåŒº: {self.workspace_name}")
    
    def check_environment(self):
        """æ£€æŸ¥æœ¬åœ°çŽ¯å¢ƒ"""
        logger.info("ðŸ” æ£€æŸ¥æœ¬åœ°çŽ¯å¢ƒ...")
        
        # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
        required_files = [
            "batch_ghost_probing_gpt41_balanced.py",
            "azure_ghost_probing_env.yml",
            "result/groundtruth_labels.csv"
        ]
        
        missing_files = []
        for file_path in required_files:
            if not os.path.exists(file_path):
                missing_files.append(file_path)
        
        if missing_files:
            logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
            return False
        
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        video_folder = Path("DADA-2000-videos")
        if not video_folder.exists():
            logger.error("âŒ è§†é¢‘æ–‡ä»¶å¤¹ä¸å­˜åœ¨: DADA-2000-videos")
            return False
        
        # ç»Ÿè®¡ç›®æ ‡è§†é¢‘
        target_videos = []
        for i in range(1, 6):  # images_1_* åˆ° images_5_*
            pattern = f"images_{i}_*.avi"
            videos = sorted(video_folder.glob(pattern))
            target_videos.extend(videos)
            if len(target_videos) >= 100:
                break
        
        target_videos = target_videos[:100]
        logger.info(f"âœ… æ‰¾åˆ° {len(target_videos)} ä¸ªç›®æ ‡è§†é¢‘")
        
        if len(target_videos) < 100:
            logger.warning(f"âš ï¸ è§†é¢‘æ•°é‡ä¸è¶³100ä¸ª")
        
        return True
    
    def check_azure_credentials(self):
        """æ£€æŸ¥Azureå‡­æ®"""
        logger.info("ðŸ”‘ æ£€æŸ¥Azureå‡­æ®...")
        
        try:
            from azure.identity import DefaultAzureCredential
            from azure.ai.ml import MLClient
            
            credential = DefaultAzureCredential()
            ml_client = MLClient(
                credential=credential,
                subscription_id=self.subscription_id,
                resource_group_name=self.resource_group,
                workspace_name=self.workspace_name
            )
            
            # æµ‹è¯•è¿žæŽ¥
            workspace = ml_client.workspaces.get(self.workspace_name)
            logger.info(f"âœ… æˆåŠŸè¿žæŽ¥åˆ°Azure MLå·¥ä½œåŒº: {workspace.name}")
            
            # æ£€æŸ¥è®¡ç®—èµ„æº
            try:
                compute = ml_client.compute.get(self.compute_name)
                logger.info(f"âœ… æ‰¾åˆ°è®¡ç®—èµ„æº: {compute.name} ({compute.type})")
            except Exception as e:
                logger.warning(f"âš ï¸ è®¡ç®—èµ„æº {self.compute_name} ä¸å­˜åœ¨: {e}")
                logger.info("å°†ä½¿ç”¨é»˜è®¤è®¡ç®—èµ„æºæˆ–åˆ›å»ºæ–°çš„")
            
            return ml_client
            
        except Exception as e:
            logger.error(f"âŒ Azureè®¤è¯å¤±è´¥: {e}")
            return None
    
    def create_job_config(self):
        """åˆ›å»ºä½œä¸šé…ç½®"""
        logger.info("ðŸ“ åˆ›å»ºä½œä¸šé…ç½®...")
        
        job_config = {
            "$schema": "https://azuremlschemas.azureedge.net/latest/commandJob.schema.json",
            "type": "command",
            "display_name": f"gpt41-balanced-ghost-probing-{self.timestamp}",
            "experiment_name": "ghost_probing_gpt41_balanced",
            "description": "Ghost probing detection using GPT-4.1 balanced prompt on 100 DADA videos",
            "code": ".",
            "environment": {
                "conda_file": "azure_ghost_probing_env.yml",
                "image": "mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu20.04:latest"
            },
            "compute": self.compute_name,
            "command": "python batch_ghost_probing_gpt41_balanced.py --video-folder ./DADA-2000-videos --output-folder ./outputs --groundtruth-file ./result/groundtruth_labels.csv --max-videos 100",
            "environment_variables": {
                "AZURE_OPENAI_API_KEY": "${{secrets.AZURE_OPENAI_API_KEY}}",
                "AZURE_OPENAI_ENDPOINT": "${{secrets.AZURE_OPENAI_ENDPOINT}}",
                "VISION_API_TYPE": "Azure",
                "VISION_DEPLOYMENT_NAME": "gpt-4.1",
                "VISION_ENDPOINT": "${{secrets.AZURE_OPENAI_ENDPOINT}}",
                "OPENAI_API_VERSION": "2024-02-15-preview",
                "AUDIO_API_TYPE": "Azure",
                "AZURE_WHISPER_KEY": "${{secrets.AZURE_WHISPER_KEY}}",
                "AZURE_WHISPER_DEPLOYMENT": "${{secrets.AZURE_WHISPER_DEPLOYMENT}}",
                "AZURE_WHISPER_ENDPOINT": "${{secrets.AZURE_WHISPER_ENDPOINT}}",
                "PYTHONPATH": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-cluster-a100/code",
                "OMP_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "settings": {
                "timeout": 14400,  # 4å°æ—¶
                "priority": "high"
            },
            "tags": {
                "model": "gpt-4.1-balanced",
                "task": "ghost_probing_detection",
                "dataset": "DADA-2000",
                "video_count": "100",
                "timestamp": self.timestamp
            }
        }
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_file = f"job_config_{self.timestamp}.yml"
        import yaml
        with open(config_file, 'w') as f:
            yaml.dump(job_config, f, default_flow_style=False)
        
        logger.info(f"âœ… ä½œä¸šé…ç½®å·²ä¿å­˜: {config_file}")
        return job_config
    
    def submit_job(self, ml_client):
        """æäº¤ä½œä¸šåˆ°Azure ML"""
        logger.info("ðŸš€ æäº¤ä½œä¸šåˆ°Azure ML...")
        
        try:
            from azure.ai.ml import command
            from azure.ai.ml.entities import Environment
            
            # åˆ›å»ºçŽ¯å¢ƒ
            environment = Environment(
                name=f"ghost-probing-gpt41-{self.timestamp}",
                description="Ghost probing detection environment with GPT-4.1 support",
                conda_file="azure_ghost_probing_env.yml",
                image="mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu20.04:latest"
            )
            
            # åˆ›å»ºå¹¶æäº¤çŽ¯å¢ƒ
            logger.info("ðŸ“¦ åˆ›å»ºçŽ¯å¢ƒ...")
            environment = ml_client.environments.create_or_update(environment)
            
            # åˆ›å»ºå‘½ä»¤ä½œä¸š
            job = command(
                name=f"gpt41-balanced-{self.timestamp}",
                display_name=f"GPT-4.1 Balanced Ghost Probing - {self.timestamp}",
                description="Process 100 DADA videos for ghost probing detection using balanced GPT-4.1 prompt",
                code=".",
                command="python batch_ghost_probing_gpt41_balanced.py --video-folder ./DADA-2000-videos --output-folder ./outputs --groundtruth-file ./result/groundtruth_labels.csv --max-videos 100",
                environment=environment,
                compute=self.compute_name,
                experiment_name="ghost_probing_gpt41_balanced",
                tags={
                    "model": "gpt-4.1-balanced",
                    "task": "ghost_probing_detection", 
                    "dataset": "DADA-2000",
                    "video_count": "100",
                    "timestamp": self.timestamp
                }
            )
            
            # è®¾ç½®çŽ¯å¢ƒå˜é‡
            job.environment_variables = {
                "AZURE_OPENAI_API_KEY": os.getenv("AZURE_OPENAI_API_KEY", ""),
                "AZURE_OPENAI_ENDPOINT": os.getenv("AZURE_OPENAI_ENDPOINT", ""),
                "VISION_API_TYPE": "Azure",
                "VISION_DEPLOYMENT_NAME": "gpt-4.1",
                "VISION_ENDPOINT": os.getenv("AZURE_OPENAI_ENDPOINT", ""),
                "OPENAI_API_VERSION": "2024-02-15-preview",
                "AUDIO_API_TYPE": "Azure",
                "AZURE_WHISPER_KEY": os.getenv("AZURE_WHISPER_KEY", ""),
                "AZURE_WHISPER_DEPLOYMENT": os.getenv("AZURE_WHISPER_DEPLOYMENT", ""),
                "AZURE_WHISPER_ENDPOINT": os.getenv("AZURE_WHISPER_ENDPOINT", ""),
                "PYTHONPATH": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/gpu-cluster-a100/code",
                "OMP_NUM_THREADS": "1",
                "CUDA_VISIBLE_DEVICES": "0"
            }
            
            # æäº¤ä½œä¸š
            submitted_job = ml_client.jobs.create_or_update(job)
            
            logger.info(f"âœ… ä½œä¸šå·²æäº¤æˆåŠŸ!")
            logger.info(f"   ä½œä¸šåç§°: {submitted_job.name}")
            logger.info(f"   ä½œä¸šçŠ¶æ€: {submitted_job.status}")
            logger.info(f"   Studioé“¾æŽ¥: {submitted_job.studio_url}")
            
            # ä¿å­˜ä½œä¸šä¿¡æ¯
            job_info = {
                "job_name": submitted_job.name,
                "job_id": submitted_job.id,
                "status": submitted_job.status,
                "studio_url": submitted_job.studio_url,
                "timestamp": self.timestamp,
                "subscription_id": self.subscription_id,
                "resource_group": self.resource_group,
                "workspace_name": self.workspace_name
            }
            
            with open(f"job_info_{self.timestamp}.json", "w") as f:
                json.dump(job_info, f, indent=2)
            
            return submitted_job
            
        except Exception as e:
            logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
            return None
    
    def monitor_job(self, ml_client, job_name):
        """ç›‘æŽ§ä½œä¸šçŠ¶æ€"""
        logger.info(f"ðŸ‘ï¸ å¼€å§‹ç›‘æŽ§ä½œä¸š: {job_name}")
        
        try:
            import time
            
            while True:
                job = ml_client.jobs.get(job_name)
                status = job.status
                
                logger.info(f"ðŸ“Š ä½œä¸šçŠ¶æ€: {status}")
                
                if status in ["Completed", "Failed", "Canceled"]:
                    if status == "Completed":
                        logger.info("ðŸŽ‰ ä½œä¸šæˆåŠŸå®Œæˆ!")
                        self.download_results(ml_client, job_name)
                    else:
                        logger.error(f"âŒ ä½œä¸šç»“æŸ: {status}")
                    break
                
                # ç­‰å¾…60ç§’åŽå†æ£€æŸ¥
                time.sleep(60)
                
        except KeyboardInterrupt:
            logger.info("â¹ï¸ ç›‘æŽ§å·²ä¸­æ–­")
        except Exception as e:
            logger.error(f"âŒ ç›‘æŽ§å¤±è´¥: {e}")
    
    def download_results(self, ml_client, job_name):
        """ä¸‹è½½ä½œä¸šç»“æžœ"""
        logger.info("ðŸ“¥ ä¸‹è½½ä½œä¸šç»“æžœ...")
        
        try:
            output_dir = f"./azure_outputs/{job_name}"
            os.makedirs(output_dir, exist_ok=True)
            
            ml_client.jobs.download(
                name=job_name,
                download_path=output_dir
            )
            
            logger.info(f"âœ… ç»“æžœå·²ä¸‹è½½åˆ°: {output_dir}")
            
            # æŸ¥æ‰¾ç»“æžœæ–‡ä»¶
            result_files = list(Path(output_dir).rglob("*.json")) + list(Path(output_dir).rglob("*.csv"))
            if result_files:
                logger.info("ðŸ“„ æ‰¾åˆ°ç»“æžœæ–‡ä»¶:")
                for file in result_files:
                    logger.info(f"   {file}")
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ç»“æžœå¤±è´¥: {e}")
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æäº¤å’Œç›‘æŽ§æµæ°´çº¿"""
        logger.info("ðŸš€ å¼€å§‹GPT-4.1 Balanced Ghost Probingä½œä¸šæäº¤æµæ°´çº¿")
        
        # 1. æ£€æŸ¥æœ¬åœ°çŽ¯å¢ƒ
        if not self.check_environment():
            logger.error("âŒ æœ¬åœ°çŽ¯å¢ƒæ£€æŸ¥å¤±è´¥")
            return False
        
        # 2. æ£€æŸ¥Azureå‡­æ®
        ml_client = self.check_azure_credentials()
        if ml_client is None:
            logger.error("âŒ Azureå‡­æ®æ£€æŸ¥å¤±è´¥")
            return False
        
        # 3. åˆ›å»ºä½œä¸šé…ç½®
        job_config = self.create_job_config()
        
        # 4. æäº¤ä½œä¸š
        submitted_job = self.submit_job(ml_client)
        if submitted_job is None:
            logger.error("âŒ ä½œä¸šæäº¤å¤±è´¥")
            return False
        
        # 5. ç›‘æŽ§ä½œä¸š
        self.monitor_job(ml_client, submitted_job.name)
        
        logger.info("âœ… æµæ°´çº¿å®Œæˆ")
        return True

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Submit GPT-4.1 Balanced Ghost Probing Job')
    parser.add_argument('--compute-name', default='gpu-cluster-a100', help='è®¡ç®—é›†ç¾¤åç§°')
    parser.add_argument('--no-monitor', action='store_true', help='æäº¤åŽä¸ç›‘æŽ§')
    parser.add_argument('--check-only', action='store_true', help='ä»…æ£€æŸ¥çŽ¯å¢ƒä¸æäº¤')
    
    args = parser.parse_args()
    
    submitter = GPT41BalancedJobSubmitter()
    submitter.compute_name = args.compute_name
    
    if args.check_only:
        logger.info("ðŸ” ä»…æ£€æŸ¥çŽ¯å¢ƒ...")
        env_ok = submitter.check_environment()
        ml_client = submitter.check_azure_credentials()
        if env_ok and ml_client:
            logger.info("âœ… çŽ¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥æäº¤ä½œä¸š")
        else:
            logger.error("âŒ çŽ¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return
    
    if args.no_monitor:
        logger.info("ðŸš€ æäº¤ä½œä¸šä½†ä¸ç›‘æŽ§...")
        if submitter.check_environment():
            ml_client = submitter.check_azure_credentials()
            if ml_client:
                submitter.submit_job(ml_client)
    else:
        submitter.run_complete_pipeline()

if __name__ == "__main__":
    main()