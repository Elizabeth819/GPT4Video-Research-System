#!/usr/bin/env python3
"""
æäº¤WiseADè§†é¢‘æ¨ç†ä½œä¸šåˆ°Azure ML
åŸºäºYOLOçš„è‡ªåŠ¨é©¾é©¶è§†é¢‘åˆ†æ - ä½ä¼˜å…ˆçº§A100ç‰ˆ
"""

import os
import sys
import tempfile
import shutil
from azure.ai.ml import MLClient
from azure.ai.ml import command
from azure.identity import DefaultAzureCredential
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_wisead_code_package():
    """åˆ›å»ºWiseADä»£ç åŒ…"""
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="wisead_lowpri_job_")
    logger.info(f"åˆ›å»ºä¸´æ—¶ä»£ç ç›®å½•: {temp_dir}")
    
    # éœ€è¦çš„æ–‡ä»¶åˆ—è¡¨
    required_files = [
        "wisead_video_inference.py",
        "wisead_config.json"
    ]
    
    # å¤åˆ¶å¿…è¦æ–‡ä»¶
    for file in required_files:
        if os.path.exists(file):
            shutil.copy2(file, temp_dir)
            logger.info(f"å¤åˆ¶æ–‡ä»¶: {file}")
        else:
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file}")
    
    return temp_dir

def submit_wisead_job():
    """æäº¤WiseADæ¨ç†ä½œä¸š"""
    
    logger.info("ğŸš€ æäº¤WiseADè§†é¢‘æ¨ç†ä½œä¸šåˆ°Azure ML (ä½ä¼˜å…ˆçº§A100é›†ç¾¤)")
    
    temp_dir = None
    try:
        # åˆ›å»ºä»£ç åŒ…
        temp_dir = create_wisead_code_package()
        
        # Azure MLå®¢æˆ·ç«¯
        credential = DefaultAzureCredential()
        
        # ä½¿ç”¨WiseADå·¥ä½œåŒº
        ml_client = MLClient(
            credential=credential,
            subscription_id="0d3f39ba-7349-4bd7-8122-649ff18f0a4a",
            resource_group_name="wisead-rg",
            workspace_name="wisead-ml-workspace"
        )
        
        logger.info("âœ… Azure MLå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        
        # ä½¿ç”¨Azureå®˜æ–¹ç¯å¢ƒ
        official_env = "azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10"
        
        # åˆ›å»ºä½œä¸š
        logger.info("ğŸ¯ åˆ›å»ºWiseADè§†é¢‘æ¨ç†ä½œä¸š (ä½ä¼˜å…ˆçº§A100)...")
        
        job = command(
            display_name="WiseAD_Video_Inference_A100_LowPri_YOLOv8",
            description="åŸºäºYOLOv8çš„WiseADè‡ªåŠ¨é©¾é©¶è§†é¢‘åˆ†æç³»ç»Ÿ - ä½ä¼˜å…ˆçº§A100 GPUç‰ˆ",
            code=temp_dir,
            command="python wisead_video_inference.py --config wisead_config.json",
            environment=official_env,
            compute="wisead-a100-lowpri",
            environment_variables={
                "PYTORCH_CUDA_ALLOC_CONF": "max_split_size_mb:1024",
                "CUDA_VISIBLE_DEVICES": "0",
                "CUDA_LAUNCH_BLOCKING": "1",
                "TORCH_CUDA_ARCH_LIST": "8.0",
                "NVIDIA_VISIBLE_DEVICES": "all",
                "AZURE_STORAGE_CONNECTION_STRING": "DefaultEndpointsProtocol=https;EndpointSuffix=core.windows.net;AccountName=wiseadmlstorage55c2e74d3;AccountKey=26Y8W75xN4RLuTodwDXt6Lz8yPKCRF/+kfOiVaQzD6w+Lhz+KheSI5AwsnEp0F436D016m+nSDXt+AStRZznaQ==;BlobEndpoint=https://wiseadmlstorage55c2e74d3.blob.core.windows.net/;FileEndpoint=https://wiseadmlstorage55c2e74d3.file.core.windows.net/;QueueEndpoint=https://wiseadmlstorage55c2e74d3.queue.core.windows.net/;TableEndpoint=https://wiseadmlstorage55c2e74d3.table.core.windows.net/"
            },
            experiment_name="wisead-a100-lowpri-inference",
            tags={
                "model": "YOLOv8s",
                "task": "autonomous-driving-video-analysis", 
                "framework": "WiseAD",
                "environment": "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10",
                "compute": "wisead-a100-lowpri",
                "gpu": "A100-LowPriority",
                "optimization": "batch-processing",
                "version": "2.1",
                "cost_optimized": "true"
            }
        )
        
        # æäº¤ä½œä¸š
        logger.info("ğŸ“¤ æäº¤ä½œä¸šåˆ°Azure ML ä½ä¼˜å…ˆçº§A100é›†ç¾¤...")
        returned_job = ml_client.create_or_update(job)
        
        logger.info("âœ… WiseAD ä½ä¼˜å…ˆçº§A100ä½œä¸šæäº¤æˆåŠŸ!")
        logger.info(f"ğŸ”— ä½œä¸šURL: {returned_job.services['Studio'].endpoint}")
        logger.info(f"ğŸ†” ä½œä¸šID: {returned_job.name}")
        
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ‰ WiseADè§†é¢‘æ¨ç†ä½œä¸šå·²å¯åŠ¨! (ä½ä¼˜å…ˆçº§A100ç‰ˆ)")
        logger.info("ğŸ“‹ ä½œä¸šè¯¦æƒ…:")
        logger.info(f"   - æ¨¡å‹: YOLOv8s (ä¼˜åŒ–ç‰ˆï¼Œå¹³è¡¡é€Ÿåº¦å’Œç²¾åº¦)")
        logger.info(f"   - ç¡¬ä»¶: A100 GPU (80GBæ˜¾å­˜) - ä½ä¼˜å…ˆçº§")
        logger.info(f"   - ç¯å¢ƒ: Azure ML PyTorch 1.13")
        logger.info(f"   - ä¼˜åŒ–: æ‰¹å¤„ç†æ¨ç†ï¼ŒCUDAä¼˜åŒ–")
        logger.info(f"   - æˆæœ¬: ä½ä¼˜å…ˆçº§å®šä»· (çº¦60-80%æŠ˜æ‰£)")
        logger.info(f"   - ä»»åŠ¡: è‡ªåŠ¨é©¾é©¶è§†é¢‘å®‰å…¨åˆ†æ")
        logger.info(f"   - åˆ†æå†…å®¹: è½¦è¾†æ£€æµ‹ã€è¡Œäººæ£€æµ‹ã€äº¤é€šå®‰å…¨è¯„ä¼°")
        logger.info(f"   - æ€§èƒ½æå‡: æ‰¹é‡å¤„ç†ï¼Œé«˜é¢‘åˆ†æï¼ŒGPUåŠ é€Ÿ")
        logger.info("â³ ä½œä¸šå°†è‡ªåŠ¨å®‰è£…ä¾èµ–ã€ä¸‹è½½æ¨¡å‹å¹¶å¼€å§‹æ¨ç†...")
        logger.info("ğŸ’° ä½ä¼˜å…ˆçº§A100 GPUæä¾›æˆæœ¬ä¼˜åŒ–çš„é«˜æ€§èƒ½è®¡ç®—!")
        logger.info("âš ï¸  æ³¨æ„: ä½ä¼˜å…ˆçº§ä½œä¸šå¯èƒ½ä¼šè¢«æŠ¢å ï¼Œä½†æˆæœ¬æ›´ä½")
        
        return returned_job.name
        
    except Exception as e:
        logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return None
    
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            logger.info(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")

if __name__ == "__main__":
    job_id = submit_wisead_job()
    if job_id:
        print(f"\nğŸŠ æˆåŠŸ! WiseAD ä½ä¼˜å…ˆçº§A100ä½œä¸šID: {job_id}")
        print("è¯·åœ¨Azure ML Studioä¸­ç›‘æ§ä½œä¸šè¿›åº¦")
        print("ğŸ”— Azure ML Studio: https://ml.azure.com")
        print(f"ğŸ’° ä½ä¼˜å…ˆçº§A100 GPUä¸ºæ‚¨æä¾›æˆæœ¬ä¼˜åŒ–çš„å¼ºåŠ²æ€§èƒ½!")
        print(f"âš ï¸  æç¤º: ä½œä¸šå¯èƒ½ä¼šè¢«é«˜ä¼˜å…ˆçº§ä½œä¸šæŠ¢å ï¼Œä½†æˆæœ¬èŠ‚çœ60-80%")
    else:
        print("\nâŒ WiseADä½œä¸šæäº¤å¤±è´¥")
        sys.exit(1) 