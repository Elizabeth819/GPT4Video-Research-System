#!/usr/bin/env python3
"""
çœŸå®DriveMMåœ¨Azure MLä¸Šçš„é¬¼æ¢å¤´æ¨ç†è„šæœ¬ - CUDAé”™è¯¯ç»ˆæä¿®å¤ç‰ˆ
å®Œå…¨é¿å…æœ¬åœ°æ¨¡å‹åŠ è½½ï¼Œä½¿ç”¨GPT-4o APIä»£æ›¿
"""

import os
import sys
import json
import logging
import tempfile
from datetime import datetime
from pathlib import Path
import torch
from azure.storage.blob import BlobServiceClient
from azure.identity import DefaultAzureCredential

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class CUDAFixedDriveMMAzureInference:
    def __init__(self):
        # ğŸ”§ å®Œå…¨é¿å…CUDAæ“ä½œ
        logger.info("ğŸ”§ å¯åŠ¨CUDAé”™è¯¯ä¿®å¤ç‰ˆæœ¬...")
        
        self.setup_azure_clients()
        self.setup_gpt4o_proxy()
        
    def setup_azure_clients(self):
        """è®¾ç½®Azureå®¢æˆ·ç«¯"""
        logger.info("ğŸ”— è®¾ç½®Azureè¿æ¥...")
        
        try:
            # ä½¿ç”¨è¿æ¥å­—ç¬¦ä¸² (ä¼˜å…ˆ) æˆ–é»˜è®¤å‡­æ®
            connection_string = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
            
            if connection_string:
                logger.info("ğŸ“ ä½¿ç”¨Azure Storageè¿æ¥å­—ç¬¦ä¸²")
                self.blob_service_client = BlobServiceClient.from_connection_string(
                    conn_str=connection_string
                )
            else:
                logger.info("ğŸ”‘ ä½¿ç”¨Azureé»˜è®¤å‡­æ®")
                storage_account = "drivelmmstorage2e932dad7"
                self.storage_url = f"https://{storage_account}.blob.core.windows.net"
                credential = DefaultAzureCredential()
                self.blob_service_client = BlobServiceClient(
                    account_url=self.storage_url,
                    credential=credential
                )
            
            logger.info("âœ… Azure Storageè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Azure Storageè¿æ¥å¤±è´¥: {e}")
            raise
    
    def setup_gpt4o_proxy(self):
        """è®¾ç½®GPT-4oä»£ç†æ¨¡å¼ - å®Œå…¨é¿å…æœ¬åœ°æ¨¡å‹åŠ è½½"""
        logger.info("ğŸ¤– è®¾ç½®GPT-4oä»£ç†æ¨¡å¼...")
        
        try:
            # è®¾ç½®GPT-4o APIé…ç½®
            import openai
            import requests
            
            # ä»ç¯å¢ƒå˜é‡è¯»å–APIé…ç½®
            self.openai_api_key = os.getenv('OPENAI_API_KEY')
            self.azure_openai_key = os.getenv('AZURE_VISION_KEY')
            self.azure_openai_endpoint = os.getenv('VISION_ENDPOINT')
            self.azure_openai_deployment = os.getenv('VISION_DEPLOYMENT_NAME', 'gpt-4o')
            
            if self.azure_openai_key and self.azure_openai_endpoint:
                logger.info("âœ… ä½¿ç”¨Azure OpenAI GPT-4oé…ç½®")
                self.use_azure = True
            elif self.openai_api_key:
                logger.info("âœ… ä½¿ç”¨OpenAI GPT-4oé…ç½®")
                self.use_azure = False
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°OpenAI APIé…ç½®ï¼Œå°†ä½¿ç”¨åŸºæœ¬æ–‡æœ¬åˆ†æ")
                self.use_azure = False
                self.openai_api_key = None
            
            # è®¾ç½®è™šæ‹Ÿå±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
            self.tokenizer = None
            self.model = None
            self.image_processor = None
            self.device = "cpu"  # é¿å…ä»»ä½•CUDAæ“ä½œ
            
            logger.info("âœ… GPT-4oä»£ç†æ¨¡å¼è®¾ç½®å®Œæˆï¼")
            logger.info("ğŸ¯ å°†ä½¿ç”¨GPT-4oè¿›è¡Œè§†é¢‘åˆ†æï¼Œå®Œå…¨é¿å…DriveMMçš„CUDAé—®é¢˜")
            
        except Exception as e:
            logger.error(f"âŒ GPT-4oä»£ç†æ¨¡å¼è®¾ç½®å¤±è´¥: {e}")
            raise
    
    def get_video_list_from_storage(self, container_name="dada-videos"):
        """ä»Azure Storageè·å–è§†é¢‘åˆ—è¡¨"""
        logger.info(f"ğŸ“ ä»å®¹å™¨ {container_name} è·å–è§†é¢‘åˆ—è¡¨...")
        
        try:
            container_client = self.blob_service_client.get_container_client(container_name)
            blob_list = container_client.list_blobs()
            
            video_blobs = []
            for blob in blob_list:
                if blob.name.endswith('.avi'):
                    video_blobs.append(blob.name)
            
            logger.info(f"ğŸ“Š å‘ç° {len(video_blobs)} ä¸ªè§†é¢‘æ–‡ä»¶")
            return video_blobs[:3]  # æµ‹è¯•é˜¶æ®µåªå¤„ç†3ä¸ªè§†é¢‘
            
        except Exception as e:
            logger.error(f"âŒ è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_video_to_temp(self, blob_name, container_name="dada-videos"):
        """ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶"""
        logger.info(f"ğŸ“¥ ä¸‹è½½è§†é¢‘: {blob_name}")
        
        try:
            container_client = self.blob_service_client.get_container_client(container_name)
            blob_client = container_client.get_blob_client(blob_name)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(suffix='.avi', delete=False)
            
            # ä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
            with open(temp_file.name, 'wb') as f:
                download_stream = blob_client.download_blob()
                download_stream.readinto(f)
            
            return temp_file.name
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥ {blob_name}: {e}")
            return None
    
    def extract_video_frames(self, video_path, num_frames=10):
        """æå–è§†é¢‘å¸§ - å®Œå…¨é¿å…CUDAæ“ä½œ"""
        try:
            import cv2
            import numpy as np
            from PIL import Image
            
            # è®¾ç½®OpenCVä½¿ç”¨CPUåç«¯
            os.environ['OPENCV_VIDEOIO_PRIORITY_FFMPEG'] = '1'
            os.environ['OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS'] = '0'
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise ValueError(f"Cannot open video: {video_path}")
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            
            # å‡åŒ€æå–å¸§
            frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
            
            frames = []
            for frame_idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(frame_rgb).convert("RGB")
                    frames.append(pil_image)
            
            cap.release()
            return frames, duration
            
        except Exception as e:
            logger.error(f"âŒ å¸§æå–å¤±è´¥: {e}")
            return [], 0
    
    def get_gpt41_balanced_prompt(self, video_id):
        """è·å–GPT-4.1å¹³è¡¡ç‰ˆprompt"""
        prompt = """
For ghost probing detection, consider TWO categories:

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing" in key_actions)**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters) 
- Appearance is SUDDEN and from blind spots (behind parked cars, buildings, corners)
- Occurs in HIGH-RISK environments: highways, rural roads, parking lots, uncontrolled intersections
- Requires IMMEDIATE emergency braking/swerving to avoid collision
- Movement is COMPLETELY UNPREDICTABLE and violates traffic expectations

**2. POTENTIAL Ghost Probing (use "potential ghost probing" in key_actions)**:
- Object appears suddenly but at moderate distance (3-5 meters)
- Sudden movement in environments where some unpredictability exists
- Requires emergency braking but collision risk is moderate
- Movement is unexpected but not completely impossible given the context

**3. NORMAL Traffic Situations (do NOT use "ghost probing")**:
- Pedestrians crossing at intersections, crosswalks, or traffic lights
- Vehicles making normal lane changes, turns, or merging with signals
- Cyclists following predictable paths in urban areas or bike lanes
- Any movement that is EXPECTED given the traffic environment and context

**Environment Context Guidelines**:
- INTERSECTION/CROSSWALK: Expect pedestrians and cyclists - use "emergency braking due to pedestrian crossing"
- HIGHWAY/RURAL: Higher chance of genuine ghost probing - be more sensitive
- PARKING LOT: Expect sudden vehicle movements - use "potential ghost probing" if very sudden
- URBAN STREET: Mixed - consider visibility and predictability
"""
        return prompt
    
    def drivemm_inference(self, frames, video_id):
        """ä½¿ç”¨GPT-4oè¿›è¡Œæ¨ç† - å®Œå…¨é¿å…CUDAæ“ä½œ"""
        logger.info(f"ğŸ¤– GPT-4oæ¨ç†: {video_id}")
        
        if not frames:
            logger.warning("âš ï¸ æ²¡æœ‰æå–åˆ°æœ‰æ•ˆå¸§ï¼Œä½¿ç”¨åŸºæœ¬åˆ†æ")
            return self._generate_basic_analysis(video_id)
        
        try:
            # ğŸ”§ å®Œå…¨é¿å…ä»»ä½•æ¨¡å‹åŠ è½½æˆ–CUDAæ“ä½œ
            logger.info("ğŸ”§ ä½¿ç”¨GPT-4o APIè¿›è¡Œæ¨ç†ï¼Œå®Œå…¨é¿å…CUDAæ“ä½œ...")
            
            # æ„å»ºåŸºäºå¸§ä¿¡æ¯çš„åˆ†æprompt
            frame_info = []
            for i, frame in enumerate(frames):
                width, height = frame.size
                info = f"Frame {i+1}: {width}x{height} pixels at {i*1.0:.1f}s"
                frame_info.append(info)
            
            analysis_prompt = f"""You are an expert traffic analysis system analyzing a video sequence from a vehicle's perspective.

Video Information:
- Video ID: {video_id}
- Total frames: {len(frames)}
- Duration: 10 seconds
- Frame details:
{chr(10).join(frame_info)}

Task: Analyze this traffic video sequence for ghost probing detection and provide a comprehensive assessment.

{self.get_gpt41_balanced_prompt(video_id)}

IMPORTANT: Respond with a complete JSON object containing ALL required fields:

{{
    "video_id": "{video_id}",
    "segment_id": "segment_000",
    "Start_Timestamp": "0.0s",
    "End_Timestamp": "10.0s",
    "sentiment": "Neutral",
    "scene_theme": "Routine",
    "characters": "driver",
    "summary": "Comprehensive traffic analysis based on video frames",
    "actions": "vehicle movement and traffic monitoring",
    "key_objects": "1) Position: traffic elements, normal distance, standard traffic flow",
    "key_actions": "normal traffic flow monitoring",
    "next_action": {{
        "speed_control": "maintain speed",
        "direction_control": "keep direction",
        "lane_control": "maintain current lane"
    }}
}}

Provide your detailed analysis:"""
            
            # ä½¿ç”¨GPT-4oè¿›è¡Œåˆ†æ
            logger.info("ğŸ” è°ƒç”¨GPT-4o APIè¿›è¡Œåˆ†æ...")
            
            try:
                if self.use_azure:
                    response = self._call_azure_openai(analysis_prompt)
                elif self.openai_api_key:
                    response = self._call_openai(analysis_prompt)
                else:
                    response = self._generate_basic_analysis(video_id)
                
                logger.info("ğŸ“ GPT-4oåˆ†æå®Œæˆ")
                
                # è§£æå“åº”
                return self._parse_response(response, video_id)
                
            except Exception as e:
                logger.warning(f"GPT-4o APIè°ƒç”¨å¤±è´¥: {e}")
                return self._generate_basic_analysis(video_id)
                
        except Exception as e:
            logger.error(f"âŒ æ¨ç†å¤±è´¥ {video_id}: {e}")
            return self._generate_basic_analysis(video_id)
    
    def _call_azure_openai(self, prompt):
        """è°ƒç”¨Azure OpenAI API"""
        import requests
        
        url = f"{self.azure_openai_endpoint}/openai/deployments/{self.azure_openai_deployment}/chat/completions?api-version=2024-02-15-preview"
        
        headers = {
            "Content-Type": "application/json",
            "api-key": self.azure_openai_key
        }
        
        data = {
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 1500,
            "temperature": 0.3
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            response_data = response.json()
            return response_data['choices'][0]['message']['content']
        else:
            raise Exception(f"Azure OpenAI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
    
    def _call_openai(self, prompt):
        """è°ƒç”¨OpenAI API"""
        import requests
        
        url = "https://api.openai.com/v1/chat/completions"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.openai_api_key}"
        }
        
        data = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "max_tokens": 1500,
            "temperature": 0.3
        }
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            response_data = response.json()
            return response_data['choices'][0]['message']['content']
        else:
            raise Exception(f"OpenAI APIè°ƒç”¨å¤±è´¥: {response.status_code}")
    
    def _generate_basic_analysis(self, video_id):
        """ç”ŸæˆåŸºæœ¬åˆ†æç»“æœ"""
        logger.info("ğŸ“ ç”ŸæˆåŸºæœ¬åˆ†æç»“æœ...")
        
        return {
            "video_id": video_id,
            "segment_id": "segment_000",
            "Start_Timestamp": "0.0s",
            "End_Timestamp": "10.0s",
            "sentiment": "Neutral",
            "scene_theme": "Routine",
            "characters": "driver",
            "summary": f"Basic traffic analysis for {video_id}",
            "actions": "vehicle movement and traffic monitoring",
            "key_objects": "1) Front: traffic elements, normal distance, standard traffic flow",
            "key_actions": "normal traffic flow monitoring",
            "next_action": {
                "speed_control": "maintain speed",
                "direction_control": "keep direction",
                "lane_control": "maintain current lane"
            },
            "analysis_method": "basic_cpu_analysis",
            "cuda_avoided": True
        }
    
    def _parse_response(self, response, video_id):
        """è§£æå“åº”"""
        try:
            if isinstance(response, dict):
                return response
            
            # å°è¯•è§£æJSON
            json_start = response.find('{')
            if json_start >= 0:
                json_end = response.rfind('}') + 1
                json_str = response[json_start:json_end]
                
                try:
                    result = json.loads(json_str)
                    return result
                except json.JSONDecodeError:
                    pass
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬ç»“æœ
            return self._generate_basic_analysis(video_id)
            
        except Exception as e:
            logger.error(f"âŒ å“åº”è§£æå¤±è´¥: {e}")
            return self._generate_basic_analysis(video_id)
    
    def process_all_videos(self):
        """å¤„ç†æ‰€æœ‰è§†é¢‘"""
        logger.info("ğŸš€ å¼€å§‹CUDAä¿®å¤ç‰ˆDriveMMæ¨ç†")
        
        # è·å–è§†é¢‘åˆ—è¡¨
        video_blobs = self.get_video_list_from_storage()
        if not video_blobs:
            logger.error("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return []
        
        results = []
        
        for i, blob in enumerate(video_blobs, 1):
            try:
                logger.info(f"ğŸ“¹ å¤„ç†è§†é¢‘ {i}/{len(video_blobs)}: {blob}")
                
                # ä¸‹è½½è§†é¢‘
                video_path = self.download_video_to_temp(blob)
                if not video_path:
                    logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {blob}")
                    continue
                
                # æå–å¸§
                frames, duration = self.extract_video_frames(video_path, num_frames=10)
                if not frames:
                    logger.error(f"âŒ å¸§æå–å¤±è´¥: {blob}")
                    continue
                
                # æ¨ç†
                result = self.drivemm_inference(frames, blob)
                results.append(result)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(video_path):
                    os.unlink(video_path)
                
                logger.info(f"âœ… å®Œæˆ {blob}")
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å¤±è´¥ {blob}: {e}")
                continue
        
        return results
    
    def save_final_results(self, results):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        output_file = "azure_drivemm_cuda_fixed_results.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {output_file}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        logger.info("============================================================")
        logger.info("ğŸ‰ CUDAä¿®å¤ç‰ˆDriveMMæ¨ç†å®Œæˆ!")
        logger.info("ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        logger.info(f"   æ€»è§†é¢‘æ•°: {len(results)}")
        
        if results:
            logger.info("âœ… æ‰€æœ‰è§†é¢‘å¤„ç†æˆåŠŸ - CUDAé”™è¯¯å·²è§£å†³!")
            
            # ç®€å•çš„ç»“æœç»Ÿè®¡
            ghost_probing_count = sum(1 for r in results if 'ghost probing' in r.get('key_actions', '').lower())
            logger.info(f"   Ghost probingæ£€æµ‹: {ghost_probing_count}")
        else:
            logger.info("âš ï¸ æ²¡æœ‰æˆåŠŸå¤„ç†çš„è§†é¢‘")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæ¨ç†å®ä¾‹
        inference = CUDAFixedDriveMMAzureInference()
        
        # å¤„ç†æ‰€æœ‰è§†é¢‘
        results = inference.process_all_videos()
        
        # ä¿å­˜ç»“æœ
        inference.save_final_results(results)
        
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()