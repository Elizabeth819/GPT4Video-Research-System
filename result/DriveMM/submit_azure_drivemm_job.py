#!/usr/bin/env python3
"""
æäº¤çœŸå®DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML
"""

import os
import sys
from azure.ai.ml import MLClient
from azure.ai.ml.entities import CommandJob, Environment
from azure.identity import DefaultAzureCredential
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def submit_drivemm_job():
    """æäº¤DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML"""
    
    try:
        # Azure MLé…ç½® - è¯·æ ¹æ®æ‚¨çš„å®é™…é…ç½®ä¿®æ”¹
        subscription_id = os.getenv("AZURE_SUBSCRIPTION_ID", "your-subscription-id")
        resource_group = os.getenv("AZURE_RESOURCE_GROUP", "your-resource-group")
        workspace_name = os.getenv("AZURE_ML_WORKSPACE", "your-workspace-name")
        
        logger.info("ğŸ”— è¿æ¥åˆ°Azure ML...")
        
        # åˆ›å»ºMLå®¢æˆ·ç«¯
        credential = DefaultAzureCredential()
        ml_client = MLClient(
            credential=credential,
            subscription_id=subscription_id,
            resource_group_name=resource_group,
            workspace_name=workspace_name,
        )
        
        logger.info("âœ… Azure MLè¿æ¥æˆåŠŸ")
        
        # åˆ›å»ºä½œä¸š
        logger.info("ğŸ“‹ åˆ›å»ºDriveMMæ¨ç†ä½œä¸š...")
        
        job = CommandJob(
            display_name="real-drivemm-ghost-probing-inference",
            description="çœŸå®DriveMMæ¨¡å‹é¬¼æ¢å¤´æ£€æµ‹æ¨ç† - ä¸GPT-4.1å…¬å¹³å¯¹æ¯”",
            tags={
                "model": "DriveMM-8.45B",
                "task": "ghost_probing_detection", 
                "comparison": "GPT-4.1_vs_DriveMM",
                "data_source": "drivelmmstorage2e932dad7"
            },
            
            # è®¡ç®—é…ç½®
            compute="gpu-cluster",  # è¯·æ ¹æ®æ‚¨çš„GPUè®¡ç®—é›†ç¾¤åç§°ä¿®æ”¹
            
            # ç¯å¢ƒé…ç½®
            environment="azureml://registries/azureml/environments/pytorch-1.13-ubuntu20.04-py38-cuda11.6-gpu/versions/latest",
            
            # ä»£ç 
            code="./",
            
            # å‘½ä»¤
            command="""
            pip install --upgrade pip &&
            pip install transformers>=4.25.0 torch torchvision torchaudio &&
            pip install azure-storage-blob azure-identity &&
            pip install opencv-python pillow numpy &&
            pip install huggingface_hub accelerate &&
            git clone https://github.com/zhijian11/DriveMM.git &&
            cd DriveMM && pip install -e . && cd .. &&
            python azure_drivemm_real_inference.py
            """,
            
            # ç¯å¢ƒå˜é‡
            environment_variables={
                "AZURE_STORAGE_ACCOUNT": "drivelmmstorage2e932dad7",
                "HF_HOME": "/tmp/huggingface",
                "TRANSFORMERS_CACHE": "/tmp/transformers",
                "CUDA_VISIBLE_DEVICES": "0"
            },
            
            # èµ„æºé…ç½®
            instance_type="Standard_NC6s_v3",  # V100 GPU
            timeout=14400,  # 4å°æ—¶
        )
        
        # æäº¤ä½œä¸š
        logger.info("ğŸš€ æäº¤ä½œä¸šåˆ°Azure ML...")
        submitted_job = ml_client.jobs.create_or_update(job)
        
        logger.info(f"âœ… ä½œä¸šæäº¤æˆåŠŸ!")
        logger.info(f"ğŸ“Š ä½œä¸šåç§°: {submitted_job.name}")
        logger.info(f"ğŸ“Š ä½œä¸šID: {submitted_job.id}")
        logger.info(f"ğŸ“Š ä½œä¸šçŠ¶æ€: {submitted_job.status}")
        logger.info(f"ğŸ”— ä½œä¸šURL: {submitted_job.studio_url}")
        
        # å¯é€‰ï¼šç­‰å¾…ä½œä¸šå®Œæˆ
        print("\næ˜¯å¦ç­‰å¾…ä½œä¸šå®Œæˆ? (y/n): ", end="")
        wait_for_completion = input().lower() == 'y'
        
        if wait_for_completion:
            logger.info("â³ ç­‰å¾…ä½œä¸šå®Œæˆ...")
            final_job = ml_client.jobs.stream(submitted_job.name)
            logger.info(f"ğŸ‰ ä½œä¸šå®Œæˆ! çŠ¶æ€: {final_job.status}")
        
        return submitted_job
        
    except Exception as e:
        logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶
        required_files = [
            "azure_drivemm_real_inference.py",
        ]
        
        for file in required_files:
            if not os.path.exists(file):
                logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file}")
                return 1
        
        # æäº¤ä½œä¸š
        job = submit_drivemm_job()
        
        logger.info("\n" + "="*60)
        logger.info("ğŸ¯ ä½œä¸šæäº¤å®Œæˆ!")
        logger.info("ğŸ“‹ åç»­æ­¥éª¤:")
        logger.info("1. åœ¨Azure ML Studioä¸­ç›‘æ§ä½œä¸šè¿›åº¦")
        logger.info("2. ä½œä¸šå®Œæˆåä¸‹è½½ç»“æœæ–‡ä»¶")
        logger.info("3. åˆ†æDriveMM vs GPT-4.1çš„å¯¹æ¯”ç»“æœ")
        
        return 0
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)