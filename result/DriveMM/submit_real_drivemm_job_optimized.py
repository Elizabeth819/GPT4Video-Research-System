#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæäº¤çœŸå®DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML
åªä¸Šä¼ å¿…è¦çš„æ–‡ä»¶ï¼Œé¿å…ä¸Šä¼ å¤§é‡ä¸å¿…è¦çš„æ•°æ®
"""

import os
import sys
import tempfile
import shutil
from azure.ai.ml import MLClient
from azure.ai.ml import command
from azure.identity import DefaultAzureCredential
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_minimal_code_package():
    """åˆ›å»ºæœ€å°åŒ–çš„ä»£ç åŒ…ï¼ŒåªåŒ…å«å¿…è¦æ–‡ä»¶"""
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp(prefix="drivemm_job_")
    logger.info(f"åˆ›å»ºä¸´æ—¶ä»£ç ç›®å½•: {temp_dir}")
    
    # éœ€è¦çš„æ–‡ä»¶åˆ—è¡¨
    required_files = [
        "azure_drivemm_real_inference.py",
        "config.json",
        "requirements.txt"
    ]
    
    # å¤åˆ¶å¿…è¦æ–‡ä»¶
    for file in required_files:
        if os.path.exists(file):
            shutil.copy2(file, temp_dir)
            logger.info(f"å¤åˆ¶æ–‡ä»¶: {file}")
        else:
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨: {file}")
    
    return temp_dir

def submit_real_drivemm_job():
    """æäº¤çœŸå®DriveMMæ¨ç†ä½œä¸š"""
    
    logger.info("ğŸš€ æäº¤ä¼˜åŒ–ç‰ˆçœŸå®DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML")
    
    temp_dir = None
    try:
        # åˆ›å»ºæœ€å°åŒ–ä»£ç åŒ…
        temp_dir = create_minimal_code_package()
        
        # Azure MLå®¢æˆ·ç«¯
        credential = DefaultAzureCredential()
        ml_client = MLClient.from_config(credential=credential)
        
        logger.info("âœ… Azure MLå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        
        # ç›´æ¥ä½¿ç”¨Azureå®˜æ–¹ç¯å¢ƒ
        official_env = "azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10"
        
        # åˆ›å»ºä½œä¸š
        logger.info("ğŸ¯ åˆ›å»ºçœŸå®DriveMMæ¨ç†ä½œä¸š...")
        
        job = command(
            display_name="DriveMM_Real_Inference_Ghost_Probing_Optimized",
            description="ä½¿ç”¨çœŸå®DriveMMæ¨¡å‹(17GB)åœ¨GPUç¯å¢ƒä¸­è¿›è¡Œé¬¼æ¢å¤´æ£€æµ‹ - ä¼˜åŒ–ç‰ˆæœ¬",
            code=temp_dir,  # ä½¿ç”¨ä¸´æ—¶ç›®å½•è€Œä¸æ˜¯å½“å‰ç›®å½•
            command="pip install transformers>=4.35.0 huggingface_hub>=0.20.0 accelerate>=0.24.0 azure-storage-blob>=12.19.0 opencv-python>=4.8.0 && python azure_drivemm_real_inference.py",
            environment=official_env,
            compute="drivemm-a100-cluster",
            environment_variables={
                "AZURE_STORAGE_CONNECTION_STRING": "DefaultEndpointsProtocol=https;AccountName=drivelmmstorage2e932dad7;AccountKey=MniZTrPWLKwVg6XpJKpu+4Rv5fuvd0x+xq2smYW+yZn1IGVpf5OcMuGfLBmSuKyOWhAjOLGnbNIq+AStpd49zQ==;EndpointSuffix=core.windows.net",
                "HF_HOME": "/tmp/huggingface_cache",
                "TRANSFORMERS_CACHE": "/tmp/transformers_cache",
                "TORCH_HOME": "/tmp/torch_cache"
            },
            experiment_name="drivemm-real-inference",
            tags={
                "model": "DriveMM-Real-17GB",
                "task": "ghost-probing-detection", 
                "comparison": "vs-GPT41-balanced",
                "environment": "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10",
                "model_source": "huggingface.co/DriveMM/DriveMM",
                "version": "optimized"
            }
        )
        
        # æäº¤ä½œä¸š
        logger.info("ğŸ“¤ æäº¤ä½œä¸šåˆ°Azure ML...")
        returned_job = ml_client.create_or_update(job)
        
        logger.info("âœ… çœŸå®DriveMMä½œä¸šæäº¤æˆåŠŸ!")
        logger.info(f"ğŸ”— ä½œä¸šURL: {returned_job.services['Studio'].endpoint}")
        logger.info(f"ğŸ†” ä½œä¸šID: {returned_job.name}")
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ ä¼˜åŒ–ç‰ˆçœŸå®DriveMMæ¨ç†ä½œä¸šå·²å¯åŠ¨!")
        logger.info("ğŸ“‹ ä½œä¸šè¯¦æƒ…:")
        logger.info(f"   - æ¨¡å‹: DriveMM/DriveMM (çœŸå®17GBæ¨¡å‹)")
        logger.info(f"   - ç¯å¢ƒ: Azure ML GPU")
        logger.info(f"   - æ•°æ®æº: drivelmmstorage2e932dad7")
        logger.info(f"   - ä»»åŠ¡: 99ä¸ªè§†é¢‘é¬¼æ¢å¤´æ£€æµ‹")
        logger.info(f"   - å¯¹æ¯”åŸºå‡†: GPT-4.1 Balanced F1=0.712")
        logger.info("â³ ä½œä¸šå°†è‡ªåŠ¨ä¸‹è½½DriveMMæ¨¡å‹å¹¶å¼€å§‹æ¨ç†...")
        
        return returned_job.name
        
    except Exception as e:
        logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        return None
    
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            logger.info(f"æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")

if __name__ == "__main__":
    job_id = submit_real_drivemm_job()
    if job_id:
        print(f"\nğŸŠ æˆåŠŸ! ä½œä¸šID: {job_id}")
        print("è¯·åœ¨Azure ML Studioä¸­ç›‘æ§ä½œä¸šè¿›åº¦")
    else:
        print("\nâŒ ä½œä¸šæäº¤å¤±è´¥")
        sys.exit(1) 