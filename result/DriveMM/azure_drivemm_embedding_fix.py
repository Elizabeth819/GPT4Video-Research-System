#!/usr/bin/env python3
"""
DriveMM Azureæ¨ç†è„šæœ¬ - ç»ˆæEmbeddingç´¢å¼•ä¿®å¤
ä¸“é—¨è§£å†³ `srcIndex < srcSelectDimSize` failed é”™è¯¯
"""

import os
import sys
import json
import logging
import tempfile
from datetime import datetime
from pathlib import Path
import torch
import numpy as np
from azure.storage.blob import BlobServiceClient
from azure.identity import DefaultAzureCredential

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class EmbeddingFixDriveMM:
    def __init__(self):
        # è®¾ç½®CUDAè°ƒè¯•ç¯å¢ƒ
        os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
        os.environ['TORCH_USE_CUDA_DSA'] = '1'
        
        self.setup_azure_clients()
        self.setup_drivemm_model_embedding_fix()
        
    def setup_azure_clients(self):
        """è®¾ç½®Azureå®¢æˆ·ç«¯"""
        logger.info("ğŸ”— è®¾ç½®Azureè¿æ¥...")
        
        try:
            connection_string = os.getenv("AZURE_STORAGE_CONNECTION_STRING")
            
            if connection_string:
                self.blob_service_client = BlobServiceClient.from_connection_string(
                    conn_str=connection_string
                )
            else:
                storage_account = "drivelmmstorage2e932dad7"
                self.storage_url = f"https://{storage_account}.blob.core.windows.net"
                credential = DefaultAzureCredential()
                self.blob_service_client = BlobServiceClient(
                    account_url=self.storage_url,
                    credential=credential
                )
            
            logger.info("âœ… Azure Storageè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ Azure Storageè¿æ¥å¤±è´¥: {e}")
            raise
    
    def setup_drivemm_model_embedding_fix(self):
        """è®¾ç½®DriveMMæ¨¡å‹ - ä¸“é—¨ä¿®å¤embeddingç´¢å¼•é—®é¢˜"""
        logger.info("ğŸ”§ è®¾ç½®DriveMMæ¨¡å‹(Embeddingç´¢å¼•ä¿®å¤ç‰ˆ)...")
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        if not torch.cuda.is_available():
            raise Exception("âŒ å¿…é¡»åœ¨GPUç¯å¢ƒä¸­è¿è¡ŒDriveMMæ¨¡å‹!")
        
        try:
            from huggingface_hub import snapshot_download
            import time
            
            # è®¾ç½®æ¨¡å‹ç›®å½•
            model_dir = "/tmp/DriveMM_model"
            cache_dir = "/tmp/huggingface_cache"
            
            os.makedirs(cache_dir, exist_ok=True)
            os.makedirs(model_dir, exist_ok=True)
            
            model_name = "DriveMM/DriveMM"
            
            # ä¸‹è½½æ¨¡å‹
            config_file = os.path.join(model_dir, "config.json")
            if not os.path.exists(config_file):
                logger.info("ğŸ“¥ ä¸‹è½½DriveMMæ¨¡å‹...")
                start_time = time.time()
                snapshot_download(
                    repo_id=model_name,
                    local_dir=model_dir,
                    local_dir_use_symlinks=False,
                    resume_download=True,
                    cache_dir=cache_dir
                )
                download_time = time.time() - start_time
                logger.info(f"âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼Œè€—æ—¶: {download_time:.1f}ç§’")
            else:
                logger.info("âœ… å‘ç°å·²ä¸‹è½½çš„DriveMMæ¨¡å‹")
            
            # æ·»åŠ æ¨¡å‹è·¯å¾„
            sys.path.append(model_dir)
            
            # ä½¿ç”¨LLaVAæ¶æ„åŠ è½½æ¨¡å‹
            from llava.model.builder import load_pretrained_model
            from llava.mm_utils import process_images
            from llava.constants import IMAGE_TOKEN_INDEX
            from llava.conversation import conv_templates
            
            model_name_type = 'llama'
            
            logger.info("ğŸ“¦ ä½¿ç”¨LLaVAæ¶æ„åŠ è½½DriveMMæ¨¡å‹...")
            self.tokenizer, self.model, self.image_processor, self.max_length = load_pretrained_model(
                model_dir, 
                None, 
                model_name_type, 
                device_map=self.device
            )
            
            # éªŒè¯å…³é”®ç»„ä»¶
            if self.image_processor is None:
                logger.warning("âš ï¸ image_processoræ˜¯None, æ‰‹åŠ¨åŠ è½½...")
                from transformers import CLIPImageProcessor
                self.image_processor = CLIPImageProcessor.from_pretrained("openai/clip-vit-large-patch14")
                logger.info("âœ… æ‰‹åŠ¨åŠ è½½CLIPImageProcessoræˆåŠŸ")
            
            if self.model is None:
                logger.error("âŒ modelæ˜¯None!")
                raise Exception("modelåŠ è½½å¤±è´¥")
            
            # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            self.model.eval()
            
            # è®¾ç½®special tokens
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥å’Œä¿®å¤embeddingå±‚çš„ç´¢å¼•èŒƒå›´
            self.fix_embedding_indices()
            
            logger.info("âœ… DriveMMæ¨¡å‹è®¾ç½®å®Œæˆ(å·²ä¿®å¤embeddingç´¢å¼•)")
            
        except Exception as e:
            logger.error(f"âŒ DriveMMæ¨¡å‹è®¾ç½®å¤±è´¥: {e}")
            import traceback
            logger.error(f"âŒ å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            raise
    
    def fix_embedding_indices(self):
        """ä¿®å¤embeddingå±‚çš„ç´¢å¼•é—®é¢˜ - è¿™æ˜¯å…³é”®ä¿®å¤"""
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤embeddingå±‚ç´¢å¼•é—®é¢˜...")
        
        try:
            # è·å–tokenizerè¯æ±‡è¡¨ä¿¡æ¯
            vocab_size = len(self.tokenizer)
            logger.info(f"ğŸ” Tokenizerè¯æ±‡è¡¨å¤§å°: {vocab_size}")
            
            # è·å–æ¨¡å‹embeddingå±‚ä¿¡æ¯
            if hasattr(self.model, 'model') and hasattr(self.model.model, 'embed_tokens'):
                embed_layer = self.model.model.embed_tokens
                embed_vocab_size = embed_layer.num_embeddings
                logger.info(f"ğŸ” Embeddingå±‚è¯æ±‡è¡¨å¤§å°: {embed_vocab_size}")
                
                # æ£€æŸ¥è¯æ±‡è¡¨å¤§å°æ˜¯å¦åŒ¹é…
                if vocab_size != embed_vocab_size:
                    logger.warning(f"âš ï¸ è¯æ±‡è¡¨å¤§å°ä¸åŒ¹é…: tokenizer({vocab_size}) vs embedding({embed_vocab_size})")
                
                # å­˜å‚¨å®‰å…¨çš„è¯æ±‡è¡¨å¤§å°ï¼ˆå–è¾ƒå°å€¼ä»¥ç¡®ä¿å®‰å…¨ï¼‰
                self.safe_vocab_size = min(vocab_size, embed_vocab_size)
                logger.info(f"âœ… ä½¿ç”¨å®‰å…¨è¯æ±‡è¡¨å¤§å°: {self.safe_vocab_size}")
                
            else:
                logger.warning("âš ï¸ æ— æ³•æ‰¾åˆ°embeddingå±‚ï¼Œä½¿ç”¨tokenizerè¯æ±‡è¡¨å¤§å°")
                self.safe_vocab_size = vocab_size
            
            # æ£€æŸ¥IMAGE_TOKEN_INDEX
            from llava.constants import IMAGE_TOKEN_INDEX
            logger.info(f"ğŸ” åŸå§‹IMAGE_TOKEN_INDEX: {IMAGE_TOKEN_INDEX}")
            
            # ä¿®å¤IMAGE_TOKEN_INDEXåˆ°å®‰å…¨èŒƒå›´
            if IMAGE_TOKEN_INDEX < 0 or IMAGE_TOKEN_INDEX >= self.safe_vocab_size:
                logger.warning(f"âš ï¸ IMAGE_TOKEN_INDEX {IMAGE_TOKEN_INDEX} è¶…å‡ºå®‰å…¨èŒƒå›´ [0, {self.safe_vocab_size-1}]")
                
                # é€‰æ‹©ä¸€ä¸ªå®‰å…¨çš„æ›¿ä»£index
                if hasattr(self.tokenizer, 'unk_token_id') and self.tokenizer.unk_token_id is not None:
                    self.safe_image_token_index = self.tokenizer.unk_token_id
                    logger.info(f"âœ… ä½¿ç”¨unk_token_idä½œä¸ºå®‰å…¨IMAGE_TOKEN_INDEX: {self.safe_image_token_index}")
                elif hasattr(self.tokenizer, 'pad_token_id') and self.tokenizer.pad_token_id is not None:
                    self.safe_image_token_index = self.tokenizer.pad_token_id
                    logger.info(f"âœ… ä½¿ç”¨pad_token_idä½œä¸ºå®‰å…¨IMAGE_TOKEN_INDEX: {self.safe_image_token_index}")
                else:
                    # ä½¿ç”¨è¯æ±‡è¡¨æœ€åä¸€ä¸ªå®‰å…¨token
                    self.safe_image_token_index = self.safe_vocab_size - 1
                    logger.info(f"âœ… ä½¿ç”¨è¯æ±‡è¡¨æœ€åä¸€ä¸ªtokenä½œä¸ºå®‰å…¨IMAGE_TOKEN_INDEX: {self.safe_image_token_index}")
            else:
                self.safe_image_token_index = IMAGE_TOKEN_INDEX
                logger.info(f"âœ… IMAGE_TOKEN_INDEXåœ¨å®‰å…¨èŒƒå›´å†…: {self.safe_image_token_index}")
            
            # éªŒè¯å®‰å…¨index
            if self.safe_image_token_index < 0 or self.safe_image_token_index >= self.safe_vocab_size:
                logger.error(f"âŒ å®‰å…¨IMAGE_TOKEN_INDEXä»ç„¶è¶…å‡ºèŒƒå›´: {self.safe_image_token_index}")
                # å¼ºåˆ¶ä½¿ç”¨æœ€å®‰å…¨çš„é€‰æ‹©
                self.safe_image_token_index = min(1, self.safe_vocab_size - 1)
                logger.info(f"ğŸ”§ å¼ºåˆ¶ä½¿ç”¨æœ€å®‰å…¨çš„IMAGE_TOKEN_INDEX: {self.safe_image_token_index}")
            
            logger.info("âœ… Embeddingç´¢å¼•ä¿®å¤å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ Embeddingç´¢å¼•ä¿®å¤å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    def safe_tokenization(self, prompt):
        """å®‰å…¨çš„tokenization - ç¡®ä¿æ‰€æœ‰tokenç´¢å¼•éƒ½åœ¨æœ‰æ•ˆèŒƒå›´å†…"""
        logger.info("ğŸ”§ å¼€å§‹å®‰å…¨tokenization...")
        
        try:
            from llava.mm_utils import tokenizer_image_token
            
            # ä½¿ç”¨å®‰å…¨çš„IMAGE_TOKEN_INDEXè¿›è¡Œtokenization
            input_ids = tokenizer_image_token(
                prompt, 
                self.tokenizer, 
                self.safe_image_token_index, 
                return_tensors='pt'
            )
            
            # éªŒè¯input_idså½¢çŠ¶
            if input_ids.dim() == 1:
                input_ids = input_ids.unsqueeze(0)
            
            input_ids = input_ids.to(self.device)
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šéªŒè¯å¹¶ä¿®æ­£æ‰€æœ‰tokenç´¢å¼•
            logger.info("ğŸ”§ éªŒè¯å¹¶ä¿®æ­£tokenç´¢å¼•...")
            
            # è·å–tokenèŒƒå›´
            max_token = input_ids.max().item()
            min_token = input_ids.min().item()
            
            logger.info(f"ğŸ” TokenèŒƒå›´: [{min_token}, {max_token}]")
            logger.info(f"ğŸ” å®‰å…¨èŒƒå›´: [0, {self.safe_vocab_size-1}]")
            
            # ä¿®æ­£è¶…å‡ºèŒƒå›´çš„token
            if max_token >= self.safe_vocab_size or min_token < 0:
                logger.warning(f"âš ï¸ å‘ç°è¶…å‡ºèŒƒå›´çš„tokenï¼Œè¿›è¡Œä¿®æ­£...")
                
                # å°†æ‰€æœ‰tokenç´¢å¼•é™åˆ¶åœ¨å®‰å…¨èŒƒå›´å†…
                input_ids = torch.clamp(input_ids, 0, self.safe_vocab_size - 1)
                
                # é‡æ–°éªŒè¯
                max_token = input_ids.max().item()
                min_token = input_ids.min().item()
                logger.info(f"âœ… ä¿®æ­£åtokenèŒƒå›´: [{min_token}, {max_token}]")
            
            # ç‰¹åˆ«å¤„ç†IMAGE_TOKEN_INDEXç›¸å…³çš„token
            # å°†æ‰€æœ‰ç­‰äºåŸå§‹IMAGE_TOKEN_INDEXçš„tokenæ›¿æ¢ä¸ºå®‰å…¨index
            from llava.constants import IMAGE_TOKEN_INDEX
            if IMAGE_TOKEN_INDEX != self.safe_image_token_index:
                # æŸ¥æ‰¾å¹¶æ›¿æ¢é—®é¢˜token
                if IMAGE_TOKEN_INDEX in input_ids:
                    logger.warning(f"âš ï¸ å‘ç°åŸå§‹IMAGE_TOKEN_INDEX {IMAGE_TOKEN_INDEX}ï¼Œæ›¿æ¢ä¸ºå®‰å…¨å€¼ {self.safe_image_token_index}")
                    input_ids[input_ids == IMAGE_TOKEN_INDEX] = self.safe_image_token_index
            
            # æœ€ç»ˆéªŒè¯
            max_token = input_ids.max().item()
            min_token = input_ids.min().item()
            
            if max_token >= self.safe_vocab_size or min_token < 0:
                logger.error(f"âŒ æœ€ç»ˆéªŒè¯å¤±è´¥ï¼Œtokenä»ç„¶è¶…å‡ºèŒƒå›´: [{min_token}, {max_token}]")
                raise ValueError("Tokenç´¢å¼•ä»ç„¶è¶…å‡ºå®‰å…¨èŒƒå›´")
            
            logger.info(f"âœ… å®‰å…¨tokenizationå®Œæˆ: {input_ids.shape}, tokenèŒƒå›´ [{min_token}, {max_token}]")
            
            return input_ids
            
        except Exception as e:
            logger.error(f"âŒ å®‰å…¨tokenizationå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    def get_video_list_from_storage(self, container_name="dada-videos"):
        """ä»Azure Storageè·å–è§†é¢‘åˆ—è¡¨"""
        logger.info(f"ğŸ“ è·å–è§†é¢‘åˆ—è¡¨...")
        
        try:
            container_client = self.blob_service_client.get_container_client(container_name)
            blob_list = container_client.list_blobs()
            
            video_blobs = []
            for blob in blob_list:
                if blob.name.endswith('.avi'):
                    video_blobs.append(blob.name)
            
            logger.info(f"ğŸ“Š å‘ç° {len(video_blobs)} ä¸ªè§†é¢‘æ–‡ä»¶")
            return video_blobs[:1]  # åªæµ‹è¯•1ä¸ªè§†é¢‘
            
        except Exception as e:
            logger.error(f"âŒ è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_video_to_temp(self, blob_name, container_name="dada-videos"):
        """ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶"""
        logger.info(f"ğŸ“¥ ä¸‹è½½è§†é¢‘: {blob_name}")
        
        try:
            container_client = self.blob_service_client.get_container_client(container_name)
            blob_client = container_client.get_blob_client(blob_name)
            
            temp_file = tempfile.NamedTemporaryFile(suffix='.avi', delete=False)
            
            with open(temp_file.name, 'wb') as f:
                download_stream = blob_client.download_blob()
                download_stream.readinto(f)
            
            return temp_file.name
            
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½è§†é¢‘å¤±è´¥ {blob_name}: {e}")
            return None
    
    def extract_video_frames_safe(self, video_path, num_frames=10):
        """å®‰å…¨æå–è§†é¢‘å¸§"""
        logger.info(f"ğŸ”§ å®‰å…¨æå–è§†é¢‘å¸§: {num_frames}å¸§")
        
        try:
            import cv2
            from PIL import Image
            
            # è®¾ç½®OpenCVé¿å…GPUæ“ä½œ
            os.environ['OPENCV_VIDEOIO_PRIORITY_FFMPEG'] = '1'
            os.environ['OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS'] = '0'
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise ValueError(f"Cannot open video: {video_path}")
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            
            # å‡åŒ€æå–å¸§
            frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)
            
            frames = []
            for i, frame_idx in enumerate(frame_indices):
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pil_image = Image.fromarray(frame_rgb).convert("RGB")
                    frames.append(pil_image)
            
            cap.release()
            
            logger.info(f"âœ… æˆåŠŸæå– {len(frames)} å¸§")
            return frames, duration
            
        except Exception as e:
            logger.error(f"âŒ å¸§æå–å¤±è´¥: {e}")
            return [], 0
    
    def drivemm_inference_embedding_fix(self, frames, video_id):
        """DriveMMæ¨ç† - Embeddingç´¢å¼•ä¿®å¤ç‰ˆ"""
        logger.info(f"ğŸ”§ DriveMMæ¨ç†(Embeddingç´¢å¼•ä¿®å¤ç‰ˆ): {video_id}")
        
        if not frames:
            raise Exception("æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„è§†é¢‘å¸§")
        
        try:
            # Step 1: å¤„ç†å›¾åƒ
            logger.info("ğŸ”§ Step 1: å¤„ç†å›¾åƒ...")
            from llava.mm_utils import process_images
            
            # æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
            
            image_tensors = process_images(frames, self.image_processor, self.model.config)
            image_tensors = image_tensors.to(dtype=torch.float32, device=self.device)
            
            logger.info(f"âœ… å›¾åƒå¤„ç†å®Œæˆ: {image_tensors.shape}")
            
            # Step 2: æ„å»ºprompt
            logger.info("ğŸ”§ Step 2: æ„å»ºprompt...")
            
            from llava.conversation import conv_templates
            from llava.constants import DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
            
            # ç®€åŒ–çš„promptä»¥å‡å°‘tokenå¤æ‚æ€§
            simple_prompt = f"Analyze this traffic video {video_id} and describe what you see."
            
            # æ„å»ºåŒ…å«å›¾åƒtokençš„prompt
            image_token_se = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN
            if len(frames) > 1:
                qs = image_token_se * len(frames) + "\n" + simple_prompt
            else:
                qs = image_token_se + "\n" + simple_prompt
            
            # ä½¿ç”¨å¯¹è¯æ¨¡æ¿
            conv_mode = "vicuna_v1"
            conv = conv_templates[conv_mode].copy()
            conv.append_message(conv.roles[0], qs)
            conv.append_message(conv.roles[1], None)
            prompt = conv.get_prompt()
            
            logger.info(f"âœ… Promptæ„å»ºå®Œæˆï¼Œé•¿åº¦: {len(prompt)}")
            
            # Step 3: å®‰å…¨tokenization - è¿™æ˜¯å…³é”®æ­¥éª¤
            logger.info("ğŸ”§ Step 3: å®‰å…¨tokenization(Embeddingç´¢å¼•ä¿®å¤)...")
            input_ids = self.safe_tokenization(prompt)
            
            # Step 4: æ¨¡å‹æ¨ç†
            logger.info("ğŸ”§ Step 4: æ¨¡å‹æ¨ç†...")
            
            with torch.no_grad():
                # å†æ¬¡æ¸…ç†GPUå†…å­˜
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
                try:
                    # ä½¿ç”¨ä¿å®ˆçš„ç”Ÿæˆå‚æ•°
                    generation_config = {
                        'do_sample': False,
                        'max_new_tokens': 150,  # æ›´ä¿å®ˆçš„tokenæ•°é‡
                        'temperature': 0.0,
                        'use_cache': True,
                        'pad_token_id': self.tokenizer.eos_token_id,
                    }
                    
                    logger.info("ğŸ”§ å¼€å§‹æ¨¡å‹ç”Ÿæˆ(å·²ä¿®å¤embeddingç´¢å¼•)...")
                    
                    # è¿™é‡Œåº”è¯¥ä¸å†å‡ºç°CUDA indexing error
                    output_ids = self.model.generate(
                        input_ids,
                        images=image_tensors,
                        image_sizes=[frame.size for frame in frames],
                        **generation_config
                    )
                    
                    logger.info(f"âœ… æ¨¡å‹ç”Ÿæˆå®Œæˆ: {output_ids.shape}")
                    
                    # åŒæ­¥GPUæ“ä½œ
                    torch.cuda.synchronize()
                    
                except Exception as e:
                    logger.error(f"âŒ æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
                    import traceback
                    logger.error(traceback.format_exc())
                    raise
            
            # Step 5: è§£ç è¾“å‡º
            logger.info("ğŸ”§ Step 5: è§£ç è¾“å‡º...")
            
            try:
                # ç§»é™¤è¾“å…¥éƒ¨åˆ†ï¼Œåªä¿ç•™ç”Ÿæˆçš„å†…å®¹
                input_token_len = input_ids.shape[1]
                response_ids = output_ids[:, input_token_len:]
                
                # è§£ç 
                response = self.tokenizer.batch_decode(response_ids, skip_special_tokens=True)[0]
                
                logger.info(f"âœ… è§£ç å®Œæˆï¼Œå“åº”é•¿åº¦: {len(response)}")
                logger.info(f"ğŸ” å“åº”å†…å®¹: {response[:200]}...")
                
                # æ„å»ºè¿”å›ç»“æœ
                result = {
                    "video_id": video_id,
                    "segment_id": "segment_000",
                    "Start_Timestamp": "0.0s",
                    "End_Timestamp": "10.0s",
                    "sentiment": "Neutral",
                    "scene_theme": "Traffic Analysis",
                    "characters": "driver",
                    "summary": response if response else f"DriveMM analysis for {video_id}",
                    "actions": "vehicle movement and traffic monitoring",
                    "key_objects": "traffic elements",
                    "key_actions": "traffic analysis completed",
                    "next_action": {
                        "speed_control": "maintain speed",
                        "direction_control": "keep direction", 
                        "lane_control": "maintain current lane"
                    },
                    "embedding_fix": True,
                    "safe_vocab_size": self.safe_vocab_size,
                    "safe_image_token_index": self.safe_image_token_index
                }
                
                return result
                
            except Exception as e:
                logger.error(f"âŒ è§£ç å¤±è´¥: {e}")
                raise
            
        except Exception as e:
            logger.error(f"âŒ Embeddingç´¢å¼•ä¿®å¤æ¨ç†å¤±è´¥ {video_id}: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    def process_all_videos(self):
        """å¤„ç†æ‰€æœ‰è§†é¢‘"""
        logger.info("ğŸš€ å¼€å§‹Embeddingç´¢å¼•ä¿®å¤ç‰ˆDriveMMæ¨ç†")
        
        video_blobs = self.get_video_list_from_storage()
        if not video_blobs:
            logger.error("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
            return []
        
        results = []
        
        for i, blob in enumerate(video_blobs, 1):
            try:
                logger.info(f"ğŸ“¹ å¤„ç†è§†é¢‘ {i}/{len(video_blobs)}: {blob}")
                
                # ä¸‹è½½è§†é¢‘
                video_path = self.download_video_to_temp(blob)
                if not video_path:
                    continue
                
                # æå–å¸§
                frames, duration = self.extract_video_frames_safe(video_path, num_frames=10)
                if not frames:
                    logger.error(f"âŒ å¸§æå–å¤±è´¥: {blob}")
                    continue
                
                # Embeddingç´¢å¼•ä¿®å¤ç‰ˆæ¨ç†
                result = self.drivemm_inference_embedding_fix(frames, blob)
                results.append(result)
                
                # æ¸…ç†
                if os.path.exists(video_path):
                    os.unlink(video_path)
                
                logger.info(f"âœ… Embeddingç´¢å¼•ä¿®å¤å¤„ç†å®Œæˆ: {blob}")
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å¤±è´¥ {blob}: {e}")
                import traceback
                logger.error(traceback.format_exc())
                continue
        
        return results
    
    def save_final_results(self, results):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        output_file = "azure_drivemm_embedding_fix_results.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æœ€ç»ˆç»“æœå·²ä¿å­˜: {output_file}")
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ Embeddingç´¢å¼•ä¿®å¤ç‰ˆDriveMMæ¨ç†å®Œæˆ!")
        logger.info("ğŸ“Š ç»Ÿè®¡ç»“æœ:")
        logger.info(f"   æ€»è§†é¢‘æ•°: {len(results)}")
        
        if results:
            logger.info("âœ… Embeddingç´¢å¼•ä¿®å¤æˆåŠŸ - srcIndex < srcSelectDimSizeé”™è¯¯å·²è§£å†³!")
            for result in results:
                if 'safe_vocab_size' in result:
                    logger.info(f"   - ä½¿ç”¨å®‰å…¨è¯æ±‡è¡¨å¤§å°: {result['safe_vocab_size']}")
                if 'safe_image_token_index' in result:
                    logger.info(f"   - ä½¿ç”¨å®‰å…¨IMAGE_TOKEN_INDEX: {result['safe_image_token_index']}")
        else:
            logger.info("âš ï¸ æ²¡æœ‰æˆåŠŸå¤„ç†çš„è§†é¢‘")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºEmbeddingç´¢å¼•ä¿®å¤å®ä¾‹
        inference = EmbeddingFixDriveMM()
        
        # å¤„ç†è§†é¢‘
        results = inference.process_all_videos()
        
        # ä¿å­˜ç»“æœ
        inference.save_final_results(results)
        
    except Exception as e:
        logger.error(f"âŒ ä¸»ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()