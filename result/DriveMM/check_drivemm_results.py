#!/usr/bin/env python3
"""
æ£€æŸ¥DriveMMæ¨ç†ç»“æœå¹¶ç”ŸæˆæŠ¥å‘Š
"""

import json
import os
import subprocess
from datetime import datetime
from pathlib import Path

def run_command(command):
    """æ‰§è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        return result.stdout.strip(), result.stderr.strip(), result.returncode
    except Exception as e:
        return "", str(e), 1

def get_job_status(job_name):
    """è·å–ä½œä¸šçŠ¶æ€"""
    command = f"az ml job show --name {job_name} --resource-group drivelm-rg --workspace-name drivelm-ml-workspace --query '{{Name:name,Status:status,StartTime:creation_context.created_at,EndTime:end_time}}' --output json"
    
    stdout, stderr, returncode = run_command(command)
    
    if returncode == 0:
        try:
            return json.loads(stdout)
        except json.JSONDecodeError:
            return None
    else:
        print(f"âŒ è·å–ä½œä¸šçŠ¶æ€å¤±è´¥: {stderr}")
        return None

def download_job_outputs(job_name):
    """ä¸‹è½½ä½œä¸šè¾“å‡º"""
    print(f"ğŸ“¥ å°è¯•ä¸‹è½½ä½œä¸šè¾“å‡º: {job_name}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = f"job_outputs_{job_name}"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¸‹è½½è¾“å‡º
    command = f"az ml job download --name {job_name} --resource-group drivelm-rg --workspace-name drivelm-ml-workspace --output-name outputs --path {output_dir}"
    stdout, stderr, returncode = run_command(command)
    
    if returncode == 0:
        print(f"âœ… ä½œä¸šè¾“å‡ºå·²ä¸‹è½½åˆ°: {output_dir}")
        return output_dir
    else:
        print(f"âŒ ä¸‹è½½ä½œä¸šè¾“å‡ºå¤±è´¥: {stderr}")
        return None

def analyze_drivemm_results(output_dir):
    """åˆ†æDriveMMç»“æœ"""
    print(f"ğŸ“Š åˆ†æDriveMMç»“æœ: {output_dir}")
    
    results_file = os.path.join(output_dir, "azure_drivemm_real_inference_results.json")
    
    if os.path.exists(results_file):
        print(f"âœ… æ‰¾åˆ°ç»“æœæ–‡ä»¶: {results_file}")
        
        try:
            with open(results_file, 'r', encoding='utf-8') as f:
                results = json.load(f)
            
            summary = results.get('real_drivemm_analysis_summary', {})
            detailed_results = results.get('detailed_results', [])
            
            print("=" * 60)
            print("ğŸ‰ DriveMMåˆ†æç»“æœæ‘˜è¦")
            print("=" * 60)
            print(f"ğŸ“‹ æ¨¡å‹: {summary.get('model', 'Unknown')}")
            print(f"ğŸ”— æ¨¡å‹æ¥æº: {summary.get('model_source', 'Unknown')}")
            print(f"ğŸ’¾ æ€»è§†é¢‘æ•°: {summary.get('total_videos_analyzed', 0)}")
            
            detection_results = summary.get('detection_results', {})
            print(f"ğŸ” æ£€æµ‹ç»“æœ:")
            print(f"   - é«˜ç¡®ä¿¡åº¦é¬¼æ¢å¤´: {detection_results.get('high_confidence_ghost_probing', 0)}")
            print(f"   - æ½œåœ¨é¬¼æ¢å¤´: {detection_results.get('potential_ghost_probing', 0)}")
            print(f"   - æ­£å¸¸äº¤é€š: {detection_results.get('normal_traffic', 0)}")
            
            detection_rates = summary.get('detection_rates', {})
            print(f"ğŸ“Š æ£€æµ‹ç‡:")
            print(f"   - é¬¼æ¢å¤´æ£€æµ‹ç‡: {detection_rates.get('ghost_probing_rate', 0):.2%}")
            print(f"   - æ½œåœ¨é¬¼æ¢å¤´ç‡: {detection_rates.get('potential_ghost_probing_rate', 0):.2%}")
            print(f"   - æ­£å¸¸äº¤é€šç‡: {detection_rates.get('normal_traffic_rate', 0):.2%}")
            
            return results
            
        except Exception as e:
            print(f"âŒ åˆ†æç»“æœå¤±è´¥: {e}")
            return None
    else:
        print(f"âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶: {results_file}")
        return None

def generate_comparison_report(drivemm_results):
    """ç”Ÿæˆä¸GPT-4.1çš„å¯¹æ¯”æŠ¥å‘Š"""
    print("ğŸ“ ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
    
    # è¯»å–GPT-4.1ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    gpt41_results_file = "result/gpt4o-100-3rd/evaluation_results.json"
    
    report = {
        "comparison_timestamp": datetime.now().isoformat(),
        "drivemm_results": drivemm_results,
        "gpt41_baseline": None,
        "comparison_summary": {}
    }
    
    if os.path.exists(gpt41_results_file):
        try:
            with open(gpt41_results_file, 'r', encoding='utf-8') as f:
                gpt41_data = json.load(f)
                report["gpt41_baseline"] = gpt41_data
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–GPT-4.1åŸºå‡†ç»“æœ: {e}")
    
    # ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
    report_file = "drivemm_vs_gpt41_comparison_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    return report_file

def main():
    """ä¸»å‡½æ•°"""
    job_name = "red_diamond_xfbmkt8klp"
    
    print("ğŸ” DriveMMç»“æœæ£€æŸ¥å™¨")
    print("=" * 60)
    print(f"ğŸ“‹ ä½œä¸šåç§°: {job_name}")
    print("=" * 60)
    
    # æ£€æŸ¥ä½œä¸šçŠ¶æ€
    job_info = get_job_status(job_name)
    if job_info:
        status = job_info.get('Status', 'Unknown')
        print(f"ğŸ“Š ä½œä¸šçŠ¶æ€: {status}")
        
        if status == "Completed":
            print("âœ… ä½œä¸šå·²å®Œæˆï¼Œå‡†å¤‡ä¸‹è½½ç»“æœ...")
            
            # ä¸‹è½½ä½œä¸šè¾“å‡º
            output_dir = download_job_outputs(job_name)
            if output_dir:
                # åˆ†æç»“æœ
                drivemm_results = analyze_drivemm_results(output_dir)
                if drivemm_results:
                    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
                    report_file = generate_comparison_report(drivemm_results)
                    print(f"ğŸ‰ åˆ†æå®Œæˆï¼å¯¹æ¯”æŠ¥å‘Š: {report_file}")
                else:
                    print("âŒ ç»“æœåˆ†æå¤±è´¥")
            else:
                print("âŒ ä¸‹è½½ä½œä¸šè¾“å‡ºå¤±è´¥")
        else:
            print(f"â³ ä½œä¸šçŠ¶æ€: {status}ï¼Œè¯·ç­‰å¾…å®Œæˆåå†è¿è¡Œæ­¤è„šæœ¬")
    else:
        print("âŒ æ— æ³•è·å–ä½œä¸šçŠ¶æ€")

if __name__ == "__main__":
    main()