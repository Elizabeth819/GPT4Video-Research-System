{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9999403945878286,
  "eval_steps": 500,
  "global_step": 6291,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0001589477657904671,
      "grad_norm": 4.378695487976074,
      "learning_rate": 5.291005291005291e-08,
      "loss": 0.5096,
      "step": 1
    },
    {
      "epoch": 0.0003178955315809342,
      "grad_norm": 4.824601650238037,
      "learning_rate": 1.0582010582010582e-07,
      "loss": 0.5618,
      "step": 2
    },
    {
      "epoch": 0.00047684329737140134,
      "grad_norm": 5.0702080726623535,
      "learning_rate": 1.5873015873015874e-07,
      "loss": 0.7227,
      "step": 3
    },
    {
      "epoch": 0.0006357910631618684,
      "grad_norm": 5.727874755859375,
      "learning_rate": 2.1164021164021165e-07,
      "loss": 0.5757,
      "step": 4
    },
    {
      "epoch": 0.0007947388289523355,
      "grad_norm": 5.255198001861572,
      "learning_rate": 2.6455026455026455e-07,
      "loss": 0.5599,
      "step": 5
    },
    {
      "epoch": 0.0009536865947428027,
      "grad_norm": 5.203065395355225,
      "learning_rate": 3.174603174603175e-07,
      "loss": 0.6688,
      "step": 6
    },
    {
      "epoch": 0.0011126343605332698,
      "grad_norm": 4.940822601318359,
      "learning_rate": 3.7037037037037036e-07,
      "loss": 0.6609,
      "step": 7
    },
    {
      "epoch": 0.001271582126323737,
      "grad_norm": 4.346892833709717,
      "learning_rate": 4.232804232804233e-07,
      "loss": 0.5997,
      "step": 8
    },
    {
      "epoch": 0.001430529892114204,
      "grad_norm": 5.035449028015137,
      "learning_rate": 4.7619047619047623e-07,
      "loss": 0.5144,
      "step": 9
    },
    {
      "epoch": 0.001589477657904671,
      "grad_norm": 3.749126434326172,
      "learning_rate": 5.291005291005291e-07,
      "loss": 0.4746,
      "step": 10
    },
    {
      "epoch": 0.0017484254236951383,
      "grad_norm": 4.047332286834717,
      "learning_rate": 5.82010582010582e-07,
      "loss": 0.6425,
      "step": 11
    },
    {
      "epoch": 0.0019073731894856053,
      "grad_norm": 4.656301498413086,
      "learning_rate": 6.34920634920635e-07,
      "loss": 0.5454,
      "step": 12
    },
    {
      "epoch": 0.0020663209552760726,
      "grad_norm": 3.8916831016540527,
      "learning_rate": 6.878306878306879e-07,
      "loss": 0.5097,
      "step": 13
    },
    {
      "epoch": 0.0022252687210665397,
      "grad_norm": 3.5083789825439453,
      "learning_rate": 7.407407407407407e-07,
      "loss": 0.5753,
      "step": 14
    },
    {
      "epoch": 0.0023842164868570067,
      "grad_norm": 3.1973953247070312,
      "learning_rate": 7.936507936507937e-07,
      "loss": 0.6963,
      "step": 15
    },
    {
      "epoch": 0.002543164252647474,
      "grad_norm": 3.2241008281707764,
      "learning_rate": 8.465608465608466e-07,
      "loss": 0.6064,
      "step": 16
    },
    {
      "epoch": 0.002702112018437941,
      "grad_norm": 2.640807628631592,
      "learning_rate": 8.994708994708995e-07,
      "loss": 0.5524,
      "step": 17
    },
    {
      "epoch": 0.002861059784228408,
      "grad_norm": 2.6505439281463623,
      "learning_rate": 9.523809523809525e-07,
      "loss": 0.6698,
      "step": 18
    },
    {
      "epoch": 0.003020007550018875,
      "grad_norm": 2.6479787826538086,
      "learning_rate": 1.0052910052910054e-06,
      "loss": 0.4812,
      "step": 19
    },
    {
      "epoch": 0.003178955315809342,
      "grad_norm": 2.187343120574951,
      "learning_rate": 1.0582010582010582e-06,
      "loss": 0.5475,
      "step": 20
    },
    {
      "epoch": 0.003337903081599809,
      "grad_norm": 2.2983014583587646,
      "learning_rate": 1.111111111111111e-06,
      "loss": 0.471,
      "step": 21
    },
    {
      "epoch": 0.0034968508473902766,
      "grad_norm": 1.7474693059921265,
      "learning_rate": 1.164021164021164e-06,
      "loss": 0.5168,
      "step": 22
    },
    {
      "epoch": 0.0036557986131807436,
      "grad_norm": 1.7394423484802246,
      "learning_rate": 1.216931216931217e-06,
      "loss": 0.4331,
      "step": 23
    },
    {
      "epoch": 0.0038147463789712107,
      "grad_norm": 1.6477463245391846,
      "learning_rate": 1.26984126984127e-06,
      "loss": 0.4116,
      "step": 24
    },
    {
      "epoch": 0.003973694144761677,
      "grad_norm": 1.7724790573120117,
      "learning_rate": 1.3227513227513228e-06,
      "loss": 0.4906,
      "step": 25
    },
    {
      "epoch": 0.004132641910552145,
      "grad_norm": 1.7242437601089478,
      "learning_rate": 1.3756613756613758e-06,
      "loss": 0.5768,
      "step": 26
    },
    {
      "epoch": 0.004291589676342612,
      "grad_norm": 1.7491846084594727,
      "learning_rate": 1.4285714285714286e-06,
      "loss": 0.553,
      "step": 27
    },
    {
      "epoch": 0.004450537442133079,
      "grad_norm": 1.476502537727356,
      "learning_rate": 1.4814814814814815e-06,
      "loss": 0.5285,
      "step": 28
    },
    {
      "epoch": 0.004609485207923546,
      "grad_norm": 1.7150282859802246,
      "learning_rate": 1.5343915343915345e-06,
      "loss": 0.6354,
      "step": 29
    },
    {
      "epoch": 0.0047684329737140135,
      "grad_norm": 1.3534517288208008,
      "learning_rate": 1.5873015873015873e-06,
      "loss": 0.3759,
      "step": 30
    },
    {
      "epoch": 0.0049273807395044805,
      "grad_norm": 1.3573064804077148,
      "learning_rate": 1.6402116402116404e-06,
      "loss": 0.4132,
      "step": 31
    },
    {
      "epoch": 0.005086328505294948,
      "grad_norm": 1.416758418083191,
      "learning_rate": 1.6931216931216932e-06,
      "loss": 0.6078,
      "step": 32
    },
    {
      "epoch": 0.005245276271085415,
      "grad_norm": 1.3125113248825073,
      "learning_rate": 1.746031746031746e-06,
      "loss": 0.3759,
      "step": 33
    },
    {
      "epoch": 0.005404224036875882,
      "grad_norm": 1.4972904920578003,
      "learning_rate": 1.798941798941799e-06,
      "loss": 0.684,
      "step": 34
    },
    {
      "epoch": 0.005563171802666349,
      "grad_norm": 1.16989004611969,
      "learning_rate": 1.8518518518518519e-06,
      "loss": 0.3654,
      "step": 35
    },
    {
      "epoch": 0.005722119568456816,
      "grad_norm": 1.1100095510482788,
      "learning_rate": 1.904761904761905e-06,
      "loss": 0.2776,
      "step": 36
    },
    {
      "epoch": 0.005881067334247283,
      "grad_norm": 1.1715221405029297,
      "learning_rate": 1.9576719576719577e-06,
      "loss": 0.3252,
      "step": 37
    },
    {
      "epoch": 0.00604001510003775,
      "grad_norm": 1.2814081907272339,
      "learning_rate": 2.0105820105820108e-06,
      "loss": 0.5586,
      "step": 38
    },
    {
      "epoch": 0.006198962865828217,
      "grad_norm": 0.9980789422988892,
      "learning_rate": 2.0634920634920634e-06,
      "loss": 0.2693,
      "step": 39
    },
    {
      "epoch": 0.006357910631618684,
      "grad_norm": 1.3799359798431396,
      "learning_rate": 2.1164021164021164e-06,
      "loss": 0.5703,
      "step": 40
    },
    {
      "epoch": 0.006516858397409151,
      "grad_norm": 1.1395457983016968,
      "learning_rate": 2.1693121693121695e-06,
      "loss": 0.3975,
      "step": 41
    },
    {
      "epoch": 0.006675806163199618,
      "grad_norm": 1.4774457216262817,
      "learning_rate": 2.222222222222222e-06,
      "loss": 0.5885,
      "step": 42
    },
    {
      "epoch": 0.006834753928990085,
      "grad_norm": 1.06889009475708,
      "learning_rate": 2.275132275132275e-06,
      "loss": 0.2211,
      "step": 43
    },
    {
      "epoch": 0.006993701694780553,
      "grad_norm": 1.1032432317733765,
      "learning_rate": 2.328042328042328e-06,
      "loss": 0.351,
      "step": 44
    },
    {
      "epoch": 0.00715264946057102,
      "grad_norm": 0.986090362071991,
      "learning_rate": 2.380952380952381e-06,
      "loss": 0.2843,
      "step": 45
    },
    {
      "epoch": 0.007311597226361487,
      "grad_norm": 1.0766079425811768,
      "learning_rate": 2.433862433862434e-06,
      "loss": 0.4092,
      "step": 46
    },
    {
      "epoch": 0.007470544992151954,
      "grad_norm": 0.9772195219993591,
      "learning_rate": 2.486772486772487e-06,
      "loss": 0.3368,
      "step": 47
    },
    {
      "epoch": 0.007629492757942421,
      "grad_norm": 1.6367084980010986,
      "learning_rate": 2.53968253968254e-06,
      "loss": 0.3198,
      "step": 48
    },
    {
      "epoch": 0.007788440523732888,
      "grad_norm": 1.2802553176879883,
      "learning_rate": 2.5925925925925925e-06,
      "loss": 0.544,
      "step": 49
    },
    {
      "epoch": 0.007947388289523355,
      "grad_norm": 1.0936709642410278,
      "learning_rate": 2.6455026455026455e-06,
      "loss": 0.421,
      "step": 50
    },
    {
      "epoch": 0.008106336055313822,
      "grad_norm": 1.0251127481460571,
      "learning_rate": 2.6984126984126986e-06,
      "loss": 0.4347,
      "step": 51
    },
    {
      "epoch": 0.00826528382110429,
      "grad_norm": 1.11297607421875,
      "learning_rate": 2.7513227513227516e-06,
      "loss": 0.3301,
      "step": 52
    },
    {
      "epoch": 0.008424231586894758,
      "grad_norm": 0.96006840467453,
      "learning_rate": 2.8042328042328042e-06,
      "loss": 0.2924,
      "step": 53
    },
    {
      "epoch": 0.008583179352685225,
      "grad_norm": 1.121166706085205,
      "learning_rate": 2.8571428571428573e-06,
      "loss": 0.3151,
      "step": 54
    },
    {
      "epoch": 0.008742127118475692,
      "grad_norm": 1.7487701177597046,
      "learning_rate": 2.9100529100529103e-06,
      "loss": 0.3505,
      "step": 55
    },
    {
      "epoch": 0.008901074884266159,
      "grad_norm": 0.8954795002937317,
      "learning_rate": 2.962962962962963e-06,
      "loss": 0.3084,
      "step": 56
    },
    {
      "epoch": 0.009060022650056626,
      "grad_norm": 0.9089216589927673,
      "learning_rate": 3.015873015873016e-06,
      "loss": 0.2768,
      "step": 57
    },
    {
      "epoch": 0.009218970415847093,
      "grad_norm": 0.990303635597229,
      "learning_rate": 3.068783068783069e-06,
      "loss": 0.4178,
      "step": 58
    },
    {
      "epoch": 0.00937791818163756,
      "grad_norm": 0.9020870327949524,
      "learning_rate": 3.1216931216931216e-06,
      "loss": 0.2659,
      "step": 59
    },
    {
      "epoch": 0.009536865947428027,
      "grad_norm": 0.9527940154075623,
      "learning_rate": 3.1746031746031746e-06,
      "loss": 0.3188,
      "step": 60
    },
    {
      "epoch": 0.009695813713218494,
      "grad_norm": 1.1578699350357056,
      "learning_rate": 3.2275132275132277e-06,
      "loss": 0.4667,
      "step": 61
    },
    {
      "epoch": 0.009854761479008961,
      "grad_norm": 0.9352280497550964,
      "learning_rate": 3.2804232804232807e-06,
      "loss": 0.2478,
      "step": 62
    },
    {
      "epoch": 0.010013709244799428,
      "grad_norm": 0.8737820982933044,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.3494,
      "step": 63
    },
    {
      "epoch": 0.010172657010589895,
      "grad_norm": 0.9618734121322632,
      "learning_rate": 3.3862433862433864e-06,
      "loss": 0.3066,
      "step": 64
    },
    {
      "epoch": 0.010331604776380362,
      "grad_norm": 0.9236706495285034,
      "learning_rate": 3.4391534391534394e-06,
      "loss": 0.3369,
      "step": 65
    },
    {
      "epoch": 0.01049055254217083,
      "grad_norm": 0.8948109149932861,
      "learning_rate": 3.492063492063492e-06,
      "loss": 0.2641,
      "step": 66
    },
    {
      "epoch": 0.010649500307961296,
      "grad_norm": 0.9407448172569275,
      "learning_rate": 3.544973544973545e-06,
      "loss": 0.281,
      "step": 67
    },
    {
      "epoch": 0.010808448073751763,
      "grad_norm": 1.0334010124206543,
      "learning_rate": 3.597883597883598e-06,
      "loss": 0.3042,
      "step": 68
    },
    {
      "epoch": 0.01096739583954223,
      "grad_norm": 1.4459878206253052,
      "learning_rate": 3.6507936507936507e-06,
      "loss": 0.4303,
      "step": 69
    },
    {
      "epoch": 0.011126343605332698,
      "grad_norm": 0.8857740163803101,
      "learning_rate": 3.7037037037037037e-06,
      "loss": 0.2664,
      "step": 70
    },
    {
      "epoch": 0.011285291371123165,
      "grad_norm": 0.9856666922569275,
      "learning_rate": 3.7566137566137568e-06,
      "loss": 0.2989,
      "step": 71
    },
    {
      "epoch": 0.011444239136913632,
      "grad_norm": 0.9204538464546204,
      "learning_rate": 3.80952380952381e-06,
      "loss": 0.2785,
      "step": 72
    },
    {
      "epoch": 0.011603186902704099,
      "grad_norm": 1.0638408660888672,
      "learning_rate": 3.862433862433863e-06,
      "loss": 0.4171,
      "step": 73
    },
    {
      "epoch": 0.011762134668494566,
      "grad_norm": 1.0161805152893066,
      "learning_rate": 3.9153439153439155e-06,
      "loss": 0.4081,
      "step": 74
    },
    {
      "epoch": 0.011921082434285033,
      "grad_norm": 0.9702437520027161,
      "learning_rate": 3.968253968253968e-06,
      "loss": 0.3558,
      "step": 75
    },
    {
      "epoch": 0.0120800302000755,
      "grad_norm": 1.1408069133758545,
      "learning_rate": 4.0211640211640215e-06,
      "loss": 0.5053,
      "step": 76
    },
    {
      "epoch": 0.012238977965865967,
      "grad_norm": 1.0649511814117432,
      "learning_rate": 4.074074074074074e-06,
      "loss": 0.3199,
      "step": 77
    },
    {
      "epoch": 0.012397925731656434,
      "grad_norm": 1.0398600101470947,
      "learning_rate": 4.126984126984127e-06,
      "loss": 0.302,
      "step": 78
    },
    {
      "epoch": 0.012556873497446901,
      "grad_norm": 1.0150346755981445,
      "learning_rate": 4.17989417989418e-06,
      "loss": 0.4003,
      "step": 79
    },
    {
      "epoch": 0.012715821263237368,
      "grad_norm": 0.8136810660362244,
      "learning_rate": 4.232804232804233e-06,
      "loss": 0.2199,
      "step": 80
    },
    {
      "epoch": 0.012874769029027835,
      "grad_norm": 0.9019972085952759,
      "learning_rate": 4.2857142857142855e-06,
      "loss": 0.2623,
      "step": 81
    },
    {
      "epoch": 0.013033716794818302,
      "grad_norm": 1.0191162824630737,
      "learning_rate": 4.338624338624339e-06,
      "loss": 0.4041,
      "step": 82
    },
    {
      "epoch": 0.01319266456060877,
      "grad_norm": 1.0062222480773926,
      "learning_rate": 4.3915343915343915e-06,
      "loss": 0.3407,
      "step": 83
    },
    {
      "epoch": 0.013351612326399236,
      "grad_norm": 1.0122078657150269,
      "learning_rate": 4.444444444444444e-06,
      "loss": 0.4102,
      "step": 84
    },
    {
      "epoch": 0.013510560092189703,
      "grad_norm": 1.0378398895263672,
      "learning_rate": 4.497354497354498e-06,
      "loss": 0.3716,
      "step": 85
    },
    {
      "epoch": 0.01366950785798017,
      "grad_norm": 1.1151397228240967,
      "learning_rate": 4.55026455026455e-06,
      "loss": 0.3041,
      "step": 86
    },
    {
      "epoch": 0.01382845562377064,
      "grad_norm": 0.8178914189338684,
      "learning_rate": 4.603174603174604e-06,
      "loss": 0.2812,
      "step": 87
    },
    {
      "epoch": 0.013987403389561106,
      "grad_norm": 0.929017961025238,
      "learning_rate": 4.656084656084656e-06,
      "loss": 0.3125,
      "step": 88
    },
    {
      "epoch": 0.014146351155351573,
      "grad_norm": 2.9938933849334717,
      "learning_rate": 4.708994708994709e-06,
      "loss": 0.3193,
      "step": 89
    },
    {
      "epoch": 0.01430529892114204,
      "grad_norm": 1.0479258298873901,
      "learning_rate": 4.761904761904762e-06,
      "loss": 0.2496,
      "step": 90
    },
    {
      "epoch": 0.014464246686932507,
      "grad_norm": 1.106461524963379,
      "learning_rate": 4.814814814814815e-06,
      "loss": 0.3209,
      "step": 91
    },
    {
      "epoch": 0.014623194452722975,
      "grad_norm": 1.0394742488861084,
      "learning_rate": 4.867724867724868e-06,
      "loss": 0.3477,
      "step": 92
    },
    {
      "epoch": 0.014782142218513442,
      "grad_norm": 1.711895227432251,
      "learning_rate": 4.920634920634921e-06,
      "loss": 0.3411,
      "step": 93
    },
    {
      "epoch": 0.014941089984303909,
      "grad_norm": 1.1107522249221802,
      "learning_rate": 4.973544973544974e-06,
      "loss": 0.2518,
      "step": 94
    },
    {
      "epoch": 0.015100037750094376,
      "grad_norm": 1.0598944425582886,
      "learning_rate": 5.026455026455027e-06,
      "loss": 0.4403,
      "step": 95
    },
    {
      "epoch": 0.015258985515884843,
      "grad_norm": 0.9859974980354309,
      "learning_rate": 5.07936507936508e-06,
      "loss": 0.361,
      "step": 96
    },
    {
      "epoch": 0.01541793328167531,
      "grad_norm": 1.2208750247955322,
      "learning_rate": 5.132275132275133e-06,
      "loss": 0.3702,
      "step": 97
    },
    {
      "epoch": 0.015576881047465777,
      "grad_norm": 0.9504444599151611,
      "learning_rate": 5.185185185185185e-06,
      "loss": 0.3838,
      "step": 98
    },
    {
      "epoch": 0.015735828813256244,
      "grad_norm": 1.0768470764160156,
      "learning_rate": 5.2380952380952384e-06,
      "loss": 0.2853,
      "step": 99
    },
    {
      "epoch": 0.01589477657904671,
      "grad_norm": 0.8190929889678955,
      "learning_rate": 5.291005291005291e-06,
      "loss": 0.2294,
      "step": 100
    },
    {
      "epoch": 0.016053724344837178,
      "grad_norm": 1.057950496673584,
      "learning_rate": 5.3439153439153445e-06,
      "loss": 0.3252,
      "step": 101
    },
    {
      "epoch": 0.016212672110627643,
      "grad_norm": 1.00523841381073,
      "learning_rate": 5.396825396825397e-06,
      "loss": 0.2621,
      "step": 102
    },
    {
      "epoch": 0.016371619876418112,
      "grad_norm": 0.9719513058662415,
      "learning_rate": 5.449735449735451e-06,
      "loss": 0.2705,
      "step": 103
    },
    {
      "epoch": 0.01653056764220858,
      "grad_norm": 1.0669764280319214,
      "learning_rate": 5.502645502645503e-06,
      "loss": 0.345,
      "step": 104
    },
    {
      "epoch": 0.016689515407999046,
      "grad_norm": 0.9321176409721375,
      "learning_rate": 5.555555555555557e-06,
      "loss": 0.3321,
      "step": 105
    },
    {
      "epoch": 0.016848463173789515,
      "grad_norm": 1.0266623497009277,
      "learning_rate": 5.6084656084656084e-06,
      "loss": 0.2675,
      "step": 106
    },
    {
      "epoch": 0.01700741093957998,
      "grad_norm": 1.0394083261489868,
      "learning_rate": 5.661375661375662e-06,
      "loss": 0.403,
      "step": 107
    },
    {
      "epoch": 0.01716635870537045,
      "grad_norm": 0.8212278485298157,
      "learning_rate": 5.7142857142857145e-06,
      "loss": 0.2062,
      "step": 108
    },
    {
      "epoch": 0.017325306471160914,
      "grad_norm": 1.219161868095398,
      "learning_rate": 5.767195767195768e-06,
      "loss": 0.4205,
      "step": 109
    },
    {
      "epoch": 0.017484254236951383,
      "grad_norm": 0.8812647461891174,
      "learning_rate": 5.820105820105821e-06,
      "loss": 0.3117,
      "step": 110
    },
    {
      "epoch": 0.01764320200274185,
      "grad_norm": 1.087443470954895,
      "learning_rate": 5.873015873015874e-06,
      "loss": 0.2501,
      "step": 111
    },
    {
      "epoch": 0.017802149768532317,
      "grad_norm": 1.2588621377944946,
      "learning_rate": 5.925925925925926e-06,
      "loss": 0.3996,
      "step": 112
    },
    {
      "epoch": 0.017961097534322783,
      "grad_norm": 1.0700181722640991,
      "learning_rate": 5.978835978835979e-06,
      "loss": 0.4231,
      "step": 113
    },
    {
      "epoch": 0.01812004530011325,
      "grad_norm": 0.7916226387023926,
      "learning_rate": 6.031746031746032e-06,
      "loss": 0.2316,
      "step": 114
    },
    {
      "epoch": 0.018278993065903717,
      "grad_norm": 0.8874453902244568,
      "learning_rate": 6.084656084656085e-06,
      "loss": 0.2731,
      "step": 115
    },
    {
      "epoch": 0.018437940831694186,
      "grad_norm": 0.7955294251441956,
      "learning_rate": 6.137566137566138e-06,
      "loss": 0.1626,
      "step": 116
    },
    {
      "epoch": 0.01859688859748465,
      "grad_norm": 0.8362354636192322,
      "learning_rate": 6.1904761904761914e-06,
      "loss": 0.2308,
      "step": 117
    },
    {
      "epoch": 0.01875583636327512,
      "grad_norm": 0.9105817079544067,
      "learning_rate": 6.243386243386243e-06,
      "loss": 0.2088,
      "step": 118
    },
    {
      "epoch": 0.018914784129065585,
      "grad_norm": 1.1898908615112305,
      "learning_rate": 6.296296296296297e-06,
      "loss": 0.4608,
      "step": 119
    },
    {
      "epoch": 0.019073731894856054,
      "grad_norm": 1.684033989906311,
      "learning_rate": 6.349206349206349e-06,
      "loss": 0.131,
      "step": 120
    },
    {
      "epoch": 0.01923267966064652,
      "grad_norm": 1.050340175628662,
      "learning_rate": 6.402116402116403e-06,
      "loss": 0.3412,
      "step": 121
    },
    {
      "epoch": 0.019391627426436988,
      "grad_norm": 1.0620871782302856,
      "learning_rate": 6.455026455026455e-06,
      "loss": 0.2236,
      "step": 122
    },
    {
      "epoch": 0.019550575192227453,
      "grad_norm": 1.1293421983718872,
      "learning_rate": 6.507936507936509e-06,
      "loss": 0.5186,
      "step": 123
    },
    {
      "epoch": 0.019709522958017922,
      "grad_norm": 1.0845589637756348,
      "learning_rate": 6.560846560846561e-06,
      "loss": 0.3901,
      "step": 124
    },
    {
      "epoch": 0.019868470723808387,
      "grad_norm": 0.8411385416984558,
      "learning_rate": 6.613756613756615e-06,
      "loss": 0.2776,
      "step": 125
    },
    {
      "epoch": 0.020027418489598856,
      "grad_norm": 0.927280843257904,
      "learning_rate": 6.666666666666667e-06,
      "loss": 0.2474,
      "step": 126
    },
    {
      "epoch": 0.02018636625538932,
      "grad_norm": 0.7972685694694519,
      "learning_rate": 6.71957671957672e-06,
      "loss": 0.218,
      "step": 127
    },
    {
      "epoch": 0.02034531402117979,
      "grad_norm": 0.7323123812675476,
      "learning_rate": 6.772486772486773e-06,
      "loss": 0.247,
      "step": 128
    },
    {
      "epoch": 0.020504261786970256,
      "grad_norm": 0.9584090709686279,
      "learning_rate": 6.825396825396826e-06,
      "loss": 0.2288,
      "step": 129
    },
    {
      "epoch": 0.020663209552760724,
      "grad_norm": 0.8862741589546204,
      "learning_rate": 6.878306878306879e-06,
      "loss": 0.2478,
      "step": 130
    },
    {
      "epoch": 0.02082215731855119,
      "grad_norm": 1.0921170711517334,
      "learning_rate": 6.931216931216932e-06,
      "loss": 0.4481,
      "step": 131
    },
    {
      "epoch": 0.02098110508434166,
      "grad_norm": 1.2749541997909546,
      "learning_rate": 6.984126984126984e-06,
      "loss": 0.2194,
      "step": 132
    },
    {
      "epoch": 0.021140052850132124,
      "grad_norm": 0.7920754551887512,
      "learning_rate": 7.0370370370370375e-06,
      "loss": 0.2098,
      "step": 133
    },
    {
      "epoch": 0.021299000615922593,
      "grad_norm": 0.980661153793335,
      "learning_rate": 7.08994708994709e-06,
      "loss": 0.3513,
      "step": 134
    },
    {
      "epoch": 0.021457948381713058,
      "grad_norm": 0.9423570036888123,
      "learning_rate": 7.1428571428571436e-06,
      "loss": 0.2871,
      "step": 135
    },
    {
      "epoch": 0.021616896147503527,
      "grad_norm": 0.8088047504425049,
      "learning_rate": 7.195767195767196e-06,
      "loss": 0.2684,
      "step": 136
    },
    {
      "epoch": 0.021775843913293992,
      "grad_norm": 0.9344165921211243,
      "learning_rate": 7.24867724867725e-06,
      "loss": 0.216,
      "step": 137
    },
    {
      "epoch": 0.02193479167908446,
      "grad_norm": 1.0982496738433838,
      "learning_rate": 7.301587301587301e-06,
      "loss": 0.4633,
      "step": 138
    },
    {
      "epoch": 0.02209373944487493,
      "grad_norm": 0.9381913542747498,
      "learning_rate": 7.354497354497355e-06,
      "loss": 0.1383,
      "step": 139
    },
    {
      "epoch": 0.022252687210665395,
      "grad_norm": 0.8539852499961853,
      "learning_rate": 7.4074074074074075e-06,
      "loss": 0.2497,
      "step": 140
    },
    {
      "epoch": 0.022411634976455864,
      "grad_norm": 1.0334514379501343,
      "learning_rate": 7.460317460317461e-06,
      "loss": 0.2356,
      "step": 141
    },
    {
      "epoch": 0.02257058274224633,
      "grad_norm": 2.378146171569824,
      "learning_rate": 7.5132275132275136e-06,
      "loss": 0.2787,
      "step": 142
    },
    {
      "epoch": 0.022729530508036798,
      "grad_norm": 0.9607858061790466,
      "learning_rate": 7.566137566137567e-06,
      "loss": 0.2576,
      "step": 143
    },
    {
      "epoch": 0.022888478273827263,
      "grad_norm": 0.9028549194335938,
      "learning_rate": 7.61904761904762e-06,
      "loss": 0.3181,
      "step": 144
    },
    {
      "epoch": 0.023047426039617732,
      "grad_norm": 0.832976758480072,
      "learning_rate": 7.671957671957672e-06,
      "loss": 0.2882,
      "step": 145
    },
    {
      "epoch": 0.023206373805408197,
      "grad_norm": 0.7908552885055542,
      "learning_rate": 7.724867724867726e-06,
      "loss": 0.1903,
      "step": 146
    },
    {
      "epoch": 0.023365321571198666,
      "grad_norm": 0.723219633102417,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.2324,
      "step": 147
    },
    {
      "epoch": 0.02352426933698913,
      "grad_norm": 0.9857068657875061,
      "learning_rate": 7.830687830687831e-06,
      "loss": 0.3824,
      "step": 148
    },
    {
      "epoch": 0.0236832171027796,
      "grad_norm": 1.120076060295105,
      "learning_rate": 7.883597883597884e-06,
      "loss": 0.5527,
      "step": 149
    },
    {
      "epoch": 0.023842164868570066,
      "grad_norm": 1.0174294710159302,
      "learning_rate": 7.936507936507936e-06,
      "loss": 0.5096,
      "step": 150
    },
    {
      "epoch": 0.024001112634360534,
      "grad_norm": 0.8485732674598694,
      "learning_rate": 7.98941798941799e-06,
      "loss": 0.2554,
      "step": 151
    },
    {
      "epoch": 0.024160060400151,
      "grad_norm": 0.8202192783355713,
      "learning_rate": 8.042328042328043e-06,
      "loss": 0.2849,
      "step": 152
    },
    {
      "epoch": 0.02431900816594147,
      "grad_norm": 1.0098985433578491,
      "learning_rate": 8.095238095238097e-06,
      "loss": 0.3864,
      "step": 153
    },
    {
      "epoch": 0.024477955931731934,
      "grad_norm": 0.8461604118347168,
      "learning_rate": 8.148148148148148e-06,
      "loss": 0.2502,
      "step": 154
    },
    {
      "epoch": 0.024636903697522403,
      "grad_norm": 1.3799047470092773,
      "learning_rate": 8.201058201058202e-06,
      "loss": 0.3266,
      "step": 155
    },
    {
      "epoch": 0.024795851463312868,
      "grad_norm": 1.0114977359771729,
      "learning_rate": 8.253968253968254e-06,
      "loss": 0.3583,
      "step": 156
    },
    {
      "epoch": 0.024954799229103337,
      "grad_norm": 0.6989408135414124,
      "learning_rate": 8.306878306878307e-06,
      "loss": 0.1804,
      "step": 157
    },
    {
      "epoch": 0.025113746994893802,
      "grad_norm": 0.7798992991447449,
      "learning_rate": 8.35978835978836e-06,
      "loss": 0.2069,
      "step": 158
    },
    {
      "epoch": 0.02527269476068427,
      "grad_norm": 1.0327283143997192,
      "learning_rate": 8.412698412698414e-06,
      "loss": 0.3088,
      "step": 159
    },
    {
      "epoch": 0.025431642526474736,
      "grad_norm": 1.215816617012024,
      "learning_rate": 8.465608465608466e-06,
      "loss": 0.4988,
      "step": 160
    },
    {
      "epoch": 0.025590590292265205,
      "grad_norm": 0.8597514629364014,
      "learning_rate": 8.518518518518519e-06,
      "loss": 0.3246,
      "step": 161
    },
    {
      "epoch": 0.02574953805805567,
      "grad_norm": 0.923014760017395,
      "learning_rate": 8.571428571428571e-06,
      "loss": 0.172,
      "step": 162
    },
    {
      "epoch": 0.02590848582384614,
      "grad_norm": 1.1405164003372192,
      "learning_rate": 8.624338624338624e-06,
      "loss": 0.2871,
      "step": 163
    },
    {
      "epoch": 0.026067433589636604,
      "grad_norm": 1.8210235834121704,
      "learning_rate": 8.677248677248678e-06,
      "loss": 0.3114,
      "step": 164
    },
    {
      "epoch": 0.026226381355427073,
      "grad_norm": 0.9409506916999817,
      "learning_rate": 8.730158730158731e-06,
      "loss": 0.3205,
      "step": 165
    },
    {
      "epoch": 0.02638532912121754,
      "grad_norm": 0.9108654260635376,
      "learning_rate": 8.783068783068783e-06,
      "loss": 0.2822,
      "step": 166
    },
    {
      "epoch": 0.026544276887008007,
      "grad_norm": 1.120527744293213,
      "learning_rate": 8.835978835978837e-06,
      "loss": 0.3727,
      "step": 167
    },
    {
      "epoch": 0.026703224652798473,
      "grad_norm": 0.7990915775299072,
      "learning_rate": 8.888888888888888e-06,
      "loss": 0.2778,
      "step": 168
    },
    {
      "epoch": 0.02686217241858894,
      "grad_norm": 0.7590847611427307,
      "learning_rate": 8.941798941798942e-06,
      "loss": 0.1728,
      "step": 169
    },
    {
      "epoch": 0.027021120184379407,
      "grad_norm": 0.954547107219696,
      "learning_rate": 8.994708994708995e-06,
      "loss": 0.2229,
      "step": 170
    },
    {
      "epoch": 0.027180067950169876,
      "grad_norm": 0.8031507730484009,
      "learning_rate": 9.047619047619049e-06,
      "loss": 0.2025,
      "step": 171
    },
    {
      "epoch": 0.02733901571596034,
      "grad_norm": 1.0743229389190674,
      "learning_rate": 9.1005291005291e-06,
      "loss": 0.4244,
      "step": 172
    },
    {
      "epoch": 0.02749796348175081,
      "grad_norm": 0.9121508002281189,
      "learning_rate": 9.153439153439154e-06,
      "loss": 0.3497,
      "step": 173
    },
    {
      "epoch": 0.02765691124754128,
      "grad_norm": 0.8578908443450928,
      "learning_rate": 9.206349206349207e-06,
      "loss": 0.1599,
      "step": 174
    },
    {
      "epoch": 0.027815859013331744,
      "grad_norm": 0.6691193580627441,
      "learning_rate": 9.25925925925926e-06,
      "loss": 0.1809,
      "step": 175
    },
    {
      "epoch": 0.027974806779122213,
      "grad_norm": 0.8664435744285583,
      "learning_rate": 9.312169312169313e-06,
      "loss": 0.2826,
      "step": 176
    },
    {
      "epoch": 0.028133754544912678,
      "grad_norm": 0.7533337473869324,
      "learning_rate": 9.365079365079366e-06,
      "loss": 0.2639,
      "step": 177
    },
    {
      "epoch": 0.028292702310703147,
      "grad_norm": 0.8514102101325989,
      "learning_rate": 9.417989417989418e-06,
      "loss": 0.286,
      "step": 178
    },
    {
      "epoch": 0.028451650076493612,
      "grad_norm": 1.0805895328521729,
      "learning_rate": 9.470899470899471e-06,
      "loss": 0.2995,
      "step": 179
    },
    {
      "epoch": 0.02861059784228408,
      "grad_norm": 0.8429794311523438,
      "learning_rate": 9.523809523809525e-06,
      "loss": 0.3189,
      "step": 180
    },
    {
      "epoch": 0.028769545608074546,
      "grad_norm": 1.000037670135498,
      "learning_rate": 9.576719576719578e-06,
      "loss": 0.4218,
      "step": 181
    },
    {
      "epoch": 0.028928493373865015,
      "grad_norm": 1.4190034866333008,
      "learning_rate": 9.62962962962963e-06,
      "loss": 0.3145,
      "step": 182
    },
    {
      "epoch": 0.02908744113965548,
      "grad_norm": 0.7676962018013,
      "learning_rate": 9.682539682539683e-06,
      "loss": 0.2046,
      "step": 183
    },
    {
      "epoch": 0.02924638890544595,
      "grad_norm": 0.8175090551376343,
      "learning_rate": 9.735449735449735e-06,
      "loss": 0.3025,
      "step": 184
    },
    {
      "epoch": 0.029405336671236414,
      "grad_norm": 0.9033287763595581,
      "learning_rate": 9.788359788359789e-06,
      "loss": 0.3458,
      "step": 185
    },
    {
      "epoch": 0.029564284437026883,
      "grad_norm": 1.4072446823120117,
      "learning_rate": 9.841269841269842e-06,
      "loss": 0.2125,
      "step": 186
    },
    {
      "epoch": 0.02972323220281735,
      "grad_norm": 0.9862352013587952,
      "learning_rate": 9.894179894179896e-06,
      "loss": 0.5049,
      "step": 187
    },
    {
      "epoch": 0.029882179968607817,
      "grad_norm": 0.6388868689537048,
      "learning_rate": 9.947089947089947e-06,
      "loss": 0.123,
      "step": 188
    },
    {
      "epoch": 0.030041127734398283,
      "grad_norm": 1.2173923254013062,
      "learning_rate": 1e-05,
      "loss": 0.446,
      "step": 189
    },
    {
      "epoch": 0.03020007550018875,
      "grad_norm": 0.7871001362800598,
      "learning_rate": 9.99999933733301e-06,
      "loss": 0.2625,
      "step": 190
    },
    {
      "epoch": 0.030359023265979217,
      "grad_norm": 0.9407187700271606,
      "learning_rate": 9.999997349332213e-06,
      "loss": 0.32,
      "step": 191
    },
    {
      "epoch": 0.030517971031769685,
      "grad_norm": 0.8473701477050781,
      "learning_rate": 9.999994035998136e-06,
      "loss": 0.3124,
      "step": 192
    },
    {
      "epoch": 0.03067691879756015,
      "grad_norm": 0.7318962216377258,
      "learning_rate": 9.99998939733166e-06,
      "loss": 0.306,
      "step": 193
    },
    {
      "epoch": 0.03083586656335062,
      "grad_norm": 0.8187666535377502,
      "learning_rate": 9.99998343333401e-06,
      "loss": 0.2862,
      "step": 194
    },
    {
      "epoch": 0.030994814329141085,
      "grad_norm": 0.7228581309318542,
      "learning_rate": 9.999976144006772e-06,
      "loss": 0.2601,
      "step": 195
    },
    {
      "epoch": 0.031153762094931554,
      "grad_norm": 0.761070191860199,
      "learning_rate": 9.999967529351872e-06,
      "loss": 0.2745,
      "step": 196
    },
    {
      "epoch": 0.03131270986072202,
      "grad_norm": 0.7900448441505432,
      "learning_rate": 9.999957589371601e-06,
      "loss": 0.2804,
      "step": 197
    },
    {
      "epoch": 0.03147165762651249,
      "grad_norm": 0.8299272060394287,
      "learning_rate": 9.999946324068588e-06,
      "loss": 0.2007,
      "step": 198
    },
    {
      "epoch": 0.03163060539230295,
      "grad_norm": 0.8384938836097717,
      "learning_rate": 9.99993373344582e-06,
      "loss": 0.3051,
      "step": 199
    },
    {
      "epoch": 0.03178955315809342,
      "grad_norm": 0.951300859451294,
      "learning_rate": 9.999919817506637e-06,
      "loss": 0.4602,
      "step": 200
    },
    {
      "epoch": 0.03194850092388389,
      "grad_norm": 0.8633637428283691,
      "learning_rate": 9.999904576254723e-06,
      "loss": 0.3702,
      "step": 201
    },
    {
      "epoch": 0.032107448689674356,
      "grad_norm": 0.7607277035713196,
      "learning_rate": 9.999888009694124e-06,
      "loss": 0.29,
      "step": 202
    },
    {
      "epoch": 0.03226639645546482,
      "grad_norm": 0.707079291343689,
      "learning_rate": 9.999870117829227e-06,
      "loss": 0.2846,
      "step": 203
    },
    {
      "epoch": 0.03242534422125529,
      "grad_norm": 0.6980706453323364,
      "learning_rate": 9.999850900664775e-06,
      "loss": 0.2448,
      "step": 204
    },
    {
      "epoch": 0.03258429198704576,
      "grad_norm": 0.763261616230011,
      "learning_rate": 9.999830358205862e-06,
      "loss": 0.2124,
      "step": 205
    },
    {
      "epoch": 0.032743239752836224,
      "grad_norm": 0.7339305877685547,
      "learning_rate": 9.999808490457934e-06,
      "loss": 0.346,
      "step": 206
    },
    {
      "epoch": 0.03290218751862669,
      "grad_norm": 0.8211643695831299,
      "learning_rate": 9.999785297426788e-06,
      "loss": 0.2475,
      "step": 207
    },
    {
      "epoch": 0.03306113528441716,
      "grad_norm": 0.8434732556343079,
      "learning_rate": 9.99976077911857e-06,
      "loss": 0.3361,
      "step": 208
    },
    {
      "epoch": 0.03322008305020763,
      "grad_norm": 0.7520304322242737,
      "learning_rate": 9.99973493553978e-06,
      "loss": 0.316,
      "step": 209
    },
    {
      "epoch": 0.03337903081599809,
      "grad_norm": 0.770191490650177,
      "learning_rate": 9.999707766697267e-06,
      "loss": 0.3258,
      "step": 210
    },
    {
      "epoch": 0.03353797858178856,
      "grad_norm": 0.7945755124092102,
      "learning_rate": 9.999679272598234e-06,
      "loss": 0.2657,
      "step": 211
    },
    {
      "epoch": 0.03369692634757903,
      "grad_norm": 0.6568441390991211,
      "learning_rate": 9.999649453250233e-06,
      "loss": 0.1814,
      "step": 212
    },
    {
      "epoch": 0.033855874113369495,
      "grad_norm": 0.9560797214508057,
      "learning_rate": 9.99961830866117e-06,
      "loss": 0.3036,
      "step": 213
    },
    {
      "epoch": 0.03401482187915996,
      "grad_norm": 0.9098444581031799,
      "learning_rate": 9.999585838839297e-06,
      "loss": 0.3744,
      "step": 214
    },
    {
      "epoch": 0.034173769644950426,
      "grad_norm": 0.6927216649055481,
      "learning_rate": 9.999552043793223e-06,
      "loss": 0.2899,
      "step": 215
    },
    {
      "epoch": 0.0343327174107409,
      "grad_norm": 0.8694790601730347,
      "learning_rate": 9.999516923531906e-06,
      "loss": 0.2932,
      "step": 216
    },
    {
      "epoch": 0.034491665176531364,
      "grad_norm": 1.038076639175415,
      "learning_rate": 9.999480478064653e-06,
      "loss": 0.4957,
      "step": 217
    },
    {
      "epoch": 0.03465061294232183,
      "grad_norm": 0.8377343416213989,
      "learning_rate": 9.999442707401127e-06,
      "loss": 0.2985,
      "step": 218
    },
    {
      "epoch": 0.034809560708112294,
      "grad_norm": 0.7995110750198364,
      "learning_rate": 9.999403611551341e-06,
      "loss": 0.3485,
      "step": 219
    },
    {
      "epoch": 0.03496850847390277,
      "grad_norm": 2.0181989669799805,
      "learning_rate": 9.999363190525655e-06,
      "loss": 0.3533,
      "step": 220
    },
    {
      "epoch": 0.03512745623969323,
      "grad_norm": 0.7254216074943542,
      "learning_rate": 9.999321444334783e-06,
      "loss": 0.2425,
      "step": 221
    },
    {
      "epoch": 0.0352864040054837,
      "grad_norm": 0.7420626282691956,
      "learning_rate": 9.999278372989792e-06,
      "loss": 0.1885,
      "step": 222
    },
    {
      "epoch": 0.03544535177127416,
      "grad_norm": 1.0371187925338745,
      "learning_rate": 9.999233976502099e-06,
      "loss": 0.3487,
      "step": 223
    },
    {
      "epoch": 0.035604299537064635,
      "grad_norm": 0.8820241093635559,
      "learning_rate": 9.99918825488347e-06,
      "loss": 0.2812,
      "step": 224
    },
    {
      "epoch": 0.0357632473028551,
      "grad_norm": 0.7283337116241455,
      "learning_rate": 9.999141208146029e-06,
      "loss": 0.2764,
      "step": 225
    },
    {
      "epoch": 0.035922195068645565,
      "grad_norm": 0.8187538385391235,
      "learning_rate": 9.99909283630224e-06,
      "loss": 0.2994,
      "step": 226
    },
    {
      "epoch": 0.03608114283443603,
      "grad_norm": 0.8483771681785583,
      "learning_rate": 9.99904313936493e-06,
      "loss": 0.3341,
      "step": 227
    },
    {
      "epoch": 0.0362400906002265,
      "grad_norm": 0.9661192297935486,
      "learning_rate": 9.99899211734727e-06,
      "loss": 0.4694,
      "step": 228
    },
    {
      "epoch": 0.03639903836601697,
      "grad_norm": 0.8242113590240479,
      "learning_rate": 9.998939770262784e-06,
      "loss": 0.3205,
      "step": 229
    },
    {
      "epoch": 0.036557986131807434,
      "grad_norm": 0.7947415113449097,
      "learning_rate": 9.998886098125348e-06,
      "loss": 0.3107,
      "step": 230
    },
    {
      "epoch": 0.0367169338975979,
      "grad_norm": 0.7406095862388611,
      "learning_rate": 9.998831100949188e-06,
      "loss": 0.2173,
      "step": 231
    },
    {
      "epoch": 0.03687588166338837,
      "grad_norm": 0.9117953181266785,
      "learning_rate": 9.998774778748884e-06,
      "loss": 0.3079,
      "step": 232
    },
    {
      "epoch": 0.03703482942917884,
      "grad_norm": 0.9176281690597534,
      "learning_rate": 9.998717131539361e-06,
      "loss": 0.3302,
      "step": 233
    },
    {
      "epoch": 0.0371937771949693,
      "grad_norm": 0.8228958249092102,
      "learning_rate": 9.998658159335903e-06,
      "loss": 0.2768,
      "step": 234
    },
    {
      "epoch": 0.03735272496075977,
      "grad_norm": 0.8701924681663513,
      "learning_rate": 9.998597862154142e-06,
      "loss": 0.3625,
      "step": 235
    },
    {
      "epoch": 0.03751167272655024,
      "grad_norm": 1.0641297101974487,
      "learning_rate": 9.998536240010058e-06,
      "loss": 0.471,
      "step": 236
    },
    {
      "epoch": 0.037670620492340705,
      "grad_norm": 0.6274664998054504,
      "learning_rate": 9.998473292919987e-06,
      "loss": 0.2205,
      "step": 237
    },
    {
      "epoch": 0.03782956825813117,
      "grad_norm": 0.8274301886558533,
      "learning_rate": 9.998409020900613e-06,
      "loss": 0.3563,
      "step": 238
    },
    {
      "epoch": 0.037988516023921635,
      "grad_norm": 0.960093080997467,
      "learning_rate": 9.998343423968972e-06,
      "loss": 0.4371,
      "step": 239
    },
    {
      "epoch": 0.03814746378971211,
      "grad_norm": 0.850314199924469,
      "learning_rate": 9.998276502142454e-06,
      "loss": 0.3926,
      "step": 240
    },
    {
      "epoch": 0.03830641155550257,
      "grad_norm": 0.6931279301643372,
      "learning_rate": 9.998208255438796e-06,
      "loss": 0.1933,
      "step": 241
    },
    {
      "epoch": 0.03846535932129304,
      "grad_norm": 0.7744444608688354,
      "learning_rate": 9.998138683876088e-06,
      "loss": 0.2543,
      "step": 242
    },
    {
      "epoch": 0.03862430708708351,
      "grad_norm": 0.9093534350395203,
      "learning_rate": 9.998067787472772e-06,
      "loss": 0.4711,
      "step": 243
    },
    {
      "epoch": 0.038783254852873976,
      "grad_norm": 0.6523995995521545,
      "learning_rate": 9.997995566247639e-06,
      "loss": 0.2016,
      "step": 244
    },
    {
      "epoch": 0.03894220261866444,
      "grad_norm": 1.0801723003387451,
      "learning_rate": 9.99792202021983e-06,
      "loss": 0.4667,
      "step": 245
    },
    {
      "epoch": 0.03910115038445491,
      "grad_norm": 0.7388065457344055,
      "learning_rate": 9.997847149408846e-06,
      "loss": 0.3195,
      "step": 246
    },
    {
      "epoch": 0.03926009815024538,
      "grad_norm": 1.2810643911361694,
      "learning_rate": 9.99777095383453e-06,
      "loss": 0.2201,
      "step": 247
    },
    {
      "epoch": 0.039419045916035844,
      "grad_norm": 0.9767518639564514,
      "learning_rate": 9.997693433517075e-06,
      "loss": 0.3706,
      "step": 248
    },
    {
      "epoch": 0.03957799368182631,
      "grad_norm": 0.9533788561820984,
      "learning_rate": 9.997614588477033e-06,
      "loss": 0.2407,
      "step": 249
    },
    {
      "epoch": 0.039736941447616775,
      "grad_norm": 0.7081993818283081,
      "learning_rate": 9.997534418735305e-06,
      "loss": 0.2469,
      "step": 250
    },
    {
      "epoch": 0.03989588921340725,
      "grad_norm": 0.7010300159454346,
      "learning_rate": 9.997452924313137e-06,
      "loss": 0.2945,
      "step": 251
    },
    {
      "epoch": 0.04005483697919771,
      "grad_norm": 0.7779151797294617,
      "learning_rate": 9.997370105232134e-06,
      "loss": 0.2552,
      "step": 252
    },
    {
      "epoch": 0.04021378474498818,
      "grad_norm": 0.7680737972259521,
      "learning_rate": 9.997285961514245e-06,
      "loss": 0.3123,
      "step": 253
    },
    {
      "epoch": 0.04037273251077864,
      "grad_norm": 0.6732094287872314,
      "learning_rate": 9.997200493181777e-06,
      "loss": 0.2402,
      "step": 254
    },
    {
      "epoch": 0.040531680276569115,
      "grad_norm": 1.5849249362945557,
      "learning_rate": 9.997113700257383e-06,
      "loss": 0.3341,
      "step": 255
    },
    {
      "epoch": 0.04069062804235958,
      "grad_norm": 0.7565295100212097,
      "learning_rate": 9.997025582764068e-06,
      "loss": 0.261,
      "step": 256
    },
    {
      "epoch": 0.040849575808150046,
      "grad_norm": 0.8090888857841492,
      "learning_rate": 9.996936140725193e-06,
      "loss": 0.3461,
      "step": 257
    },
    {
      "epoch": 0.04100852357394051,
      "grad_norm": 0.9080298542976379,
      "learning_rate": 9.996845374164462e-06,
      "loss": 0.3103,
      "step": 258
    },
    {
      "epoch": 0.041167471339730984,
      "grad_norm": 0.7550322413444519,
      "learning_rate": 9.996753283105935e-06,
      "loss": 0.3484,
      "step": 259
    },
    {
      "epoch": 0.04132641910552145,
      "grad_norm": 0.8356097340583801,
      "learning_rate": 9.996659867574023e-06,
      "loss": 0.4338,
      "step": 260
    },
    {
      "epoch": 0.041485366871311914,
      "grad_norm": 1.341680645942688,
      "learning_rate": 9.99656512759349e-06,
      "loss": 0.2371,
      "step": 261
    },
    {
      "epoch": 0.04164431463710238,
      "grad_norm": 0.6715090274810791,
      "learning_rate": 9.996469063189442e-06,
      "loss": 0.2108,
      "step": 262
    },
    {
      "epoch": 0.04180326240289285,
      "grad_norm": 0.6852392554283142,
      "learning_rate": 9.996371674387348e-06,
      "loss": 0.2562,
      "step": 263
    },
    {
      "epoch": 0.04196221016868332,
      "grad_norm": 0.710966944694519,
      "learning_rate": 9.996272961213022e-06,
      "loss": 0.2801,
      "step": 264
    },
    {
      "epoch": 0.04212115793447378,
      "grad_norm": 0.6884452700614929,
      "learning_rate": 9.996172923692627e-06,
      "loss": 0.2397,
      "step": 265
    },
    {
      "epoch": 0.04228010570026425,
      "grad_norm": 0.7886796593666077,
      "learning_rate": 9.996071561852681e-06,
      "loss": 0.3001,
      "step": 266
    },
    {
      "epoch": 0.04243905346605472,
      "grad_norm": 0.7218585014343262,
      "learning_rate": 9.995968875720052e-06,
      "loss": 0.2415,
      "step": 267
    },
    {
      "epoch": 0.042598001231845185,
      "grad_norm": 0.8136324882507324,
      "learning_rate": 9.995864865321957e-06,
      "loss": 0.3711,
      "step": 268
    },
    {
      "epoch": 0.04275694899763565,
      "grad_norm": 0.711279571056366,
      "learning_rate": 9.99575953068597e-06,
      "loss": 0.2956,
      "step": 269
    },
    {
      "epoch": 0.042915896763426116,
      "grad_norm": 0.7544323801994324,
      "learning_rate": 9.995652871840006e-06,
      "loss": 0.3125,
      "step": 270
    },
    {
      "epoch": 0.04307484452921659,
      "grad_norm": 0.7363303899765015,
      "learning_rate": 9.995544888812342e-06,
      "loss": 0.3628,
      "step": 271
    },
    {
      "epoch": 0.043233792295007054,
      "grad_norm": 0.7059290409088135,
      "learning_rate": 9.995435581631595e-06,
      "loss": 0.2944,
      "step": 272
    },
    {
      "epoch": 0.04339274006079752,
      "grad_norm": 0.7384774088859558,
      "learning_rate": 9.995324950326746e-06,
      "loss": 0.239,
      "step": 273
    },
    {
      "epoch": 0.043551687826587984,
      "grad_norm": 0.7877505421638489,
      "learning_rate": 9.995212994927112e-06,
      "loss": 0.3771,
      "step": 274
    },
    {
      "epoch": 0.043710635592378456,
      "grad_norm": 0.7499035000801086,
      "learning_rate": 9.995099715462373e-06,
      "loss": 0.3473,
      "step": 275
    },
    {
      "epoch": 0.04386958335816892,
      "grad_norm": 0.7988438010215759,
      "learning_rate": 9.994985111962555e-06,
      "loss": 0.4192,
      "step": 276
    },
    {
      "epoch": 0.04402853112395939,
      "grad_norm": 0.7862171530723572,
      "learning_rate": 9.994869184458036e-06,
      "loss": 0.397,
      "step": 277
    },
    {
      "epoch": 0.04418747888974986,
      "grad_norm": 0.7879248261451721,
      "learning_rate": 9.994751932979545e-06,
      "loss": 0.2647,
      "step": 278
    },
    {
      "epoch": 0.044346426655540325,
      "grad_norm": 0.8473849296569824,
      "learning_rate": 9.994633357558158e-06,
      "loss": 0.287,
      "step": 279
    },
    {
      "epoch": 0.04450537442133079,
      "grad_norm": 0.6047155261039734,
      "learning_rate": 9.99451345822531e-06,
      "loss": 0.1666,
      "step": 280
    },
    {
      "epoch": 0.044664322187121255,
      "grad_norm": 1.4150851964950562,
      "learning_rate": 9.99439223501278e-06,
      "loss": 0.2425,
      "step": 281
    },
    {
      "epoch": 0.04482326995291173,
      "grad_norm": 0.8245825171470642,
      "learning_rate": 9.9942696879527e-06,
      "loss": 0.3254,
      "step": 282
    },
    {
      "epoch": 0.04498221771870219,
      "grad_norm": 0.8423281311988831,
      "learning_rate": 9.994145817077554e-06,
      "loss": 0.3948,
      "step": 283
    },
    {
      "epoch": 0.04514116548449266,
      "grad_norm": 0.6882190108299255,
      "learning_rate": 9.994020622420175e-06,
      "loss": 0.1506,
      "step": 284
    },
    {
      "epoch": 0.045300113250283124,
      "grad_norm": 0.8282231092453003,
      "learning_rate": 9.993894104013748e-06,
      "loss": 0.3085,
      "step": 285
    },
    {
      "epoch": 0.045459061016073596,
      "grad_norm": 0.7669751644134521,
      "learning_rate": 9.993766261891809e-06,
      "loss": 0.2682,
      "step": 286
    },
    {
      "epoch": 0.04561800878186406,
      "grad_norm": 0.9479261636734009,
      "learning_rate": 9.993637096088248e-06,
      "loss": 0.3257,
      "step": 287
    },
    {
      "epoch": 0.045776956547654526,
      "grad_norm": 0.8359250426292419,
      "learning_rate": 9.993506606637297e-06,
      "loss": 0.3965,
      "step": 288
    },
    {
      "epoch": 0.04593590431344499,
      "grad_norm": 0.6839097142219543,
      "learning_rate": 9.993374793573547e-06,
      "loss": 0.226,
      "step": 289
    },
    {
      "epoch": 0.046094852079235464,
      "grad_norm": 0.7813120484352112,
      "learning_rate": 9.993241656931938e-06,
      "loss": 0.2448,
      "step": 290
    },
    {
      "epoch": 0.04625379984502593,
      "grad_norm": 0.6687162518501282,
      "learning_rate": 9.99310719674776e-06,
      "loss": 0.1945,
      "step": 291
    },
    {
      "epoch": 0.046412747610816395,
      "grad_norm": 1.000091314315796,
      "learning_rate": 9.992971413056653e-06,
      "loss": 0.3486,
      "step": 292
    },
    {
      "epoch": 0.04657169537660686,
      "grad_norm": 0.8527373671531677,
      "learning_rate": 9.99283430589461e-06,
      "loss": 0.3616,
      "step": 293
    },
    {
      "epoch": 0.04673064314239733,
      "grad_norm": 1.2061355113983154,
      "learning_rate": 9.992695875297972e-06,
      "loss": 0.2461,
      "step": 294
    },
    {
      "epoch": 0.0468895909081878,
      "grad_norm": 0.7558437585830688,
      "learning_rate": 9.992556121303434e-06,
      "loss": 0.3314,
      "step": 295
    },
    {
      "epoch": 0.04704853867397826,
      "grad_norm": 0.7499142289161682,
      "learning_rate": 9.992415043948039e-06,
      "loss": 0.292,
      "step": 296
    },
    {
      "epoch": 0.04720748643976873,
      "grad_norm": 0.6584942936897278,
      "learning_rate": 9.992272643269181e-06,
      "loss": 0.2719,
      "step": 297
    },
    {
      "epoch": 0.0473664342055592,
      "grad_norm": 0.8989967107772827,
      "learning_rate": 9.992128919304607e-06,
      "loss": 0.5024,
      "step": 298
    },
    {
      "epoch": 0.047525381971349666,
      "grad_norm": 0.7220375537872314,
      "learning_rate": 9.991983872092414e-06,
      "loss": 0.2486,
      "step": 299
    },
    {
      "epoch": 0.04768432973714013,
      "grad_norm": 0.7515804171562195,
      "learning_rate": 9.99183750167105e-06,
      "loss": 0.2631,
      "step": 300
    },
    {
      "epoch": 0.047843277502930597,
      "grad_norm": 0.7966707348823547,
      "learning_rate": 9.991689808079308e-06,
      "loss": 0.2922,
      "step": 301
    },
    {
      "epoch": 0.04800222526872107,
      "grad_norm": 0.6157737970352173,
      "learning_rate": 9.991540791356342e-06,
      "loss": 0.1883,
      "step": 302
    },
    {
      "epoch": 0.048161173034511534,
      "grad_norm": 0.7489227056503296,
      "learning_rate": 9.99139045154165e-06,
      "loss": 0.2371,
      "step": 303
    },
    {
      "epoch": 0.048320120800302,
      "grad_norm": 0.6514971852302551,
      "learning_rate": 9.99123878867508e-06,
      "loss": 0.2111,
      "step": 304
    },
    {
      "epoch": 0.048479068566092465,
      "grad_norm": 0.7467895150184631,
      "learning_rate": 9.991085802796835e-06,
      "loss": 0.2628,
      "step": 305
    },
    {
      "epoch": 0.04863801633188294,
      "grad_norm": 0.7112692594528198,
      "learning_rate": 9.990931493947467e-06,
      "loss": 0.2463,
      "step": 306
    },
    {
      "epoch": 0.0487969640976734,
      "grad_norm": 0.6749563813209534,
      "learning_rate": 9.990775862167875e-06,
      "loss": 0.2664,
      "step": 307
    },
    {
      "epoch": 0.04895591186346387,
      "grad_norm": 0.8838339447975159,
      "learning_rate": 9.990618907499314e-06,
      "loss": 0.3012,
      "step": 308
    },
    {
      "epoch": 0.04911485962925433,
      "grad_norm": 0.703900933265686,
      "learning_rate": 9.99046062998339e-06,
      "loss": 0.2287,
      "step": 309
    },
    {
      "epoch": 0.049273807395044805,
      "grad_norm": 0.8858597278594971,
      "learning_rate": 9.990301029662051e-06,
      "loss": 0.3076,
      "step": 310
    },
    {
      "epoch": 0.04943275516083527,
      "grad_norm": 0.7066421508789062,
      "learning_rate": 9.990140106577608e-06,
      "loss": 0.2797,
      "step": 311
    },
    {
      "epoch": 0.049591702926625736,
      "grad_norm": 0.7212801575660706,
      "learning_rate": 9.98997786077271e-06,
      "loss": 0.3204,
      "step": 312
    },
    {
      "epoch": 0.04975065069241621,
      "grad_norm": 0.8130508661270142,
      "learning_rate": 9.989814292290369e-06,
      "loss": 0.3481,
      "step": 313
    },
    {
      "epoch": 0.04990959845820667,
      "grad_norm": 1.130664348602295,
      "learning_rate": 9.989649401173939e-06,
      "loss": 0.3558,
      "step": 314
    },
    {
      "epoch": 0.05006854622399714,
      "grad_norm": 0.5964086651802063,
      "learning_rate": 9.989483187467128e-06,
      "loss": 0.1496,
      "step": 315
    },
    {
      "epoch": 0.050227493989787604,
      "grad_norm": 0.7951100468635559,
      "learning_rate": 9.98931565121399e-06,
      "loss": 0.3306,
      "step": 316
    },
    {
      "epoch": 0.050386441755578076,
      "grad_norm": 0.5242862105369568,
      "learning_rate": 9.98914679245894e-06,
      "loss": 0.2046,
      "step": 317
    },
    {
      "epoch": 0.05054538952136854,
      "grad_norm": 0.7510749697685242,
      "learning_rate": 9.98897661124673e-06,
      "loss": 0.3196,
      "step": 318
    },
    {
      "epoch": 0.05070433728715901,
      "grad_norm": 0.6013298034667969,
      "learning_rate": 9.988805107622473e-06,
      "loss": 0.1883,
      "step": 319
    },
    {
      "epoch": 0.05086328505294947,
      "grad_norm": 0.7128048539161682,
      "learning_rate": 9.98863228163163e-06,
      "loss": 0.226,
      "step": 320
    },
    {
      "epoch": 0.051022232818739945,
      "grad_norm": 0.6364060044288635,
      "learning_rate": 9.988458133320009e-06,
      "loss": 0.2246,
      "step": 321
    },
    {
      "epoch": 0.05118118058453041,
      "grad_norm": 0.5987584590911865,
      "learning_rate": 9.988282662733772e-06,
      "loss": 0.205,
      "step": 322
    },
    {
      "epoch": 0.051340128350320875,
      "grad_norm": 0.7464677691459656,
      "learning_rate": 9.988105869919429e-06,
      "loss": 0.2972,
      "step": 323
    },
    {
      "epoch": 0.05149907611611134,
      "grad_norm": 0.821291983127594,
      "learning_rate": 9.987927754923844e-06,
      "loss": 0.3585,
      "step": 324
    },
    {
      "epoch": 0.05165802388190181,
      "grad_norm": 0.7323029041290283,
      "learning_rate": 9.987748317794228e-06,
      "loss": 0.2408,
      "step": 325
    },
    {
      "epoch": 0.05181697164769228,
      "grad_norm": 0.6443277597427368,
      "learning_rate": 9.987567558578146e-06,
      "loss": 0.1979,
      "step": 326
    },
    {
      "epoch": 0.051975919413482743,
      "grad_norm": 0.6557705998420715,
      "learning_rate": 9.987385477323507e-06,
      "loss": 0.1894,
      "step": 327
    },
    {
      "epoch": 0.05213486717927321,
      "grad_norm": 0.8202553391456604,
      "learning_rate": 9.98720207407858e-06,
      "loss": 0.2787,
      "step": 328
    },
    {
      "epoch": 0.05229381494506368,
      "grad_norm": 0.8888444900512695,
      "learning_rate": 9.987017348891974e-06,
      "loss": 0.3688,
      "step": 329
    },
    {
      "epoch": 0.052452762710854146,
      "grad_norm": 0.7398427128791809,
      "learning_rate": 9.986831301812656e-06,
      "loss": 0.1788,
      "step": 330
    },
    {
      "epoch": 0.05261171047664461,
      "grad_norm": 0.7196225523948669,
      "learning_rate": 9.986643932889941e-06,
      "loss": 0.2617,
      "step": 331
    },
    {
      "epoch": 0.05277065824243508,
      "grad_norm": 0.7869532704353333,
      "learning_rate": 9.986455242173496e-06,
      "loss": 0.2888,
      "step": 332
    },
    {
      "epoch": 0.05292960600822555,
      "grad_norm": 0.7708911895751953,
      "learning_rate": 9.986265229713332e-06,
      "loss": 0.2996,
      "step": 333
    },
    {
      "epoch": 0.053088553774016015,
      "grad_norm": 0.6977096796035767,
      "learning_rate": 9.986073895559821e-06,
      "loss": 0.269,
      "step": 334
    },
    {
      "epoch": 0.05324750153980648,
      "grad_norm": 0.6525721549987793,
      "learning_rate": 9.985881239763674e-06,
      "loss": 0.2446,
      "step": 335
    },
    {
      "epoch": 0.053406449305596945,
      "grad_norm": 0.9549838304519653,
      "learning_rate": 9.985687262375958e-06,
      "loss": 0.3165,
      "step": 336
    },
    {
      "epoch": 0.05356539707138742,
      "grad_norm": 0.7351298928260803,
      "learning_rate": 9.985491963448093e-06,
      "loss": 0.2655,
      "step": 337
    },
    {
      "epoch": 0.05372434483717788,
      "grad_norm": 0.7616121172904968,
      "learning_rate": 9.985295343031847e-06,
      "loss": 0.2078,
      "step": 338
    },
    {
      "epoch": 0.05388329260296835,
      "grad_norm": 0.7052868604660034,
      "learning_rate": 9.985097401179333e-06,
      "loss": 0.2369,
      "step": 339
    },
    {
      "epoch": 0.054042240368758813,
      "grad_norm": 0.7001633048057556,
      "learning_rate": 9.984898137943021e-06,
      "loss": 0.2992,
      "step": 340
    },
    {
      "epoch": 0.054201188134549286,
      "grad_norm": 0.6187527775764465,
      "learning_rate": 9.984697553375731e-06,
      "loss": 0.2732,
      "step": 341
    },
    {
      "epoch": 0.05436013590033975,
      "grad_norm": 0.8364429473876953,
      "learning_rate": 9.98449564753063e-06,
      "loss": 0.3779,
      "step": 342
    },
    {
      "epoch": 0.054519083666130216,
      "grad_norm": 0.6149042844772339,
      "learning_rate": 9.984292420461234e-06,
      "loss": 0.2392,
      "step": 343
    },
    {
      "epoch": 0.05467803143192068,
      "grad_norm": 0.7915179133415222,
      "learning_rate": 9.984087872221416e-06,
      "loss": 0.2235,
      "step": 344
    },
    {
      "epoch": 0.054836979197711154,
      "grad_norm": 0.6503407955169678,
      "learning_rate": 9.983882002865392e-06,
      "loss": 0.2102,
      "step": 345
    },
    {
      "epoch": 0.05499592696350162,
      "grad_norm": 0.7126255035400391,
      "learning_rate": 9.983674812447733e-06,
      "loss": 0.3576,
      "step": 346
    },
    {
      "epoch": 0.055154874729292085,
      "grad_norm": 0.6518324017524719,
      "learning_rate": 9.983466301023355e-06,
      "loss": 0.2262,
      "step": 347
    },
    {
      "epoch": 0.05531382249508256,
      "grad_norm": 1.2333682775497437,
      "learning_rate": 9.98325646864753e-06,
      "loss": 0.3524,
      "step": 348
    },
    {
      "epoch": 0.05547277026087302,
      "grad_norm": 0.5228100419044495,
      "learning_rate": 9.98304531537588e-06,
      "loss": 0.1623,
      "step": 349
    },
    {
      "epoch": 0.05563171802666349,
      "grad_norm": 0.6186750531196594,
      "learning_rate": 9.98283284126437e-06,
      "loss": 0.2596,
      "step": 350
    },
    {
      "epoch": 0.05579066579245395,
      "grad_norm": 0.7113720774650574,
      "learning_rate": 9.982619046369321e-06,
      "loss": 0.2904,
      "step": 351
    },
    {
      "epoch": 0.055949613558244425,
      "grad_norm": 0.8212244510650635,
      "learning_rate": 9.982403930747407e-06,
      "loss": 0.349,
      "step": 352
    },
    {
      "epoch": 0.05610856132403489,
      "grad_norm": 0.6947135329246521,
      "learning_rate": 9.982187494455642e-06,
      "loss": 0.3161,
      "step": 353
    },
    {
      "epoch": 0.056267509089825356,
      "grad_norm": 0.721544623374939,
      "learning_rate": 9.9819697375514e-06,
      "loss": 0.2835,
      "step": 354
    },
    {
      "epoch": 0.05642645685561582,
      "grad_norm": 0.6563253402709961,
      "learning_rate": 9.981750660092401e-06,
      "loss": 0.2265,
      "step": 355
    },
    {
      "epoch": 0.05658540462140629,
      "grad_norm": 0.6670923829078674,
      "learning_rate": 9.981530262136714e-06,
      "loss": 0.2812,
      "step": 356
    },
    {
      "epoch": 0.05674435238719676,
      "grad_norm": 0.8641726970672607,
      "learning_rate": 9.981308543742759e-06,
      "loss": 0.4286,
      "step": 357
    },
    {
      "epoch": 0.056903300152987224,
      "grad_norm": 0.540471076965332,
      "learning_rate": 9.981085504969306e-06,
      "loss": 0.159,
      "step": 358
    },
    {
      "epoch": 0.05706224791877769,
      "grad_norm": 0.7721562385559082,
      "learning_rate": 9.980861145875475e-06,
      "loss": 0.3574,
      "step": 359
    },
    {
      "epoch": 0.05722119568456816,
      "grad_norm": 0.6810352802276611,
      "learning_rate": 9.980635466520738e-06,
      "loss": 0.2865,
      "step": 360
    },
    {
      "epoch": 0.05738014345035863,
      "grad_norm": 0.7841323614120483,
      "learning_rate": 9.980408466964914e-06,
      "loss": 0.3751,
      "step": 361
    },
    {
      "epoch": 0.05753909121614909,
      "grad_norm": 0.6580289006233215,
      "learning_rate": 9.980180147268172e-06,
      "loss": 0.2745,
      "step": 362
    },
    {
      "epoch": 0.05769803898193956,
      "grad_norm": 0.6430429816246033,
      "learning_rate": 9.979950507491035e-06,
      "loss": 0.266,
      "step": 363
    },
    {
      "epoch": 0.05785698674773003,
      "grad_norm": 0.7177208662033081,
      "learning_rate": 9.979719547694369e-06,
      "loss": 0.3324,
      "step": 364
    },
    {
      "epoch": 0.058015934513520495,
      "grad_norm": 0.7979825735092163,
      "learning_rate": 9.979487267939396e-06,
      "loss": 0.4261,
      "step": 365
    },
    {
      "epoch": 0.05817488227931096,
      "grad_norm": 0.7109466791152954,
      "learning_rate": 9.979253668287687e-06,
      "loss": 0.2691,
      "step": 366
    },
    {
      "epoch": 0.058333830045101426,
      "grad_norm": 0.6447128057479858,
      "learning_rate": 9.979018748801159e-06,
      "loss": 0.2417,
      "step": 367
    },
    {
      "epoch": 0.0584927778108919,
      "grad_norm": 0.9025484323501587,
      "learning_rate": 9.97878250954208e-06,
      "loss": 0.3637,
      "step": 368
    },
    {
      "epoch": 0.05865172557668236,
      "grad_norm": 0.6198840141296387,
      "learning_rate": 9.978544950573075e-06,
      "loss": 0.245,
      "step": 369
    },
    {
      "epoch": 0.05881067334247283,
      "grad_norm": 0.8449203968048096,
      "learning_rate": 9.978306071957106e-06,
      "loss": 0.4085,
      "step": 370
    },
    {
      "epoch": 0.058969621108263294,
      "grad_norm": 0.7435483336448669,
      "learning_rate": 9.978065873757497e-06,
      "loss": 0.3499,
      "step": 371
    },
    {
      "epoch": 0.059128568874053766,
      "grad_norm": 0.5527241230010986,
      "learning_rate": 9.977824356037914e-06,
      "loss": 0.1745,
      "step": 372
    },
    {
      "epoch": 0.05928751663984423,
      "grad_norm": 0.6689598560333252,
      "learning_rate": 9.977581518862379e-06,
      "loss": 0.2615,
      "step": 373
    },
    {
      "epoch": 0.0594464644056347,
      "grad_norm": 0.5303553938865662,
      "learning_rate": 9.977337362295253e-06,
      "loss": 0.1242,
      "step": 374
    },
    {
      "epoch": 0.05960541217142516,
      "grad_norm": 0.8035372495651245,
      "learning_rate": 9.97709188640126e-06,
      "loss": 0.3455,
      "step": 375
    },
    {
      "epoch": 0.059764359937215634,
      "grad_norm": 0.7162306904792786,
      "learning_rate": 9.976845091245464e-06,
      "loss": 0.3307,
      "step": 376
    },
    {
      "epoch": 0.0599233077030061,
      "grad_norm": 0.7100907564163208,
      "learning_rate": 9.976596976893284e-06,
      "loss": 0.2607,
      "step": 377
    },
    {
      "epoch": 0.060082255468796565,
      "grad_norm": 0.6902601718902588,
      "learning_rate": 9.976347543410487e-06,
      "loss": 0.2538,
      "step": 378
    },
    {
      "epoch": 0.06024120323458703,
      "grad_norm": 0.6647873520851135,
      "learning_rate": 9.97609679086319e-06,
      "loss": 0.2736,
      "step": 379
    },
    {
      "epoch": 0.0604001510003775,
      "grad_norm": 0.5420880317687988,
      "learning_rate": 9.975844719317857e-06,
      "loss": 0.1434,
      "step": 380
    },
    {
      "epoch": 0.06055909876616797,
      "grad_norm": 0.7445337176322937,
      "learning_rate": 9.975591328841306e-06,
      "loss": 0.3357,
      "step": 381
    },
    {
      "epoch": 0.06071804653195843,
      "grad_norm": 0.7356078624725342,
      "learning_rate": 9.9753366195007e-06,
      "loss": 0.2652,
      "step": 382
    },
    {
      "epoch": 0.060876994297748906,
      "grad_norm": 0.5046064853668213,
      "learning_rate": 9.975080591363556e-06,
      "loss": 0.1052,
      "step": 383
    },
    {
      "epoch": 0.06103594206353937,
      "grad_norm": 0.7832808494567871,
      "learning_rate": 9.974823244497738e-06,
      "loss": 0.415,
      "step": 384
    },
    {
      "epoch": 0.061194889829329836,
      "grad_norm": 0.7406861782073975,
      "learning_rate": 9.974564578971459e-06,
      "loss": 0.3049,
      "step": 385
    },
    {
      "epoch": 0.0613538375951203,
      "grad_norm": 0.9127622246742249,
      "learning_rate": 9.974304594853286e-06,
      "loss": 0.3379,
      "step": 386
    },
    {
      "epoch": 0.061512785360910774,
      "grad_norm": 0.743205189704895,
      "learning_rate": 9.974043292212129e-06,
      "loss": 0.2876,
      "step": 387
    },
    {
      "epoch": 0.06167173312670124,
      "grad_norm": 0.7277542948722839,
      "learning_rate": 9.973780671117251e-06,
      "loss": 0.2541,
      "step": 388
    },
    {
      "epoch": 0.061830680892491705,
      "grad_norm": 0.6409409642219543,
      "learning_rate": 9.973516731638265e-06,
      "loss": 0.192,
      "step": 389
    },
    {
      "epoch": 0.06198962865828217,
      "grad_norm": 0.7500599026679993,
      "learning_rate": 9.973251473845131e-06,
      "loss": 0.3594,
      "step": 390
    },
    {
      "epoch": 0.06214857642407264,
      "grad_norm": 0.7531819343566895,
      "learning_rate": 9.972984897808163e-06,
      "loss": 0.3335,
      "step": 391
    },
    {
      "epoch": 0.06230752418986311,
      "grad_norm": 0.7669028639793396,
      "learning_rate": 9.97271700359802e-06,
      "loss": 0.2642,
      "step": 392
    },
    {
      "epoch": 0.06246647195565357,
      "grad_norm": 0.8043821454048157,
      "learning_rate": 9.97244779128571e-06,
      "loss": 0.3357,
      "step": 393
    },
    {
      "epoch": 0.06262541972144405,
      "grad_norm": 0.9739862084388733,
      "learning_rate": 9.972177260942595e-06,
      "loss": 0.3325,
      "step": 394
    },
    {
      "epoch": 0.06278436748723451,
      "grad_norm": 0.8570742011070251,
      "learning_rate": 9.971905412640381e-06,
      "loss": 0.4604,
      "step": 395
    },
    {
      "epoch": 0.06294331525302498,
      "grad_norm": 0.71455317735672,
      "learning_rate": 9.97163224645113e-06,
      "loss": 0.312,
      "step": 396
    },
    {
      "epoch": 0.06310226301881544,
      "grad_norm": 0.698207437992096,
      "learning_rate": 9.971357762447244e-06,
      "loss": 0.3255,
      "step": 397
    },
    {
      "epoch": 0.0632612107846059,
      "grad_norm": 0.6390173435211182,
      "learning_rate": 9.971081960701484e-06,
      "loss": 0.2055,
      "step": 398
    },
    {
      "epoch": 0.06342015855039637,
      "grad_norm": 0.7662673592567444,
      "learning_rate": 9.970804841286954e-06,
      "loss": 0.3447,
      "step": 399
    },
    {
      "epoch": 0.06357910631618684,
      "grad_norm": 0.6723694801330566,
      "learning_rate": 9.970526404277108e-06,
      "loss": 0.3867,
      "step": 400
    },
    {
      "epoch": 0.06373805408197732,
      "grad_norm": 0.7363776564598083,
      "learning_rate": 9.970246649745752e-06,
      "loss": 0.3057,
      "step": 401
    },
    {
      "epoch": 0.06389700184776778,
      "grad_norm": 0.828906774520874,
      "learning_rate": 9.969965577767042e-06,
      "loss": 0.3808,
      "step": 402
    },
    {
      "epoch": 0.06405594961355825,
      "grad_norm": 0.6832997798919678,
      "learning_rate": 9.969683188415475e-06,
      "loss": 0.2315,
      "step": 403
    },
    {
      "epoch": 0.06421489737934871,
      "grad_norm": 0.6404817700386047,
      "learning_rate": 9.969399481765908e-06,
      "loss": 0.1416,
      "step": 404
    },
    {
      "epoch": 0.06437384514513918,
      "grad_norm": 0.6972605586051941,
      "learning_rate": 9.96911445789354e-06,
      "loss": 0.3459,
      "step": 405
    },
    {
      "epoch": 0.06453279291092964,
      "grad_norm": 0.4506922960281372,
      "learning_rate": 9.968828116873921e-06,
      "loss": 0.1151,
      "step": 406
    },
    {
      "epoch": 0.06469174067672011,
      "grad_norm": 0.8154855966567993,
      "learning_rate": 9.968540458782952e-06,
      "loss": 0.3585,
      "step": 407
    },
    {
      "epoch": 0.06485068844251057,
      "grad_norm": 0.6905555725097656,
      "learning_rate": 9.968251483696882e-06,
      "loss": 0.2336,
      "step": 408
    },
    {
      "epoch": 0.06500963620830105,
      "grad_norm": 0.6442907452583313,
      "learning_rate": 9.967961191692308e-06,
      "loss": 0.2385,
      "step": 409
    },
    {
      "epoch": 0.06516858397409152,
      "grad_norm": 0.6362861394882202,
      "learning_rate": 9.967669582846173e-06,
      "loss": 0.2691,
      "step": 410
    },
    {
      "epoch": 0.06532753173988198,
      "grad_norm": 0.6439472436904907,
      "learning_rate": 9.96737665723578e-06,
      "loss": 0.2526,
      "step": 411
    },
    {
      "epoch": 0.06548647950567245,
      "grad_norm": 0.6314184069633484,
      "learning_rate": 9.967082414938768e-06,
      "loss": 0.2089,
      "step": 412
    },
    {
      "epoch": 0.06564542727146291,
      "grad_norm": 0.8705910444259644,
      "learning_rate": 9.966786856033134e-06,
      "loss": 0.3654,
      "step": 413
    },
    {
      "epoch": 0.06580437503725338,
      "grad_norm": 0.6960529088973999,
      "learning_rate": 9.966489980597217e-06,
      "loss": 0.2124,
      "step": 414
    },
    {
      "epoch": 0.06596332280304384,
      "grad_norm": 0.9412773251533508,
      "learning_rate": 9.966191788709716e-06,
      "loss": 0.4117,
      "step": 415
    },
    {
      "epoch": 0.06612227056883432,
      "grad_norm": 0.6905795335769653,
      "learning_rate": 9.965892280449665e-06,
      "loss": 0.3456,
      "step": 416
    },
    {
      "epoch": 0.06628121833462479,
      "grad_norm": 0.5381160974502563,
      "learning_rate": 9.965591455896456e-06,
      "loss": 0.1816,
      "step": 417
    },
    {
      "epoch": 0.06644016610041525,
      "grad_norm": 0.7199984192848206,
      "learning_rate": 9.965289315129829e-06,
      "loss": 0.2376,
      "step": 418
    },
    {
      "epoch": 0.06659911386620572,
      "grad_norm": 0.6145692467689514,
      "learning_rate": 9.96498585822987e-06,
      "loss": 0.1508,
      "step": 419
    },
    {
      "epoch": 0.06675806163199619,
      "grad_norm": 0.580280601978302,
      "learning_rate": 9.964681085277013e-06,
      "loss": 0.191,
      "step": 420
    },
    {
      "epoch": 0.06691700939778665,
      "grad_norm": 0.6709649562835693,
      "learning_rate": 9.964374996352048e-06,
      "loss": 0.2576,
      "step": 421
    },
    {
      "epoch": 0.06707595716357712,
      "grad_norm": 0.9186763763427734,
      "learning_rate": 9.964067591536106e-06,
      "loss": 0.4247,
      "step": 422
    },
    {
      "epoch": 0.06723490492936758,
      "grad_norm": 0.6618556380271912,
      "learning_rate": 9.963758870910672e-06,
      "loss": 0.27,
      "step": 423
    },
    {
      "epoch": 0.06739385269515806,
      "grad_norm": 0.7412678003311157,
      "learning_rate": 9.963448834557575e-06,
      "loss": 0.331,
      "step": 424
    },
    {
      "epoch": 0.06755280046094853,
      "grad_norm": 0.7855427861213684,
      "learning_rate": 9.963137482558996e-06,
      "loss": 0.3924,
      "step": 425
    },
    {
      "epoch": 0.06771174822673899,
      "grad_norm": 1.3043838739395142,
      "learning_rate": 9.962824814997464e-06,
      "loss": 0.1769,
      "step": 426
    },
    {
      "epoch": 0.06787069599252946,
      "grad_norm": 0.6799257397651672,
      "learning_rate": 9.96251083195586e-06,
      "loss": 0.3053,
      "step": 427
    },
    {
      "epoch": 0.06802964375831992,
      "grad_norm": 0.7478651404380798,
      "learning_rate": 9.962195533517404e-06,
      "loss": 0.2827,
      "step": 428
    },
    {
      "epoch": 0.06818859152411039,
      "grad_norm": 0.789239227771759,
      "learning_rate": 9.961878919765678e-06,
      "loss": 0.3801,
      "step": 429
    },
    {
      "epoch": 0.06834753928990085,
      "grad_norm": 0.6625396013259888,
      "learning_rate": 9.961560990784603e-06,
      "loss": 0.3064,
      "step": 430
    },
    {
      "epoch": 0.06850648705569132,
      "grad_norm": 0.6983871459960938,
      "learning_rate": 9.96124174665845e-06,
      "loss": 0.3284,
      "step": 431
    },
    {
      "epoch": 0.0686654348214818,
      "grad_norm": 0.6384926438331604,
      "learning_rate": 9.960921187471841e-06,
      "loss": 0.2374,
      "step": 432
    },
    {
      "epoch": 0.06882438258727226,
      "grad_norm": 0.6757774353027344,
      "learning_rate": 9.960599313309745e-06,
      "loss": 0.2142,
      "step": 433
    },
    {
      "epoch": 0.06898333035306273,
      "grad_norm": 0.7921888828277588,
      "learning_rate": 9.960276124257481e-06,
      "loss": 0.3464,
      "step": 434
    },
    {
      "epoch": 0.06914227811885319,
      "grad_norm": 0.6822479367256165,
      "learning_rate": 9.95995162040072e-06,
      "loss": 0.3297,
      "step": 435
    },
    {
      "epoch": 0.06930122588464366,
      "grad_norm": 0.7804194092750549,
      "learning_rate": 9.959625801825468e-06,
      "loss": 0.3392,
      "step": 436
    },
    {
      "epoch": 0.06946017365043412,
      "grad_norm": 0.7814785838127136,
      "learning_rate": 9.959298668618094e-06,
      "loss": 0.3157,
      "step": 437
    },
    {
      "epoch": 0.06961912141622459,
      "grad_norm": 0.8295469284057617,
      "learning_rate": 9.958970220865312e-06,
      "loss": 0.3881,
      "step": 438
    },
    {
      "epoch": 0.06977806918201505,
      "grad_norm": 0.6828784346580505,
      "learning_rate": 9.958640458654178e-06,
      "loss": 0.2272,
      "step": 439
    },
    {
      "epoch": 0.06993701694780553,
      "grad_norm": 0.7337888479232788,
      "learning_rate": 9.958309382072104e-06,
      "loss": 0.3862,
      "step": 440
    },
    {
      "epoch": 0.070095964713596,
      "grad_norm": 0.6495670080184937,
      "learning_rate": 9.957976991206847e-06,
      "loss": 0.2575,
      "step": 441
    },
    {
      "epoch": 0.07025491247938646,
      "grad_norm": 0.6457007527351379,
      "learning_rate": 9.957643286146512e-06,
      "loss": 0.2255,
      "step": 442
    },
    {
      "epoch": 0.07041386024517693,
      "grad_norm": 0.5952752232551575,
      "learning_rate": 9.957308266979553e-06,
      "loss": 0.2721,
      "step": 443
    },
    {
      "epoch": 0.0705728080109674,
      "grad_norm": 0.8016515970230103,
      "learning_rate": 9.956971933794775e-06,
      "loss": 0.2364,
      "step": 444
    },
    {
      "epoch": 0.07073175577675786,
      "grad_norm": 0.6101402640342712,
      "learning_rate": 9.956634286681325e-06,
      "loss": 0.1663,
      "step": 445
    },
    {
      "epoch": 0.07089070354254833,
      "grad_norm": 0.9466536045074463,
      "learning_rate": 9.956295325728705e-06,
      "loss": 0.2433,
      "step": 446
    },
    {
      "epoch": 0.07104965130833879,
      "grad_norm": 0.7909488081932068,
      "learning_rate": 9.95595505102676e-06,
      "loss": 0.2727,
      "step": 447
    },
    {
      "epoch": 0.07120859907412927,
      "grad_norm": 0.7998983860015869,
      "learning_rate": 9.955613462665688e-06,
      "loss": 0.2567,
      "step": 448
    },
    {
      "epoch": 0.07136754683991973,
      "grad_norm": 1.0341482162475586,
      "learning_rate": 9.95527056073603e-06,
      "loss": 0.2765,
      "step": 449
    },
    {
      "epoch": 0.0715264946057102,
      "grad_norm": 0.6928191184997559,
      "learning_rate": 9.95492634532868e-06,
      "loss": 0.2137,
      "step": 450
    },
    {
      "epoch": 0.07168544237150067,
      "grad_norm": 0.6861610412597656,
      "learning_rate": 9.954580816534879e-06,
      "loss": 0.2403,
      "step": 451
    },
    {
      "epoch": 0.07184439013729113,
      "grad_norm": 0.6618624329566956,
      "learning_rate": 9.95423397444621e-06,
      "loss": 0.2319,
      "step": 452
    },
    {
      "epoch": 0.0720033379030816,
      "grad_norm": 0.5575526356697083,
      "learning_rate": 9.953885819154615e-06,
      "loss": 0.1429,
      "step": 453
    },
    {
      "epoch": 0.07216228566887206,
      "grad_norm": 0.7803030014038086,
      "learning_rate": 9.953536350752377e-06,
      "loss": 0.3632,
      "step": 454
    },
    {
      "epoch": 0.07232123343466254,
      "grad_norm": 0.7655369639396667,
      "learning_rate": 9.953185569332127e-06,
      "loss": 0.2917,
      "step": 455
    },
    {
      "epoch": 0.072480181200453,
      "grad_norm": 0.8028934597969055,
      "learning_rate": 9.952833474986847e-06,
      "loss": 0.1876,
      "step": 456
    },
    {
      "epoch": 0.07263912896624347,
      "grad_norm": 0.6514338850975037,
      "learning_rate": 9.952480067809863e-06,
      "loss": 0.2242,
      "step": 457
    },
    {
      "epoch": 0.07279807673203394,
      "grad_norm": 0.6682825088500977,
      "learning_rate": 9.952125347894854e-06,
      "loss": 0.27,
      "step": 458
    },
    {
      "epoch": 0.0729570244978244,
      "grad_norm": 0.6382580995559692,
      "learning_rate": 9.951769315335843e-06,
      "loss": 0.2651,
      "step": 459
    },
    {
      "epoch": 0.07311597226361487,
      "grad_norm": 0.7366971373558044,
      "learning_rate": 9.951411970227206e-06,
      "loss": 0.2957,
      "step": 460
    },
    {
      "epoch": 0.07327492002940533,
      "grad_norm": 0.613239586353302,
      "learning_rate": 9.951053312663659e-06,
      "loss": 0.1615,
      "step": 461
    },
    {
      "epoch": 0.0734338677951958,
      "grad_norm": 0.6294453740119934,
      "learning_rate": 9.950693342740271e-06,
      "loss": 0.1945,
      "step": 462
    },
    {
      "epoch": 0.07359281556098628,
      "grad_norm": 0.6037889719009399,
      "learning_rate": 9.95033206055246e-06,
      "loss": 0.2199,
      "step": 463
    },
    {
      "epoch": 0.07375176332677674,
      "grad_norm": 0.8292614817619324,
      "learning_rate": 9.949969466195989e-06,
      "loss": 0.162,
      "step": 464
    },
    {
      "epoch": 0.07391071109256721,
      "grad_norm": 0.6133434176445007,
      "learning_rate": 9.949605559766969e-06,
      "loss": 0.1602,
      "step": 465
    },
    {
      "epoch": 0.07406965885835767,
      "grad_norm": 0.6136700510978699,
      "learning_rate": 9.94924034136186e-06,
      "loss": 0.179,
      "step": 466
    },
    {
      "epoch": 0.07422860662414814,
      "grad_norm": 0.8150445222854614,
      "learning_rate": 9.94887381107747e-06,
      "loss": 0.3247,
      "step": 467
    },
    {
      "epoch": 0.0743875543899386,
      "grad_norm": 0.7465639114379883,
      "learning_rate": 9.94850596901095e-06,
      "loss": 0.3826,
      "step": 468
    },
    {
      "epoch": 0.07454650215572907,
      "grad_norm": 0.7529109120368958,
      "learning_rate": 9.948136815259809e-06,
      "loss": 0.4075,
      "step": 469
    },
    {
      "epoch": 0.07470544992151953,
      "grad_norm": 0.7313408851623535,
      "learning_rate": 9.947766349921894e-06,
      "loss": 0.4064,
      "step": 470
    },
    {
      "epoch": 0.07486439768731001,
      "grad_norm": 0.5868017673492432,
      "learning_rate": 9.947394573095403e-06,
      "loss": 0.2639,
      "step": 471
    },
    {
      "epoch": 0.07502334545310048,
      "grad_norm": 0.651290774345398,
      "learning_rate": 9.947021484878883e-06,
      "loss": 0.2563,
      "step": 472
    },
    {
      "epoch": 0.07518229321889094,
      "grad_norm": 0.8226175904273987,
      "learning_rate": 9.946647085371223e-06,
      "loss": 0.2765,
      "step": 473
    },
    {
      "epoch": 0.07534124098468141,
      "grad_norm": 0.7546384930610657,
      "learning_rate": 9.946271374671672e-06,
      "loss": 0.2825,
      "step": 474
    },
    {
      "epoch": 0.07550018875047187,
      "grad_norm": 0.7002866864204407,
      "learning_rate": 9.94589435287981e-06,
      "loss": 0.3316,
      "step": 475
    },
    {
      "epoch": 0.07565913651626234,
      "grad_norm": 0.6625904440879822,
      "learning_rate": 9.94551602009558e-06,
      "loss": 0.2906,
      "step": 476
    },
    {
      "epoch": 0.0758180842820528,
      "grad_norm": 0.5329777002334595,
      "learning_rate": 9.94513637641926e-06,
      "loss": 0.1356,
      "step": 477
    },
    {
      "epoch": 0.07597703204784327,
      "grad_norm": 0.7350439429283142,
      "learning_rate": 9.944755421951484e-06,
      "loss": 0.2952,
      "step": 478
    },
    {
      "epoch": 0.07613597981363375,
      "grad_norm": 0.6663036942481995,
      "learning_rate": 9.944373156793227e-06,
      "loss": 0.2715,
      "step": 479
    },
    {
      "epoch": 0.07629492757942422,
      "grad_norm": 0.6830780506134033,
      "learning_rate": 9.943989581045821e-06,
      "loss": 0.3186,
      "step": 480
    },
    {
      "epoch": 0.07645387534521468,
      "grad_norm": 0.6102436780929565,
      "learning_rate": 9.943604694810934e-06,
      "loss": 0.2656,
      "step": 481
    },
    {
      "epoch": 0.07661282311100515,
      "grad_norm": 0.8772360682487488,
      "learning_rate": 9.943218498190587e-06,
      "loss": 0.2105,
      "step": 482
    },
    {
      "epoch": 0.07677177087679561,
      "grad_norm": 0.7391338348388672,
      "learning_rate": 9.942830991287149e-06,
      "loss": 0.1988,
      "step": 483
    },
    {
      "epoch": 0.07693071864258608,
      "grad_norm": 1.1291781663894653,
      "learning_rate": 9.942442174203337e-06,
      "loss": 0.2153,
      "step": 484
    },
    {
      "epoch": 0.07708966640837654,
      "grad_norm": 0.5783388018608093,
      "learning_rate": 9.94205204704221e-06,
      "loss": 0.2124,
      "step": 485
    },
    {
      "epoch": 0.07724861417416702,
      "grad_norm": 0.6584206223487854,
      "learning_rate": 9.94166060990718e-06,
      "loss": 0.3224,
      "step": 486
    },
    {
      "epoch": 0.07740756193995749,
      "grad_norm": 0.6655791401863098,
      "learning_rate": 9.941267862902003e-06,
      "loss": 0.2536,
      "step": 487
    },
    {
      "epoch": 0.07756650970574795,
      "grad_norm": 0.9121261239051819,
      "learning_rate": 9.940873806130784e-06,
      "loss": 0.2767,
      "step": 488
    },
    {
      "epoch": 0.07772545747153842,
      "grad_norm": 0.6675073504447937,
      "learning_rate": 9.940478439697973e-06,
      "loss": 0.3387,
      "step": 489
    },
    {
      "epoch": 0.07788440523732888,
      "grad_norm": 0.7592376470565796,
      "learning_rate": 9.940081763708371e-06,
      "loss": 0.3177,
      "step": 490
    },
    {
      "epoch": 0.07804335300311935,
      "grad_norm": 0.5923437476158142,
      "learning_rate": 9.93968377826712e-06,
      "loss": 0.2068,
      "step": 491
    },
    {
      "epoch": 0.07820230076890981,
      "grad_norm": 0.7556771636009216,
      "learning_rate": 9.939284483479716e-06,
      "loss": 0.3317,
      "step": 492
    },
    {
      "epoch": 0.07836124853470028,
      "grad_norm": 0.710115373134613,
      "learning_rate": 9.938883879451999e-06,
      "loss": 0.3175,
      "step": 493
    },
    {
      "epoch": 0.07852019630049076,
      "grad_norm": 0.6304197311401367,
      "learning_rate": 9.938481966290153e-06,
      "loss": 0.1713,
      "step": 494
    },
    {
      "epoch": 0.07867914406628122,
      "grad_norm": 0.5494393110275269,
      "learning_rate": 9.938078744100713e-06,
      "loss": 0.1603,
      "step": 495
    },
    {
      "epoch": 0.07883809183207169,
      "grad_norm": 0.7161945700645447,
      "learning_rate": 9.93767421299056e-06,
      "loss": 0.2953,
      "step": 496
    },
    {
      "epoch": 0.07899703959786215,
      "grad_norm": 0.6638477444648743,
      "learning_rate": 9.937268373066922e-06,
      "loss": 0.2953,
      "step": 497
    },
    {
      "epoch": 0.07915598736365262,
      "grad_norm": 0.6110430955886841,
      "learning_rate": 9.936861224437374e-06,
      "loss": 0.2183,
      "step": 498
    },
    {
      "epoch": 0.07931493512944308,
      "grad_norm": 0.669783353805542,
      "learning_rate": 9.936452767209837e-06,
      "loss": 0.2438,
      "step": 499
    },
    {
      "epoch": 0.07947388289523355,
      "grad_norm": 0.6094478964805603,
      "learning_rate": 9.936043001492579e-06,
      "loss": 0.2999,
      "step": 500
    },
    {
      "epoch": 0.07963283066102401,
      "grad_norm": 0.8212153315544128,
      "learning_rate": 9.935631927394216e-06,
      "loss": 0.3912,
      "step": 501
    },
    {
      "epoch": 0.0797917784268145,
      "grad_norm": 0.5460955500602722,
      "learning_rate": 9.93521954502371e-06,
      "loss": 0.1707,
      "step": 502
    },
    {
      "epoch": 0.07995072619260496,
      "grad_norm": 0.45689788460731506,
      "learning_rate": 9.93480585449037e-06,
      "loss": 0.11,
      "step": 503
    },
    {
      "epoch": 0.08010967395839542,
      "grad_norm": 0.6022889018058777,
      "learning_rate": 9.934390855903852e-06,
      "loss": 0.2032,
      "step": 504
    },
    {
      "epoch": 0.08026862172418589,
      "grad_norm": 0.6949602365493774,
      "learning_rate": 9.933974549374157e-06,
      "loss": 0.284,
      "step": 505
    },
    {
      "epoch": 0.08042756948997636,
      "grad_norm": 0.5249112248420715,
      "learning_rate": 9.933556935011636e-06,
      "loss": 0.1993,
      "step": 506
    },
    {
      "epoch": 0.08058651725576682,
      "grad_norm": 0.5755918622016907,
      "learning_rate": 9.933138012926982e-06,
      "loss": 0.2028,
      "step": 507
    },
    {
      "epoch": 0.08074546502155729,
      "grad_norm": 0.6858382821083069,
      "learning_rate": 9.93271778323124e-06,
      "loss": 0.2103,
      "step": 508
    },
    {
      "epoch": 0.08090441278734775,
      "grad_norm": 0.8568384647369385,
      "learning_rate": 9.932296246035797e-06,
      "loss": 0.3978,
      "step": 509
    },
    {
      "epoch": 0.08106336055313823,
      "grad_norm": 0.6695636510848999,
      "learning_rate": 9.93187340145239e-06,
      "loss": 0.2644,
      "step": 510
    },
    {
      "epoch": 0.0812223083189287,
      "grad_norm": 0.9293104410171509,
      "learning_rate": 9.9314492495931e-06,
      "loss": 0.3307,
      "step": 511
    },
    {
      "epoch": 0.08138125608471916,
      "grad_norm": 0.6503332257270813,
      "learning_rate": 9.931023790570356e-06,
      "loss": 0.23,
      "step": 512
    },
    {
      "epoch": 0.08154020385050963,
      "grad_norm": 0.6247533559799194,
      "learning_rate": 9.930597024496933e-06,
      "loss": 0.274,
      "step": 513
    },
    {
      "epoch": 0.08169915161630009,
      "grad_norm": 0.7948765754699707,
      "learning_rate": 9.930168951485951e-06,
      "loss": 0.3579,
      "step": 514
    },
    {
      "epoch": 0.08185809938209056,
      "grad_norm": 0.5820950865745544,
      "learning_rate": 9.92973957165088e-06,
      "loss": 0.179,
      "step": 515
    },
    {
      "epoch": 0.08201704714788102,
      "grad_norm": 0.7014245390892029,
      "learning_rate": 9.929308885105535e-06,
      "loss": 0.314,
      "step": 516
    },
    {
      "epoch": 0.08217599491367149,
      "grad_norm": 0.6531240940093994,
      "learning_rate": 9.928876891964076e-06,
      "loss": 0.243,
      "step": 517
    },
    {
      "epoch": 0.08233494267946197,
      "grad_norm": 0.9150536060333252,
      "learning_rate": 9.928443592341008e-06,
      "loss": 0.4119,
      "step": 518
    },
    {
      "epoch": 0.08249389044525243,
      "grad_norm": 0.6066513657569885,
      "learning_rate": 9.928008986351187e-06,
      "loss": 0.2294,
      "step": 519
    },
    {
      "epoch": 0.0826528382110429,
      "grad_norm": 0.7447512745857239,
      "learning_rate": 9.92757307410981e-06,
      "loss": 0.2661,
      "step": 520
    },
    {
      "epoch": 0.08281178597683336,
      "grad_norm": 0.5956487655639648,
      "learning_rate": 9.927135855732426e-06,
      "loss": 0.2245,
      "step": 521
    },
    {
      "epoch": 0.08297073374262383,
      "grad_norm": 0.7287901639938354,
      "learning_rate": 9.926697331334924e-06,
      "loss": 0.3312,
      "step": 522
    },
    {
      "epoch": 0.0831296815084143,
      "grad_norm": 0.753642201423645,
      "learning_rate": 9.926257501033545e-06,
      "loss": 0.3583,
      "step": 523
    },
    {
      "epoch": 0.08328862927420476,
      "grad_norm": 0.680992066860199,
      "learning_rate": 9.925816364944872e-06,
      "loss": 0.2508,
      "step": 524
    },
    {
      "epoch": 0.08344757703999524,
      "grad_norm": 0.6495366096496582,
      "learning_rate": 9.925373923185835e-06,
      "loss": 0.2551,
      "step": 525
    },
    {
      "epoch": 0.0836065248057857,
      "grad_norm": 0.6557493209838867,
      "learning_rate": 9.924930175873712e-06,
      "loss": 0.2044,
      "step": 526
    },
    {
      "epoch": 0.08376547257157617,
      "grad_norm": 0.6469241976737976,
      "learning_rate": 9.924485123126124e-06,
      "loss": 0.3226,
      "step": 527
    },
    {
      "epoch": 0.08392442033736663,
      "grad_norm": 0.7080928087234497,
      "learning_rate": 9.924038765061042e-06,
      "loss": 0.3215,
      "step": 528
    },
    {
      "epoch": 0.0840833681031571,
      "grad_norm": 0.636532187461853,
      "learning_rate": 9.923591101796777e-06,
      "loss": 0.2626,
      "step": 529
    },
    {
      "epoch": 0.08424231586894756,
      "grad_norm": 0.5769767761230469,
      "learning_rate": 9.923142133451994e-06,
      "loss": 0.1787,
      "step": 530
    },
    {
      "epoch": 0.08440126363473803,
      "grad_norm": 0.7453742623329163,
      "learning_rate": 9.922691860145696e-06,
      "loss": 0.2862,
      "step": 531
    },
    {
      "epoch": 0.0845602114005285,
      "grad_norm": 0.7278614640235901,
      "learning_rate": 9.92224028199724e-06,
      "loss": 0.2534,
      "step": 532
    },
    {
      "epoch": 0.08471915916631897,
      "grad_norm": 0.6787813901901245,
      "learning_rate": 9.921787399126319e-06,
      "loss": 0.2774,
      "step": 533
    },
    {
      "epoch": 0.08487810693210944,
      "grad_norm": 0.8191449642181396,
      "learning_rate": 9.921333211652979e-06,
      "loss": 0.3768,
      "step": 534
    },
    {
      "epoch": 0.0850370546978999,
      "grad_norm": 0.702735424041748,
      "learning_rate": 9.920877719697612e-06,
      "loss": 0.3101,
      "step": 535
    },
    {
      "epoch": 0.08519600246369037,
      "grad_norm": 0.5573081970214844,
      "learning_rate": 9.920420923380954e-06,
      "loss": 0.2141,
      "step": 536
    },
    {
      "epoch": 0.08535495022948084,
      "grad_norm": 5.711931228637695,
      "learning_rate": 9.919962822824083e-06,
      "loss": 0.2607,
      "step": 537
    },
    {
      "epoch": 0.0855138979952713,
      "grad_norm": 0.6364037394523621,
      "learning_rate": 9.919503418148428e-06,
      "loss": 0.2617,
      "step": 538
    },
    {
      "epoch": 0.08567284576106177,
      "grad_norm": 1.1641297340393066,
      "learning_rate": 9.919042709475763e-06,
      "loss": 0.3253,
      "step": 539
    },
    {
      "epoch": 0.08583179352685223,
      "grad_norm": 0.6790488362312317,
      "learning_rate": 9.918580696928206e-06,
      "loss": 0.29,
      "step": 540
    },
    {
      "epoch": 0.08599074129264271,
      "grad_norm": 0.637140154838562,
      "learning_rate": 9.91811738062822e-06,
      "loss": 0.2367,
      "step": 541
    },
    {
      "epoch": 0.08614968905843318,
      "grad_norm": 0.8904571533203125,
      "learning_rate": 9.917652760698618e-06,
      "loss": 0.2048,
      "step": 542
    },
    {
      "epoch": 0.08630863682422364,
      "grad_norm": 0.6445255279541016,
      "learning_rate": 9.917186837262552e-06,
      "loss": 0.2881,
      "step": 543
    },
    {
      "epoch": 0.08646758459001411,
      "grad_norm": 0.6622262001037598,
      "learning_rate": 9.916719610443523e-06,
      "loss": 0.2984,
      "step": 544
    },
    {
      "epoch": 0.08662653235580457,
      "grad_norm": 0.7993186712265015,
      "learning_rate": 9.916251080365378e-06,
      "loss": 0.3956,
      "step": 545
    },
    {
      "epoch": 0.08678548012159504,
      "grad_norm": 0.7697802782058716,
      "learning_rate": 9.91578124715231e-06,
      "loss": 0.2888,
      "step": 546
    },
    {
      "epoch": 0.0869444278873855,
      "grad_norm": 0.7394181489944458,
      "learning_rate": 9.915310110928855e-06,
      "loss": 0.3423,
      "step": 547
    },
    {
      "epoch": 0.08710337565317597,
      "grad_norm": 0.5885687470436096,
      "learning_rate": 9.914837671819894e-06,
      "loss": 0.2118,
      "step": 548
    },
    {
      "epoch": 0.08726232341896645,
      "grad_norm": 0.7011678218841553,
      "learning_rate": 9.91436392995066e-06,
      "loss": 0.3502,
      "step": 549
    },
    {
      "epoch": 0.08742127118475691,
      "grad_norm": 0.5367738008499146,
      "learning_rate": 9.91388888544672e-06,
      "loss": 0.1502,
      "step": 550
    },
    {
      "epoch": 0.08758021895054738,
      "grad_norm": 0.6866468191146851,
      "learning_rate": 9.913412538433998e-06,
      "loss": 0.3436,
      "step": 551
    },
    {
      "epoch": 0.08773916671633784,
      "grad_norm": 0.6447843313217163,
      "learning_rate": 9.912934889038752e-06,
      "loss": 0.2107,
      "step": 552
    },
    {
      "epoch": 0.08789811448212831,
      "grad_norm": 0.729262113571167,
      "learning_rate": 9.912455937387596e-06,
      "loss": 0.2223,
      "step": 553
    },
    {
      "epoch": 0.08805706224791877,
      "grad_norm": 0.6998603343963623,
      "learning_rate": 9.911975683607482e-06,
      "loss": 0.2898,
      "step": 554
    },
    {
      "epoch": 0.08821601001370924,
      "grad_norm": 0.7087949514389038,
      "learning_rate": 9.91149412782571e-06,
      "loss": 0.3492,
      "step": 555
    },
    {
      "epoch": 0.08837495777949972,
      "grad_norm": 1.0601528882980347,
      "learning_rate": 9.911011270169924e-06,
      "loss": 0.2368,
      "step": 556
    },
    {
      "epoch": 0.08853390554529018,
      "grad_norm": 0.7194111943244934,
      "learning_rate": 9.910527110768113e-06,
      "loss": 0.3297,
      "step": 557
    },
    {
      "epoch": 0.08869285331108065,
      "grad_norm": 0.643875002861023,
      "learning_rate": 9.910041649748613e-06,
      "loss": 0.2228,
      "step": 558
    },
    {
      "epoch": 0.08885180107687111,
      "grad_norm": 0.7161715030670166,
      "learning_rate": 9.909554887240104e-06,
      "loss": 0.3083,
      "step": 559
    },
    {
      "epoch": 0.08901074884266158,
      "grad_norm": 0.4338666796684265,
      "learning_rate": 9.909066823371609e-06,
      "loss": 0.0957,
      "step": 560
    },
    {
      "epoch": 0.08916969660845205,
      "grad_norm": 0.774033784866333,
      "learning_rate": 9.908577458272496e-06,
      "loss": 0.3096,
      "step": 561
    },
    {
      "epoch": 0.08932864437424251,
      "grad_norm": 1.1213910579681396,
      "learning_rate": 9.908086792072482e-06,
      "loss": 0.2508,
      "step": 562
    },
    {
      "epoch": 0.08948759214003298,
      "grad_norm": 0.643531858921051,
      "learning_rate": 9.907594824901628e-06,
      "loss": 0.1999,
      "step": 563
    },
    {
      "epoch": 0.08964653990582346,
      "grad_norm": 0.7296023964881897,
      "learning_rate": 9.907101556890332e-06,
      "loss": 0.3685,
      "step": 564
    },
    {
      "epoch": 0.08980548767161392,
      "grad_norm": 0.6313891410827637,
      "learning_rate": 9.906606988169349e-06,
      "loss": 0.2236,
      "step": 565
    },
    {
      "epoch": 0.08996443543740439,
      "grad_norm": 0.7255531549453735,
      "learning_rate": 9.906111118869773e-06,
      "loss": 0.3692,
      "step": 566
    },
    {
      "epoch": 0.09012338320319485,
      "grad_norm": 0.5888744592666626,
      "learning_rate": 9.905613949123036e-06,
      "loss": 0.2218,
      "step": 567
    },
    {
      "epoch": 0.09028233096898532,
      "grad_norm": 0.5029332041740417,
      "learning_rate": 9.905115479060927e-06,
      "loss": 0.1689,
      "step": 568
    },
    {
      "epoch": 0.09044127873477578,
      "grad_norm": 0.9302825331687927,
      "learning_rate": 9.904615708815572e-06,
      "loss": 0.3364,
      "step": 569
    },
    {
      "epoch": 0.09060022650056625,
      "grad_norm": 0.674639105796814,
      "learning_rate": 9.904114638519444e-06,
      "loss": 0.2303,
      "step": 570
    },
    {
      "epoch": 0.09075917426635671,
      "grad_norm": 0.5966745615005493,
      "learning_rate": 9.903612268305359e-06,
      "loss": 0.2296,
      "step": 571
    },
    {
      "epoch": 0.09091812203214719,
      "grad_norm": 0.6610140204429626,
      "learning_rate": 9.90310859830648e-06,
      "loss": 0.3076,
      "step": 572
    },
    {
      "epoch": 0.09107706979793766,
      "grad_norm": 0.7279877066612244,
      "learning_rate": 9.902603628656312e-06,
      "loss": 0.4065,
      "step": 573
    },
    {
      "epoch": 0.09123601756372812,
      "grad_norm": 0.664792537689209,
      "learning_rate": 9.902097359488707e-06,
      "loss": 0.2362,
      "step": 574
    },
    {
      "epoch": 0.09139496532951859,
      "grad_norm": 0.5439140200614929,
      "learning_rate": 9.90158979093786e-06,
      "loss": 0.1838,
      "step": 575
    },
    {
      "epoch": 0.09155391309530905,
      "grad_norm": 0.5925586223602295,
      "learning_rate": 9.901080923138308e-06,
      "loss": 0.2205,
      "step": 576
    },
    {
      "epoch": 0.09171286086109952,
      "grad_norm": 0.6452662944793701,
      "learning_rate": 9.900570756224938e-06,
      "loss": 0.3155,
      "step": 577
    },
    {
      "epoch": 0.09187180862688998,
      "grad_norm": 0.5970516800880432,
      "learning_rate": 9.900059290332977e-06,
      "loss": 0.2582,
      "step": 578
    },
    {
      "epoch": 0.09203075639268045,
      "grad_norm": 0.8480368256568909,
      "learning_rate": 9.899546525597998e-06,
      "loss": 0.522,
      "step": 579
    },
    {
      "epoch": 0.09218970415847093,
      "grad_norm": 0.5284443497657776,
      "learning_rate": 9.89903246215592e-06,
      "loss": 0.2262,
      "step": 580
    },
    {
      "epoch": 0.0923486519242614,
      "grad_norm": 0.6320599913597107,
      "learning_rate": 9.898517100143e-06,
      "loss": 0.2774,
      "step": 581
    },
    {
      "epoch": 0.09250759969005186,
      "grad_norm": 0.598490834236145,
      "learning_rate": 9.898000439695844e-06,
      "loss": 0.2204,
      "step": 582
    },
    {
      "epoch": 0.09266654745584232,
      "grad_norm": 1.0750585794448853,
      "learning_rate": 9.897482480951403e-06,
      "loss": 0.2295,
      "step": 583
    },
    {
      "epoch": 0.09282549522163279,
      "grad_norm": 0.6282559633255005,
      "learning_rate": 9.896963224046973e-06,
      "loss": 0.1819,
      "step": 584
    },
    {
      "epoch": 0.09298444298742325,
      "grad_norm": 0.6737957000732422,
      "learning_rate": 9.896442669120188e-06,
      "loss": 0.2121,
      "step": 585
    },
    {
      "epoch": 0.09314339075321372,
      "grad_norm": 0.5906959772109985,
      "learning_rate": 9.89592081630903e-06,
      "loss": 0.1954,
      "step": 586
    },
    {
      "epoch": 0.09330233851900419,
      "grad_norm": 0.5272713899612427,
      "learning_rate": 9.895397665751827e-06,
      "loss": 0.1655,
      "step": 587
    },
    {
      "epoch": 0.09346128628479466,
      "grad_norm": 0.6050112843513489,
      "learning_rate": 9.894873217587247e-06,
      "loss": 0.2209,
      "step": 588
    },
    {
      "epoch": 0.09362023405058513,
      "grad_norm": 0.6353368163108826,
      "learning_rate": 9.894347471954305e-06,
      "loss": 0.3042,
      "step": 589
    },
    {
      "epoch": 0.0937791818163756,
      "grad_norm": 0.6396725177764893,
      "learning_rate": 9.893820428992358e-06,
      "loss": 0.2948,
      "step": 590
    },
    {
      "epoch": 0.09393812958216606,
      "grad_norm": 0.7008914351463318,
      "learning_rate": 9.893292088841109e-06,
      "loss": 0.3395,
      "step": 591
    },
    {
      "epoch": 0.09409707734795653,
      "grad_norm": 0.7042093276977539,
      "learning_rate": 9.892762451640602e-06,
      "loss": 0.3259,
      "step": 592
    },
    {
      "epoch": 0.09425602511374699,
      "grad_norm": 0.7051785588264465,
      "learning_rate": 9.892231517531225e-06,
      "loss": 0.3652,
      "step": 593
    },
    {
      "epoch": 0.09441497287953746,
      "grad_norm": 0.5270639657974243,
      "learning_rate": 9.891699286653714e-06,
      "loss": 0.2158,
      "step": 594
    },
    {
      "epoch": 0.09457392064532794,
      "grad_norm": 0.9062164425849915,
      "learning_rate": 9.891165759149144e-06,
      "loss": 0.1847,
      "step": 595
    },
    {
      "epoch": 0.0947328684111184,
      "grad_norm": 0.6163140535354614,
      "learning_rate": 9.890630935158936e-06,
      "loss": 0.2913,
      "step": 596
    },
    {
      "epoch": 0.09489181617690887,
      "grad_norm": 0.5903862714767456,
      "learning_rate": 9.890094814824854e-06,
      "loss": 0.233,
      "step": 597
    },
    {
      "epoch": 0.09505076394269933,
      "grad_norm": 0.5219899415969849,
      "learning_rate": 9.889557398289005e-06,
      "loss": 0.2039,
      "step": 598
    },
    {
      "epoch": 0.0952097117084898,
      "grad_norm": 0.6425687074661255,
      "learning_rate": 9.889018685693839e-06,
      "loss": 0.2664,
      "step": 599
    },
    {
      "epoch": 0.09536865947428026,
      "grad_norm": 0.5929945111274719,
      "learning_rate": 9.888478677182155e-06,
      "loss": 0.2197,
      "step": 600
    },
    {
      "epoch": 0.09552760724007073,
      "grad_norm": 0.6422923803329468,
      "learning_rate": 9.887937372897089e-06,
      "loss": 0.2815,
      "step": 601
    },
    {
      "epoch": 0.09568655500586119,
      "grad_norm": 0.5520352125167847,
      "learning_rate": 9.887394772982122e-06,
      "loss": 0.1617,
      "step": 602
    },
    {
      "epoch": 0.09584550277165167,
      "grad_norm": 0.6165762543678284,
      "learning_rate": 9.886850877581079e-06,
      "loss": 0.213,
      "step": 603
    },
    {
      "epoch": 0.09600445053744214,
      "grad_norm": 0.6057076454162598,
      "learning_rate": 9.88630568683813e-06,
      "loss": 0.2138,
      "step": 604
    },
    {
      "epoch": 0.0961633983032326,
      "grad_norm": 0.4585711658000946,
      "learning_rate": 9.885759200897786e-06,
      "loss": 0.1742,
      "step": 605
    },
    {
      "epoch": 0.09632234606902307,
      "grad_norm": 0.6535313725471497,
      "learning_rate": 9.885211419904905e-06,
      "loss": 0.1676,
      "step": 606
    },
    {
      "epoch": 0.09648129383481353,
      "grad_norm": 0.5688518285751343,
      "learning_rate": 9.884662344004681e-06,
      "loss": 0.2172,
      "step": 607
    },
    {
      "epoch": 0.096640241600604,
      "grad_norm": 1.0149024724960327,
      "learning_rate": 9.884111973342659e-06,
      "loss": 0.2861,
      "step": 608
    },
    {
      "epoch": 0.09679918936639446,
      "grad_norm": 0.7665132284164429,
      "learning_rate": 9.883560308064723e-06,
      "loss": 0.2572,
      "step": 609
    },
    {
      "epoch": 0.09695813713218493,
      "grad_norm": 0.5802195072174072,
      "learning_rate": 9.883007348317101e-06,
      "loss": 0.1851,
      "step": 610
    },
    {
      "epoch": 0.09711708489797541,
      "grad_norm": 0.5581627488136292,
      "learning_rate": 9.882453094246366e-06,
      "loss": 0.2657,
      "step": 611
    },
    {
      "epoch": 0.09727603266376587,
      "grad_norm": 0.716196596622467,
      "learning_rate": 9.88189754599943e-06,
      "loss": 0.3719,
      "step": 612
    },
    {
      "epoch": 0.09743498042955634,
      "grad_norm": 0.636868417263031,
      "learning_rate": 9.88134070372355e-06,
      "loss": 0.2596,
      "step": 613
    },
    {
      "epoch": 0.0975939281953468,
      "grad_norm": 0.61662757396698,
      "learning_rate": 9.88078256756633e-06,
      "loss": 0.2948,
      "step": 614
    },
    {
      "epoch": 0.09775287596113727,
      "grad_norm": 0.5784598588943481,
      "learning_rate": 9.880223137675709e-06,
      "loss": 0.224,
      "step": 615
    },
    {
      "epoch": 0.09791182372692774,
      "grad_norm": 0.5777772665023804,
      "learning_rate": 9.879662414199976e-06,
      "loss": 0.2727,
      "step": 616
    },
    {
      "epoch": 0.0980707714927182,
      "grad_norm": 0.5898900032043457,
      "learning_rate": 9.87910039728776e-06,
      "loss": 0.2215,
      "step": 617
    },
    {
      "epoch": 0.09822971925850867,
      "grad_norm": 0.6800330877304077,
      "learning_rate": 9.878537087088031e-06,
      "loss": 0.3626,
      "step": 618
    },
    {
      "epoch": 0.09838866702429915,
      "grad_norm": 0.6177088022232056,
      "learning_rate": 9.877972483750107e-06,
      "loss": 0.2419,
      "step": 619
    },
    {
      "epoch": 0.09854761479008961,
      "grad_norm": 0.5934364199638367,
      "learning_rate": 9.877406587423643e-06,
      "loss": 0.2377,
      "step": 620
    },
    {
      "epoch": 0.09870656255588008,
      "grad_norm": 1.100352168083191,
      "learning_rate": 9.87683939825864e-06,
      "loss": 0.2432,
      "step": 621
    },
    {
      "epoch": 0.09886551032167054,
      "grad_norm": 0.6986895799636841,
      "learning_rate": 9.876270916405442e-06,
      "loss": 0.3798,
      "step": 622
    },
    {
      "epoch": 0.099024458087461,
      "grad_norm": 0.5252204537391663,
      "learning_rate": 9.875701142014735e-06,
      "loss": 0.2245,
      "step": 623
    },
    {
      "epoch": 0.09918340585325147,
      "grad_norm": 0.6208921670913696,
      "learning_rate": 9.875130075237544e-06,
      "loss": 0.2647,
      "step": 624
    },
    {
      "epoch": 0.09934235361904194,
      "grad_norm": 0.665963888168335,
      "learning_rate": 9.874557716225244e-06,
      "loss": 0.3035,
      "step": 625
    },
    {
      "epoch": 0.09950130138483242,
      "grad_norm": 0.8487067818641663,
      "learning_rate": 9.873984065129544e-06,
      "loss": 0.4787,
      "step": 626
    },
    {
      "epoch": 0.09966024915062288,
      "grad_norm": 0.6454005241394043,
      "learning_rate": 9.873409122102505e-06,
      "loss": 0.3598,
      "step": 627
    },
    {
      "epoch": 0.09981919691641335,
      "grad_norm": 0.5514479875564575,
      "learning_rate": 9.872832887296522e-06,
      "loss": 0.1893,
      "step": 628
    },
    {
      "epoch": 0.09997814468220381,
      "grad_norm": 0.5593662858009338,
      "learning_rate": 9.872255360864335e-06,
      "loss": 0.2134,
      "step": 629
    },
    {
      "epoch": 0.10013709244799428,
      "grad_norm": 1.3107503652572632,
      "learning_rate": 9.87167654295903e-06,
      "loss": 0.3093,
      "step": 630
    },
    {
      "epoch": 0.10029604021378474,
      "grad_norm": 0.7285627722740173,
      "learning_rate": 9.87109643373403e-06,
      "loss": 0.3228,
      "step": 631
    },
    {
      "epoch": 0.10045498797957521,
      "grad_norm": 0.6341620087623596,
      "learning_rate": 9.870515033343104e-06,
      "loss": 0.2041,
      "step": 632
    },
    {
      "epoch": 0.10061393574536567,
      "grad_norm": 0.6919119954109192,
      "learning_rate": 9.86993234194036e-06,
      "loss": 0.2943,
      "step": 633
    },
    {
      "epoch": 0.10077288351115615,
      "grad_norm": 0.5472947955131531,
      "learning_rate": 9.869348359680252e-06,
      "loss": 0.2542,
      "step": 634
    },
    {
      "epoch": 0.10093183127694662,
      "grad_norm": 0.6426556706428528,
      "learning_rate": 9.868763086717575e-06,
      "loss": 0.2374,
      "step": 635
    },
    {
      "epoch": 0.10109077904273708,
      "grad_norm": 0.6849910020828247,
      "learning_rate": 9.868176523207465e-06,
      "loss": 0.2587,
      "step": 636
    },
    {
      "epoch": 0.10124972680852755,
      "grad_norm": 0.5685378313064575,
      "learning_rate": 9.867588669305397e-06,
      "loss": 0.2122,
      "step": 637
    },
    {
      "epoch": 0.10140867457431801,
      "grad_norm": 0.7133554220199585,
      "learning_rate": 9.866999525167196e-06,
      "loss": 0.336,
      "step": 638
    },
    {
      "epoch": 0.10156762234010848,
      "grad_norm": 0.9174104332923889,
      "learning_rate": 9.866409090949023e-06,
      "loss": 0.2727,
      "step": 639
    },
    {
      "epoch": 0.10172657010589894,
      "grad_norm": 0.734403669834137,
      "learning_rate": 9.865817366807382e-06,
      "loss": 0.4554,
      "step": 640
    },
    {
      "epoch": 0.10188551787168941,
      "grad_norm": 0.6036725044250488,
      "learning_rate": 9.86522435289912e-06,
      "loss": 0.2197,
      "step": 641
    },
    {
      "epoch": 0.10204446563747989,
      "grad_norm": 0.6838693022727966,
      "learning_rate": 9.864630049381425e-06,
      "loss": 0.4031,
      "step": 642
    },
    {
      "epoch": 0.10220341340327035,
      "grad_norm": 0.7187343239784241,
      "learning_rate": 9.864034456411829e-06,
      "loss": 0.4725,
      "step": 643
    },
    {
      "epoch": 0.10236236116906082,
      "grad_norm": 0.6609770655632019,
      "learning_rate": 9.863437574148199e-06,
      "loss": 0.1818,
      "step": 644
    },
    {
      "epoch": 0.10252130893485129,
      "grad_norm": 0.6183878779411316,
      "learning_rate": 9.862839402748754e-06,
      "loss": 0.1403,
      "step": 645
    },
    {
      "epoch": 0.10268025670064175,
      "grad_norm": 0.5164926648139954,
      "learning_rate": 9.862239942372047e-06,
      "loss": 0.1572,
      "step": 646
    },
    {
      "epoch": 0.10283920446643222,
      "grad_norm": 0.6517187356948853,
      "learning_rate": 9.861639193176976e-06,
      "loss": 0.2032,
      "step": 647
    },
    {
      "epoch": 0.10299815223222268,
      "grad_norm": 0.6411435604095459,
      "learning_rate": 9.861037155322777e-06,
      "loss": 0.2606,
      "step": 648
    },
    {
      "epoch": 0.10315709999801315,
      "grad_norm": 0.6884721517562866,
      "learning_rate": 9.860433828969034e-06,
      "loss": 0.2543,
      "step": 649
    },
    {
      "epoch": 0.10331604776380363,
      "grad_norm": 0.6222977638244629,
      "learning_rate": 9.859829214275664e-06,
      "loss": 0.184,
      "step": 650
    },
    {
      "epoch": 0.10347499552959409,
      "grad_norm": 0.6461228728294373,
      "learning_rate": 9.859223311402937e-06,
      "loss": 0.2755,
      "step": 651
    },
    {
      "epoch": 0.10363394329538456,
      "grad_norm": 0.6896335482597351,
      "learning_rate": 9.858616120511453e-06,
      "loss": 0.2609,
      "step": 652
    },
    {
      "epoch": 0.10379289106117502,
      "grad_norm": 0.6987204551696777,
      "learning_rate": 9.858007641762158e-06,
      "loss": 0.3167,
      "step": 653
    },
    {
      "epoch": 0.10395183882696549,
      "grad_norm": 0.5873239040374756,
      "learning_rate": 9.857397875316341e-06,
      "loss": 0.2366,
      "step": 654
    },
    {
      "epoch": 0.10411078659275595,
      "grad_norm": 0.541484534740448,
      "learning_rate": 9.856786821335631e-06,
      "loss": 0.2164,
      "step": 655
    },
    {
      "epoch": 0.10426973435854642,
      "grad_norm": 0.5460968017578125,
      "learning_rate": 9.856174479981997e-06,
      "loss": 0.167,
      "step": 656
    },
    {
      "epoch": 0.10442868212433688,
      "grad_norm": 0.6229105591773987,
      "learning_rate": 9.855560851417752e-06,
      "loss": 0.2182,
      "step": 657
    },
    {
      "epoch": 0.10458762989012736,
      "grad_norm": 0.7919700145721436,
      "learning_rate": 9.854945935805547e-06,
      "loss": 0.377,
      "step": 658
    },
    {
      "epoch": 0.10474657765591783,
      "grad_norm": 0.6541404128074646,
      "learning_rate": 9.854329733308375e-06,
      "loss": 0.3073,
      "step": 659
    },
    {
      "epoch": 0.10490552542170829,
      "grad_norm": 1.2080224752426147,
      "learning_rate": 9.853712244089572e-06,
      "loss": 0.2388,
      "step": 660
    },
    {
      "epoch": 0.10506447318749876,
      "grad_norm": 0.6812763810157776,
      "learning_rate": 9.853093468312817e-06,
      "loss": 0.3508,
      "step": 661
    },
    {
      "epoch": 0.10522342095328922,
      "grad_norm": 0.5721216201782227,
      "learning_rate": 9.852473406142122e-06,
      "loss": 0.2025,
      "step": 662
    },
    {
      "epoch": 0.10538236871907969,
      "grad_norm": 0.5969102382659912,
      "learning_rate": 9.851852057741846e-06,
      "loss": 0.2778,
      "step": 663
    },
    {
      "epoch": 0.10554131648487015,
      "grad_norm": 0.7505307197570801,
      "learning_rate": 9.85122942327669e-06,
      "loss": 0.266,
      "step": 664
    },
    {
      "epoch": 0.10570026425066063,
      "grad_norm": 0.5752218961715698,
      "learning_rate": 9.850605502911691e-06,
      "loss": 0.2323,
      "step": 665
    },
    {
      "epoch": 0.1058592120164511,
      "grad_norm": 0.6040011644363403,
      "learning_rate": 9.849980296812231e-06,
      "loss": 0.2676,
      "step": 666
    },
    {
      "epoch": 0.10601815978224156,
      "grad_norm": 0.6651144623756409,
      "learning_rate": 9.849353805144033e-06,
      "loss": 0.2764,
      "step": 667
    },
    {
      "epoch": 0.10617710754803203,
      "grad_norm": 0.6360971331596375,
      "learning_rate": 9.848726028073156e-06,
      "loss": 0.2155,
      "step": 668
    },
    {
      "epoch": 0.1063360553138225,
      "grad_norm": 0.5927290320396423,
      "learning_rate": 9.848096965766005e-06,
      "loss": 0.2888,
      "step": 669
    },
    {
      "epoch": 0.10649500307961296,
      "grad_norm": 0.6988226771354675,
      "learning_rate": 9.847466618389321e-06,
      "loss": 0.3016,
      "step": 670
    },
    {
      "epoch": 0.10665395084540343,
      "grad_norm": 0.6013391017913818,
      "learning_rate": 9.846834986110192e-06,
      "loss": 0.1724,
      "step": 671
    },
    {
      "epoch": 0.10681289861119389,
      "grad_norm": 0.43658584356307983,
      "learning_rate": 9.84620206909604e-06,
      "loss": 0.1083,
      "step": 672
    },
    {
      "epoch": 0.10697184637698437,
      "grad_norm": 0.5848294496536255,
      "learning_rate": 9.84556786751463e-06,
      "loss": 0.2722,
      "step": 673
    },
    {
      "epoch": 0.10713079414277484,
      "grad_norm": 0.4969616234302521,
      "learning_rate": 9.844932381534069e-06,
      "loss": 0.1721,
      "step": 674
    },
    {
      "epoch": 0.1072897419085653,
      "grad_norm": 0.6183708310127258,
      "learning_rate": 9.844295611322804e-06,
      "loss": 0.2329,
      "step": 675
    },
    {
      "epoch": 0.10744868967435577,
      "grad_norm": 0.5704097747802734,
      "learning_rate": 9.84365755704962e-06,
      "loss": 0.2515,
      "step": 676
    },
    {
      "epoch": 0.10760763744014623,
      "grad_norm": 0.6246934533119202,
      "learning_rate": 9.843018218883645e-06,
      "loss": 0.2647,
      "step": 677
    },
    {
      "epoch": 0.1077665852059367,
      "grad_norm": 0.7836776971817017,
      "learning_rate": 9.842377596994345e-06,
      "loss": 0.2549,
      "step": 678
    },
    {
      "epoch": 0.10792553297172716,
      "grad_norm": 0.62638920545578,
      "learning_rate": 9.84173569155153e-06,
      "loss": 0.2512,
      "step": 679
    },
    {
      "epoch": 0.10808448073751763,
      "grad_norm": 0.6255860328674316,
      "learning_rate": 9.841092502725346e-06,
      "loss": 0.3284,
      "step": 680
    },
    {
      "epoch": 0.1082434285033081,
      "grad_norm": 0.5651288032531738,
      "learning_rate": 9.84044803068628e-06,
      "loss": 0.1744,
      "step": 681
    },
    {
      "epoch": 0.10840237626909857,
      "grad_norm": 0.7131785750389099,
      "learning_rate": 9.839802275605164e-06,
      "loss": 0.2916,
      "step": 682
    },
    {
      "epoch": 0.10856132403488904,
      "grad_norm": 0.5722540020942688,
      "learning_rate": 9.839155237653161e-06,
      "loss": 0.2147,
      "step": 683
    },
    {
      "epoch": 0.1087202718006795,
      "grad_norm": 0.6494225263595581,
      "learning_rate": 9.838506917001784e-06,
      "loss": 0.2646,
      "step": 684
    },
    {
      "epoch": 0.10887921956646997,
      "grad_norm": 0.6155762672424316,
      "learning_rate": 9.837857313822878e-06,
      "loss": 0.2511,
      "step": 685
    },
    {
      "epoch": 0.10903816733226043,
      "grad_norm": 0.601335346698761,
      "learning_rate": 9.837206428288633e-06,
      "loss": 0.2527,
      "step": 686
    },
    {
      "epoch": 0.1091971150980509,
      "grad_norm": 0.7106847763061523,
      "learning_rate": 9.836554260571577e-06,
      "loss": 0.3645,
      "step": 687
    },
    {
      "epoch": 0.10935606286384136,
      "grad_norm": 0.5731980204582214,
      "learning_rate": 9.83590081084458e-06,
      "loss": 0.1796,
      "step": 688
    },
    {
      "epoch": 0.10951501062963184,
      "grad_norm": 0.7882025241851807,
      "learning_rate": 9.835246079280842e-06,
      "loss": 0.3467,
      "step": 689
    },
    {
      "epoch": 0.10967395839542231,
      "grad_norm": 0.769930362701416,
      "learning_rate": 9.83459006605392e-06,
      "loss": 0.345,
      "step": 690
    },
    {
      "epoch": 0.10983290616121277,
      "grad_norm": 0.462322860956192,
      "learning_rate": 9.833932771337697e-06,
      "loss": 0.1641,
      "step": 691
    },
    {
      "epoch": 0.10999185392700324,
      "grad_norm": 0.4522906541824341,
      "learning_rate": 9.833274195306399e-06,
      "loss": 0.1437,
      "step": 692
    },
    {
      "epoch": 0.1101508016927937,
      "grad_norm": 0.6551764011383057,
      "learning_rate": 9.832614338134595e-06,
      "loss": 0.2912,
      "step": 693
    },
    {
      "epoch": 0.11030974945858417,
      "grad_norm": 0.6722983717918396,
      "learning_rate": 9.831953199997191e-06,
      "loss": 0.2566,
      "step": 694
    },
    {
      "epoch": 0.11046869722437463,
      "grad_norm": 0.5662277936935425,
      "learning_rate": 9.831290781069431e-06,
      "loss": 0.2225,
      "step": 695
    },
    {
      "epoch": 0.11062764499016511,
      "grad_norm": 0.6359855532646179,
      "learning_rate": 9.830627081526902e-06,
      "loss": 0.2838,
      "step": 696
    },
    {
      "epoch": 0.11078659275595558,
      "grad_norm": 0.7111298441886902,
      "learning_rate": 9.829962101545527e-06,
      "loss": 0.3744,
      "step": 697
    },
    {
      "epoch": 0.11094554052174604,
      "grad_norm": 0.7042221426963806,
      "learning_rate": 9.829295841301572e-06,
      "loss": 0.3919,
      "step": 698
    },
    {
      "epoch": 0.11110448828753651,
      "grad_norm": 0.46493303775787354,
      "learning_rate": 9.828628300971639e-06,
      "loss": 0.1671,
      "step": 699
    },
    {
      "epoch": 0.11126343605332698,
      "grad_norm": 0.6696193814277649,
      "learning_rate": 9.827959480732671e-06,
      "loss": 0.3407,
      "step": 700
    },
    {
      "epoch": 0.11142238381911744,
      "grad_norm": 0.6348670721054077,
      "learning_rate": 9.827289380761953e-06,
      "loss": 0.2601,
      "step": 701
    },
    {
      "epoch": 0.1115813315849079,
      "grad_norm": 0.5871545076370239,
      "learning_rate": 9.826618001237101e-06,
      "loss": 0.1818,
      "step": 702
    },
    {
      "epoch": 0.11174027935069837,
      "grad_norm": 0.4974304735660553,
      "learning_rate": 9.825945342336079e-06,
      "loss": 0.1525,
      "step": 703
    },
    {
      "epoch": 0.11189922711648885,
      "grad_norm": 0.6012148261070251,
      "learning_rate": 9.825271404237187e-06,
      "loss": 0.2379,
      "step": 704
    },
    {
      "epoch": 0.11205817488227932,
      "grad_norm": 0.5616613030433655,
      "learning_rate": 9.82459618711906e-06,
      "loss": 0.2799,
      "step": 705
    },
    {
      "epoch": 0.11221712264806978,
      "grad_norm": 0.6501995325088501,
      "learning_rate": 9.82391969116068e-06,
      "loss": 0.3241,
      "step": 706
    },
    {
      "epoch": 0.11237607041386025,
      "grad_norm": 0.550492525100708,
      "learning_rate": 9.82324191654136e-06,
      "loss": 0.2212,
      "step": 707
    },
    {
      "epoch": 0.11253501817965071,
      "grad_norm": 0.6576758027076721,
      "learning_rate": 9.822562863440757e-06,
      "loss": 0.2661,
      "step": 708
    },
    {
      "epoch": 0.11269396594544118,
      "grad_norm": 0.5708886384963989,
      "learning_rate": 9.821882532038866e-06,
      "loss": 0.2134,
      "step": 709
    },
    {
      "epoch": 0.11285291371123164,
      "grad_norm": 0.6390810012817383,
      "learning_rate": 9.821200922516019e-06,
      "loss": 0.2808,
      "step": 710
    },
    {
      "epoch": 0.11301186147702211,
      "grad_norm": 0.5682689547538757,
      "learning_rate": 9.82051803505289e-06,
      "loss": 0.2388,
      "step": 711
    },
    {
      "epoch": 0.11317080924281259,
      "grad_norm": 0.5902893543243408,
      "learning_rate": 9.819833869830487e-06,
      "loss": 0.2926,
      "step": 712
    },
    {
      "epoch": 0.11332975700860305,
      "grad_norm": 0.7030308246612549,
      "learning_rate": 9.819148427030163e-06,
      "loss": 0.2636,
      "step": 713
    },
    {
      "epoch": 0.11348870477439352,
      "grad_norm": 0.6451651453971863,
      "learning_rate": 9.818461706833603e-06,
      "loss": 0.2988,
      "step": 714
    },
    {
      "epoch": 0.11364765254018398,
      "grad_norm": 0.7003216743469238,
      "learning_rate": 9.817773709422835e-06,
      "loss": 0.268,
      "step": 715
    },
    {
      "epoch": 0.11380660030597445,
      "grad_norm": 0.6431633234024048,
      "learning_rate": 9.817084434980223e-06,
      "loss": 0.269,
      "step": 716
    },
    {
      "epoch": 0.11396554807176491,
      "grad_norm": 0.5273224711418152,
      "learning_rate": 9.816393883688475e-06,
      "loss": 0.1624,
      "step": 717
    },
    {
      "epoch": 0.11412449583755538,
      "grad_norm": 0.6465290188789368,
      "learning_rate": 9.81570205573063e-06,
      "loss": 0.279,
      "step": 718
    },
    {
      "epoch": 0.11428344360334584,
      "grad_norm": 0.5813251733779907,
      "learning_rate": 9.815008951290066e-06,
      "loss": 0.2791,
      "step": 719
    },
    {
      "epoch": 0.11444239136913632,
      "grad_norm": 0.49316954612731934,
      "learning_rate": 9.814314570550506e-06,
      "loss": 0.1512,
      "step": 720
    },
    {
      "epoch": 0.11460133913492679,
      "grad_norm": 0.6550154089927673,
      "learning_rate": 9.813618913696005e-06,
      "loss": 0.2756,
      "step": 721
    },
    {
      "epoch": 0.11476028690071725,
      "grad_norm": 0.6395670175552368,
      "learning_rate": 9.812921980910963e-06,
      "loss": 0.2715,
      "step": 722
    },
    {
      "epoch": 0.11491923466650772,
      "grad_norm": 0.702616810798645,
      "learning_rate": 9.812223772380107e-06,
      "loss": 0.3772,
      "step": 723
    },
    {
      "epoch": 0.11507818243229818,
      "grad_norm": 0.6170244812965393,
      "learning_rate": 9.811524288288514e-06,
      "loss": 0.3111,
      "step": 724
    },
    {
      "epoch": 0.11523713019808865,
      "grad_norm": 0.6056216955184937,
      "learning_rate": 9.81082352882159e-06,
      "loss": 0.2357,
      "step": 725
    },
    {
      "epoch": 0.11539607796387912,
      "grad_norm": 0.6045450568199158,
      "learning_rate": 9.810121494165088e-06,
      "loss": 0.2638,
      "step": 726
    },
    {
      "epoch": 0.11555502572966958,
      "grad_norm": 0.6259638071060181,
      "learning_rate": 9.809418184505091e-06,
      "loss": 0.2008,
      "step": 727
    },
    {
      "epoch": 0.11571397349546006,
      "grad_norm": 0.6586573123931885,
      "learning_rate": 9.808713600028023e-06,
      "loss": 0.3752,
      "step": 728
    },
    {
      "epoch": 0.11587292126125052,
      "grad_norm": 0.8701809644699097,
      "learning_rate": 9.808007740920647e-06,
      "loss": 0.2791,
      "step": 729
    },
    {
      "epoch": 0.11603186902704099,
      "grad_norm": 0.7127154469490051,
      "learning_rate": 9.80730060737006e-06,
      "loss": 0.4009,
      "step": 730
    },
    {
      "epoch": 0.11619081679283146,
      "grad_norm": 0.5057111382484436,
      "learning_rate": 9.806592199563703e-06,
      "loss": 0.1364,
      "step": 731
    },
    {
      "epoch": 0.11634976455862192,
      "grad_norm": 0.6375819444656372,
      "learning_rate": 9.80588251768935e-06,
      "loss": 0.3643,
      "step": 732
    },
    {
      "epoch": 0.11650871232441239,
      "grad_norm": 0.6106845140457153,
      "learning_rate": 9.805171561935116e-06,
      "loss": 0.2487,
      "step": 733
    },
    {
      "epoch": 0.11666766009020285,
      "grad_norm": 0.6413806080818176,
      "learning_rate": 9.804459332489448e-06,
      "loss": 0.3116,
      "step": 734
    },
    {
      "epoch": 0.11682660785599333,
      "grad_norm": 0.5244285464286804,
      "learning_rate": 9.803745829541138e-06,
      "loss": 0.2197,
      "step": 735
    },
    {
      "epoch": 0.1169855556217838,
      "grad_norm": 0.7454008460044861,
      "learning_rate": 9.803031053279308e-06,
      "loss": 0.3709,
      "step": 736
    },
    {
      "epoch": 0.11714450338757426,
      "grad_norm": 0.5708292126655579,
      "learning_rate": 9.802315003893426e-06,
      "loss": 0.2339,
      "step": 737
    },
    {
      "epoch": 0.11730345115336473,
      "grad_norm": 0.5530438423156738,
      "learning_rate": 9.80159768157329e-06,
      "loss": 0.2067,
      "step": 738
    },
    {
      "epoch": 0.11746239891915519,
      "grad_norm": 0.5600000023841858,
      "learning_rate": 9.800879086509039e-06,
      "loss": 0.1897,
      "step": 739
    },
    {
      "epoch": 0.11762134668494566,
      "grad_norm": 0.548418402671814,
      "learning_rate": 9.80015921889115e-06,
      "loss": 0.1994,
      "step": 740
    },
    {
      "epoch": 0.11778029445073612,
      "grad_norm": 0.5930530428886414,
      "learning_rate": 9.799438078910433e-06,
      "loss": 0.2007,
      "step": 741
    },
    {
      "epoch": 0.11793924221652659,
      "grad_norm": 0.553622841835022,
      "learning_rate": 9.79871566675804e-06,
      "loss": 0.1561,
      "step": 742
    },
    {
      "epoch": 0.11809818998231707,
      "grad_norm": 0.6682994365692139,
      "learning_rate": 9.797991982625462e-06,
      "loss": 0.3228,
      "step": 743
    },
    {
      "epoch": 0.11825713774810753,
      "grad_norm": 0.5702691674232483,
      "learning_rate": 9.797267026704516e-06,
      "loss": 0.226,
      "step": 744
    },
    {
      "epoch": 0.118416085513898,
      "grad_norm": 0.4826664924621582,
      "learning_rate": 9.79654079918737e-06,
      "loss": 0.1179,
      "step": 745
    },
    {
      "epoch": 0.11857503327968846,
      "grad_norm": 0.5489474534988403,
      "learning_rate": 9.79581330026652e-06,
      "loss": 0.2459,
      "step": 746
    },
    {
      "epoch": 0.11873398104547893,
      "grad_norm": 0.5595270395278931,
      "learning_rate": 9.795084530134801e-06,
      "loss": 0.2198,
      "step": 747
    },
    {
      "epoch": 0.1188929288112694,
      "grad_norm": 0.8788889646530151,
      "learning_rate": 9.79435448898539e-06,
      "loss": 0.3264,
      "step": 748
    },
    {
      "epoch": 0.11905187657705986,
      "grad_norm": 0.628128170967102,
      "learning_rate": 9.793623177011793e-06,
      "loss": 0.2866,
      "step": 749
    },
    {
      "epoch": 0.11921082434285032,
      "grad_norm": 0.7207876443862915,
      "learning_rate": 9.792890594407856e-06,
      "loss": 0.346,
      "step": 750
    },
    {
      "epoch": 0.1193697721086408,
      "grad_norm": 0.5395873785018921,
      "learning_rate": 9.792156741367766e-06,
      "loss": 0.1902,
      "step": 751
    },
    {
      "epoch": 0.11952871987443127,
      "grad_norm": 0.6802169680595398,
      "learning_rate": 9.791421618086038e-06,
      "loss": 0.3821,
      "step": 752
    },
    {
      "epoch": 0.11968766764022173,
      "grad_norm": 0.573792040348053,
      "learning_rate": 9.790685224757534e-06,
      "loss": 0.2299,
      "step": 753
    },
    {
      "epoch": 0.1198466154060122,
      "grad_norm": 0.8230257034301758,
      "learning_rate": 9.789947561577445e-06,
      "loss": 0.3827,
      "step": 754
    },
    {
      "epoch": 0.12000556317180266,
      "grad_norm": 0.6718461513519287,
      "learning_rate": 9.789208628741301e-06,
      "loss": 0.2982,
      "step": 755
    },
    {
      "epoch": 0.12016451093759313,
      "grad_norm": 0.548064649105072,
      "learning_rate": 9.788468426444968e-06,
      "loss": 0.2207,
      "step": 756
    },
    {
      "epoch": 0.1203234587033836,
      "grad_norm": 0.6295731663703918,
      "learning_rate": 9.78772695488465e-06,
      "loss": 0.3211,
      "step": 757
    },
    {
      "epoch": 0.12048240646917406,
      "grad_norm": 0.5486401915550232,
      "learning_rate": 9.786984214256887e-06,
      "loss": 0.2086,
      "step": 758
    },
    {
      "epoch": 0.12064135423496454,
      "grad_norm": 0.6834962368011475,
      "learning_rate": 9.786240204758552e-06,
      "loss": 0.3481,
      "step": 759
    },
    {
      "epoch": 0.120800302000755,
      "grad_norm": 0.5992876887321472,
      "learning_rate": 9.785494926586861e-06,
      "loss": 0.2889,
      "step": 760
    },
    {
      "epoch": 0.12095924976654547,
      "grad_norm": 0.6053423881530762,
      "learning_rate": 9.784748379939359e-06,
      "loss": 0.3271,
      "step": 761
    },
    {
      "epoch": 0.12111819753233594,
      "grad_norm": 0.5844933390617371,
      "learning_rate": 9.784000565013934e-06,
      "loss": 0.2112,
      "step": 762
    },
    {
      "epoch": 0.1212771452981264,
      "grad_norm": 0.5916872024536133,
      "learning_rate": 9.783251482008804e-06,
      "loss": 0.195,
      "step": 763
    },
    {
      "epoch": 0.12143609306391687,
      "grad_norm": 0.6217025518417358,
      "learning_rate": 9.78250113112253e-06,
      "loss": 0.2219,
      "step": 764
    },
    {
      "epoch": 0.12159504082970733,
      "grad_norm": 0.8015320301055908,
      "learning_rate": 9.781749512554e-06,
      "loss": 0.2061,
      "step": 765
    },
    {
      "epoch": 0.12175398859549781,
      "grad_norm": 0.5931090712547302,
      "learning_rate": 9.780996626502447e-06,
      "loss": 0.275,
      "step": 766
    },
    {
      "epoch": 0.12191293636128828,
      "grad_norm": 0.577236533164978,
      "learning_rate": 9.780242473167434e-06,
      "loss": 0.2495,
      "step": 767
    },
    {
      "epoch": 0.12207188412707874,
      "grad_norm": 0.7100372314453125,
      "learning_rate": 9.779487052748865e-06,
      "loss": 0.3819,
      "step": 768
    },
    {
      "epoch": 0.12223083189286921,
      "grad_norm": 0.7108115553855896,
      "learning_rate": 9.778730365446972e-06,
      "loss": 0.3312,
      "step": 769
    },
    {
      "epoch": 0.12238977965865967,
      "grad_norm": 0.6687682271003723,
      "learning_rate": 9.777972411462331e-06,
      "loss": 0.2998,
      "step": 770
    },
    {
      "epoch": 0.12254872742445014,
      "grad_norm": 0.7180570363998413,
      "learning_rate": 9.777213190995849e-06,
      "loss": 0.4535,
      "step": 771
    },
    {
      "epoch": 0.1227076751902406,
      "grad_norm": 0.6878809332847595,
      "learning_rate": 9.776452704248772e-06,
      "loss": 0.3568,
      "step": 772
    },
    {
      "epoch": 0.12286662295603107,
      "grad_norm": 0.6413043737411499,
      "learning_rate": 9.775690951422678e-06,
      "loss": 0.2423,
      "step": 773
    },
    {
      "epoch": 0.12302557072182155,
      "grad_norm": 0.5439435243606567,
      "learning_rate": 9.774927932719484e-06,
      "loss": 0.2212,
      "step": 774
    },
    {
      "epoch": 0.12318451848761201,
      "grad_norm": 0.6012130379676819,
      "learning_rate": 9.77416364834144e-06,
      "loss": 0.2568,
      "step": 775
    },
    {
      "epoch": 0.12334346625340248,
      "grad_norm": 0.5816197395324707,
      "learning_rate": 9.773398098491131e-06,
      "loss": 0.1512,
      "step": 776
    },
    {
      "epoch": 0.12350241401919294,
      "grad_norm": 0.735941469669342,
      "learning_rate": 9.772631283371481e-06,
      "loss": 0.2637,
      "step": 777
    },
    {
      "epoch": 0.12366136178498341,
      "grad_norm": 0.5022810697555542,
      "learning_rate": 9.771863203185746e-06,
      "loss": 0.1467,
      "step": 778
    },
    {
      "epoch": 0.12382030955077387,
      "grad_norm": 0.6070138216018677,
      "learning_rate": 9.77109385813752e-06,
      "loss": 0.2512,
      "step": 779
    },
    {
      "epoch": 0.12397925731656434,
      "grad_norm": 0.5414883494377136,
      "learning_rate": 9.770323248430728e-06,
      "loss": 0.1695,
      "step": 780
    },
    {
      "epoch": 0.1241382050823548,
      "grad_norm": 0.5832330584526062,
      "learning_rate": 9.769551374269637e-06,
      "loss": 0.2437,
      "step": 781
    },
    {
      "epoch": 0.12429715284814528,
      "grad_norm": 0.5375244617462158,
      "learning_rate": 9.768778235858842e-06,
      "loss": 0.217,
      "step": 782
    },
    {
      "epoch": 0.12445610061393575,
      "grad_norm": 0.7542282938957214,
      "learning_rate": 9.768003833403278e-06,
      "loss": 0.4252,
      "step": 783
    },
    {
      "epoch": 0.12461504837972621,
      "grad_norm": 0.5601425766944885,
      "learning_rate": 9.767228167108211e-06,
      "loss": 0.1932,
      "step": 784
    },
    {
      "epoch": 0.12477399614551668,
      "grad_norm": 0.6604436039924622,
      "learning_rate": 9.766451237179249e-06,
      "loss": 0.2211,
      "step": 785
    },
    {
      "epoch": 0.12493294391130715,
      "grad_norm": 0.5004429817199707,
      "learning_rate": 9.765673043822325e-06,
      "loss": 0.1694,
      "step": 786
    },
    {
      "epoch": 0.1250918916770976,
      "grad_norm": 0.48627156019210815,
      "learning_rate": 9.764893587243717e-06,
      "loss": 0.1263,
      "step": 787
    },
    {
      "epoch": 0.1252508394428881,
      "grad_norm": 0.7125306725502014,
      "learning_rate": 9.764112867650029e-06,
      "loss": 0.3533,
      "step": 788
    },
    {
      "epoch": 0.12540978720867854,
      "grad_norm": 0.6767341494560242,
      "learning_rate": 9.763330885248206e-06,
      "loss": 0.3634,
      "step": 789
    },
    {
      "epoch": 0.12556873497446902,
      "grad_norm": 0.5391532182693481,
      "learning_rate": 9.762547640245525e-06,
      "loss": 0.1956,
      "step": 790
    },
    {
      "epoch": 0.12572768274025947,
      "grad_norm": 0.668400764465332,
      "learning_rate": 9.7617631328496e-06,
      "loss": 0.2971,
      "step": 791
    },
    {
      "epoch": 0.12588663050604995,
      "grad_norm": 0.5583027601242065,
      "learning_rate": 9.760977363268374e-06,
      "loss": 0.2333,
      "step": 792
    },
    {
      "epoch": 0.1260455782718404,
      "grad_norm": 0.5275965332984924,
      "learning_rate": 9.760190331710133e-06,
      "loss": 0.2261,
      "step": 793
    },
    {
      "epoch": 0.12620452603763088,
      "grad_norm": 0.8161000609397888,
      "learning_rate": 9.75940203838349e-06,
      "loss": 0.2315,
      "step": 794
    },
    {
      "epoch": 0.12636347380342136,
      "grad_norm": 0.6835513114929199,
      "learning_rate": 9.758612483497395e-06,
      "loss": 0.2641,
      "step": 795
    },
    {
      "epoch": 0.1265224215692118,
      "grad_norm": 0.7108862996101379,
      "learning_rate": 9.757821667261133e-06,
      "loss": 0.3273,
      "step": 796
    },
    {
      "epoch": 0.1266813693350023,
      "grad_norm": 0.6132303476333618,
      "learning_rate": 9.757029589884327e-06,
      "loss": 0.3043,
      "step": 797
    },
    {
      "epoch": 0.12684031710079274,
      "grad_norm": 0.7451602816581726,
      "learning_rate": 9.756236251576925e-06,
      "loss": 0.3366,
      "step": 798
    },
    {
      "epoch": 0.12699926486658322,
      "grad_norm": 0.6216033101081848,
      "learning_rate": 9.755441652549218e-06,
      "loss": 0.2817,
      "step": 799
    },
    {
      "epoch": 0.12715821263237367,
      "grad_norm": 0.5580516457557678,
      "learning_rate": 9.754645793011826e-06,
      "loss": 0.2221,
      "step": 800
    },
    {
      "epoch": 0.12731716039816415,
      "grad_norm": 1.1075799465179443,
      "learning_rate": 9.753848673175707e-06,
      "loss": 0.3372,
      "step": 801
    },
    {
      "epoch": 0.12747610816395463,
      "grad_norm": 0.8392127752304077,
      "learning_rate": 9.753050293252149e-06,
      "loss": 0.413,
      "step": 802
    },
    {
      "epoch": 0.12763505592974508,
      "grad_norm": 0.5948123335838318,
      "learning_rate": 9.752250653452777e-06,
      "loss": 0.1932,
      "step": 803
    },
    {
      "epoch": 0.12779400369553556,
      "grad_norm": 1.1210523843765259,
      "learning_rate": 9.751449753989548e-06,
      "loss": 0.3191,
      "step": 804
    },
    {
      "epoch": 0.12795295146132601,
      "grad_norm": 0.7282294034957886,
      "learning_rate": 9.750647595074755e-06,
      "loss": 0.3189,
      "step": 805
    },
    {
      "epoch": 0.1281118992271165,
      "grad_norm": 0.5492563247680664,
      "learning_rate": 9.749844176921023e-06,
      "loss": 0.2298,
      "step": 806
    },
    {
      "epoch": 0.12827084699290695,
      "grad_norm": 0.5848921537399292,
      "learning_rate": 9.749039499741313e-06,
      "loss": 0.2621,
      "step": 807
    },
    {
      "epoch": 0.12842979475869742,
      "grad_norm": 0.6691039800643921,
      "learning_rate": 9.748233563748917e-06,
      "loss": 0.2998,
      "step": 808
    },
    {
      "epoch": 0.1285887425244879,
      "grad_norm": 0.6554386019706726,
      "learning_rate": 9.74742636915746e-06,
      "loss": 0.3296,
      "step": 809
    },
    {
      "epoch": 0.12874769029027835,
      "grad_norm": 0.6801124811172485,
      "learning_rate": 9.746617916180906e-06,
      "loss": 0.2556,
      "step": 810
    },
    {
      "epoch": 0.12890663805606883,
      "grad_norm": 0.7028271555900574,
      "learning_rate": 9.745808205033547e-06,
      "loss": 0.2143,
      "step": 811
    },
    {
      "epoch": 0.12906558582185929,
      "grad_norm": 0.7446557879447937,
      "learning_rate": 9.74499723593001e-06,
      "loss": 0.2806,
      "step": 812
    },
    {
      "epoch": 0.12922453358764976,
      "grad_norm": 0.7317588925361633,
      "learning_rate": 9.744185009085258e-06,
      "loss": 0.2291,
      "step": 813
    },
    {
      "epoch": 0.12938348135344022,
      "grad_norm": 0.7117791175842285,
      "learning_rate": 9.743371524714583e-06,
      "loss": 0.3482,
      "step": 814
    },
    {
      "epoch": 0.1295424291192307,
      "grad_norm": 0.48736366629600525,
      "learning_rate": 9.742556783033615e-06,
      "loss": 0.1368,
      "step": 815
    },
    {
      "epoch": 0.12970137688502115,
      "grad_norm": 0.7010034918785095,
      "learning_rate": 9.741740784258314e-06,
      "loss": 0.3312,
      "step": 816
    },
    {
      "epoch": 0.12986032465081163,
      "grad_norm": 0.7044858336448669,
      "learning_rate": 9.740923528604973e-06,
      "loss": 0.3009,
      "step": 817
    },
    {
      "epoch": 0.1300192724166021,
      "grad_norm": 0.5798578858375549,
      "learning_rate": 9.740105016290223e-06,
      "loss": 0.2155,
      "step": 818
    },
    {
      "epoch": 0.13017822018239256,
      "grad_norm": 0.5766908526420593,
      "learning_rate": 9.739285247531019e-06,
      "loss": 0.2681,
      "step": 819
    },
    {
      "epoch": 0.13033716794818304,
      "grad_norm": 0.7586296796798706,
      "learning_rate": 9.738464222544657e-06,
      "loss": 0.3473,
      "step": 820
    },
    {
      "epoch": 0.1304961157139735,
      "grad_norm": 0.549190104007721,
      "learning_rate": 9.737641941548765e-06,
      "loss": 0.2089,
      "step": 821
    },
    {
      "epoch": 0.13065506347976397,
      "grad_norm": 0.6515082716941833,
      "learning_rate": 9.736818404761303e-06,
      "loss": 0.1974,
      "step": 822
    },
    {
      "epoch": 0.13081401124555442,
      "grad_norm": 0.7037386894226074,
      "learning_rate": 9.735993612400559e-06,
      "loss": 0.2814,
      "step": 823
    },
    {
      "epoch": 0.1309729590113449,
      "grad_norm": 0.6375799775123596,
      "learning_rate": 9.735167564685162e-06,
      "loss": 0.2544,
      "step": 824
    },
    {
      "epoch": 0.13113190677713538,
      "grad_norm": 0.8200080394744873,
      "learning_rate": 9.734340261834068e-06,
      "loss": 0.3736,
      "step": 825
    },
    {
      "epoch": 0.13129085454292583,
      "grad_norm": 0.48334383964538574,
      "learning_rate": 9.733511704066567e-06,
      "loss": 0.1511,
      "step": 826
    },
    {
      "epoch": 0.1314498023087163,
      "grad_norm": 0.5245338678359985,
      "learning_rate": 9.732681891602283e-06,
      "loss": 0.2043,
      "step": 827
    },
    {
      "epoch": 0.13160875007450676,
      "grad_norm": 1.06187105178833,
      "learning_rate": 9.731850824661171e-06,
      "loss": 0.1677,
      "step": 828
    },
    {
      "epoch": 0.13176769784029724,
      "grad_norm": 0.5366033911705017,
      "learning_rate": 9.731018503463522e-06,
      "loss": 0.1692,
      "step": 829
    },
    {
      "epoch": 0.1319266456060877,
      "grad_norm": 0.6087852716445923,
      "learning_rate": 9.730184928229954e-06,
      "loss": 0.1946,
      "step": 830
    },
    {
      "epoch": 0.13208559337187817,
      "grad_norm": 0.644677460193634,
      "learning_rate": 9.72935009918142e-06,
      "loss": 0.3129,
      "step": 831
    },
    {
      "epoch": 0.13224454113766865,
      "grad_norm": 0.6110976338386536,
      "learning_rate": 9.728514016539208e-06,
      "loss": 0.2855,
      "step": 832
    },
    {
      "epoch": 0.1324034889034591,
      "grad_norm": 0.5715271830558777,
      "learning_rate": 9.727676680524933e-06,
      "loss": 0.2672,
      "step": 833
    },
    {
      "epoch": 0.13256243666924958,
      "grad_norm": 0.9228211045265198,
      "learning_rate": 9.726838091360547e-06,
      "loss": 0.3237,
      "step": 834
    },
    {
      "epoch": 0.13272138443504003,
      "grad_norm": 0.5996583104133606,
      "learning_rate": 9.72599824926833e-06,
      "loss": 0.2207,
      "step": 835
    },
    {
      "epoch": 0.1328803322008305,
      "grad_norm": 0.5398930907249451,
      "learning_rate": 9.725157154470899e-06,
      "loss": 0.2287,
      "step": 836
    },
    {
      "epoch": 0.13303927996662096,
      "grad_norm": 0.6008905172348022,
      "learning_rate": 9.724314807191197e-06,
      "loss": 0.253,
      "step": 837
    },
    {
      "epoch": 0.13319822773241144,
      "grad_norm": 0.6353186368942261,
      "learning_rate": 9.723471207652504e-06,
      "loss": 0.3021,
      "step": 838
    },
    {
      "epoch": 0.1333571754982019,
      "grad_norm": 0.5947064757347107,
      "learning_rate": 9.722626356078431e-06,
      "loss": 0.2367,
      "step": 839
    },
    {
      "epoch": 0.13351612326399237,
      "grad_norm": 0.8495191931724548,
      "learning_rate": 9.721780252692918e-06,
      "loss": 0.2452,
      "step": 840
    },
    {
      "epoch": 0.13367507102978285,
      "grad_norm": 0.5733830332756042,
      "learning_rate": 9.72093289772024e-06,
      "loss": 0.2022,
      "step": 841
    },
    {
      "epoch": 0.1338340187955733,
      "grad_norm": 0.6338624358177185,
      "learning_rate": 9.720084291385005e-06,
      "loss": 0.2595,
      "step": 842
    },
    {
      "epoch": 0.13399296656136378,
      "grad_norm": 0.6255444288253784,
      "learning_rate": 9.719234433912148e-06,
      "loss": 0.218,
      "step": 843
    },
    {
      "epoch": 0.13415191432715423,
      "grad_norm": 0.5266631245613098,
      "learning_rate": 9.718383325526939e-06,
      "loss": 0.1577,
      "step": 844
    },
    {
      "epoch": 0.1343108620929447,
      "grad_norm": 0.5811774730682373,
      "learning_rate": 9.717530966454976e-06,
      "loss": 0.2214,
      "step": 845
    },
    {
      "epoch": 0.13446980985873516,
      "grad_norm": 0.6281124353408813,
      "learning_rate": 9.716677356922193e-06,
      "loss": 0.3195,
      "step": 846
    },
    {
      "epoch": 0.13462875762452564,
      "grad_norm": 0.678870677947998,
      "learning_rate": 9.715822497154855e-06,
      "loss": 0.3826,
      "step": 847
    },
    {
      "epoch": 0.13478770539031612,
      "grad_norm": 0.49499619007110596,
      "learning_rate": 9.714966387379554e-06,
      "loss": 0.1233,
      "step": 848
    },
    {
      "epoch": 0.13494665315610657,
      "grad_norm": 0.5980741381645203,
      "learning_rate": 9.714109027823218e-06,
      "loss": 0.3194,
      "step": 849
    },
    {
      "epoch": 0.13510560092189705,
      "grad_norm": 0.6646329164505005,
      "learning_rate": 9.713250418713104e-06,
      "loss": 0.2889,
      "step": 850
    },
    {
      "epoch": 0.1352645486876875,
      "grad_norm": 0.4806360602378845,
      "learning_rate": 9.7123905602768e-06,
      "loss": 0.1713,
      "step": 851
    },
    {
      "epoch": 0.13542349645347798,
      "grad_norm": 0.6281716227531433,
      "learning_rate": 9.71152945274223e-06,
      "loss": 0.3237,
      "step": 852
    },
    {
      "epoch": 0.13558244421926843,
      "grad_norm": 0.7223203778266907,
      "learning_rate": 9.710667096337641e-06,
      "loss": 0.2491,
      "step": 853
    },
    {
      "epoch": 0.1357413919850589,
      "grad_norm": 0.6657041311264038,
      "learning_rate": 9.709803491291615e-06,
      "loss": 0.2842,
      "step": 854
    },
    {
      "epoch": 0.13590033975084936,
      "grad_norm": 0.49868783354759216,
      "learning_rate": 9.708938637833065e-06,
      "loss": 0.1697,
      "step": 855
    },
    {
      "epoch": 0.13605928751663984,
      "grad_norm": 0.49384069442749023,
      "learning_rate": 9.708072536191237e-06,
      "loss": 0.1785,
      "step": 856
    },
    {
      "epoch": 0.13621823528243032,
      "grad_norm": 0.7524503469467163,
      "learning_rate": 9.707205186595706e-06,
      "loss": 0.3584,
      "step": 857
    },
    {
      "epoch": 0.13637718304822077,
      "grad_norm": 0.6802863478660583,
      "learning_rate": 9.706336589276375e-06,
      "loss": 0.2735,
      "step": 858
    },
    {
      "epoch": 0.13653613081401125,
      "grad_norm": 0.7145323157310486,
      "learning_rate": 9.705466744463484e-06,
      "loss": 0.3962,
      "step": 859
    },
    {
      "epoch": 0.1366950785798017,
      "grad_norm": 0.48361262679100037,
      "learning_rate": 9.704595652387595e-06,
      "loss": 0.1157,
      "step": 860
    },
    {
      "epoch": 0.13685402634559218,
      "grad_norm": 0.624702513217926,
      "learning_rate": 9.703723313279607e-06,
      "loss": 0.2463,
      "step": 861
    },
    {
      "epoch": 0.13701297411138263,
      "grad_norm": 0.6292932629585266,
      "learning_rate": 9.702849727370752e-06,
      "loss": 0.2889,
      "step": 862
    },
    {
      "epoch": 0.13717192187717311,
      "grad_norm": 0.5495856404304504,
      "learning_rate": 9.701974894892586e-06,
      "loss": 0.2091,
      "step": 863
    },
    {
      "epoch": 0.1373308696429636,
      "grad_norm": 0.5880763530731201,
      "learning_rate": 9.701098816076995e-06,
      "loss": 0.242,
      "step": 864
    },
    {
      "epoch": 0.13748981740875404,
      "grad_norm": 0.6294143199920654,
      "learning_rate": 9.700221491156205e-06,
      "loss": 0.2451,
      "step": 865
    },
    {
      "epoch": 0.13764876517454452,
      "grad_norm": 0.5283061861991882,
      "learning_rate": 9.69934292036276e-06,
      "loss": 0.2137,
      "step": 866
    },
    {
      "epoch": 0.13780771294033498,
      "grad_norm": 0.85317063331604,
      "learning_rate": 9.698463103929542e-06,
      "loss": 0.3507,
      "step": 867
    },
    {
      "epoch": 0.13796666070612545,
      "grad_norm": 0.5601024031639099,
      "learning_rate": 9.697582042089763e-06,
      "loss": 0.2609,
      "step": 868
    },
    {
      "epoch": 0.1381256084719159,
      "grad_norm": 0.6264028549194336,
      "learning_rate": 9.696699735076959e-06,
      "loss": 0.2301,
      "step": 869
    },
    {
      "epoch": 0.13828455623770639,
      "grad_norm": 0.6051129102706909,
      "learning_rate": 9.695816183125005e-06,
      "loss": 0.3178,
      "step": 870
    },
    {
      "epoch": 0.13844350400349686,
      "grad_norm": 0.6650993227958679,
      "learning_rate": 9.694931386468099e-06,
      "loss": 0.2381,
      "step": 871
    },
    {
      "epoch": 0.13860245176928732,
      "grad_norm": 2.3573720455169678,
      "learning_rate": 9.694045345340768e-06,
      "loss": 0.3202,
      "step": 872
    },
    {
      "epoch": 0.1387613995350778,
      "grad_norm": 0.5651445388793945,
      "learning_rate": 9.693158059977879e-06,
      "loss": 0.2235,
      "step": 873
    },
    {
      "epoch": 0.13892034730086825,
      "grad_norm": 0.6320403218269348,
      "learning_rate": 9.692269530614615e-06,
      "loss": 0.2911,
      "step": 874
    },
    {
      "epoch": 0.13907929506665873,
      "grad_norm": 0.5806150436401367,
      "learning_rate": 9.6913797574865e-06,
      "loss": 0.2257,
      "step": 875
    },
    {
      "epoch": 0.13923824283244918,
      "grad_norm": 0.5430469512939453,
      "learning_rate": 9.690488740829383e-06,
      "loss": 0.2332,
      "step": 876
    },
    {
      "epoch": 0.13939719059823966,
      "grad_norm": 0.6135278344154358,
      "learning_rate": 9.689596480879442e-06,
      "loss": 0.2684,
      "step": 877
    },
    {
      "epoch": 0.1395561383640301,
      "grad_norm": 0.5827518105506897,
      "learning_rate": 9.688702977873186e-06,
      "loss": 0.2231,
      "step": 878
    },
    {
      "epoch": 0.1397150861298206,
      "grad_norm": 0.6494693756103516,
      "learning_rate": 9.687808232047452e-06,
      "loss": 0.3126,
      "step": 879
    },
    {
      "epoch": 0.13987403389561107,
      "grad_norm": 0.6765371561050415,
      "learning_rate": 9.686912243639407e-06,
      "loss": 0.3138,
      "step": 880
    },
    {
      "epoch": 0.14003298166140152,
      "grad_norm": 0.7109108567237854,
      "learning_rate": 9.686015012886549e-06,
      "loss": 0.4395,
      "step": 881
    },
    {
      "epoch": 0.140191929427192,
      "grad_norm": 0.687110185623169,
      "learning_rate": 9.685116540026703e-06,
      "loss": 0.2309,
      "step": 882
    },
    {
      "epoch": 0.14035087719298245,
      "grad_norm": 0.5443525910377502,
      "learning_rate": 9.684216825298028e-06,
      "loss": 0.1867,
      "step": 883
    },
    {
      "epoch": 0.14050982495877293,
      "grad_norm": 0.6062039732933044,
      "learning_rate": 9.683315868939003e-06,
      "loss": 0.2782,
      "step": 884
    },
    {
      "epoch": 0.14066877272456338,
      "grad_norm": 0.7720573544502258,
      "learning_rate": 9.682413671188444e-06,
      "loss": 0.3032,
      "step": 885
    },
    {
      "epoch": 0.14082772049035386,
      "grad_norm": 0.5982033610343933,
      "learning_rate": 9.681510232285495e-06,
      "loss": 0.2546,
      "step": 886
    },
    {
      "epoch": 0.14098666825614434,
      "grad_norm": 0.5534794330596924,
      "learning_rate": 9.680605552469625e-06,
      "loss": 0.2584,
      "step": 887
    },
    {
      "epoch": 0.1411456160219348,
      "grad_norm": 0.5795634984970093,
      "learning_rate": 9.679699631980639e-06,
      "loss": 0.2577,
      "step": 888
    },
    {
      "epoch": 0.14130456378772527,
      "grad_norm": 0.6227530837059021,
      "learning_rate": 9.678792471058662e-06,
      "loss": 0.3163,
      "step": 889
    },
    {
      "epoch": 0.14146351155351572,
      "grad_norm": 0.5651524662971497,
      "learning_rate": 9.677884069944154e-06,
      "loss": 0.2348,
      "step": 890
    },
    {
      "epoch": 0.1416224593193062,
      "grad_norm": 0.6998920440673828,
      "learning_rate": 9.6769744288779e-06,
      "loss": 0.2332,
      "step": 891
    },
    {
      "epoch": 0.14178140708509665,
      "grad_norm": 0.7745844125747681,
      "learning_rate": 9.67606354810102e-06,
      "loss": 0.3641,
      "step": 892
    },
    {
      "epoch": 0.14194035485088713,
      "grad_norm": 0.5531427264213562,
      "learning_rate": 9.675151427854955e-06,
      "loss": 0.2078,
      "step": 893
    },
    {
      "epoch": 0.14209930261667758,
      "grad_norm": 0.6313076019287109,
      "learning_rate": 9.674238068381478e-06,
      "loss": 0.3489,
      "step": 894
    },
    {
      "epoch": 0.14225825038246806,
      "grad_norm": 0.6229528784751892,
      "learning_rate": 9.673323469922692e-06,
      "loss": 0.3058,
      "step": 895
    },
    {
      "epoch": 0.14241719814825854,
      "grad_norm": 0.6102258563041687,
      "learning_rate": 9.672407632721023e-06,
      "loss": 0.3047,
      "step": 896
    },
    {
      "epoch": 0.142576145914049,
      "grad_norm": 0.4732629954814911,
      "learning_rate": 9.671490557019234e-06,
      "loss": 0.147,
      "step": 897
    },
    {
      "epoch": 0.14273509367983947,
      "grad_norm": 0.5067133903503418,
      "learning_rate": 9.670572243060407e-06,
      "loss": 0.2209,
      "step": 898
    },
    {
      "epoch": 0.14289404144562992,
      "grad_norm": 0.4962787628173828,
      "learning_rate": 9.66965269108796e-06,
      "loss": 0.1915,
      "step": 899
    },
    {
      "epoch": 0.1430529892114204,
      "grad_norm": 0.5701944828033447,
      "learning_rate": 9.668731901345632e-06,
      "loss": 0.213,
      "step": 900
    },
    {
      "epoch": 0.14321193697721085,
      "grad_norm": 0.6328195929527283,
      "learning_rate": 9.667809874077497e-06,
      "loss": 0.3139,
      "step": 901
    },
    {
      "epoch": 0.14337088474300133,
      "grad_norm": 0.513780951499939,
      "learning_rate": 9.666886609527952e-06,
      "loss": 0.1994,
      "step": 902
    },
    {
      "epoch": 0.1435298325087918,
      "grad_norm": 0.638847291469574,
      "learning_rate": 9.665962107941725e-06,
      "loss": 0.3345,
      "step": 903
    },
    {
      "epoch": 0.14368878027458226,
      "grad_norm": 0.6304276585578918,
      "learning_rate": 9.66503636956387e-06,
      "loss": 0.3064,
      "step": 904
    },
    {
      "epoch": 0.14384772804037274,
      "grad_norm": 0.7373536229133606,
      "learning_rate": 9.66410939463977e-06,
      "loss": 0.2354,
      "step": 905
    },
    {
      "epoch": 0.1440066758061632,
      "grad_norm": 0.9273519515991211,
      "learning_rate": 9.663181183415133e-06,
      "loss": 0.3361,
      "step": 906
    },
    {
      "epoch": 0.14416562357195367,
      "grad_norm": 0.6060356497764587,
      "learning_rate": 9.662251736136e-06,
      "loss": 0.244,
      "step": 907
    },
    {
      "epoch": 0.14432457133774412,
      "grad_norm": 0.6166573166847229,
      "learning_rate": 9.661321053048736e-06,
      "loss": 0.3264,
      "step": 908
    },
    {
      "epoch": 0.1444835191035346,
      "grad_norm": 0.8390973210334778,
      "learning_rate": 9.660389134400034e-06,
      "loss": 0.3164,
      "step": 909
    },
    {
      "epoch": 0.14464246686932508,
      "grad_norm": 0.6807826161384583,
      "learning_rate": 9.659455980436913e-06,
      "loss": 0.347,
      "step": 910
    },
    {
      "epoch": 0.14480141463511553,
      "grad_norm": 0.5796770453453064,
      "learning_rate": 9.658521591406722e-06,
      "loss": 0.2554,
      "step": 911
    },
    {
      "epoch": 0.144960362400906,
      "grad_norm": 0.6145482659339905,
      "learning_rate": 9.657585967557138e-06,
      "loss": 0.2041,
      "step": 912
    },
    {
      "epoch": 0.14511931016669646,
      "grad_norm": 0.5440738797187805,
      "learning_rate": 9.656649109136162e-06,
      "loss": 0.2232,
      "step": 913
    },
    {
      "epoch": 0.14527825793248694,
      "grad_norm": 0.6517451405525208,
      "learning_rate": 9.655711016392127e-06,
      "loss": 0.3268,
      "step": 914
    },
    {
      "epoch": 0.1454372056982774,
      "grad_norm": 0.6560478806495667,
      "learning_rate": 9.654771689573685e-06,
      "loss": 0.3385,
      "step": 915
    },
    {
      "epoch": 0.14559615346406787,
      "grad_norm": 0.6144936680793762,
      "learning_rate": 9.653831128929825e-06,
      "loss": 0.2756,
      "step": 916
    },
    {
      "epoch": 0.14575510122985832,
      "grad_norm": 0.6978621482849121,
      "learning_rate": 9.652889334709857e-06,
      "loss": 0.3599,
      "step": 917
    },
    {
      "epoch": 0.1459140489956488,
      "grad_norm": 0.6155895590782166,
      "learning_rate": 9.651946307163417e-06,
      "loss": 0.2964,
      "step": 918
    },
    {
      "epoch": 0.14607299676143928,
      "grad_norm": 0.5097109079360962,
      "learning_rate": 9.651002046540476e-06,
      "loss": 0.2392,
      "step": 919
    },
    {
      "epoch": 0.14623194452722973,
      "grad_norm": 0.599890410900116,
      "learning_rate": 9.65005655309132e-06,
      "loss": 0.1935,
      "step": 920
    },
    {
      "epoch": 0.14639089229302021,
      "grad_norm": 0.5768917798995972,
      "learning_rate": 9.649109827066572e-06,
      "loss": 0.2189,
      "step": 921
    },
    {
      "epoch": 0.14654984005881067,
      "grad_norm": 0.6550362706184387,
      "learning_rate": 9.648161868717176e-06,
      "loss": 0.3709,
      "step": 922
    },
    {
      "epoch": 0.14670878782460114,
      "grad_norm": 0.6057537198066711,
      "learning_rate": 9.647212678294403e-06,
      "loss": 0.2868,
      "step": 923
    },
    {
      "epoch": 0.1468677355903916,
      "grad_norm": 0.6297710537910461,
      "learning_rate": 9.646262256049854e-06,
      "loss": 0.2981,
      "step": 924
    },
    {
      "epoch": 0.14702668335618208,
      "grad_norm": 0.5891332030296326,
      "learning_rate": 9.645310602235453e-06,
      "loss": 0.2342,
      "step": 925
    },
    {
      "epoch": 0.14718563112197255,
      "grad_norm": 0.6039777994155884,
      "learning_rate": 9.644357717103454e-06,
      "loss": 0.2662,
      "step": 926
    },
    {
      "epoch": 0.147344578887763,
      "grad_norm": 0.6769871115684509,
      "learning_rate": 9.643403600906433e-06,
      "loss": 0.3127,
      "step": 927
    },
    {
      "epoch": 0.14750352665355349,
      "grad_norm": 0.7596186995506287,
      "learning_rate": 9.642448253897297e-06,
      "loss": 0.3904,
      "step": 928
    },
    {
      "epoch": 0.14766247441934394,
      "grad_norm": 0.65718013048172,
      "learning_rate": 9.641491676329274e-06,
      "loss": 0.3399,
      "step": 929
    },
    {
      "epoch": 0.14782142218513442,
      "grad_norm": 0.6650791168212891,
      "learning_rate": 9.64053386845592e-06,
      "loss": 0.2604,
      "step": 930
    },
    {
      "epoch": 0.14798036995092487,
      "grad_norm": 0.6922844052314758,
      "learning_rate": 9.639574830531121e-06,
      "loss": 0.3076,
      "step": 931
    },
    {
      "epoch": 0.14813931771671535,
      "grad_norm": 0.603316068649292,
      "learning_rate": 9.638614562809086e-06,
      "loss": 0.2444,
      "step": 932
    },
    {
      "epoch": 0.1482982654825058,
      "grad_norm": 0.6996915340423584,
      "learning_rate": 9.637653065544349e-06,
      "loss": 0.3883,
      "step": 933
    },
    {
      "epoch": 0.14845721324829628,
      "grad_norm": 0.5585647225379944,
      "learning_rate": 9.63669033899177e-06,
      "loss": 0.2236,
      "step": 934
    },
    {
      "epoch": 0.14861616101408676,
      "grad_norm": 0.6731256246566772,
      "learning_rate": 9.635726383406539e-06,
      "loss": 0.2881,
      "step": 935
    },
    {
      "epoch": 0.1487751087798772,
      "grad_norm": 0.5799337029457092,
      "learning_rate": 9.634761199044165e-06,
      "loss": 0.2324,
      "step": 936
    },
    {
      "epoch": 0.1489340565456677,
      "grad_norm": 0.7169976830482483,
      "learning_rate": 9.63379478616049e-06,
      "loss": 0.3419,
      "step": 937
    },
    {
      "epoch": 0.14909300431145814,
      "grad_norm": 0.5599067211151123,
      "learning_rate": 9.632827145011674e-06,
      "loss": 0.1457,
      "step": 938
    },
    {
      "epoch": 0.14925195207724862,
      "grad_norm": 0.6284099817276001,
      "learning_rate": 9.63185827585421e-06,
      "loss": 0.3035,
      "step": 939
    },
    {
      "epoch": 0.14941089984303907,
      "grad_norm": 0.7572813034057617,
      "learning_rate": 9.63088817894491e-06,
      "loss": 0.2233,
      "step": 940
    },
    {
      "epoch": 0.14956984760882955,
      "grad_norm": 0.5198282599449158,
      "learning_rate": 9.629916854540916e-06,
      "loss": 0.1225,
      "step": 941
    },
    {
      "epoch": 0.14972879537462003,
      "grad_norm": 0.5713048577308655,
      "learning_rate": 9.628944302899696e-06,
      "loss": 0.2539,
      "step": 942
    },
    {
      "epoch": 0.14988774314041048,
      "grad_norm": 0.5780136585235596,
      "learning_rate": 9.627970524279038e-06,
      "loss": 0.2107,
      "step": 943
    },
    {
      "epoch": 0.15004669090620096,
      "grad_norm": 0.6624169945716858,
      "learning_rate": 9.62699551893706e-06,
      "loss": 0.1938,
      "step": 944
    },
    {
      "epoch": 0.1502056386719914,
      "grad_norm": 0.6147835850715637,
      "learning_rate": 9.626019287132202e-06,
      "loss": 0.2659,
      "step": 945
    },
    {
      "epoch": 0.1503645864377819,
      "grad_norm": 0.4798586368560791,
      "learning_rate": 9.625041829123232e-06,
      "loss": 0.1758,
      "step": 946
    },
    {
      "epoch": 0.15052353420357234,
      "grad_norm": 0.5892589092254639,
      "learning_rate": 9.624063145169242e-06,
      "loss": 0.257,
      "step": 947
    },
    {
      "epoch": 0.15068248196936282,
      "grad_norm": 0.584098219871521,
      "learning_rate": 9.623083235529647e-06,
      "loss": 0.2777,
      "step": 948
    },
    {
      "epoch": 0.1508414297351533,
      "grad_norm": 0.7043084502220154,
      "learning_rate": 9.622102100464189e-06,
      "loss": 0.3731,
      "step": 949
    },
    {
      "epoch": 0.15100037750094375,
      "grad_norm": 0.4773777425289154,
      "learning_rate": 9.621119740232937e-06,
      "loss": 0.1607,
      "step": 950
    },
    {
      "epoch": 0.15115932526673423,
      "grad_norm": 0.5701091289520264,
      "learning_rate": 9.620136155096276e-06,
      "loss": 0.1711,
      "step": 951
    },
    {
      "epoch": 0.15131827303252468,
      "grad_norm": 0.4331433176994324,
      "learning_rate": 9.619151345314928e-06,
      "loss": 0.1203,
      "step": 952
    },
    {
      "epoch": 0.15147722079831516,
      "grad_norm": 0.523872435092926,
      "learning_rate": 9.618165311149931e-06,
      "loss": 0.2228,
      "step": 953
    },
    {
      "epoch": 0.1516361685641056,
      "grad_norm": 0.6303418278694153,
      "learning_rate": 9.617178052862648e-06,
      "loss": 0.3265,
      "step": 954
    },
    {
      "epoch": 0.1517951163298961,
      "grad_norm": 0.6140421628952026,
      "learning_rate": 9.616189570714772e-06,
      "loss": 0.3273,
      "step": 955
    },
    {
      "epoch": 0.15195406409568654,
      "grad_norm": 0.6215227246284485,
      "learning_rate": 9.615199864968316e-06,
      "loss": 0.2991,
      "step": 956
    },
    {
      "epoch": 0.15211301186147702,
      "grad_norm": 0.5947223901748657,
      "learning_rate": 9.614208935885615e-06,
      "loss": 0.3538,
      "step": 957
    },
    {
      "epoch": 0.1522719596272675,
      "grad_norm": 0.5255367755889893,
      "learning_rate": 9.613216783729334e-06,
      "loss": 0.2314,
      "step": 958
    },
    {
      "epoch": 0.15243090739305795,
      "grad_norm": 0.5898014307022095,
      "learning_rate": 9.61222340876246e-06,
      "loss": 0.254,
      "step": 959
    },
    {
      "epoch": 0.15258985515884843,
      "grad_norm": 0.5984818935394287,
      "learning_rate": 9.611228811248303e-06,
      "loss": 0.2401,
      "step": 960
    },
    {
      "epoch": 0.15274880292463888,
      "grad_norm": 0.6288771629333496,
      "learning_rate": 9.610232991450497e-06,
      "loss": 0.2688,
      "step": 961
    },
    {
      "epoch": 0.15290775069042936,
      "grad_norm": 0.8188885450363159,
      "learning_rate": 9.609235949633003e-06,
      "loss": 0.2316,
      "step": 962
    },
    {
      "epoch": 0.1530666984562198,
      "grad_norm": 0.6198049187660217,
      "learning_rate": 9.608237686060099e-06,
      "loss": 0.2441,
      "step": 963
    },
    {
      "epoch": 0.1532256462220103,
      "grad_norm": 0.7664963006973267,
      "learning_rate": 9.607238200996396e-06,
      "loss": 0.4435,
      "step": 964
    },
    {
      "epoch": 0.15338459398780077,
      "grad_norm": 0.5875465273857117,
      "learning_rate": 9.606237494706826e-06,
      "loss": 0.3241,
      "step": 965
    },
    {
      "epoch": 0.15354354175359122,
      "grad_norm": 0.6113054156303406,
      "learning_rate": 9.605235567456636e-06,
      "loss": 0.2258,
      "step": 966
    },
    {
      "epoch": 0.1537024895193817,
      "grad_norm": 0.5887241959571838,
      "learning_rate": 9.604232419511408e-06,
      "loss": 0.2091,
      "step": 967
    },
    {
      "epoch": 0.15386143728517215,
      "grad_norm": 0.7204530239105225,
      "learning_rate": 9.603228051137044e-06,
      "loss": 0.3941,
      "step": 968
    },
    {
      "epoch": 0.15402038505096263,
      "grad_norm": 0.6796135902404785,
      "learning_rate": 9.602222462599768e-06,
      "loss": 0.3713,
      "step": 969
    },
    {
      "epoch": 0.15417933281675308,
      "grad_norm": 0.6421734094619751,
      "learning_rate": 9.601215654166127e-06,
      "loss": 0.3547,
      "step": 970
    },
    {
      "epoch": 0.15433828058254356,
      "grad_norm": 0.5559566617012024,
      "learning_rate": 9.600207626102993e-06,
      "loss": 0.2113,
      "step": 971
    },
    {
      "epoch": 0.15449722834833404,
      "grad_norm": 0.6490916013717651,
      "learning_rate": 9.599198378677559e-06,
      "loss": 0.3527,
      "step": 972
    },
    {
      "epoch": 0.1546561761141245,
      "grad_norm": 0.5922896265983582,
      "learning_rate": 9.598187912157347e-06,
      "loss": 0.2622,
      "step": 973
    },
    {
      "epoch": 0.15481512387991497,
      "grad_norm": 0.6859853863716125,
      "learning_rate": 9.597176226810196e-06,
      "loss": 0.3949,
      "step": 974
    },
    {
      "epoch": 0.15497407164570542,
      "grad_norm": 0.49920713901519775,
      "learning_rate": 9.59616332290427e-06,
      "loss": 0.1601,
      "step": 975
    },
    {
      "epoch": 0.1551330194114959,
      "grad_norm": 0.39167317748069763,
      "learning_rate": 9.595149200708056e-06,
      "loss": 0.1218,
      "step": 976
    },
    {
      "epoch": 0.15529196717728636,
      "grad_norm": 0.6411412358283997,
      "learning_rate": 9.594133860490365e-06,
      "loss": 0.349,
      "step": 977
    },
    {
      "epoch": 0.15545091494307683,
      "grad_norm": 0.5583620667457581,
      "learning_rate": 9.593117302520329e-06,
      "loss": 0.1975,
      "step": 978
    },
    {
      "epoch": 0.15560986270886729,
      "grad_norm": 0.7905454635620117,
      "learning_rate": 9.592099527067405e-06,
      "loss": 0.2319,
      "step": 979
    },
    {
      "epoch": 0.15576881047465777,
      "grad_norm": 0.5371581315994263,
      "learning_rate": 9.591080534401371e-06,
      "loss": 0.2447,
      "step": 980
    },
    {
      "epoch": 0.15592775824044824,
      "grad_norm": 0.6092560887336731,
      "learning_rate": 9.590060324792328e-06,
      "loss": 0.248,
      "step": 981
    },
    {
      "epoch": 0.1560867060062387,
      "grad_norm": 0.588283360004425,
      "learning_rate": 9.589038898510698e-06,
      "loss": 0.2203,
      "step": 982
    },
    {
      "epoch": 0.15624565377202917,
      "grad_norm": 0.5768011808395386,
      "learning_rate": 9.588016255827229e-06,
      "loss": 0.2025,
      "step": 983
    },
    {
      "epoch": 0.15640460153781963,
      "grad_norm": 0.660297155380249,
      "learning_rate": 9.58699239701299e-06,
      "loss": 0.2436,
      "step": 984
    },
    {
      "epoch": 0.1565635493036101,
      "grad_norm": 0.5787302851676941,
      "learning_rate": 9.585967322339371e-06,
      "loss": 0.1865,
      "step": 985
    },
    {
      "epoch": 0.15672249706940056,
      "grad_norm": 0.44794031977653503,
      "learning_rate": 9.584941032078087e-06,
      "loss": 0.153,
      "step": 986
    },
    {
      "epoch": 0.15688144483519104,
      "grad_norm": 0.5109971165657043,
      "learning_rate": 9.58391352650117e-06,
      "loss": 0.2373,
      "step": 987
    },
    {
      "epoch": 0.15704039260098152,
      "grad_norm": 0.527249813079834,
      "learning_rate": 9.58288480588098e-06,
      "loss": 0.1226,
      "step": 988
    },
    {
      "epoch": 0.15719934036677197,
      "grad_norm": 0.6119333505630493,
      "learning_rate": 9.581854870490198e-06,
      "loss": 0.2599,
      "step": 989
    },
    {
      "epoch": 0.15735828813256245,
      "grad_norm": 0.6545140147209167,
      "learning_rate": 9.580823720601824e-06,
      "loss": 0.3809,
      "step": 990
    },
    {
      "epoch": 0.1575172358983529,
      "grad_norm": 0.5471827387809753,
      "learning_rate": 9.579791356489179e-06,
      "loss": 0.2319,
      "step": 991
    },
    {
      "epoch": 0.15767618366414338,
      "grad_norm": 0.6697707772254944,
      "learning_rate": 9.578757778425914e-06,
      "loss": 0.3593,
      "step": 992
    },
    {
      "epoch": 0.15783513142993383,
      "grad_norm": 0.5959227681159973,
      "learning_rate": 9.577722986685992e-06,
      "loss": 0.2951,
      "step": 993
    },
    {
      "epoch": 0.1579940791957243,
      "grad_norm": 0.5690892338752747,
      "learning_rate": 9.576686981543703e-06,
      "loss": 0.2502,
      "step": 994
    },
    {
      "epoch": 0.15815302696151476,
      "grad_norm": 1.2778104543685913,
      "learning_rate": 9.575649763273658e-06,
      "loss": 0.4967,
      "step": 995
    },
    {
      "epoch": 0.15831197472730524,
      "grad_norm": 0.599777102470398,
      "learning_rate": 9.574611332150789e-06,
      "loss": 0.2967,
      "step": 996
    },
    {
      "epoch": 0.15847092249309572,
      "grad_norm": 0.5689222812652588,
      "learning_rate": 9.57357168845035e-06,
      "loss": 0.2179,
      "step": 997
    },
    {
      "epoch": 0.15862987025888617,
      "grad_norm": 0.5391448140144348,
      "learning_rate": 9.572530832447915e-06,
      "loss": 0.1569,
      "step": 998
    },
    {
      "epoch": 0.15878881802467665,
      "grad_norm": 0.959257960319519,
      "learning_rate": 9.571488764419381e-06,
      "loss": 0.3118,
      "step": 999
    },
    {
      "epoch": 0.1589477657904671,
      "grad_norm": 0.6233915686607361,
      "learning_rate": 9.570445484640967e-06,
      "loss": 0.3456,
      "step": 1000
    },
    {
      "epoch": 0.15910671355625758,
      "grad_norm": 0.8051057457923889,
      "learning_rate": 9.569400993389209e-06,
      "loss": 0.2697,
      "step": 1001
    },
    {
      "epoch": 0.15926566132204803,
      "grad_norm": 0.642424464225769,
      "learning_rate": 9.568355290940967e-06,
      "loss": 0.287,
      "step": 1002
    },
    {
      "epoch": 0.1594246090878385,
      "grad_norm": 0.5840645432472229,
      "learning_rate": 9.567308377573426e-06,
      "loss": 0.2127,
      "step": 1003
    },
    {
      "epoch": 0.159583556853629,
      "grad_norm": 0.5086025595664978,
      "learning_rate": 9.566260253564084e-06,
      "loss": 0.1844,
      "step": 1004
    },
    {
      "epoch": 0.15974250461941944,
      "grad_norm": 0.6493726968765259,
      "learning_rate": 9.565210919190764e-06,
      "loss": 0.3835,
      "step": 1005
    },
    {
      "epoch": 0.15990145238520992,
      "grad_norm": 0.5931459665298462,
      "learning_rate": 9.564160374731612e-06,
      "loss": 0.2662,
      "step": 1006
    },
    {
      "epoch": 0.16006040015100037,
      "grad_norm": 0.5253170728683472,
      "learning_rate": 9.563108620465092e-06,
      "loss": 0.2245,
      "step": 1007
    },
    {
      "epoch": 0.16021934791679085,
      "grad_norm": 0.6099633574485779,
      "learning_rate": 9.562055656669988e-06,
      "loss": 0.2001,
      "step": 1008
    },
    {
      "epoch": 0.1603782956825813,
      "grad_norm": 0.5570539832115173,
      "learning_rate": 9.561001483625406e-06,
      "loss": 0.3077,
      "step": 1009
    },
    {
      "epoch": 0.16053724344837178,
      "grad_norm": 0.6171038150787354,
      "learning_rate": 9.559946101610773e-06,
      "loss": 0.3602,
      "step": 1010
    },
    {
      "epoch": 0.16069619121416226,
      "grad_norm": 0.5868517160415649,
      "learning_rate": 9.558889510905836e-06,
      "loss": 0.2927,
      "step": 1011
    },
    {
      "epoch": 0.1608551389799527,
      "grad_norm": 0.656652569770813,
      "learning_rate": 9.55783171179066e-06,
      "loss": 0.3838,
      "step": 1012
    },
    {
      "epoch": 0.1610140867457432,
      "grad_norm": 0.6141334772109985,
      "learning_rate": 9.556772704545634e-06,
      "loss": 0.2991,
      "step": 1013
    },
    {
      "epoch": 0.16117303451153364,
      "grad_norm": 0.5459528565406799,
      "learning_rate": 9.555712489451465e-06,
      "loss": 0.2766,
      "step": 1014
    },
    {
      "epoch": 0.16133198227732412,
      "grad_norm": 0.5051867961883545,
      "learning_rate": 9.554651066789181e-06,
      "loss": 0.1885,
      "step": 1015
    },
    {
      "epoch": 0.16149093004311457,
      "grad_norm": 0.4998140037059784,
      "learning_rate": 9.55358843684013e-06,
      "loss": 0.1756,
      "step": 1016
    },
    {
      "epoch": 0.16164987780890505,
      "grad_norm": 0.5254557132720947,
      "learning_rate": 9.552524599885982e-06,
      "loss": 0.2084,
      "step": 1017
    },
    {
      "epoch": 0.1618088255746955,
      "grad_norm": 0.5191154479980469,
      "learning_rate": 9.551459556208723e-06,
      "loss": 0.2455,
      "step": 1018
    },
    {
      "epoch": 0.16196777334048598,
      "grad_norm": 0.5573101043701172,
      "learning_rate": 9.550393306090658e-06,
      "loss": 0.2336,
      "step": 1019
    },
    {
      "epoch": 0.16212672110627646,
      "grad_norm": 0.5098205208778381,
      "learning_rate": 9.549325849814419e-06,
      "loss": 0.1145,
      "step": 1020
    },
    {
      "epoch": 0.1622856688720669,
      "grad_norm": 0.5895224213600159,
      "learning_rate": 9.54825718766295e-06,
      "loss": 0.2341,
      "step": 1021
    },
    {
      "epoch": 0.1624446166378574,
      "grad_norm": 0.4636912941932678,
      "learning_rate": 9.54718731991952e-06,
      "loss": 0.1603,
      "step": 1022
    },
    {
      "epoch": 0.16260356440364784,
      "grad_norm": 0.590128481388092,
      "learning_rate": 9.546116246867716e-06,
      "loss": 0.1836,
      "step": 1023
    },
    {
      "epoch": 0.16276251216943832,
      "grad_norm": 0.6070719957351685,
      "learning_rate": 9.54504396879144e-06,
      "loss": 0.1911,
      "step": 1024
    },
    {
      "epoch": 0.16292145993522877,
      "grad_norm": 0.6829928755760193,
      "learning_rate": 9.54397048597492e-06,
      "loss": 0.2651,
      "step": 1025
    },
    {
      "epoch": 0.16308040770101925,
      "grad_norm": 0.7690804600715637,
      "learning_rate": 9.542895798702702e-06,
      "loss": 0.4907,
      "step": 1026
    },
    {
      "epoch": 0.16323935546680973,
      "grad_norm": 0.508248507976532,
      "learning_rate": 9.541819907259649e-06,
      "loss": 0.2266,
      "step": 1027
    },
    {
      "epoch": 0.16339830323260018,
      "grad_norm": 0.4515659511089325,
      "learning_rate": 9.540742811930941e-06,
      "loss": 0.1474,
      "step": 1028
    },
    {
      "epoch": 0.16355725099839066,
      "grad_norm": 0.5515416264533997,
      "learning_rate": 9.539664513002085e-06,
      "loss": 0.2249,
      "step": 1029
    },
    {
      "epoch": 0.16371619876418111,
      "grad_norm": 0.5847939848899841,
      "learning_rate": 9.538585010758898e-06,
      "loss": 0.1872,
      "step": 1030
    },
    {
      "epoch": 0.1638751465299716,
      "grad_norm": 0.7081881165504456,
      "learning_rate": 9.537504305487524e-06,
      "loss": 0.2521,
      "step": 1031
    },
    {
      "epoch": 0.16403409429576205,
      "grad_norm": 0.5121135711669922,
      "learning_rate": 9.536422397474418e-06,
      "loss": 0.1344,
      "step": 1032
    },
    {
      "epoch": 0.16419304206155252,
      "grad_norm": 0.5316445827484131,
      "learning_rate": 9.535339287006362e-06,
      "loss": 0.1698,
      "step": 1033
    },
    {
      "epoch": 0.16435198982734298,
      "grad_norm": 0.8488301634788513,
      "learning_rate": 9.53425497437045e-06,
      "loss": 0.3374,
      "step": 1034
    },
    {
      "epoch": 0.16451093759313345,
      "grad_norm": 0.6295388340950012,
      "learning_rate": 9.5331694598541e-06,
      "loss": 0.2186,
      "step": 1035
    },
    {
      "epoch": 0.16466988535892393,
      "grad_norm": 0.6125937104225159,
      "learning_rate": 9.53208274374504e-06,
      "loss": 0.2248,
      "step": 1036
    },
    {
      "epoch": 0.16482883312471439,
      "grad_norm": 0.797369122505188,
      "learning_rate": 9.53099482633133e-06,
      "loss": 0.2897,
      "step": 1037
    },
    {
      "epoch": 0.16498778089050486,
      "grad_norm": 0.606654942035675,
      "learning_rate": 9.529905707901335e-06,
      "loss": 0.2622,
      "step": 1038
    },
    {
      "epoch": 0.16514672865629532,
      "grad_norm": 0.9633757472038269,
      "learning_rate": 9.528815388743745e-06,
      "loss": 0.1789,
      "step": 1039
    },
    {
      "epoch": 0.1653056764220858,
      "grad_norm": 0.6311959624290466,
      "learning_rate": 9.52772386914757e-06,
      "loss": 0.3168,
      "step": 1040
    },
    {
      "epoch": 0.16546462418787625,
      "grad_norm": 0.6214268803596497,
      "learning_rate": 9.526631149402135e-06,
      "loss": 0.2702,
      "step": 1041
    },
    {
      "epoch": 0.16562357195366673,
      "grad_norm": 0.5088934302330017,
      "learning_rate": 9.52553722979708e-06,
      "loss": 0.2207,
      "step": 1042
    },
    {
      "epoch": 0.1657825197194572,
      "grad_norm": 0.5431897640228271,
      "learning_rate": 9.524442110622374e-06,
      "loss": 0.1679,
      "step": 1043
    },
    {
      "epoch": 0.16594146748524766,
      "grad_norm": 0.6188631057739258,
      "learning_rate": 9.52334579216829e-06,
      "loss": 0.212,
      "step": 1044
    },
    {
      "epoch": 0.16610041525103814,
      "grad_norm": 0.6408163905143738,
      "learning_rate": 9.522248274725427e-06,
      "loss": 0.2718,
      "step": 1045
    },
    {
      "epoch": 0.1662593630168286,
      "grad_norm": 0.6250103116035461,
      "learning_rate": 9.521149558584703e-06,
      "loss": 0.3102,
      "step": 1046
    },
    {
      "epoch": 0.16641831078261907,
      "grad_norm": 0.6092674136161804,
      "learning_rate": 9.520049644037349e-06,
      "loss": 0.2261,
      "step": 1047
    },
    {
      "epoch": 0.16657725854840952,
      "grad_norm": 0.5352316498756409,
      "learning_rate": 9.518948531374916e-06,
      "loss": 0.154,
      "step": 1048
    },
    {
      "epoch": 0.1667362063142,
      "grad_norm": 0.7515552043914795,
      "learning_rate": 9.517846220889274e-06,
      "loss": 0.3421,
      "step": 1049
    },
    {
      "epoch": 0.16689515407999048,
      "grad_norm": 0.7627915740013123,
      "learning_rate": 9.516742712872606e-06,
      "loss": 0.2597,
      "step": 1050
    },
    {
      "epoch": 0.16705410184578093,
      "grad_norm": 0.6391174793243408,
      "learning_rate": 9.515638007617418e-06,
      "loss": 0.3386,
      "step": 1051
    },
    {
      "epoch": 0.1672130496115714,
      "grad_norm": 0.681148886680603,
      "learning_rate": 9.51453210541653e-06,
      "loss": 0.2513,
      "step": 1052
    },
    {
      "epoch": 0.16737199737736186,
      "grad_norm": 0.5502294301986694,
      "learning_rate": 9.51342500656308e-06,
      "loss": 0.1799,
      "step": 1053
    },
    {
      "epoch": 0.16753094514315234,
      "grad_norm": 0.5571255087852478,
      "learning_rate": 9.512316711350521e-06,
      "loss": 0.2488,
      "step": 1054
    },
    {
      "epoch": 0.1676898929089428,
      "grad_norm": 0.6574186682701111,
      "learning_rate": 9.51120722007263e-06,
      "loss": 0.3172,
      "step": 1055
    },
    {
      "epoch": 0.16784884067473327,
      "grad_norm": 0.6009631752967834,
      "learning_rate": 9.510096533023491e-06,
      "loss": 0.2168,
      "step": 1056
    },
    {
      "epoch": 0.16800778844052372,
      "grad_norm": 0.5555230975151062,
      "learning_rate": 9.508984650497513e-06,
      "loss": 0.2037,
      "step": 1057
    },
    {
      "epoch": 0.1681667362063142,
      "grad_norm": 0.7372065782546997,
      "learning_rate": 9.50787157278942e-06,
      "loss": 0.3183,
      "step": 1058
    },
    {
      "epoch": 0.16832568397210468,
      "grad_norm": 0.5838369131088257,
      "learning_rate": 9.506757300194249e-06,
      "loss": 0.263,
      "step": 1059
    },
    {
      "epoch": 0.16848463173789513,
      "grad_norm": 0.8080450296401978,
      "learning_rate": 9.50564183300736e-06,
      "loss": 0.4465,
      "step": 1060
    },
    {
      "epoch": 0.1686435795036856,
      "grad_norm": 0.5709170699119568,
      "learning_rate": 9.504525171524423e-06,
      "loss": 0.2398,
      "step": 1061
    },
    {
      "epoch": 0.16880252726947606,
      "grad_norm": 0.7214350700378418,
      "learning_rate": 9.503407316041432e-06,
      "loss": 0.2932,
      "step": 1062
    },
    {
      "epoch": 0.16896147503526654,
      "grad_norm": 0.6830903887748718,
      "learning_rate": 9.502288266854688e-06,
      "loss": 0.1828,
      "step": 1063
    },
    {
      "epoch": 0.169120422801057,
      "grad_norm": 0.6996552348136902,
      "learning_rate": 9.50116802426082e-06,
      "loss": 0.366,
      "step": 1064
    },
    {
      "epoch": 0.16927937056684747,
      "grad_norm": 0.5832937359809875,
      "learning_rate": 9.500046588556762e-06,
      "loss": 0.2365,
      "step": 1065
    },
    {
      "epoch": 0.16943831833263795,
      "grad_norm": 0.5853913426399231,
      "learning_rate": 9.498923960039773e-06,
      "loss": 0.2876,
      "step": 1066
    },
    {
      "epoch": 0.1695972660984284,
      "grad_norm": 0.5348491668701172,
      "learning_rate": 9.49780013900742e-06,
      "loss": 0.1845,
      "step": 1067
    },
    {
      "epoch": 0.16975621386421888,
      "grad_norm": 1.1185792684555054,
      "learning_rate": 9.496675125757594e-06,
      "loss": 0.2427,
      "step": 1068
    },
    {
      "epoch": 0.16991516163000933,
      "grad_norm": 0.6568857431411743,
      "learning_rate": 9.495548920588501e-06,
      "loss": 0.2197,
      "step": 1069
    },
    {
      "epoch": 0.1700741093957998,
      "grad_norm": 0.6295941472053528,
      "learning_rate": 9.494421523798657e-06,
      "loss": 0.2175,
      "step": 1070
    },
    {
      "epoch": 0.17023305716159026,
      "grad_norm": 0.7547208666801453,
      "learning_rate": 9.493292935686896e-06,
      "loss": 0.2631,
      "step": 1071
    },
    {
      "epoch": 0.17039200492738074,
      "grad_norm": 0.6676024794578552,
      "learning_rate": 9.492163156552372e-06,
      "loss": 0.3136,
      "step": 1072
    },
    {
      "epoch": 0.1705509526931712,
      "grad_norm": 0.7661548852920532,
      "learning_rate": 9.49103218669455e-06,
      "loss": 0.2786,
      "step": 1073
    },
    {
      "epoch": 0.17070990045896167,
      "grad_norm": 0.586088240146637,
      "learning_rate": 9.489900026413217e-06,
      "loss": 0.3034,
      "step": 1074
    },
    {
      "epoch": 0.17086884822475215,
      "grad_norm": 0.6544140577316284,
      "learning_rate": 9.488766676008466e-06,
      "loss": 0.2922,
      "step": 1075
    },
    {
      "epoch": 0.1710277959905426,
      "grad_norm": 0.7065383791923523,
      "learning_rate": 9.487632135780713e-06,
      "loss": 0.404,
      "step": 1076
    },
    {
      "epoch": 0.17118674375633308,
      "grad_norm": 0.5277273058891296,
      "learning_rate": 9.486496406030687e-06,
      "loss": 0.1896,
      "step": 1077
    },
    {
      "epoch": 0.17134569152212353,
      "grad_norm": 0.8234696984291077,
      "learning_rate": 9.48535948705943e-06,
      "loss": 0.2252,
      "step": 1078
    },
    {
      "epoch": 0.171504639287914,
      "grad_norm": 0.6104786396026611,
      "learning_rate": 9.484221379168304e-06,
      "loss": 0.326,
      "step": 1079
    },
    {
      "epoch": 0.17166358705370446,
      "grad_norm": 0.549587070941925,
      "learning_rate": 9.483082082658984e-06,
      "loss": 0.185,
      "step": 1080
    },
    {
      "epoch": 0.17182253481949494,
      "grad_norm": 0.5182344317436218,
      "learning_rate": 9.481941597833457e-06,
      "loss": 0.2005,
      "step": 1081
    },
    {
      "epoch": 0.17198148258528542,
      "grad_norm": 0.5527113676071167,
      "learning_rate": 9.48079992499403e-06,
      "loss": 0.2662,
      "step": 1082
    },
    {
      "epoch": 0.17214043035107587,
      "grad_norm": 0.7133564352989197,
      "learning_rate": 9.479657064443321e-06,
      "loss": 0.2386,
      "step": 1083
    },
    {
      "epoch": 0.17229937811686635,
      "grad_norm": 0.5435158610343933,
      "learning_rate": 9.478513016484265e-06,
      "loss": 0.2137,
      "step": 1084
    },
    {
      "epoch": 0.1724583258826568,
      "grad_norm": 0.4760218858718872,
      "learning_rate": 9.477367781420113e-06,
      "loss": 0.201,
      "step": 1085
    },
    {
      "epoch": 0.17261727364844728,
      "grad_norm": 0.6578670740127563,
      "learning_rate": 9.476221359554426e-06,
      "loss": 0.3138,
      "step": 1086
    },
    {
      "epoch": 0.17277622141423774,
      "grad_norm": 0.7117260098457336,
      "learning_rate": 9.475073751191082e-06,
      "loss": 0.2335,
      "step": 1087
    },
    {
      "epoch": 0.17293516918002821,
      "grad_norm": 0.7059352397918701,
      "learning_rate": 9.473924956634277e-06,
      "loss": 0.2968,
      "step": 1088
    },
    {
      "epoch": 0.1730941169458187,
      "grad_norm": 0.6368888020515442,
      "learning_rate": 9.472774976188515e-06,
      "loss": 0.3217,
      "step": 1089
    },
    {
      "epoch": 0.17325306471160914,
      "grad_norm": 0.5178913474082947,
      "learning_rate": 9.47162381015862e-06,
      "loss": 0.1979,
      "step": 1090
    },
    {
      "epoch": 0.17341201247739962,
      "grad_norm": 0.665759265422821,
      "learning_rate": 9.470471458849727e-06,
      "loss": 0.2409,
      "step": 1091
    },
    {
      "epoch": 0.17357096024319008,
      "grad_norm": 0.5218313336372375,
      "learning_rate": 9.469317922567287e-06,
      "loss": 0.1915,
      "step": 1092
    },
    {
      "epoch": 0.17372990800898055,
      "grad_norm": 0.4572206139564514,
      "learning_rate": 9.468163201617063e-06,
      "loss": 0.0968,
      "step": 1093
    },
    {
      "epoch": 0.173888855774771,
      "grad_norm": 0.5879161953926086,
      "learning_rate": 9.467007296305132e-06,
      "loss": 0.2696,
      "step": 1094
    },
    {
      "epoch": 0.17404780354056149,
      "grad_norm": 0.6411197781562805,
      "learning_rate": 9.46585020693789e-06,
      "loss": 0.3253,
      "step": 1095
    },
    {
      "epoch": 0.17420675130635194,
      "grad_norm": 0.7650845646858215,
      "learning_rate": 9.464691933822038e-06,
      "loss": 0.256,
      "step": 1096
    },
    {
      "epoch": 0.17436569907214242,
      "grad_norm": 0.6694778203964233,
      "learning_rate": 9.463532477264598e-06,
      "loss": 0.3275,
      "step": 1097
    },
    {
      "epoch": 0.1745246468379329,
      "grad_norm": 0.6145108938217163,
      "learning_rate": 9.462371837572907e-06,
      "loss": 0.2447,
      "step": 1098
    },
    {
      "epoch": 0.17468359460372335,
      "grad_norm": 0.5322924256324768,
      "learning_rate": 9.461210015054607e-06,
      "loss": 0.2984,
      "step": 1099
    },
    {
      "epoch": 0.17484254236951383,
      "grad_norm": 0.6311894059181213,
      "learning_rate": 9.46004701001766e-06,
      "loss": 0.2741,
      "step": 1100
    },
    {
      "epoch": 0.17500149013530428,
      "grad_norm": 0.47159481048583984,
      "learning_rate": 9.458882822770342e-06,
      "loss": 0.2092,
      "step": 1101
    },
    {
      "epoch": 0.17516043790109476,
      "grad_norm": 0.5925946831703186,
      "learning_rate": 9.457717453621235e-06,
      "loss": 0.2421,
      "step": 1102
    },
    {
      "epoch": 0.1753193856668852,
      "grad_norm": 1.190881609916687,
      "learning_rate": 9.456550902879248e-06,
      "loss": 0.2089,
      "step": 1103
    },
    {
      "epoch": 0.1754783334326757,
      "grad_norm": 0.7657623887062073,
      "learning_rate": 9.455383170853587e-06,
      "loss": 0.3462,
      "step": 1104
    },
    {
      "epoch": 0.17563728119846617,
      "grad_norm": 0.6163924932479858,
      "learning_rate": 9.454214257853785e-06,
      "loss": 0.2972,
      "step": 1105
    },
    {
      "epoch": 0.17579622896425662,
      "grad_norm": 0.6363900303840637,
      "learning_rate": 9.453044164189677e-06,
      "loss": 0.3395,
      "step": 1106
    },
    {
      "epoch": 0.1759551767300471,
      "grad_norm": 0.5907636880874634,
      "learning_rate": 9.451872890171419e-06,
      "loss": 0.2234,
      "step": 1107
    },
    {
      "epoch": 0.17611412449583755,
      "grad_norm": 0.640008807182312,
      "learning_rate": 9.450700436109476e-06,
      "loss": 0.3073,
      "step": 1108
    },
    {
      "epoch": 0.17627307226162803,
      "grad_norm": 0.7240703701972961,
      "learning_rate": 9.449526802314628e-06,
      "loss": 0.4103,
      "step": 1109
    },
    {
      "epoch": 0.17643202002741848,
      "grad_norm": 0.6610993146896362,
      "learning_rate": 9.448351989097964e-06,
      "loss": 0.4011,
      "step": 1110
    },
    {
      "epoch": 0.17659096779320896,
      "grad_norm": 0.6264216303825378,
      "learning_rate": 9.44717599677089e-06,
      "loss": 0.3005,
      "step": 1111
    },
    {
      "epoch": 0.17674991555899944,
      "grad_norm": 0.6325094699859619,
      "learning_rate": 9.44599882564512e-06,
      "loss": 0.1922,
      "step": 1112
    },
    {
      "epoch": 0.1769088633247899,
      "grad_norm": 0.492492139339447,
      "learning_rate": 9.444820476032687e-06,
      "loss": 0.155,
      "step": 1113
    },
    {
      "epoch": 0.17706781109058037,
      "grad_norm": 0.565757155418396,
      "learning_rate": 9.443640948245929e-06,
      "loss": 0.2366,
      "step": 1114
    },
    {
      "epoch": 0.17722675885637082,
      "grad_norm": 0.5237843990325928,
      "learning_rate": 9.4424602425975e-06,
      "loss": 0.1863,
      "step": 1115
    },
    {
      "epoch": 0.1773857066221613,
      "grad_norm": 0.6744375824928284,
      "learning_rate": 9.441278359400366e-06,
      "loss": 0.2984,
      "step": 1116
    },
    {
      "epoch": 0.17754465438795175,
      "grad_norm": 0.5352686643600464,
      "learning_rate": 9.440095298967806e-06,
      "loss": 0.1898,
      "step": 1117
    },
    {
      "epoch": 0.17770360215374223,
      "grad_norm": 0.5218223333358765,
      "learning_rate": 9.43891106161341e-06,
      "loss": 0.1897,
      "step": 1118
    },
    {
      "epoch": 0.17786254991953268,
      "grad_norm": 0.5344921946525574,
      "learning_rate": 9.43772564765108e-06,
      "loss": 0.1721,
      "step": 1119
    },
    {
      "epoch": 0.17802149768532316,
      "grad_norm": 0.4244472086429596,
      "learning_rate": 9.436539057395029e-06,
      "loss": 0.1073,
      "step": 1120
    },
    {
      "epoch": 0.17818044545111364,
      "grad_norm": 0.5141486525535583,
      "learning_rate": 9.435351291159782e-06,
      "loss": 0.2339,
      "step": 1121
    },
    {
      "epoch": 0.1783393932169041,
      "grad_norm": 0.5194724202156067,
      "learning_rate": 9.434162349260178e-06,
      "loss": 0.1793,
      "step": 1122
    },
    {
      "epoch": 0.17849834098269457,
      "grad_norm": 0.6227115988731384,
      "learning_rate": 9.432972232011367e-06,
      "loss": 0.2905,
      "step": 1123
    },
    {
      "epoch": 0.17865728874848502,
      "grad_norm": 0.6504666805267334,
      "learning_rate": 9.431780939728805e-06,
      "loss": 0.3193,
      "step": 1124
    },
    {
      "epoch": 0.1788162365142755,
      "grad_norm": 0.5665733814239502,
      "learning_rate": 9.430588472728271e-06,
      "loss": 0.2467,
      "step": 1125
    },
    {
      "epoch": 0.17897518428006595,
      "grad_norm": 0.5824786424636841,
      "learning_rate": 9.429394831325841e-06,
      "loss": 0.2048,
      "step": 1126
    },
    {
      "epoch": 0.17913413204585643,
      "grad_norm": 0.5788630843162537,
      "learning_rate": 9.428200015837914e-06,
      "loss": 0.2231,
      "step": 1127
    },
    {
      "epoch": 0.1792930798116469,
      "grad_norm": 0.6453768610954285,
      "learning_rate": 9.427004026581197e-06,
      "loss": 0.3411,
      "step": 1128
    },
    {
      "epoch": 0.17945202757743736,
      "grad_norm": 0.5571147203445435,
      "learning_rate": 9.425806863872703e-06,
      "loss": 0.2261,
      "step": 1129
    },
    {
      "epoch": 0.17961097534322784,
      "grad_norm": 0.5430075526237488,
      "learning_rate": 9.424608528029763e-06,
      "loss": 0.2619,
      "step": 1130
    },
    {
      "epoch": 0.1797699231090183,
      "grad_norm": 0.6011972427368164,
      "learning_rate": 9.423409019370015e-06,
      "loss": 0.3561,
      "step": 1131
    },
    {
      "epoch": 0.17992887087480877,
      "grad_norm": 0.5140666961669922,
      "learning_rate": 9.422208338211409e-06,
      "loss": 0.1781,
      "step": 1132
    },
    {
      "epoch": 0.18008781864059922,
      "grad_norm": 0.6820948123931885,
      "learning_rate": 9.421006484872208e-06,
      "loss": 0.3263,
      "step": 1133
    },
    {
      "epoch": 0.1802467664063897,
      "grad_norm": 0.6273918747901917,
      "learning_rate": 9.41980345967098e-06,
      "loss": 0.2653,
      "step": 1134
    },
    {
      "epoch": 0.18040571417218015,
      "grad_norm": 0.6743749380111694,
      "learning_rate": 9.418599262926607e-06,
      "loss": 0.3828,
      "step": 1135
    },
    {
      "epoch": 0.18056466193797063,
      "grad_norm": 0.5587109923362732,
      "learning_rate": 9.417393894958285e-06,
      "loss": 0.2643,
      "step": 1136
    },
    {
      "epoch": 0.1807236097037611,
      "grad_norm": 0.6042871475219727,
      "learning_rate": 9.416187356085513e-06,
      "loss": 0.2154,
      "step": 1137
    },
    {
      "epoch": 0.18088255746955156,
      "grad_norm": 0.6651947498321533,
      "learning_rate": 9.414979646628108e-06,
      "loss": 0.3111,
      "step": 1138
    },
    {
      "epoch": 0.18104150523534204,
      "grad_norm": 0.6064229607582092,
      "learning_rate": 9.413770766906191e-06,
      "loss": 0.1746,
      "step": 1139
    },
    {
      "epoch": 0.1812004530011325,
      "grad_norm": 0.5877323150634766,
      "learning_rate": 9.412560717240197e-06,
      "loss": 0.2365,
      "step": 1140
    },
    {
      "epoch": 0.18135940076692297,
      "grad_norm": 0.653037965297699,
      "learning_rate": 9.41134949795087e-06,
      "loss": 0.2595,
      "step": 1141
    },
    {
      "epoch": 0.18151834853271342,
      "grad_norm": 0.6219725608825684,
      "learning_rate": 9.410137109359265e-06,
      "loss": 0.2404,
      "step": 1142
    },
    {
      "epoch": 0.1816772962985039,
      "grad_norm": 0.5756300091743469,
      "learning_rate": 9.408923551786742e-06,
      "loss": 0.2994,
      "step": 1143
    },
    {
      "epoch": 0.18183624406429438,
      "grad_norm": 0.5386376976966858,
      "learning_rate": 9.40770882555498e-06,
      "loss": 0.2549,
      "step": 1144
    },
    {
      "epoch": 0.18199519183008483,
      "grad_norm": 0.44832369685173035,
      "learning_rate": 9.406492930985959e-06,
      "loss": 0.1261,
      "step": 1145
    },
    {
      "epoch": 0.18215413959587531,
      "grad_norm": 0.6325493454933167,
      "learning_rate": 9.405275868401975e-06,
      "loss": 0.3315,
      "step": 1146
    },
    {
      "epoch": 0.18231308736166577,
      "grad_norm": 0.5980087518692017,
      "learning_rate": 9.40405763812563e-06,
      "loss": 0.3354,
      "step": 1147
    },
    {
      "epoch": 0.18247203512745624,
      "grad_norm": 0.646716296672821,
      "learning_rate": 9.402838240479835e-06,
      "loss": 0.3049,
      "step": 1148
    },
    {
      "epoch": 0.1826309828932467,
      "grad_norm": 0.646869957447052,
      "learning_rate": 9.401617675787812e-06,
      "loss": 0.2953,
      "step": 1149
    },
    {
      "epoch": 0.18278993065903718,
      "grad_norm": 0.539973795413971,
      "learning_rate": 9.400395944373093e-06,
      "loss": 0.2308,
      "step": 1150
    },
    {
      "epoch": 0.18294887842482765,
      "grad_norm": 0.649946391582489,
      "learning_rate": 9.399173046559518e-06,
      "loss": 0.3204,
      "step": 1151
    },
    {
      "epoch": 0.1831078261906181,
      "grad_norm": 0.6569987535476685,
      "learning_rate": 9.397948982671237e-06,
      "loss": 0.3132,
      "step": 1152
    },
    {
      "epoch": 0.18326677395640859,
      "grad_norm": 0.5393201112747192,
      "learning_rate": 9.39672375303271e-06,
      "loss": 0.2331,
      "step": 1153
    },
    {
      "epoch": 0.18342572172219904,
      "grad_norm": 0.6809177398681641,
      "learning_rate": 9.395497357968702e-06,
      "loss": 0.3144,
      "step": 1154
    },
    {
      "epoch": 0.18358466948798952,
      "grad_norm": 0.7838943600654602,
      "learning_rate": 9.39426979780429e-06,
      "loss": 0.3639,
      "step": 1155
    },
    {
      "epoch": 0.18374361725377997,
      "grad_norm": 0.5423293113708496,
      "learning_rate": 9.393041072864861e-06,
      "loss": 0.2072,
      "step": 1156
    },
    {
      "epoch": 0.18390256501957045,
      "grad_norm": 0.617988109588623,
      "learning_rate": 9.391811183476109e-06,
      "loss": 0.3401,
      "step": 1157
    },
    {
      "epoch": 0.1840615127853609,
      "grad_norm": 0.592184841632843,
      "learning_rate": 9.390580129964036e-06,
      "loss": 0.2256,
      "step": 1158
    },
    {
      "epoch": 0.18422046055115138,
      "grad_norm": 0.6870673894882202,
      "learning_rate": 9.389347912654953e-06,
      "loss": 0.3038,
      "step": 1159
    },
    {
      "epoch": 0.18437940831694186,
      "grad_norm": 0.5793887376785278,
      "learning_rate": 9.388114531875483e-06,
      "loss": 0.2421,
      "step": 1160
    },
    {
      "epoch": 0.1845383560827323,
      "grad_norm": 0.6320104002952576,
      "learning_rate": 9.386879987952549e-06,
      "loss": 0.2789,
      "step": 1161
    },
    {
      "epoch": 0.1846973038485228,
      "grad_norm": 0.5326126217842102,
      "learning_rate": 9.385644281213393e-06,
      "loss": 0.1707,
      "step": 1162
    },
    {
      "epoch": 0.18485625161431324,
      "grad_norm": 0.5721117258071899,
      "learning_rate": 9.384407411985557e-06,
      "loss": 0.2591,
      "step": 1163
    },
    {
      "epoch": 0.18501519938010372,
      "grad_norm": 0.5094910264015198,
      "learning_rate": 9.383169380596893e-06,
      "loss": 0.1973,
      "step": 1164
    },
    {
      "epoch": 0.18517414714589417,
      "grad_norm": 0.6028003692626953,
      "learning_rate": 9.381930187375563e-06,
      "loss": 0.3031,
      "step": 1165
    },
    {
      "epoch": 0.18533309491168465,
      "grad_norm": 0.503318190574646,
      "learning_rate": 9.380689832650038e-06,
      "loss": 0.2032,
      "step": 1166
    },
    {
      "epoch": 0.18549204267747513,
      "grad_norm": 0.5909861922264099,
      "learning_rate": 9.379448316749092e-06,
      "loss": 0.2699,
      "step": 1167
    },
    {
      "epoch": 0.18565099044326558,
      "grad_norm": 0.584876298904419,
      "learning_rate": 9.378205640001811e-06,
      "loss": 0.2727,
      "step": 1168
    },
    {
      "epoch": 0.18580993820905606,
      "grad_norm": 0.4448755085468292,
      "learning_rate": 9.376961802737588e-06,
      "loss": 0.1334,
      "step": 1169
    },
    {
      "epoch": 0.1859688859748465,
      "grad_norm": 0.5755999684333801,
      "learning_rate": 9.375716805286122e-06,
      "loss": 0.3159,
      "step": 1170
    },
    {
      "epoch": 0.186127833740637,
      "grad_norm": 0.7009713649749756,
      "learning_rate": 9.374470647977419e-06,
      "loss": 0.2014,
      "step": 1171
    },
    {
      "epoch": 0.18628678150642744,
      "grad_norm": 0.6489793658256531,
      "learning_rate": 9.373223331141796e-06,
      "loss": 0.2883,
      "step": 1172
    },
    {
      "epoch": 0.18644572927221792,
      "grad_norm": 0.5842390656471252,
      "learning_rate": 9.371974855109876e-06,
      "loss": 0.297,
      "step": 1173
    },
    {
      "epoch": 0.18660467703800837,
      "grad_norm": 0.563133180141449,
      "learning_rate": 9.370725220212586e-06,
      "loss": 0.2216,
      "step": 1174
    },
    {
      "epoch": 0.18676362480379885,
      "grad_norm": 0.5645643472671509,
      "learning_rate": 9.369474426781165e-06,
      "loss": 0.2034,
      "step": 1175
    },
    {
      "epoch": 0.18692257256958933,
      "grad_norm": 1.3353115320205688,
      "learning_rate": 9.368222475147155e-06,
      "loss": 0.1575,
      "step": 1176
    },
    {
      "epoch": 0.18708152033537978,
      "grad_norm": 0.7236249446868896,
      "learning_rate": 9.36696936564241e-06,
      "loss": 0.2732,
      "step": 1177
    },
    {
      "epoch": 0.18724046810117026,
      "grad_norm": 0.508733332157135,
      "learning_rate": 9.365715098599082e-06,
      "loss": 0.1771,
      "step": 1178
    },
    {
      "epoch": 0.1873994158669607,
      "grad_norm": 0.5864689946174622,
      "learning_rate": 9.364459674349642e-06,
      "loss": 0.2227,
      "step": 1179
    },
    {
      "epoch": 0.1875583636327512,
      "grad_norm": 0.7010839581489563,
      "learning_rate": 9.363203093226855e-06,
      "loss": 0.2284,
      "step": 1180
    },
    {
      "epoch": 0.18771731139854164,
      "grad_norm": 0.47390130162239075,
      "learning_rate": 9.361945355563805e-06,
      "loss": 0.2144,
      "step": 1181
    },
    {
      "epoch": 0.18787625916433212,
      "grad_norm": 0.6313083171844482,
      "learning_rate": 9.360686461693873e-06,
      "loss": 0.3524,
      "step": 1182
    },
    {
      "epoch": 0.1880352069301226,
      "grad_norm": 0.6091468930244446,
      "learning_rate": 9.359426411950749e-06,
      "loss": 0.3436,
      "step": 1183
    },
    {
      "epoch": 0.18819415469591305,
      "grad_norm": 0.5357345342636108,
      "learning_rate": 9.358165206668435e-06,
      "loss": 0.2565,
      "step": 1184
    },
    {
      "epoch": 0.18835310246170353,
      "grad_norm": 1.1515312194824219,
      "learning_rate": 9.356902846181229e-06,
      "loss": 0.2687,
      "step": 1185
    },
    {
      "epoch": 0.18851205022749398,
      "grad_norm": 0.6359491348266602,
      "learning_rate": 9.355639330823745e-06,
      "loss": 0.2,
      "step": 1186
    },
    {
      "epoch": 0.18867099799328446,
      "grad_norm": 0.5674190521240234,
      "learning_rate": 9.354374660930897e-06,
      "loss": 0.2143,
      "step": 1187
    },
    {
      "epoch": 0.1888299457590749,
      "grad_norm": 0.540071427822113,
      "learning_rate": 9.353108836837907e-06,
      "loss": 0.2698,
      "step": 1188
    },
    {
      "epoch": 0.1889888935248654,
      "grad_norm": 0.6257748603820801,
      "learning_rate": 9.351841858880304e-06,
      "loss": 0.2784,
      "step": 1189
    },
    {
      "epoch": 0.18914784129065587,
      "grad_norm": 0.6595891118049622,
      "learning_rate": 9.350573727393919e-06,
      "loss": 0.333,
      "step": 1190
    },
    {
      "epoch": 0.18930678905644632,
      "grad_norm": 0.5002295970916748,
      "learning_rate": 9.349304442714895e-06,
      "loss": 0.2404,
      "step": 1191
    },
    {
      "epoch": 0.1894657368222368,
      "grad_norm": 0.6428094506263733,
      "learning_rate": 9.348034005179678e-06,
      "loss": 0.3341,
      "step": 1192
    },
    {
      "epoch": 0.18962468458802725,
      "grad_norm": 0.6412282586097717,
      "learning_rate": 9.346762415125014e-06,
      "loss": 0.2889,
      "step": 1193
    },
    {
      "epoch": 0.18978363235381773,
      "grad_norm": 0.6073048710823059,
      "learning_rate": 9.345489672887963e-06,
      "loss": 0.2576,
      "step": 1194
    },
    {
      "epoch": 0.18994258011960818,
      "grad_norm": 0.4702916741371155,
      "learning_rate": 9.344215778805885e-06,
      "loss": 0.1634,
      "step": 1195
    },
    {
      "epoch": 0.19010152788539866,
      "grad_norm": 0.6178445219993591,
      "learning_rate": 9.34294073321645e-06,
      "loss": 0.2999,
      "step": 1196
    },
    {
      "epoch": 0.19026047565118911,
      "grad_norm": 0.514154851436615,
      "learning_rate": 9.341664536457626e-06,
      "loss": 0.1914,
      "step": 1197
    },
    {
      "epoch": 0.1904194234169796,
      "grad_norm": 0.6233608722686768,
      "learning_rate": 9.340387188867694e-06,
      "loss": 0.1416,
      "step": 1198
    },
    {
      "epoch": 0.19057837118277007,
      "grad_norm": 0.9091663360595703,
      "learning_rate": 9.339108690785232e-06,
      "loss": 0.4055,
      "step": 1199
    },
    {
      "epoch": 0.19073731894856052,
      "grad_norm": 0.542353093624115,
      "learning_rate": 9.337829042549133e-06,
      "loss": 0.2286,
      "step": 1200
    },
    {
      "epoch": 0.190896266714351,
      "grad_norm": 0.5271442532539368,
      "learning_rate": 9.336548244498585e-06,
      "loss": 0.2206,
      "step": 1201
    },
    {
      "epoch": 0.19105521448014146,
      "grad_norm": 0.5560027956962585,
      "learning_rate": 9.335266296973087e-06,
      "loss": 0.2826,
      "step": 1202
    },
    {
      "epoch": 0.19121416224593193,
      "grad_norm": 0.5582074522972107,
      "learning_rate": 9.33398320031244e-06,
      "loss": 0.2385,
      "step": 1203
    },
    {
      "epoch": 0.19137311001172239,
      "grad_norm": 0.6783924698829651,
      "learning_rate": 9.33269895485675e-06,
      "loss": 0.179,
      "step": 1204
    },
    {
      "epoch": 0.19153205777751287,
      "grad_norm": 1.3906430006027222,
      "learning_rate": 9.331413560946432e-06,
      "loss": 0.3804,
      "step": 1205
    },
    {
      "epoch": 0.19169100554330334,
      "grad_norm": 0.4419516623020172,
      "learning_rate": 9.330127018922195e-06,
      "loss": 0.132,
      "step": 1206
    },
    {
      "epoch": 0.1918499533090938,
      "grad_norm": 0.5404289364814758,
      "learning_rate": 9.32883932912506e-06,
      "loss": 0.2158,
      "step": 1207
    },
    {
      "epoch": 0.19200890107488428,
      "grad_norm": 0.541440486907959,
      "learning_rate": 9.327550491896353e-06,
      "loss": 0.2544,
      "step": 1208
    },
    {
      "epoch": 0.19216784884067473,
      "grad_norm": 0.5936337113380432,
      "learning_rate": 9.326260507577702e-06,
      "loss": 0.2725,
      "step": 1209
    },
    {
      "epoch": 0.1923267966064652,
      "grad_norm": 0.7116859555244446,
      "learning_rate": 9.324969376511037e-06,
      "loss": 0.2896,
      "step": 1210
    },
    {
      "epoch": 0.19248574437225566,
      "grad_norm": 0.6217499375343323,
      "learning_rate": 9.323677099038594e-06,
      "loss": 0.3607,
      "step": 1211
    },
    {
      "epoch": 0.19264469213804614,
      "grad_norm": 0.5157530903816223,
      "learning_rate": 9.322383675502915e-06,
      "loss": 0.2193,
      "step": 1212
    },
    {
      "epoch": 0.19280363990383662,
      "grad_norm": 0.49605661630630493,
      "learning_rate": 9.321089106246844e-06,
      "loss": 0.1831,
      "step": 1213
    },
    {
      "epoch": 0.19296258766962707,
      "grad_norm": 0.5520949363708496,
      "learning_rate": 9.319793391613522e-06,
      "loss": 0.171,
      "step": 1214
    },
    {
      "epoch": 0.19312153543541755,
      "grad_norm": 0.6614869832992554,
      "learning_rate": 9.318496531946411e-06,
      "loss": 0.4611,
      "step": 1215
    },
    {
      "epoch": 0.193280483201208,
      "grad_norm": 0.5853868722915649,
      "learning_rate": 9.317198527589254e-06,
      "loss": 0.2675,
      "step": 1216
    },
    {
      "epoch": 0.19343943096699848,
      "grad_norm": 0.5115537047386169,
      "learning_rate": 9.315899378886117e-06,
      "loss": 0.1926,
      "step": 1217
    },
    {
      "epoch": 0.19359837873278893,
      "grad_norm": 0.5767868757247925,
      "learning_rate": 9.314599086181357e-06,
      "loss": 0.2892,
      "step": 1218
    },
    {
      "epoch": 0.1937573264985794,
      "grad_norm": 0.44877350330352783,
      "learning_rate": 9.31329764981964e-06,
      "loss": 0.2078,
      "step": 1219
    },
    {
      "epoch": 0.19391627426436986,
      "grad_norm": 0.6240465044975281,
      "learning_rate": 9.311995070145932e-06,
      "loss": 0.3356,
      "step": 1220
    },
    {
      "epoch": 0.19407522203016034,
      "grad_norm": 1.1169676780700684,
      "learning_rate": 9.310691347505506e-06,
      "loss": 0.1963,
      "step": 1221
    },
    {
      "epoch": 0.19423416979595082,
      "grad_norm": 0.7306432723999023,
      "learning_rate": 9.309386482243934e-06,
      "loss": 0.2685,
      "step": 1222
    },
    {
      "epoch": 0.19439311756174127,
      "grad_norm": 0.4943714737892151,
      "learning_rate": 9.308080474707093e-06,
      "loss": 0.1545,
      "step": 1223
    },
    {
      "epoch": 0.19455206532753175,
      "grad_norm": 0.46942242980003357,
      "learning_rate": 9.306773325241161e-06,
      "loss": 0.1288,
      "step": 1224
    },
    {
      "epoch": 0.1947110130933222,
      "grad_norm": 0.6060385704040527,
      "learning_rate": 9.305465034192623e-06,
      "loss": 0.2681,
      "step": 1225
    },
    {
      "epoch": 0.19486996085911268,
      "grad_norm": 0.46183985471725464,
      "learning_rate": 9.30415560190826e-06,
      "loss": 0.1417,
      "step": 1226
    },
    {
      "epoch": 0.19502890862490313,
      "grad_norm": 0.5665185451507568,
      "learning_rate": 9.30284502873516e-06,
      "loss": 0.2711,
      "step": 1227
    },
    {
      "epoch": 0.1951878563906936,
      "grad_norm": 0.6253119707107544,
      "learning_rate": 9.301533315020714e-06,
      "loss": 0.2822,
      "step": 1228
    },
    {
      "epoch": 0.1953468041564841,
      "grad_norm": 0.45553210377693176,
      "learning_rate": 9.300220461112613e-06,
      "loss": 0.1079,
      "step": 1229
    },
    {
      "epoch": 0.19550575192227454,
      "grad_norm": 0.542646586894989,
      "learning_rate": 9.29890646735885e-06,
      "loss": 0.2021,
      "step": 1230
    },
    {
      "epoch": 0.19566469968806502,
      "grad_norm": 0.6026649475097656,
      "learning_rate": 9.297591334107722e-06,
      "loss": 0.264,
      "step": 1231
    },
    {
      "epoch": 0.19582364745385547,
      "grad_norm": 0.5210433602333069,
      "learning_rate": 9.296275061707827e-06,
      "loss": 0.1795,
      "step": 1232
    },
    {
      "epoch": 0.19598259521964595,
      "grad_norm": 0.6973989605903625,
      "learning_rate": 9.294957650508065e-06,
      "loss": 0.1614,
      "step": 1233
    },
    {
      "epoch": 0.1961415429854364,
      "grad_norm": 0.6037260293960571,
      "learning_rate": 9.293639100857638e-06,
      "loss": 0.2524,
      "step": 1234
    },
    {
      "epoch": 0.19630049075122688,
      "grad_norm": 0.5468659996986389,
      "learning_rate": 9.29231941310605e-06,
      "loss": 0.2261,
      "step": 1235
    },
    {
      "epoch": 0.19645943851701733,
      "grad_norm": 0.6007722616195679,
      "learning_rate": 9.290998587603106e-06,
      "loss": 0.3224,
      "step": 1236
    },
    {
      "epoch": 0.1966183862828078,
      "grad_norm": 0.5505387783050537,
      "learning_rate": 9.289676624698914e-06,
      "loss": 0.1793,
      "step": 1237
    },
    {
      "epoch": 0.1967773340485983,
      "grad_norm": 0.6106947660446167,
      "learning_rate": 9.28835352474388e-06,
      "loss": 0.3795,
      "step": 1238
    },
    {
      "epoch": 0.19693628181438874,
      "grad_norm": 0.6755906939506531,
      "learning_rate": 9.287029288088716e-06,
      "loss": 0.306,
      "step": 1239
    },
    {
      "epoch": 0.19709522958017922,
      "grad_norm": 0.5828086733818054,
      "learning_rate": 9.285703915084435e-06,
      "loss": 0.2958,
      "step": 1240
    },
    {
      "epoch": 0.19725417734596967,
      "grad_norm": 0.7702056169509888,
      "learning_rate": 9.284377406082343e-06,
      "loss": 0.4039,
      "step": 1241
    },
    {
      "epoch": 0.19741312511176015,
      "grad_norm": 0.6516947746276855,
      "learning_rate": 9.283049761434059e-06,
      "loss": 0.2609,
      "step": 1242
    },
    {
      "epoch": 0.1975720728775506,
      "grad_norm": 0.5496990084648132,
      "learning_rate": 9.281720981491497e-06,
      "loss": 0.3194,
      "step": 1243
    },
    {
      "epoch": 0.19773102064334108,
      "grad_norm": 0.6348690986633301,
      "learning_rate": 9.28039106660687e-06,
      "loss": 0.3223,
      "step": 1244
    },
    {
      "epoch": 0.19788996840913156,
      "grad_norm": 0.6176532506942749,
      "learning_rate": 9.279060017132698e-06,
      "loss": 0.2899,
      "step": 1245
    },
    {
      "epoch": 0.198048916174922,
      "grad_norm": 0.6179118752479553,
      "learning_rate": 9.277727833421795e-06,
      "loss": 0.271,
      "step": 1246
    },
    {
      "epoch": 0.1982078639407125,
      "grad_norm": 0.5935864448547363,
      "learning_rate": 9.276394515827278e-06,
      "loss": 0.2302,
      "step": 1247
    },
    {
      "epoch": 0.19836681170650294,
      "grad_norm": 0.4824427366256714,
      "learning_rate": 9.275060064702568e-06,
      "loss": 0.147,
      "step": 1248
    },
    {
      "epoch": 0.19852575947229342,
      "grad_norm": 0.5474430918693542,
      "learning_rate": 9.273724480401383e-06,
      "loss": 0.2569,
      "step": 1249
    },
    {
      "epoch": 0.19868470723808387,
      "grad_norm": 0.6344802975654602,
      "learning_rate": 9.272387763277739e-06,
      "loss": 0.318,
      "step": 1250
    },
    {
      "epoch": 0.19884365500387435,
      "grad_norm": 0.5438523292541504,
      "learning_rate": 9.27104991368596e-06,
      "loss": 0.1983,
      "step": 1251
    },
    {
      "epoch": 0.19900260276966483,
      "grad_norm": 0.612494707107544,
      "learning_rate": 9.269710931980663e-06,
      "loss": 0.3,
      "step": 1252
    },
    {
      "epoch": 0.19916155053545528,
      "grad_norm": 0.6532289981842041,
      "learning_rate": 9.268370818516767e-06,
      "loss": 0.376,
      "step": 1253
    },
    {
      "epoch": 0.19932049830124576,
      "grad_norm": 0.5971760153770447,
      "learning_rate": 9.267029573649491e-06,
      "loss": 0.3229,
      "step": 1254
    },
    {
      "epoch": 0.19947944606703621,
      "grad_norm": 0.8865857720375061,
      "learning_rate": 9.265687197734359e-06,
      "loss": 0.3239,
      "step": 1255
    },
    {
      "epoch": 0.1996383938328267,
      "grad_norm": 0.5363630056381226,
      "learning_rate": 9.264343691127185e-06,
      "loss": 0.2303,
      "step": 1256
    },
    {
      "epoch": 0.19979734159861715,
      "grad_norm": 0.5436702966690063,
      "learning_rate": 9.262999054184093e-06,
      "loss": 0.2349,
      "step": 1257
    },
    {
      "epoch": 0.19995628936440762,
      "grad_norm": 0.5494236350059509,
      "learning_rate": 9.261653287261495e-06,
      "loss": 0.1256,
      "step": 1258
    },
    {
      "epoch": 0.20011523713019808,
      "grad_norm": 3.2456860542297363,
      "learning_rate": 9.260306390716114e-06,
      "loss": 0.1908,
      "step": 1259
    },
    {
      "epoch": 0.20027418489598856,
      "grad_norm": 0.7369356155395508,
      "learning_rate": 9.258958364904966e-06,
      "loss": 0.3698,
      "step": 1260
    },
    {
      "epoch": 0.20043313266177903,
      "grad_norm": 0.6113365292549133,
      "learning_rate": 9.25760921018537e-06,
      "loss": 0.3291,
      "step": 1261
    },
    {
      "epoch": 0.20059208042756949,
      "grad_norm": 0.720287024974823,
      "learning_rate": 9.25625892691494e-06,
      "loss": 0.2309,
      "step": 1262
    },
    {
      "epoch": 0.20075102819335996,
      "grad_norm": 0.5404455065727234,
      "learning_rate": 9.254907515451593e-06,
      "loss": 0.1807,
      "step": 1263
    },
    {
      "epoch": 0.20090997595915042,
      "grad_norm": 0.5961242914199829,
      "learning_rate": 9.25355497615354e-06,
      "loss": 0.2818,
      "step": 1264
    },
    {
      "epoch": 0.2010689237249409,
      "grad_norm": 0.5654964447021484,
      "learning_rate": 9.252201309379296e-06,
      "loss": 0.282,
      "step": 1265
    },
    {
      "epoch": 0.20122787149073135,
      "grad_norm": 0.6321694254875183,
      "learning_rate": 9.250846515487674e-06,
      "loss": 0.1758,
      "step": 1266
    },
    {
      "epoch": 0.20138681925652183,
      "grad_norm": 0.551109790802002,
      "learning_rate": 9.249490594837784e-06,
      "loss": 0.2077,
      "step": 1267
    },
    {
      "epoch": 0.2015457670223123,
      "grad_norm": 0.673605740070343,
      "learning_rate": 9.248133547789037e-06,
      "loss": 0.3643,
      "step": 1268
    },
    {
      "epoch": 0.20170471478810276,
      "grad_norm": 0.693608820438385,
      "learning_rate": 9.246775374701139e-06,
      "loss": 0.3602,
      "step": 1269
    },
    {
      "epoch": 0.20186366255389324,
      "grad_norm": 0.5674886107444763,
      "learning_rate": 9.245416075934097e-06,
      "loss": 0.2177,
      "step": 1270
    },
    {
      "epoch": 0.2020226103196837,
      "grad_norm": 0.4459613263607025,
      "learning_rate": 9.244055651848218e-06,
      "loss": 0.1397,
      "step": 1271
    },
    {
      "epoch": 0.20218155808547417,
      "grad_norm": 0.6051117181777954,
      "learning_rate": 9.242694102804103e-06,
      "loss": 0.1968,
      "step": 1272
    },
    {
      "epoch": 0.20234050585126462,
      "grad_norm": 0.5610470175743103,
      "learning_rate": 9.241331429162654e-06,
      "loss": 0.2213,
      "step": 1273
    },
    {
      "epoch": 0.2024994536170551,
      "grad_norm": 0.5771853923797607,
      "learning_rate": 9.239967631285071e-06,
      "loss": 0.2624,
      "step": 1274
    },
    {
      "epoch": 0.20265840138284555,
      "grad_norm": 0.5512641668319702,
      "learning_rate": 9.238602709532851e-06,
      "loss": 0.2623,
      "step": 1275
    },
    {
      "epoch": 0.20281734914863603,
      "grad_norm": 0.6593021154403687,
      "learning_rate": 9.23723666426779e-06,
      "loss": 0.301,
      "step": 1276
    },
    {
      "epoch": 0.2029762969144265,
      "grad_norm": 0.5248328447341919,
      "learning_rate": 9.23586949585198e-06,
      "loss": 0.1623,
      "step": 1277
    },
    {
      "epoch": 0.20313524468021696,
      "grad_norm": 0.6790057420730591,
      "learning_rate": 9.234501204647814e-06,
      "loss": 0.31,
      "step": 1278
    },
    {
      "epoch": 0.20329419244600744,
      "grad_norm": 0.5896161794662476,
      "learning_rate": 9.23313179101798e-06,
      "loss": 0.276,
      "step": 1279
    },
    {
      "epoch": 0.2034531402117979,
      "grad_norm": 0.494274765253067,
      "learning_rate": 9.231761255325461e-06,
      "loss": 0.1674,
      "step": 1280
    },
    {
      "epoch": 0.20361208797758837,
      "grad_norm": 0.6469205617904663,
      "learning_rate": 9.230389597933545e-06,
      "loss": 0.3143,
      "step": 1281
    },
    {
      "epoch": 0.20377103574337882,
      "grad_norm": 0.6662050485610962,
      "learning_rate": 9.229016819205812e-06,
      "loss": 0.3212,
      "step": 1282
    },
    {
      "epoch": 0.2039299835091693,
      "grad_norm": 0.5710428953170776,
      "learning_rate": 9.227642919506136e-06,
      "loss": 0.2725,
      "step": 1283
    },
    {
      "epoch": 0.20408893127495978,
      "grad_norm": 0.5704834461212158,
      "learning_rate": 9.226267899198698e-06,
      "loss": 0.2809,
      "step": 1284
    },
    {
      "epoch": 0.20424787904075023,
      "grad_norm": 0.4844355285167694,
      "learning_rate": 9.224891758647965e-06,
      "loss": 0.172,
      "step": 1285
    },
    {
      "epoch": 0.2044068268065407,
      "grad_norm": 0.6239476203918457,
      "learning_rate": 9.223514498218709e-06,
      "loss": 0.1743,
      "step": 1286
    },
    {
      "epoch": 0.20456577457233116,
      "grad_norm": 0.8370827436447144,
      "learning_rate": 9.222136118275996e-06,
      "loss": 0.3063,
      "step": 1287
    },
    {
      "epoch": 0.20472472233812164,
      "grad_norm": 0.5774219632148743,
      "learning_rate": 9.220756619185189e-06,
      "loss": 0.2317,
      "step": 1288
    },
    {
      "epoch": 0.2048836701039121,
      "grad_norm": 0.712213933467865,
      "learning_rate": 9.219376001311945e-06,
      "loss": 0.2062,
      "step": 1289
    },
    {
      "epoch": 0.20504261786970257,
      "grad_norm": 0.6054879426956177,
      "learning_rate": 9.217994265022224e-06,
      "loss": 0.3138,
      "step": 1290
    },
    {
      "epoch": 0.20520156563549305,
      "grad_norm": 0.7036890387535095,
      "learning_rate": 9.216611410682274e-06,
      "loss": 0.2088,
      "step": 1291
    },
    {
      "epoch": 0.2053605134012835,
      "grad_norm": 0.565261960029602,
      "learning_rate": 9.215227438658646e-06,
      "loss": 0.3056,
      "step": 1292
    },
    {
      "epoch": 0.20551946116707398,
      "grad_norm": 0.5197595953941345,
      "learning_rate": 9.213842349318185e-06,
      "loss": 0.2028,
      "step": 1293
    },
    {
      "epoch": 0.20567840893286443,
      "grad_norm": 0.5864391922950745,
      "learning_rate": 9.212456143028032e-06,
      "loss": 0.3369,
      "step": 1294
    },
    {
      "epoch": 0.2058373566986549,
      "grad_norm": 0.7907952070236206,
      "learning_rate": 9.211068820155626e-06,
      "loss": 0.1832,
      "step": 1295
    },
    {
      "epoch": 0.20599630446444536,
      "grad_norm": 0.5454829335212708,
      "learning_rate": 9.209680381068698e-06,
      "loss": 0.2445,
      "step": 1296
    },
    {
      "epoch": 0.20615525223023584,
      "grad_norm": 0.6723591685295105,
      "learning_rate": 9.208290826135276e-06,
      "loss": 0.3228,
      "step": 1297
    },
    {
      "epoch": 0.2063141999960263,
      "grad_norm": 0.6299682259559631,
      "learning_rate": 9.206900155723689e-06,
      "loss": 0.2769,
      "step": 1298
    },
    {
      "epoch": 0.20647314776181677,
      "grad_norm": 0.5813374519348145,
      "learning_rate": 9.205508370202552e-06,
      "loss": 0.2958,
      "step": 1299
    },
    {
      "epoch": 0.20663209552760725,
      "grad_norm": 0.9506819844245911,
      "learning_rate": 9.204115469940786e-06,
      "loss": 0.3396,
      "step": 1300
    },
    {
      "epoch": 0.2067910432933977,
      "grad_norm": 0.5778878927230835,
      "learning_rate": 9.202721455307599e-06,
      "loss": 0.1856,
      "step": 1301
    },
    {
      "epoch": 0.20694999105918818,
      "grad_norm": 0.5208447575569153,
      "learning_rate": 9.201326326672502e-06,
      "loss": 0.1765,
      "step": 1302
    },
    {
      "epoch": 0.20710893882497863,
      "grad_norm": 0.5449093580245972,
      "learning_rate": 9.199930084405295e-06,
      "loss": 0.2026,
      "step": 1303
    },
    {
      "epoch": 0.2072678865907691,
      "grad_norm": 0.6599854230880737,
      "learning_rate": 9.198532728876075e-06,
      "loss": 0.3157,
      "step": 1304
    },
    {
      "epoch": 0.20742683435655956,
      "grad_norm": 0.5292561650276184,
      "learning_rate": 9.197134260455233e-06,
      "loss": 0.1868,
      "step": 1305
    },
    {
      "epoch": 0.20758578212235004,
      "grad_norm": 0.4943870007991791,
      "learning_rate": 9.195734679513461e-06,
      "loss": 0.1494,
      "step": 1306
    },
    {
      "epoch": 0.20774472988814052,
      "grad_norm": 0.6321591138839722,
      "learning_rate": 9.194333986421739e-06,
      "loss": 0.371,
      "step": 1307
    },
    {
      "epoch": 0.20790367765393097,
      "grad_norm": 0.6295109391212463,
      "learning_rate": 9.192932181551343e-06,
      "loss": 0.2641,
      "step": 1308
    },
    {
      "epoch": 0.20806262541972145,
      "grad_norm": 0.5643830299377441,
      "learning_rate": 9.191529265273849e-06,
      "loss": 0.2252,
      "step": 1309
    },
    {
      "epoch": 0.2082215731855119,
      "grad_norm": 0.7540766596794128,
      "learning_rate": 9.190125237961118e-06,
      "loss": 0.3304,
      "step": 1310
    },
    {
      "epoch": 0.20838052095130238,
      "grad_norm": 0.6427795886993408,
      "learning_rate": 9.188720099985316e-06,
      "loss": 0.3544,
      "step": 1311
    },
    {
      "epoch": 0.20853946871709284,
      "grad_norm": 0.6961489915847778,
      "learning_rate": 9.187313851718894e-06,
      "loss": 0.3468,
      "step": 1312
    },
    {
      "epoch": 0.20869841648288331,
      "grad_norm": 0.6255195140838623,
      "learning_rate": 9.185906493534605e-06,
      "loss": 0.2928,
      "step": 1313
    },
    {
      "epoch": 0.20885736424867377,
      "grad_norm": 0.6340171098709106,
      "learning_rate": 9.184498025805493e-06,
      "loss": 0.2101,
      "step": 1314
    },
    {
      "epoch": 0.20901631201446425,
      "grad_norm": 0.7294000387191772,
      "learning_rate": 9.183088448904893e-06,
      "loss": 0.4575,
      "step": 1315
    },
    {
      "epoch": 0.20917525978025472,
      "grad_norm": 0.6156558990478516,
      "learning_rate": 9.181677763206441e-06,
      "loss": 0.2171,
      "step": 1316
    },
    {
      "epoch": 0.20933420754604518,
      "grad_norm": 0.5667884945869446,
      "learning_rate": 9.180265969084058e-06,
      "loss": 0.2276,
      "step": 1317
    },
    {
      "epoch": 0.20949315531183565,
      "grad_norm": 0.61887526512146,
      "learning_rate": 9.178853066911968e-06,
      "loss": 0.3003,
      "step": 1318
    },
    {
      "epoch": 0.2096521030776261,
      "grad_norm": 0.5920543074607849,
      "learning_rate": 9.177439057064684e-06,
      "loss": 0.2534,
      "step": 1319
    },
    {
      "epoch": 0.20981105084341659,
      "grad_norm": 0.6409757733345032,
      "learning_rate": 9.17602393991701e-06,
      "loss": 0.2781,
      "step": 1320
    },
    {
      "epoch": 0.20996999860920704,
      "grad_norm": 0.5942524671554565,
      "learning_rate": 9.17460771584405e-06,
      "loss": 0.2432,
      "step": 1321
    },
    {
      "epoch": 0.21012894637499752,
      "grad_norm": 0.5600436925888062,
      "learning_rate": 9.173190385221196e-06,
      "loss": 0.2757,
      "step": 1322
    },
    {
      "epoch": 0.210287894140788,
      "grad_norm": 0.4697512686252594,
      "learning_rate": 9.171771948424138e-06,
      "loss": 0.1708,
      "step": 1323
    },
    {
      "epoch": 0.21044684190657845,
      "grad_norm": 0.5116783976554871,
      "learning_rate": 9.170352405828852e-06,
      "loss": 0.2363,
      "step": 1324
    },
    {
      "epoch": 0.21060578967236893,
      "grad_norm": 0.6303390860557556,
      "learning_rate": 9.168931757811614e-06,
      "loss": 0.3283,
      "step": 1325
    },
    {
      "epoch": 0.21076473743815938,
      "grad_norm": 0.501224935054779,
      "learning_rate": 9.167510004748992e-06,
      "loss": 0.184,
      "step": 1326
    },
    {
      "epoch": 0.21092368520394986,
      "grad_norm": 0.5180496573448181,
      "learning_rate": 9.166087147017843e-06,
      "loss": 0.2627,
      "step": 1327
    },
    {
      "epoch": 0.2110826329697403,
      "grad_norm": 0.6120802164077759,
      "learning_rate": 9.164663184995322e-06,
      "loss": 0.3622,
      "step": 1328
    },
    {
      "epoch": 0.2112415807355308,
      "grad_norm": 0.53017258644104,
      "learning_rate": 9.163238119058873e-06,
      "loss": 0.2199,
      "step": 1329
    },
    {
      "epoch": 0.21140052850132127,
      "grad_norm": 0.5405678153038025,
      "learning_rate": 9.16181194958623e-06,
      "loss": 0.2,
      "step": 1330
    },
    {
      "epoch": 0.21155947626711172,
      "grad_norm": 0.5445757508277893,
      "learning_rate": 9.160384676955429e-06,
      "loss": 0.2229,
      "step": 1331
    },
    {
      "epoch": 0.2117184240329022,
      "grad_norm": 0.4549531936645508,
      "learning_rate": 9.158956301544791e-06,
      "loss": 0.1407,
      "step": 1332
    },
    {
      "epoch": 0.21187737179869265,
      "grad_norm": 0.5528172254562378,
      "learning_rate": 9.157526823732927e-06,
      "loss": 0.2783,
      "step": 1333
    },
    {
      "epoch": 0.21203631956448313,
      "grad_norm": 0.6287438273429871,
      "learning_rate": 9.156096243898749e-06,
      "loss": 0.3044,
      "step": 1334
    },
    {
      "epoch": 0.21219526733027358,
      "grad_norm": 0.641716718673706,
      "learning_rate": 9.154664562421453e-06,
      "loss": 0.3345,
      "step": 1335
    },
    {
      "epoch": 0.21235421509606406,
      "grad_norm": 0.7331928014755249,
      "learning_rate": 9.153231779680533e-06,
      "loss": 0.2852,
      "step": 1336
    },
    {
      "epoch": 0.2125131628618545,
      "grad_norm": 0.4570556581020355,
      "learning_rate": 9.15179789605577e-06,
      "loss": 0.1371,
      "step": 1337
    },
    {
      "epoch": 0.212672110627645,
      "grad_norm": 0.5467870235443115,
      "learning_rate": 9.150362911927239e-06,
      "loss": 0.2458,
      "step": 1338
    },
    {
      "epoch": 0.21283105839343547,
      "grad_norm": 0.7031927108764648,
      "learning_rate": 9.148926827675308e-06,
      "loss": 0.2776,
      "step": 1339
    },
    {
      "epoch": 0.21299000615922592,
      "grad_norm": 1.1700026988983154,
      "learning_rate": 9.147489643680633e-06,
      "loss": 0.2211,
      "step": 1340
    },
    {
      "epoch": 0.2131489539250164,
      "grad_norm": 0.5259586572647095,
      "learning_rate": 9.146051360324166e-06,
      "loss": 0.2602,
      "step": 1341
    },
    {
      "epoch": 0.21330790169080685,
      "grad_norm": 0.5299826264381409,
      "learning_rate": 9.144611977987149e-06,
      "loss": 0.2078,
      "step": 1342
    },
    {
      "epoch": 0.21346684945659733,
      "grad_norm": 0.6664965748786926,
      "learning_rate": 9.143171497051109e-06,
      "loss": 0.357,
      "step": 1343
    },
    {
      "epoch": 0.21362579722238778,
      "grad_norm": 0.5501234531402588,
      "learning_rate": 9.141729917897875e-06,
      "loss": 0.2369,
      "step": 1344
    },
    {
      "epoch": 0.21378474498817826,
      "grad_norm": 0.660124659538269,
      "learning_rate": 9.140287240909562e-06,
      "loss": 0.3409,
      "step": 1345
    },
    {
      "epoch": 0.21394369275396874,
      "grad_norm": 0.5868461728096008,
      "learning_rate": 9.138843466468571e-06,
      "loss": 0.2818,
      "step": 1346
    },
    {
      "epoch": 0.2141026405197592,
      "grad_norm": 0.5554459095001221,
      "learning_rate": 9.137398594957605e-06,
      "loss": 0.1854,
      "step": 1347
    },
    {
      "epoch": 0.21426158828554967,
      "grad_norm": 0.5002650022506714,
      "learning_rate": 9.135952626759645e-06,
      "loss": 0.2223,
      "step": 1348
    },
    {
      "epoch": 0.21442053605134012,
      "grad_norm": 0.7011845111846924,
      "learning_rate": 9.134505562257974e-06,
      "loss": 0.3018,
      "step": 1349
    },
    {
      "epoch": 0.2145794838171306,
      "grad_norm": 0.5789698958396912,
      "learning_rate": 9.13305740183616e-06,
      "loss": 0.245,
      "step": 1350
    },
    {
      "epoch": 0.21473843158292105,
      "grad_norm": 0.6339703798294067,
      "learning_rate": 9.13160814587806e-06,
      "loss": 0.3384,
      "step": 1351
    },
    {
      "epoch": 0.21489737934871153,
      "grad_norm": 0.5173148512840271,
      "learning_rate": 9.130157794767825e-06,
      "loss": 0.1622,
      "step": 1352
    },
    {
      "epoch": 0.215056327114502,
      "grad_norm": 0.6187409162521362,
      "learning_rate": 9.128706348889895e-06,
      "loss": 0.2717,
      "step": 1353
    },
    {
      "epoch": 0.21521527488029246,
      "grad_norm": 0.7609419822692871,
      "learning_rate": 9.127253808629e-06,
      "loss": 0.298,
      "step": 1354
    },
    {
      "epoch": 0.21537422264608294,
      "grad_norm": 0.5779836773872375,
      "learning_rate": 9.12580017437016e-06,
      "loss": 0.2558,
      "step": 1355
    },
    {
      "epoch": 0.2155331704118734,
      "grad_norm": 0.5752668380737305,
      "learning_rate": 9.124345446498685e-06,
      "loss": 0.2594,
      "step": 1356
    },
    {
      "epoch": 0.21569211817766387,
      "grad_norm": 0.5587663054466248,
      "learning_rate": 9.122889625400175e-06,
      "loss": 0.1893,
      "step": 1357
    },
    {
      "epoch": 0.21585106594345432,
      "grad_norm": 0.5627209544181824,
      "learning_rate": 9.121432711460521e-06,
      "loss": 0.2308,
      "step": 1358
    },
    {
      "epoch": 0.2160100137092448,
      "grad_norm": 0.5179524421691895,
      "learning_rate": 9.119974705065902e-06,
      "loss": 0.2056,
      "step": 1359
    },
    {
      "epoch": 0.21616896147503525,
      "grad_norm": 0.6521059274673462,
      "learning_rate": 9.118515606602786e-06,
      "loss": 0.2986,
      "step": 1360
    },
    {
      "epoch": 0.21632790924082573,
      "grad_norm": 0.6398621797561646,
      "learning_rate": 9.117055416457931e-06,
      "loss": 0.3685,
      "step": 1361
    },
    {
      "epoch": 0.2164868570066162,
      "grad_norm": 0.5685462355613708,
      "learning_rate": 9.11559413501839e-06,
      "loss": 0.1991,
      "step": 1362
    },
    {
      "epoch": 0.21664580477240666,
      "grad_norm": 0.564197838306427,
      "learning_rate": 9.114131762671494e-06,
      "loss": 0.2544,
      "step": 1363
    },
    {
      "epoch": 0.21680475253819714,
      "grad_norm": 0.6371234059333801,
      "learning_rate": 9.112668299804871e-06,
      "loss": 0.4024,
      "step": 1364
    },
    {
      "epoch": 0.2169637003039876,
      "grad_norm": 0.6481654644012451,
      "learning_rate": 9.111203746806439e-06,
      "loss": 0.3804,
      "step": 1365
    },
    {
      "epoch": 0.21712264806977807,
      "grad_norm": 0.6132615804672241,
      "learning_rate": 9.1097381040644e-06,
      "loss": 0.2862,
      "step": 1366
    },
    {
      "epoch": 0.21728159583556853,
      "grad_norm": 2.244957208633423,
      "learning_rate": 9.108271371967247e-06,
      "loss": 0.1872,
      "step": 1367
    },
    {
      "epoch": 0.217440543601359,
      "grad_norm": 0.6982511281967163,
      "learning_rate": 9.106803550903765e-06,
      "loss": 0.2734,
      "step": 1368
    },
    {
      "epoch": 0.21759949136714948,
      "grad_norm": 0.7247628569602966,
      "learning_rate": 9.105334641263022e-06,
      "loss": 0.427,
      "step": 1369
    },
    {
      "epoch": 0.21775843913293993,
      "grad_norm": 0.6464287042617798,
      "learning_rate": 9.103864643434376e-06,
      "loss": 0.3552,
      "step": 1370
    },
    {
      "epoch": 0.21791738689873041,
      "grad_norm": 0.5517017841339111,
      "learning_rate": 9.102393557807476e-06,
      "loss": 0.1709,
      "step": 1371
    },
    {
      "epoch": 0.21807633466452087,
      "grad_norm": 0.6384478807449341,
      "learning_rate": 9.10092138477226e-06,
      "loss": 0.2436,
      "step": 1372
    },
    {
      "epoch": 0.21823528243031134,
      "grad_norm": 0.5334092974662781,
      "learning_rate": 9.09944812471895e-06,
      "loss": 0.2168,
      "step": 1373
    },
    {
      "epoch": 0.2183942301961018,
      "grad_norm": 0.5773296356201172,
      "learning_rate": 9.097973778038058e-06,
      "loss": 0.2761,
      "step": 1374
    },
    {
      "epoch": 0.21855317796189228,
      "grad_norm": 0.6926344633102417,
      "learning_rate": 9.096498345120386e-06,
      "loss": 0.255,
      "step": 1375
    },
    {
      "epoch": 0.21871212572768273,
      "grad_norm": 0.5873900651931763,
      "learning_rate": 9.09502182635702e-06,
      "loss": 0.2762,
      "step": 1376
    },
    {
      "epoch": 0.2188710734934732,
      "grad_norm": 0.5466423034667969,
      "learning_rate": 9.093544222139338e-06,
      "loss": 0.226,
      "step": 1377
    },
    {
      "epoch": 0.21903002125926369,
      "grad_norm": 0.5379108786582947,
      "learning_rate": 9.092065532859003e-06,
      "loss": 0.1347,
      "step": 1378
    },
    {
      "epoch": 0.21918896902505414,
      "grad_norm": 0.5536089539527893,
      "learning_rate": 9.090585758907966e-06,
      "loss": 0.1839,
      "step": 1379
    },
    {
      "epoch": 0.21934791679084462,
      "grad_norm": 0.6043499112129211,
      "learning_rate": 9.089104900678468e-06,
      "loss": 0.2487,
      "step": 1380
    },
    {
      "epoch": 0.21950686455663507,
      "grad_norm": 0.5171852707862854,
      "learning_rate": 9.087622958563033e-06,
      "loss": 0.2135,
      "step": 1381
    },
    {
      "epoch": 0.21966581232242555,
      "grad_norm": 0.5908963084220886,
      "learning_rate": 9.086139932954476e-06,
      "loss": 0.1997,
      "step": 1382
    },
    {
      "epoch": 0.219824760088216,
      "grad_norm": 0.5722616910934448,
      "learning_rate": 9.084655824245899e-06,
      "loss": 0.2376,
      "step": 1383
    },
    {
      "epoch": 0.21998370785400648,
      "grad_norm": 0.5804275870323181,
      "learning_rate": 9.083170632830686e-06,
      "loss": 0.2064,
      "step": 1384
    },
    {
      "epoch": 0.22014265561979696,
      "grad_norm": 0.5385906100273132,
      "learning_rate": 9.081684359102514e-06,
      "loss": 0.1975,
      "step": 1385
    },
    {
      "epoch": 0.2203016033855874,
      "grad_norm": 0.4583173394203186,
      "learning_rate": 9.080197003455347e-06,
      "loss": 0.1217,
      "step": 1386
    },
    {
      "epoch": 0.2204605511513779,
      "grad_norm": 0.5064978003501892,
      "learning_rate": 9.078708566283432e-06,
      "loss": 0.1837,
      "step": 1387
    },
    {
      "epoch": 0.22061949891716834,
      "grad_norm": 0.4959532618522644,
      "learning_rate": 9.077219047981303e-06,
      "loss": 0.1141,
      "step": 1388
    },
    {
      "epoch": 0.22077844668295882,
      "grad_norm": 0.4771563708782196,
      "learning_rate": 9.075728448943783e-06,
      "loss": 0.1449,
      "step": 1389
    },
    {
      "epoch": 0.22093739444874927,
      "grad_norm": 0.6941186189651489,
      "learning_rate": 9.074236769565979e-06,
      "loss": 0.2983,
      "step": 1390
    },
    {
      "epoch": 0.22109634221453975,
      "grad_norm": 0.4245920181274414,
      "learning_rate": 9.072744010243289e-06,
      "loss": 0.1226,
      "step": 1391
    },
    {
      "epoch": 0.22125528998033023,
      "grad_norm": 0.5373367667198181,
      "learning_rate": 9.071250171371391e-06,
      "loss": 0.1986,
      "step": 1392
    },
    {
      "epoch": 0.22141423774612068,
      "grad_norm": 0.546952486038208,
      "learning_rate": 9.069755253346251e-06,
      "loss": 0.1473,
      "step": 1393
    },
    {
      "epoch": 0.22157318551191116,
      "grad_norm": 0.5795486569404602,
      "learning_rate": 9.068259256564125e-06,
      "loss": 0.2168,
      "step": 1394
    },
    {
      "epoch": 0.2217321332777016,
      "grad_norm": 0.6727731823921204,
      "learning_rate": 9.066762181421552e-06,
      "loss": 0.2499,
      "step": 1395
    },
    {
      "epoch": 0.2218910810434921,
      "grad_norm": 0.8724284768104553,
      "learning_rate": 9.065264028315355e-06,
      "loss": 0.1699,
      "step": 1396
    },
    {
      "epoch": 0.22205002880928254,
      "grad_norm": 0.4686731696128845,
      "learning_rate": 9.063764797642647e-06,
      "loss": 0.1885,
      "step": 1397
    },
    {
      "epoch": 0.22220897657507302,
      "grad_norm": 0.6811093091964722,
      "learning_rate": 9.062264489800823e-06,
      "loss": 0.3763,
      "step": 1398
    },
    {
      "epoch": 0.22236792434086347,
      "grad_norm": 0.608900785446167,
      "learning_rate": 9.060763105187562e-06,
      "loss": 0.285,
      "step": 1399
    },
    {
      "epoch": 0.22252687210665395,
      "grad_norm": 0.5593289136886597,
      "learning_rate": 9.059260644200836e-06,
      "loss": 0.2778,
      "step": 1400
    },
    {
      "epoch": 0.22268581987244443,
      "grad_norm": 0.5784389972686768,
      "learning_rate": 9.057757107238897e-06,
      "loss": 0.2637,
      "step": 1401
    },
    {
      "epoch": 0.22284476763823488,
      "grad_norm": 0.5863272547721863,
      "learning_rate": 9.056252494700278e-06,
      "loss": 0.2675,
      "step": 1402
    },
    {
      "epoch": 0.22300371540402536,
      "grad_norm": 0.49610212445259094,
      "learning_rate": 9.054746806983806e-06,
      "loss": 0.1813,
      "step": 1403
    },
    {
      "epoch": 0.2231626631698158,
      "grad_norm": 0.5816887617111206,
      "learning_rate": 9.053240044488587e-06,
      "loss": 0.1827,
      "step": 1404
    },
    {
      "epoch": 0.2233216109356063,
      "grad_norm": 0.6146851778030396,
      "learning_rate": 9.051732207614014e-06,
      "loss": 0.3018,
      "step": 1405
    },
    {
      "epoch": 0.22348055870139674,
      "grad_norm": 0.6470179557800293,
      "learning_rate": 9.050223296759768e-06,
      "loss": 0.3049,
      "step": 1406
    },
    {
      "epoch": 0.22363950646718722,
      "grad_norm": 0.6619890332221985,
      "learning_rate": 9.048713312325806e-06,
      "loss": 0.2958,
      "step": 1407
    },
    {
      "epoch": 0.2237984542329777,
      "grad_norm": 0.5915316939353943,
      "learning_rate": 9.047202254712378e-06,
      "loss": 0.3025,
      "step": 1408
    },
    {
      "epoch": 0.22395740199876815,
      "grad_norm": 0.6319730281829834,
      "learning_rate": 9.045690124320013e-06,
      "loss": 0.2488,
      "step": 1409
    },
    {
      "epoch": 0.22411634976455863,
      "grad_norm": 0.7105380296707153,
      "learning_rate": 9.044176921549527e-06,
      "loss": 0.4191,
      "step": 1410
    },
    {
      "epoch": 0.22427529753034908,
      "grad_norm": 0.5682350397109985,
      "learning_rate": 9.042662646802023e-06,
      "loss": 0.2609,
      "step": 1411
    },
    {
      "epoch": 0.22443424529613956,
      "grad_norm": 0.5890820622444153,
      "learning_rate": 9.04114730047888e-06,
      "loss": 0.2683,
      "step": 1412
    },
    {
      "epoch": 0.22459319306193,
      "grad_norm": 0.7176281809806824,
      "learning_rate": 9.039630882981769e-06,
      "loss": 0.3817,
      "step": 1413
    },
    {
      "epoch": 0.2247521408277205,
      "grad_norm": 0.7094361186027527,
      "learning_rate": 9.038113394712642e-06,
      "loss": 0.2096,
      "step": 1414
    },
    {
      "epoch": 0.22491108859351094,
      "grad_norm": 4.12414026260376,
      "learning_rate": 9.036594836073733e-06,
      "loss": 0.1848,
      "step": 1415
    },
    {
      "epoch": 0.22507003635930142,
      "grad_norm": 0.6434813141822815,
      "learning_rate": 9.035075207467564e-06,
      "loss": 0.351,
      "step": 1416
    },
    {
      "epoch": 0.2252289841250919,
      "grad_norm": 0.555164635181427,
      "learning_rate": 9.033554509296935e-06,
      "loss": 0.2521,
      "step": 1417
    },
    {
      "epoch": 0.22538793189088235,
      "grad_norm": 0.5831575989723206,
      "learning_rate": 9.032032741964936e-06,
      "loss": 0.2202,
      "step": 1418
    },
    {
      "epoch": 0.22554687965667283,
      "grad_norm": 0.6097381114959717,
      "learning_rate": 9.030509905874934e-06,
      "loss": 0.2372,
      "step": 1419
    },
    {
      "epoch": 0.22570582742246328,
      "grad_norm": 0.5073509216308594,
      "learning_rate": 9.028986001430584e-06,
      "loss": 0.2347,
      "step": 1420
    },
    {
      "epoch": 0.22586477518825376,
      "grad_norm": 0.5633249282836914,
      "learning_rate": 9.027461029035821e-06,
      "loss": 0.2494,
      "step": 1421
    },
    {
      "epoch": 0.22602372295404421,
      "grad_norm": 0.6387967467308044,
      "learning_rate": 9.025934989094866e-06,
      "loss": 0.3591,
      "step": 1422
    },
    {
      "epoch": 0.2261826707198347,
      "grad_norm": 0.587700366973877,
      "learning_rate": 9.024407882012223e-06,
      "loss": 0.2974,
      "step": 1423
    },
    {
      "epoch": 0.22634161848562517,
      "grad_norm": 0.6038728952407837,
      "learning_rate": 9.022879708192674e-06,
      "loss": 0.3527,
      "step": 1424
    },
    {
      "epoch": 0.22650056625141562,
      "grad_norm": 1.0841751098632812,
      "learning_rate": 9.021350468041287e-06,
      "loss": 0.1773,
      "step": 1425
    },
    {
      "epoch": 0.2266595140172061,
      "grad_norm": 0.8224171996116638,
      "learning_rate": 9.019820161963415e-06,
      "loss": 0.4317,
      "step": 1426
    },
    {
      "epoch": 0.22681846178299656,
      "grad_norm": 0.8271178603172302,
      "learning_rate": 9.018288790364692e-06,
      "loss": 0.1933,
      "step": 1427
    },
    {
      "epoch": 0.22697740954878703,
      "grad_norm": 0.5206484794616699,
      "learning_rate": 9.016756353651032e-06,
      "loss": 0.2377,
      "step": 1428
    },
    {
      "epoch": 0.22713635731457749,
      "grad_norm": 1.9466198682785034,
      "learning_rate": 9.015222852228634e-06,
      "loss": 0.2272,
      "step": 1429
    },
    {
      "epoch": 0.22729530508036797,
      "grad_norm": 0.6258533000946045,
      "learning_rate": 9.013688286503977e-06,
      "loss": 0.2047,
      "step": 1430
    },
    {
      "epoch": 0.22745425284615844,
      "grad_norm": 5.339234828948975,
      "learning_rate": 9.012152656883824e-06,
      "loss": 0.2089,
      "step": 1431
    },
    {
      "epoch": 0.2276132006119489,
      "grad_norm": 0.6070773005485535,
      "learning_rate": 9.01061596377522e-06,
      "loss": 0.1733,
      "step": 1432
    },
    {
      "epoch": 0.22777214837773938,
      "grad_norm": 0.6023798584938049,
      "learning_rate": 9.009078207585491e-06,
      "loss": 0.2858,
      "step": 1433
    },
    {
      "epoch": 0.22793109614352983,
      "grad_norm": 0.5039433836936951,
      "learning_rate": 9.007539388722245e-06,
      "loss": 0.1602,
      "step": 1434
    },
    {
      "epoch": 0.2280900439093203,
      "grad_norm": 0.899470329284668,
      "learning_rate": 9.005999507593373e-06,
      "loss": 0.2206,
      "step": 1435
    },
    {
      "epoch": 0.22824899167511076,
      "grad_norm": 0.5592594742774963,
      "learning_rate": 9.004458564607043e-06,
      "loss": 0.1869,
      "step": 1436
    },
    {
      "epoch": 0.22840793944090124,
      "grad_norm": 0.6388521790504456,
      "learning_rate": 9.002916560171713e-06,
      "loss": 0.3354,
      "step": 1437
    },
    {
      "epoch": 0.2285668872066917,
      "grad_norm": 0.517170250415802,
      "learning_rate": 9.001373494696113e-06,
      "loss": 0.2009,
      "step": 1438
    },
    {
      "epoch": 0.22872583497248217,
      "grad_norm": 0.5423389673233032,
      "learning_rate": 8.999829368589258e-06,
      "loss": 0.1896,
      "step": 1439
    },
    {
      "epoch": 0.22888478273827265,
      "grad_norm": 0.6143364310264587,
      "learning_rate": 8.998284182260448e-06,
      "loss": 0.2404,
      "step": 1440
    },
    {
      "epoch": 0.2290437305040631,
      "grad_norm": 0.7445533275604248,
      "learning_rate": 8.996737936119257e-06,
      "loss": 0.2678,
      "step": 1441
    },
    {
      "epoch": 0.22920267826985358,
      "grad_norm": 0.6985602378845215,
      "learning_rate": 8.995190630575547e-06,
      "loss": 0.3322,
      "step": 1442
    },
    {
      "epoch": 0.22936162603564403,
      "grad_norm": 0.5118439793586731,
      "learning_rate": 8.993642266039457e-06,
      "loss": 0.1699,
      "step": 1443
    },
    {
      "epoch": 0.2295205738014345,
      "grad_norm": 0.6677566170692444,
      "learning_rate": 8.992092842921403e-06,
      "loss": 0.2969,
      "step": 1444
    },
    {
      "epoch": 0.22967952156722496,
      "grad_norm": 0.6533506512641907,
      "learning_rate": 8.99054236163209e-06,
      "loss": 0.1953,
      "step": 1445
    },
    {
      "epoch": 0.22983846933301544,
      "grad_norm": 0.7137758135795593,
      "learning_rate": 8.988990822582497e-06,
      "loss": 0.4607,
      "step": 1446
    },
    {
      "epoch": 0.22999741709880592,
      "grad_norm": 0.6059355735778809,
      "learning_rate": 8.987438226183886e-06,
      "loss": 0.2583,
      "step": 1447
    },
    {
      "epoch": 0.23015636486459637,
      "grad_norm": 0.5643770694732666,
      "learning_rate": 8.985884572847799e-06,
      "loss": 0.2498,
      "step": 1448
    },
    {
      "epoch": 0.23031531263038685,
      "grad_norm": 0.5386871099472046,
      "learning_rate": 8.984329862986056e-06,
      "loss": 0.1942,
      "step": 1449
    },
    {
      "epoch": 0.2304742603961773,
      "grad_norm": 0.6407085061073303,
      "learning_rate": 8.982774097010762e-06,
      "loss": 0.2086,
      "step": 1450
    },
    {
      "epoch": 0.23063320816196778,
      "grad_norm": 0.6320650577545166,
      "learning_rate": 8.981217275334297e-06,
      "loss": 0.2866,
      "step": 1451
    },
    {
      "epoch": 0.23079215592775823,
      "grad_norm": 0.8035076856613159,
      "learning_rate": 8.979659398369323e-06,
      "loss": 0.1939,
      "step": 1452
    },
    {
      "epoch": 0.2309511036935487,
      "grad_norm": 0.6230798959732056,
      "learning_rate": 8.978100466528781e-06,
      "loss": 0.2935,
      "step": 1453
    },
    {
      "epoch": 0.23111005145933916,
      "grad_norm": 0.5719193816184998,
      "learning_rate": 8.976540480225894e-06,
      "loss": 0.196,
      "step": 1454
    },
    {
      "epoch": 0.23126899922512964,
      "grad_norm": 0.5623413920402527,
      "learning_rate": 8.974979439874161e-06,
      "loss": 0.2294,
      "step": 1455
    },
    {
      "epoch": 0.23142794699092012,
      "grad_norm": 0.5935807228088379,
      "learning_rate": 8.97341734588736e-06,
      "loss": 0.3217,
      "step": 1456
    },
    {
      "epoch": 0.23158689475671057,
      "grad_norm": 0.8851186037063599,
      "learning_rate": 8.971854198679556e-06,
      "loss": 0.3652,
      "step": 1457
    },
    {
      "epoch": 0.23174584252250105,
      "grad_norm": 0.6204185485839844,
      "learning_rate": 8.970289998665083e-06,
      "loss": 0.2498,
      "step": 1458
    },
    {
      "epoch": 0.2319047902882915,
      "grad_norm": 0.53363037109375,
      "learning_rate": 8.968724746258558e-06,
      "loss": 0.2318,
      "step": 1459
    },
    {
      "epoch": 0.23206373805408198,
      "grad_norm": 0.5231325626373291,
      "learning_rate": 8.967158441874879e-06,
      "loss": 0.2924,
      "step": 1460
    },
    {
      "epoch": 0.23222268581987243,
      "grad_norm": 0.6184788942337036,
      "learning_rate": 8.965591085929222e-06,
      "loss": 0.2637,
      "step": 1461
    },
    {
      "epoch": 0.2323816335856629,
      "grad_norm": 0.5674688816070557,
      "learning_rate": 8.96402267883704e-06,
      "loss": 0.2683,
      "step": 1462
    },
    {
      "epoch": 0.2325405813514534,
      "grad_norm": 0.6948736310005188,
      "learning_rate": 8.962453221014065e-06,
      "loss": 0.3774,
      "step": 1463
    },
    {
      "epoch": 0.23269952911724384,
      "grad_norm": 0.7558566927909851,
      "learning_rate": 8.96088271287631e-06,
      "loss": 0.3825,
      "step": 1464
    },
    {
      "epoch": 0.23285847688303432,
      "grad_norm": 0.6012505292892456,
      "learning_rate": 8.959311154840063e-06,
      "loss": 0.2975,
      "step": 1465
    },
    {
      "epoch": 0.23301742464882477,
      "grad_norm": 0.6933932304382324,
      "learning_rate": 8.957738547321892e-06,
      "loss": 0.3671,
      "step": 1466
    },
    {
      "epoch": 0.23317637241461525,
      "grad_norm": 0.5381906032562256,
      "learning_rate": 8.956164890738643e-06,
      "loss": 0.226,
      "step": 1467
    },
    {
      "epoch": 0.2333353201804057,
      "grad_norm": 1.1601879596710205,
      "learning_rate": 8.95459018550744e-06,
      "loss": 0.2277,
      "step": 1468
    },
    {
      "epoch": 0.23349426794619618,
      "grad_norm": 0.5609063506126404,
      "learning_rate": 8.95301443204569e-06,
      "loss": 0.2154,
      "step": 1469
    },
    {
      "epoch": 0.23365321571198666,
      "grad_norm": 0.5029638409614563,
      "learning_rate": 8.951437630771065e-06,
      "loss": 0.1632,
      "step": 1470
    },
    {
      "epoch": 0.2338121634777771,
      "grad_norm": 0.7627411484718323,
      "learning_rate": 8.949859782101526e-06,
      "loss": 0.4184,
      "step": 1471
    },
    {
      "epoch": 0.2339711112435676,
      "grad_norm": 0.6953269243240356,
      "learning_rate": 8.948280886455308e-06,
      "loss": 0.391,
      "step": 1472
    },
    {
      "epoch": 0.23413005900935804,
      "grad_norm": 0.5154257416725159,
      "learning_rate": 8.946700944250925e-06,
      "loss": 0.2288,
      "step": 1473
    },
    {
      "epoch": 0.23428900677514852,
      "grad_norm": 0.6169201135635376,
      "learning_rate": 8.945119955907166e-06,
      "loss": 0.2331,
      "step": 1474
    },
    {
      "epoch": 0.23444795454093897,
      "grad_norm": 0.6578251719474792,
      "learning_rate": 8.9435379218431e-06,
      "loss": 0.3367,
      "step": 1475
    },
    {
      "epoch": 0.23460690230672945,
      "grad_norm": 0.6869258880615234,
      "learning_rate": 8.941954842478071e-06,
      "loss": 0.3785,
      "step": 1476
    },
    {
      "epoch": 0.2347658500725199,
      "grad_norm": 0.5776644945144653,
      "learning_rate": 8.940370718231699e-06,
      "loss": 0.276,
      "step": 1477
    },
    {
      "epoch": 0.23492479783831038,
      "grad_norm": 0.48039352893829346,
      "learning_rate": 8.938785549523885e-06,
      "loss": 0.2257,
      "step": 1478
    },
    {
      "epoch": 0.23508374560410086,
      "grad_norm": 0.5448310971260071,
      "learning_rate": 8.937199336774805e-06,
      "loss": 0.1902,
      "step": 1479
    },
    {
      "epoch": 0.23524269336989131,
      "grad_norm": 0.6035172939300537,
      "learning_rate": 8.935612080404907e-06,
      "loss": 0.2413,
      "step": 1480
    },
    {
      "epoch": 0.2354016411356818,
      "grad_norm": 0.8453184962272644,
      "learning_rate": 8.934023780834926e-06,
      "loss": 0.2026,
      "step": 1481
    },
    {
      "epoch": 0.23556058890147225,
      "grad_norm": 0.6705960631370544,
      "learning_rate": 8.932434438485864e-06,
      "loss": 0.2947,
      "step": 1482
    },
    {
      "epoch": 0.23571953666726272,
      "grad_norm": 0.5499978065490723,
      "learning_rate": 8.930844053779002e-06,
      "loss": 0.1839,
      "step": 1483
    },
    {
      "epoch": 0.23587848443305318,
      "grad_norm": 0.6647804975509644,
      "learning_rate": 8.929252627135901e-06,
      "loss": 0.3563,
      "step": 1484
    },
    {
      "epoch": 0.23603743219884366,
      "grad_norm": 0.8576536774635315,
      "learning_rate": 8.927660158978392e-06,
      "loss": 0.2465,
      "step": 1485
    },
    {
      "epoch": 0.23619637996463413,
      "grad_norm": 0.5962234735488892,
      "learning_rate": 8.92606664972859e-06,
      "loss": 0.271,
      "step": 1486
    },
    {
      "epoch": 0.23635532773042459,
      "grad_norm": 0.4902828633785248,
      "learning_rate": 8.924472099808878e-06,
      "loss": 0.1653,
      "step": 1487
    },
    {
      "epoch": 0.23651427549621507,
      "grad_norm": 0.5904030799865723,
      "learning_rate": 8.92287650964192e-06,
      "loss": 0.3057,
      "step": 1488
    },
    {
      "epoch": 0.23667322326200552,
      "grad_norm": 0.5597796440124512,
      "learning_rate": 8.921279879650651e-06,
      "loss": 0.3118,
      "step": 1489
    },
    {
      "epoch": 0.236832171027796,
      "grad_norm": 0.5950592160224915,
      "learning_rate": 8.919682210258287e-06,
      "loss": 0.1704,
      "step": 1490
    },
    {
      "epoch": 0.23699111879358645,
      "grad_norm": 0.539215087890625,
      "learning_rate": 8.918083501888318e-06,
      "loss": 0.2551,
      "step": 1491
    },
    {
      "epoch": 0.23715006655937693,
      "grad_norm": 0.4948407709598541,
      "learning_rate": 8.916483754964506e-06,
      "loss": 0.1694,
      "step": 1492
    },
    {
      "epoch": 0.2373090143251674,
      "grad_norm": 0.5784921050071716,
      "learning_rate": 8.914882969910891e-06,
      "loss": 0.2827,
      "step": 1493
    },
    {
      "epoch": 0.23746796209095786,
      "grad_norm": 0.5492063164710999,
      "learning_rate": 8.913281147151793e-06,
      "loss": 0.2332,
      "step": 1494
    },
    {
      "epoch": 0.23762690985674834,
      "grad_norm": 0.5139246582984924,
      "learning_rate": 8.911678287111795e-06,
      "loss": 0.2045,
      "step": 1495
    },
    {
      "epoch": 0.2377858576225388,
      "grad_norm": 0.5658360719680786,
      "learning_rate": 8.910074390215766e-06,
      "loss": 0.2596,
      "step": 1496
    },
    {
      "epoch": 0.23794480538832927,
      "grad_norm": 0.5911167860031128,
      "learning_rate": 8.908469456888845e-06,
      "loss": 0.2112,
      "step": 1497
    },
    {
      "epoch": 0.23810375315411972,
      "grad_norm": 0.4965025782585144,
      "learning_rate": 8.906863487556443e-06,
      "loss": 0.2004,
      "step": 1498
    },
    {
      "epoch": 0.2382627009199102,
      "grad_norm": 0.504237711429596,
      "learning_rate": 8.905256482644256e-06,
      "loss": 0.2233,
      "step": 1499
    },
    {
      "epoch": 0.23842164868570065,
      "grad_norm": 0.8510310649871826,
      "learning_rate": 8.903648442578244e-06,
      "loss": 0.2832,
      "step": 1500
    },
    {
      "epoch": 0.23858059645149113,
      "grad_norm": 0.5518277287483215,
      "learning_rate": 8.902039367784645e-06,
      "loss": 0.2575,
      "step": 1501
    },
    {
      "epoch": 0.2387395442172816,
      "grad_norm": 0.46595340967178345,
      "learning_rate": 8.90042925868997e-06,
      "loss": 0.1537,
      "step": 1502
    },
    {
      "epoch": 0.23889849198307206,
      "grad_norm": 0.6186582446098328,
      "learning_rate": 8.898818115721009e-06,
      "loss": 0.3107,
      "step": 1503
    },
    {
      "epoch": 0.23905743974886254,
      "grad_norm": 0.5058174729347229,
      "learning_rate": 8.897205939304819e-06,
      "loss": 0.2351,
      "step": 1504
    },
    {
      "epoch": 0.239216387514653,
      "grad_norm": 0.5993143916130066,
      "learning_rate": 8.895592729868736e-06,
      "loss": 0.3305,
      "step": 1505
    },
    {
      "epoch": 0.23937533528044347,
      "grad_norm": 0.4175272583961487,
      "learning_rate": 8.893978487840367e-06,
      "loss": 0.1312,
      "step": 1506
    },
    {
      "epoch": 0.23953428304623392,
      "grad_norm": 0.5630750060081482,
      "learning_rate": 8.892363213647597e-06,
      "loss": 0.2639,
      "step": 1507
    },
    {
      "epoch": 0.2396932308120244,
      "grad_norm": 0.5632078647613525,
      "learning_rate": 8.890746907718579e-06,
      "loss": 0.2556,
      "step": 1508
    },
    {
      "epoch": 0.23985217857781488,
      "grad_norm": 0.5459447503089905,
      "learning_rate": 8.889129570481742e-06,
      "loss": 0.2687,
      "step": 1509
    },
    {
      "epoch": 0.24001112634360533,
      "grad_norm": 0.4891301989555359,
      "learning_rate": 8.887511202365791e-06,
      "loss": 0.1392,
      "step": 1510
    },
    {
      "epoch": 0.2401700741093958,
      "grad_norm": 0.6384308338165283,
      "learning_rate": 8.885891803799697e-06,
      "loss": 0.268,
      "step": 1511
    },
    {
      "epoch": 0.24032902187518626,
      "grad_norm": 0.620553731918335,
      "learning_rate": 8.884271375212714e-06,
      "loss": 0.1963,
      "step": 1512
    },
    {
      "epoch": 0.24048796964097674,
      "grad_norm": 0.5516260862350464,
      "learning_rate": 8.88264991703436e-06,
      "loss": 0.2662,
      "step": 1513
    },
    {
      "epoch": 0.2406469174067672,
      "grad_norm": 0.5867634415626526,
      "learning_rate": 8.881027429694433e-06,
      "loss": 0.2955,
      "step": 1514
    },
    {
      "epoch": 0.24080586517255767,
      "grad_norm": 0.5655052065849304,
      "learning_rate": 8.879403913622996e-06,
      "loss": 0.2731,
      "step": 1515
    },
    {
      "epoch": 0.24096481293834812,
      "grad_norm": 0.6265062093734741,
      "learning_rate": 8.877779369250394e-06,
      "loss": 0.3433,
      "step": 1516
    },
    {
      "epoch": 0.2411237607041386,
      "grad_norm": 0.7549909949302673,
      "learning_rate": 8.876153797007235e-06,
      "loss": 0.3728,
      "step": 1517
    },
    {
      "epoch": 0.24128270846992908,
      "grad_norm": 0.5241219997406006,
      "learning_rate": 8.87452719732441e-06,
      "loss": 0.192,
      "step": 1518
    },
    {
      "epoch": 0.24144165623571953,
      "grad_norm": 0.5278089046478271,
      "learning_rate": 8.872899570633071e-06,
      "loss": 0.2041,
      "step": 1519
    },
    {
      "epoch": 0.24160060400151,
      "grad_norm": 0.6404463052749634,
      "learning_rate": 8.87127091736465e-06,
      "loss": 0.3303,
      "step": 1520
    },
    {
      "epoch": 0.24175955176730046,
      "grad_norm": 0.5251197814941406,
      "learning_rate": 8.86964123795085e-06,
      "loss": 0.1395,
      "step": 1521
    },
    {
      "epoch": 0.24191849953309094,
      "grad_norm": 0.5647996068000793,
      "learning_rate": 8.868010532823644e-06,
      "loss": 0.2573,
      "step": 1522
    },
    {
      "epoch": 0.2420774472988814,
      "grad_norm": 0.5887165069580078,
      "learning_rate": 8.866378802415277e-06,
      "loss": 0.2388,
      "step": 1523
    },
    {
      "epoch": 0.24223639506467187,
      "grad_norm": 0.5302605032920837,
      "learning_rate": 8.864746047158267e-06,
      "loss": 0.1717,
      "step": 1524
    },
    {
      "epoch": 0.24239534283046235,
      "grad_norm": 0.5199137926101685,
      "learning_rate": 8.863112267485405e-06,
      "loss": 0.193,
      "step": 1525
    },
    {
      "epoch": 0.2425542905962528,
      "grad_norm": 0.8949974179267883,
      "learning_rate": 8.861477463829748e-06,
      "loss": 0.2316,
      "step": 1526
    },
    {
      "epoch": 0.24271323836204328,
      "grad_norm": 0.5220600366592407,
      "learning_rate": 8.859841636624632e-06,
      "loss": 0.1966,
      "step": 1527
    },
    {
      "epoch": 0.24287218612783373,
      "grad_norm": 0.7056722640991211,
      "learning_rate": 8.858204786303658e-06,
      "loss": 0.4387,
      "step": 1528
    },
    {
      "epoch": 0.2430311338936242,
      "grad_norm": 0.5667027235031128,
      "learning_rate": 8.856566913300703e-06,
      "loss": 0.2779,
      "step": 1529
    },
    {
      "epoch": 0.24319008165941466,
      "grad_norm": 0.5611714720726013,
      "learning_rate": 8.85492801804991e-06,
      "loss": 0.2504,
      "step": 1530
    },
    {
      "epoch": 0.24334902942520514,
      "grad_norm": 0.5956385135650635,
      "learning_rate": 8.853288100985698e-06,
      "loss": 0.2075,
      "step": 1531
    },
    {
      "epoch": 0.24350797719099562,
      "grad_norm": 0.5967864990234375,
      "learning_rate": 8.851647162542753e-06,
      "loss": 0.2495,
      "step": 1532
    },
    {
      "epoch": 0.24366692495678607,
      "grad_norm": 0.6020870804786682,
      "learning_rate": 8.850005203156035e-06,
      "loss": 0.3134,
      "step": 1533
    },
    {
      "epoch": 0.24382587272257655,
      "grad_norm": 0.45812392234802246,
      "learning_rate": 8.84836222326077e-06,
      "loss": 0.1701,
      "step": 1534
    },
    {
      "epoch": 0.243984820488367,
      "grad_norm": 0.4774402678012848,
      "learning_rate": 8.846718223292461e-06,
      "loss": 0.1554,
      "step": 1535
    },
    {
      "epoch": 0.24414376825415748,
      "grad_norm": 0.5770247578620911,
      "learning_rate": 8.845073203686874e-06,
      "loss": 0.3031,
      "step": 1536
    },
    {
      "epoch": 0.24430271601994794,
      "grad_norm": 0.5404133200645447,
      "learning_rate": 8.843427164880052e-06,
      "loss": 0.2619,
      "step": 1537
    },
    {
      "epoch": 0.24446166378573841,
      "grad_norm": 0.4920059144496918,
      "learning_rate": 8.841780107308304e-06,
      "loss": 0.2119,
      "step": 1538
    },
    {
      "epoch": 0.24462061155152887,
      "grad_norm": 0.6617791652679443,
      "learning_rate": 8.84013203140821e-06,
      "loss": 0.3067,
      "step": 1539
    },
    {
      "epoch": 0.24477955931731935,
      "grad_norm": 0.5848733186721802,
      "learning_rate": 8.838482937616623e-06,
      "loss": 0.3089,
      "step": 1540
    },
    {
      "epoch": 0.24493850708310982,
      "grad_norm": 0.5706285834312439,
      "learning_rate": 8.83683282637066e-06,
      "loss": 0.3663,
      "step": 1541
    },
    {
      "epoch": 0.24509745484890028,
      "grad_norm": 0.6017156839370728,
      "learning_rate": 8.83518169810771e-06,
      "loss": 0.2484,
      "step": 1542
    },
    {
      "epoch": 0.24525640261469075,
      "grad_norm": 0.493488609790802,
      "learning_rate": 8.833529553265437e-06,
      "loss": 0.2116,
      "step": 1543
    },
    {
      "epoch": 0.2454153503804812,
      "grad_norm": 0.5960364937782288,
      "learning_rate": 8.831876392281763e-06,
      "loss": 0.2946,
      "step": 1544
    },
    {
      "epoch": 0.24557429814627169,
      "grad_norm": 0.7340980172157288,
      "learning_rate": 8.83022221559489e-06,
      "loss": 0.2287,
      "step": 1545
    },
    {
      "epoch": 0.24573324591206214,
      "grad_norm": 0.50015789270401,
      "learning_rate": 8.828567023643287e-06,
      "loss": 0.1341,
      "step": 1546
    },
    {
      "epoch": 0.24589219367785262,
      "grad_norm": 0.5027156472206116,
      "learning_rate": 8.826910816865687e-06,
      "loss": 0.2017,
      "step": 1547
    },
    {
      "epoch": 0.2460511414436431,
      "grad_norm": 0.5563527941703796,
      "learning_rate": 8.825253595701097e-06,
      "loss": 0.1902,
      "step": 1548
    },
    {
      "epoch": 0.24621008920943355,
      "grad_norm": 0.5753066539764404,
      "learning_rate": 8.823595360588791e-06,
      "loss": 0.2558,
      "step": 1549
    },
    {
      "epoch": 0.24636903697522403,
      "grad_norm": 0.5673471093177795,
      "learning_rate": 8.821936111968312e-06,
      "loss": 0.2101,
      "step": 1550
    },
    {
      "epoch": 0.24652798474101448,
      "grad_norm": 0.5677931904792786,
      "learning_rate": 8.820275850279473e-06,
      "loss": 0.2112,
      "step": 1551
    },
    {
      "epoch": 0.24668693250680496,
      "grad_norm": 0.5127156972885132,
      "learning_rate": 8.818614575962352e-06,
      "loss": 0.2069,
      "step": 1552
    },
    {
      "epoch": 0.2468458802725954,
      "grad_norm": 0.6109454035758972,
      "learning_rate": 8.816952289457298e-06,
      "loss": 0.2691,
      "step": 1553
    },
    {
      "epoch": 0.2470048280383859,
      "grad_norm": 0.61966472864151,
      "learning_rate": 8.815288991204932e-06,
      "loss": 0.2738,
      "step": 1554
    },
    {
      "epoch": 0.24716377580417634,
      "grad_norm": 0.6626712083816528,
      "learning_rate": 8.813624681646131e-06,
      "loss": 0.3133,
      "step": 1555
    },
    {
      "epoch": 0.24732272356996682,
      "grad_norm": 0.5137765407562256,
      "learning_rate": 8.811959361222056e-06,
      "loss": 0.2273,
      "step": 1556
    },
    {
      "epoch": 0.2474816713357573,
      "grad_norm": 0.6357101798057556,
      "learning_rate": 8.810293030374126e-06,
      "loss": 0.3398,
      "step": 1557
    },
    {
      "epoch": 0.24764061910154775,
      "grad_norm": 0.5167413949966431,
      "learning_rate": 8.808625689544027e-06,
      "loss": 0.2214,
      "step": 1558
    },
    {
      "epoch": 0.24779956686733823,
      "grad_norm": 0.4973461925983429,
      "learning_rate": 8.80695733917372e-06,
      "loss": 0.1395,
      "step": 1559
    },
    {
      "epoch": 0.24795851463312868,
      "grad_norm": 0.5229418277740479,
      "learning_rate": 8.805287979705425e-06,
      "loss": 0.247,
      "step": 1560
    },
    {
      "epoch": 0.24811746239891916,
      "grad_norm": 0.6241110563278198,
      "learning_rate": 8.803617611581638e-06,
      "loss": 0.2242,
      "step": 1561
    },
    {
      "epoch": 0.2482764101647096,
      "grad_norm": 0.688291609287262,
      "learning_rate": 8.801946235245116e-06,
      "loss": 0.2343,
      "step": 1562
    },
    {
      "epoch": 0.2484353579305001,
      "grad_norm": 0.6320724487304688,
      "learning_rate": 8.800273851138882e-06,
      "loss": 0.3638,
      "step": 1563
    },
    {
      "epoch": 0.24859430569629057,
      "grad_norm": 0.7705875039100647,
      "learning_rate": 8.798600459706237e-06,
      "loss": 0.4746,
      "step": 1564
    },
    {
      "epoch": 0.24875325346208102,
      "grad_norm": 0.5772733092308044,
      "learning_rate": 8.796926061390735e-06,
      "loss": 0.3401,
      "step": 1565
    },
    {
      "epoch": 0.2489122012278715,
      "grad_norm": 0.6231255531311035,
      "learning_rate": 8.795250656636207e-06,
      "loss": 0.2448,
      "step": 1566
    },
    {
      "epoch": 0.24907114899366195,
      "grad_norm": 0.5769446492195129,
      "learning_rate": 8.793574245886747e-06,
      "loss": 0.2481,
      "step": 1567
    },
    {
      "epoch": 0.24923009675945243,
      "grad_norm": 0.46104514598846436,
      "learning_rate": 8.791896829586713e-06,
      "loss": 0.1711,
      "step": 1568
    },
    {
      "epoch": 0.24938904452524288,
      "grad_norm": 0.8380531072616577,
      "learning_rate": 8.790218408180736e-06,
      "loss": 0.4399,
      "step": 1569
    },
    {
      "epoch": 0.24954799229103336,
      "grad_norm": 0.5184769630432129,
      "learning_rate": 8.788538982113706e-06,
      "loss": 0.231,
      "step": 1570
    },
    {
      "epoch": 0.24970694005682384,
      "grad_norm": 0.6154674887657166,
      "learning_rate": 8.786858551830787e-06,
      "loss": 0.2984,
      "step": 1571
    },
    {
      "epoch": 0.2498658878226143,
      "grad_norm": 0.516196072101593,
      "learning_rate": 8.785177117777401e-06,
      "loss": 0.2082,
      "step": 1572
    },
    {
      "epoch": 0.25002483558840477,
      "grad_norm": 0.6206950545310974,
      "learning_rate": 8.783494680399246e-06,
      "loss": 0.2589,
      "step": 1573
    },
    {
      "epoch": 0.2501837833541952,
      "grad_norm": 0.5495589971542358,
      "learning_rate": 8.781811240142275e-06,
      "loss": 0.2624,
      "step": 1574
    },
    {
      "epoch": 0.2503427311199857,
      "grad_norm": 0.6119630336761475,
      "learning_rate": 8.780126797452713e-06,
      "loss": 0.2504,
      "step": 1575
    },
    {
      "epoch": 0.2505016788857762,
      "grad_norm": 0.5307334661483765,
      "learning_rate": 8.778441352777052e-06,
      "loss": 0.2171,
      "step": 1576
    },
    {
      "epoch": 0.25066062665156663,
      "grad_norm": 0.561527669429779,
      "learning_rate": 8.776754906562048e-06,
      "loss": 0.2552,
      "step": 1577
    },
    {
      "epoch": 0.2508195744173571,
      "grad_norm": 0.4860438406467438,
      "learning_rate": 8.775067459254718e-06,
      "loss": 0.2004,
      "step": 1578
    },
    {
      "epoch": 0.2509785221831476,
      "grad_norm": 0.577470600605011,
      "learning_rate": 8.773379011302351e-06,
      "loss": 0.2906,
      "step": 1579
    },
    {
      "epoch": 0.25113746994893804,
      "grad_norm": 0.5600326061248779,
      "learning_rate": 8.771689563152497e-06,
      "loss": 0.1982,
      "step": 1580
    },
    {
      "epoch": 0.2512964177147285,
      "grad_norm": 0.5666026473045349,
      "learning_rate": 8.769999115252976e-06,
      "loss": 0.2149,
      "step": 1581
    },
    {
      "epoch": 0.25145536548051894,
      "grad_norm": 0.6550458073616028,
      "learning_rate": 8.768307668051865e-06,
      "loss": 0.3032,
      "step": 1582
    },
    {
      "epoch": 0.25161431324630945,
      "grad_norm": 0.7856097221374512,
      "learning_rate": 8.766615221997514e-06,
      "loss": 0.4166,
      "step": 1583
    },
    {
      "epoch": 0.2517732610120999,
      "grad_norm": 0.5661250948905945,
      "learning_rate": 8.764921777538533e-06,
      "loss": 0.2546,
      "step": 1584
    },
    {
      "epoch": 0.25193220877789035,
      "grad_norm": 0.5857150554656982,
      "learning_rate": 8.763227335123796e-06,
      "loss": 0.285,
      "step": 1585
    },
    {
      "epoch": 0.2520911565436808,
      "grad_norm": 0.5356098413467407,
      "learning_rate": 8.761531895202448e-06,
      "loss": 0.2224,
      "step": 1586
    },
    {
      "epoch": 0.2522501043094713,
      "grad_norm": 0.5279682278633118,
      "learning_rate": 8.759835458223889e-06,
      "loss": 0.2174,
      "step": 1587
    },
    {
      "epoch": 0.25240905207526176,
      "grad_norm": 0.5736472010612488,
      "learning_rate": 8.758138024637792e-06,
      "loss": 0.2201,
      "step": 1588
    },
    {
      "epoch": 0.2525679998410522,
      "grad_norm": 0.5931122303009033,
      "learning_rate": 8.756439594894086e-06,
      "loss": 0.2443,
      "step": 1589
    },
    {
      "epoch": 0.2527269476068427,
      "grad_norm": 0.5897016525268555,
      "learning_rate": 8.754740169442972e-06,
      "loss": 0.2288,
      "step": 1590
    },
    {
      "epoch": 0.2528858953726332,
      "grad_norm": 0.6339796185493469,
      "learning_rate": 8.75303974873491e-06,
      "loss": 0.3187,
      "step": 1591
    },
    {
      "epoch": 0.2530448431384236,
      "grad_norm": 0.6620451807975769,
      "learning_rate": 8.751338333220626e-06,
      "loss": 0.3968,
      "step": 1592
    },
    {
      "epoch": 0.2532037909042141,
      "grad_norm": 0.5779317021369934,
      "learning_rate": 8.749635923351108e-06,
      "loss": 0.2809,
      "step": 1593
    },
    {
      "epoch": 0.2533627386700046,
      "grad_norm": 0.5367059707641602,
      "learning_rate": 8.747932519577607e-06,
      "loss": 0.2511,
      "step": 1594
    },
    {
      "epoch": 0.25352168643579504,
      "grad_norm": 0.6259066462516785,
      "learning_rate": 8.74622812235164e-06,
      "loss": 0.2156,
      "step": 1595
    },
    {
      "epoch": 0.2536806342015855,
      "grad_norm": 0.5539476871490479,
      "learning_rate": 8.744522732124987e-06,
      "loss": 0.2439,
      "step": 1596
    },
    {
      "epoch": 0.253839581967376,
      "grad_norm": 0.6215549111366272,
      "learning_rate": 8.74281634934969e-06,
      "loss": 0.3249,
      "step": 1597
    },
    {
      "epoch": 0.25399852973316644,
      "grad_norm": 0.5044696927070618,
      "learning_rate": 8.741108974478053e-06,
      "loss": 0.1887,
      "step": 1598
    },
    {
      "epoch": 0.2541574774989569,
      "grad_norm": 0.5367884635925293,
      "learning_rate": 8.739400607962644e-06,
      "loss": 0.2222,
      "step": 1599
    },
    {
      "epoch": 0.25431642526474735,
      "grad_norm": 0.4971419870853424,
      "learning_rate": 8.737691250256299e-06,
      "loss": 0.2091,
      "step": 1600
    },
    {
      "epoch": 0.25447537303053785,
      "grad_norm": 0.46978694200515747,
      "learning_rate": 8.735980901812104e-06,
      "loss": 0.1507,
      "step": 1601
    },
    {
      "epoch": 0.2546343207963283,
      "grad_norm": 0.4873577058315277,
      "learning_rate": 8.734269563083424e-06,
      "loss": 0.1699,
      "step": 1602
    },
    {
      "epoch": 0.25479326856211876,
      "grad_norm": 0.5922146439552307,
      "learning_rate": 8.732557234523873e-06,
      "loss": 0.2351,
      "step": 1603
    },
    {
      "epoch": 0.25495221632790926,
      "grad_norm": 0.6024078726768494,
      "learning_rate": 8.730843916587333e-06,
      "loss": 0.2889,
      "step": 1604
    },
    {
      "epoch": 0.2551111640936997,
      "grad_norm": 0.6118400692939758,
      "learning_rate": 8.729129609727948e-06,
      "loss": 0.3256,
      "step": 1605
    },
    {
      "epoch": 0.25527011185949017,
      "grad_norm": 0.5511430501937866,
      "learning_rate": 8.727414314400125e-06,
      "loss": 0.1597,
      "step": 1606
    },
    {
      "epoch": 0.2554290596252806,
      "grad_norm": 0.48573702573776245,
      "learning_rate": 8.72569803105853e-06,
      "loss": 0.1865,
      "step": 1607
    },
    {
      "epoch": 0.2555880073910711,
      "grad_norm": 0.5907546877861023,
      "learning_rate": 8.723980760158092e-06,
      "loss": 0.3503,
      "step": 1608
    },
    {
      "epoch": 0.2557469551568616,
      "grad_norm": 0.6024855971336365,
      "learning_rate": 8.722262502154007e-06,
      "loss": 0.1689,
      "step": 1609
    },
    {
      "epoch": 0.25590590292265203,
      "grad_norm": 0.6102820634841919,
      "learning_rate": 8.720543257501726e-06,
      "loss": 0.3567,
      "step": 1610
    },
    {
      "epoch": 0.25606485068844254,
      "grad_norm": 0.5295976400375366,
      "learning_rate": 8.71882302665696e-06,
      "loss": 0.2407,
      "step": 1611
    },
    {
      "epoch": 0.256223798454233,
      "grad_norm": 0.5305261015892029,
      "learning_rate": 8.71710181007569e-06,
      "loss": 0.269,
      "step": 1612
    },
    {
      "epoch": 0.25638274622002344,
      "grad_norm": 0.8450720310211182,
      "learning_rate": 8.715379608214151e-06,
      "loss": 0.2418,
      "step": 1613
    },
    {
      "epoch": 0.2565416939858139,
      "grad_norm": 0.5575023293495178,
      "learning_rate": 8.713656421528842e-06,
      "loss": 0.2613,
      "step": 1614
    },
    {
      "epoch": 0.2567006417516044,
      "grad_norm": 0.5288826823234558,
      "learning_rate": 8.711932250476522e-06,
      "loss": 0.2025,
      "step": 1615
    },
    {
      "epoch": 0.25685958951739485,
      "grad_norm": 0.599647581577301,
      "learning_rate": 8.710207095514211e-06,
      "loss": 0.2827,
      "step": 1616
    },
    {
      "epoch": 0.2570185372831853,
      "grad_norm": 0.5263710021972656,
      "learning_rate": 8.708480957099195e-06,
      "loss": 0.1897,
      "step": 1617
    },
    {
      "epoch": 0.2571774850489758,
      "grad_norm": 0.5448490977287292,
      "learning_rate": 8.706753835689009e-06,
      "loss": 0.2295,
      "step": 1618
    },
    {
      "epoch": 0.25733643281476626,
      "grad_norm": 0.44323161244392395,
      "learning_rate": 8.70502573174146e-06,
      "loss": 0.1762,
      "step": 1619
    },
    {
      "epoch": 0.2574953805805567,
      "grad_norm": 0.5898856520652771,
      "learning_rate": 8.70329664571461e-06,
      "loss": 0.3269,
      "step": 1620
    },
    {
      "epoch": 0.25765432834634716,
      "grad_norm": 0.5955473780632019,
      "learning_rate": 8.701566578066781e-06,
      "loss": 0.2783,
      "step": 1621
    },
    {
      "epoch": 0.25781327611213767,
      "grad_norm": 0.5465410351753235,
      "learning_rate": 8.69983552925656e-06,
      "loss": 0.2686,
      "step": 1622
    },
    {
      "epoch": 0.2579722238779281,
      "grad_norm": 0.752989649772644,
      "learning_rate": 8.698103499742785e-06,
      "loss": 0.2594,
      "step": 1623
    },
    {
      "epoch": 0.25813117164371857,
      "grad_norm": 0.523237943649292,
      "learning_rate": 8.696370489984565e-06,
      "loss": 0.2334,
      "step": 1624
    },
    {
      "epoch": 0.258290119409509,
      "grad_norm": 0.4749687612056732,
      "learning_rate": 8.69463650044126e-06,
      "loss": 0.2071,
      "step": 1625
    },
    {
      "epoch": 0.25844906717529953,
      "grad_norm": 0.5548723936080933,
      "learning_rate": 8.692901531572494e-06,
      "loss": 0.2364,
      "step": 1626
    },
    {
      "epoch": 0.25860801494109,
      "grad_norm": 0.5412757992744446,
      "learning_rate": 8.69116558383815e-06,
      "loss": 0.2784,
      "step": 1627
    },
    {
      "epoch": 0.25876696270688043,
      "grad_norm": 0.6677502393722534,
      "learning_rate": 8.68942865769837e-06,
      "loss": 0.267,
      "step": 1628
    },
    {
      "epoch": 0.25892591047267094,
      "grad_norm": 0.9676268100738525,
      "learning_rate": 8.687690753613554e-06,
      "loss": 0.2304,
      "step": 1629
    },
    {
      "epoch": 0.2590848582384614,
      "grad_norm": 0.46160927414894104,
      "learning_rate": 8.685951872044365e-06,
      "loss": 0.1656,
      "step": 1630
    },
    {
      "epoch": 0.25924380600425184,
      "grad_norm": 0.4425312876701355,
      "learning_rate": 8.684212013451722e-06,
      "loss": 0.1391,
      "step": 1631
    },
    {
      "epoch": 0.2594027537700423,
      "grad_norm": 0.5881794691085815,
      "learning_rate": 8.682471178296803e-06,
      "loss": 0.2881,
      "step": 1632
    },
    {
      "epoch": 0.2595617015358328,
      "grad_norm": 0.5192254185676575,
      "learning_rate": 8.680729367041047e-06,
      "loss": 0.2366,
      "step": 1633
    },
    {
      "epoch": 0.25972064930162325,
      "grad_norm": 0.6680822372436523,
      "learning_rate": 8.678986580146148e-06,
      "loss": 0.4184,
      "step": 1634
    },
    {
      "epoch": 0.2598795970674137,
      "grad_norm": 0.4637020528316498,
      "learning_rate": 8.677242818074064e-06,
      "loss": 0.1617,
      "step": 1635
    },
    {
      "epoch": 0.2600385448332042,
      "grad_norm": 0.569212019443512,
      "learning_rate": 8.675498081287006e-06,
      "loss": 0.2763,
      "step": 1636
    },
    {
      "epoch": 0.26019749259899466,
      "grad_norm": 0.5148665904998779,
      "learning_rate": 8.673752370247444e-06,
      "loss": 0.2385,
      "step": 1637
    },
    {
      "epoch": 0.2603564403647851,
      "grad_norm": 0.5353614687919617,
      "learning_rate": 8.672005685418115e-06,
      "loss": 0.1858,
      "step": 1638
    },
    {
      "epoch": 0.26051538813057556,
      "grad_norm": 0.5686963200569153,
      "learning_rate": 8.670258027262e-06,
      "loss": 0.2506,
      "step": 1639
    },
    {
      "epoch": 0.26067433589636607,
      "grad_norm": 0.6138842701911926,
      "learning_rate": 8.668509396242348e-06,
      "loss": 0.296,
      "step": 1640
    },
    {
      "epoch": 0.2608332836621565,
      "grad_norm": 0.5394668579101562,
      "learning_rate": 8.666759792822662e-06,
      "loss": 0.2224,
      "step": 1641
    },
    {
      "epoch": 0.260992231427947,
      "grad_norm": 0.5847263932228088,
      "learning_rate": 8.665009217466706e-06,
      "loss": 0.1987,
      "step": 1642
    },
    {
      "epoch": 0.2611511791937375,
      "grad_norm": 0.5001175999641418,
      "learning_rate": 8.663257670638498e-06,
      "loss": 0.2296,
      "step": 1643
    },
    {
      "epoch": 0.26131012695952793,
      "grad_norm": 0.5587190985679626,
      "learning_rate": 8.661505152802315e-06,
      "loss": 0.2831,
      "step": 1644
    },
    {
      "epoch": 0.2614690747253184,
      "grad_norm": 0.4965698719024658,
      "learning_rate": 8.65975166442269e-06,
      "loss": 0.2085,
      "step": 1645
    },
    {
      "epoch": 0.26162802249110884,
      "grad_norm": 0.6167827248573303,
      "learning_rate": 8.657997205964417e-06,
      "loss": 0.2389,
      "step": 1646
    },
    {
      "epoch": 0.26178697025689934,
      "grad_norm": 0.5651637315750122,
      "learning_rate": 8.656241777892544e-06,
      "loss": 0.3056,
      "step": 1647
    },
    {
      "epoch": 0.2619459180226898,
      "grad_norm": 0.4675809144973755,
      "learning_rate": 8.654485380672375e-06,
      "loss": 0.1931,
      "step": 1648
    },
    {
      "epoch": 0.26210486578848025,
      "grad_norm": 0.574894905090332,
      "learning_rate": 8.652728014769476e-06,
      "loss": 0.3293,
      "step": 1649
    },
    {
      "epoch": 0.26226381355427075,
      "grad_norm": 0.5882089734077454,
      "learning_rate": 8.650969680649662e-06,
      "loss": 0.2832,
      "step": 1650
    },
    {
      "epoch": 0.2624227613200612,
      "grad_norm": 0.6069473624229431,
      "learning_rate": 8.64921037877901e-06,
      "loss": 0.2936,
      "step": 1651
    },
    {
      "epoch": 0.26258170908585166,
      "grad_norm": 0.5795387029647827,
      "learning_rate": 8.647450109623856e-06,
      "loss": 0.283,
      "step": 1652
    },
    {
      "epoch": 0.2627406568516421,
      "grad_norm": 0.5410722494125366,
      "learning_rate": 8.645688873650785e-06,
      "loss": 0.2092,
      "step": 1653
    },
    {
      "epoch": 0.2628996046174326,
      "grad_norm": 0.6994245648384094,
      "learning_rate": 8.643926671326645e-06,
      "loss": 0.1609,
      "step": 1654
    },
    {
      "epoch": 0.26305855238322307,
      "grad_norm": 0.5667481422424316,
      "learning_rate": 8.642163503118535e-06,
      "loss": 0.2701,
      "step": 1655
    },
    {
      "epoch": 0.2632175001490135,
      "grad_norm": 0.627505362033844,
      "learning_rate": 8.640399369493813e-06,
      "loss": 0.3106,
      "step": 1656
    },
    {
      "epoch": 0.263376447914804,
      "grad_norm": 0.5681377649307251,
      "learning_rate": 8.638634270920094e-06,
      "loss": 0.2168,
      "step": 1657
    },
    {
      "epoch": 0.2635353956805945,
      "grad_norm": 0.4707620441913605,
      "learning_rate": 8.636868207865244e-06,
      "loss": 0.1903,
      "step": 1658
    },
    {
      "epoch": 0.2636943434463849,
      "grad_norm": 0.5701688528060913,
      "learning_rate": 8.635101180797391e-06,
      "loss": 0.2056,
      "step": 1659
    },
    {
      "epoch": 0.2638532912121754,
      "grad_norm": 0.5005789995193481,
      "learning_rate": 8.633333190184912e-06,
      "loss": 0.1761,
      "step": 1660
    },
    {
      "epoch": 0.2640122389779659,
      "grad_norm": 0.480161190032959,
      "learning_rate": 8.631564236496446e-06,
      "loss": 0.154,
      "step": 1661
    },
    {
      "epoch": 0.26417118674375634,
      "grad_norm": 0.5410808324813843,
      "learning_rate": 8.629794320200879e-06,
      "loss": 0.2549,
      "step": 1662
    },
    {
      "epoch": 0.2643301345095468,
      "grad_norm": 0.4276880621910095,
      "learning_rate": 8.628023441767364e-06,
      "loss": 0.1238,
      "step": 1663
    },
    {
      "epoch": 0.2644890822753373,
      "grad_norm": 0.5121041536331177,
      "learning_rate": 8.626251601665295e-06,
      "loss": 0.1565,
      "step": 1664
    },
    {
      "epoch": 0.26464803004112775,
      "grad_norm": 0.5195674896240234,
      "learning_rate": 8.624478800364332e-06,
      "loss": 0.2115,
      "step": 1665
    },
    {
      "epoch": 0.2648069778069182,
      "grad_norm": 0.5960717797279358,
      "learning_rate": 8.622705038334385e-06,
      "loss": 0.2841,
      "step": 1666
    },
    {
      "epoch": 0.26496592557270865,
      "grad_norm": 0.5494935512542725,
      "learning_rate": 8.620930316045619e-06,
      "loss": 0.2258,
      "step": 1667
    },
    {
      "epoch": 0.26512487333849916,
      "grad_norm": 0.5216155648231506,
      "learning_rate": 8.619154633968455e-06,
      "loss": 0.1957,
      "step": 1668
    },
    {
      "epoch": 0.2652838211042896,
      "grad_norm": 0.5379285216331482,
      "learning_rate": 8.617377992573567e-06,
      "loss": 0.1539,
      "step": 1669
    },
    {
      "epoch": 0.26544276887008006,
      "grad_norm": 0.5744303464889526,
      "learning_rate": 8.615600392331883e-06,
      "loss": 0.2798,
      "step": 1670
    },
    {
      "epoch": 0.2656017166358705,
      "grad_norm": 0.5619645118713379,
      "learning_rate": 8.613821833714584e-06,
      "loss": 0.2319,
      "step": 1671
    },
    {
      "epoch": 0.265760664401661,
      "grad_norm": 0.517917811870575,
      "learning_rate": 8.61204231719311e-06,
      "loss": 0.2509,
      "step": 1672
    },
    {
      "epoch": 0.26591961216745147,
      "grad_norm": 0.5858862400054932,
      "learning_rate": 8.610261843239152e-06,
      "loss": 0.2531,
      "step": 1673
    },
    {
      "epoch": 0.2660785599332419,
      "grad_norm": 0.5257763862609863,
      "learning_rate": 8.608480412324652e-06,
      "loss": 0.2176,
      "step": 1674
    },
    {
      "epoch": 0.2662375076990324,
      "grad_norm": 0.5745623111724854,
      "learning_rate": 8.60669802492181e-06,
      "loss": 0.2075,
      "step": 1675
    },
    {
      "epoch": 0.2663964554648229,
      "grad_norm": 0.457725465297699,
      "learning_rate": 8.604914681503076e-06,
      "loss": 0.1866,
      "step": 1676
    },
    {
      "epoch": 0.26655540323061333,
      "grad_norm": 0.5179212689399719,
      "learning_rate": 8.603130382541156e-06,
      "loss": 0.2253,
      "step": 1677
    },
    {
      "epoch": 0.2667143509964038,
      "grad_norm": 0.5424606204032898,
      "learning_rate": 8.60134512850901e-06,
      "loss": 0.259,
      "step": 1678
    },
    {
      "epoch": 0.2668732987621943,
      "grad_norm": 0.5828793048858643,
      "learning_rate": 8.599558919879847e-06,
      "loss": 0.2141,
      "step": 1679
    },
    {
      "epoch": 0.26703224652798474,
      "grad_norm": 0.5343950390815735,
      "learning_rate": 8.597771757127134e-06,
      "loss": 0.1827,
      "step": 1680
    },
    {
      "epoch": 0.2671911942937752,
      "grad_norm": 0.5402601957321167,
      "learning_rate": 8.595983640724585e-06,
      "loss": 0.2812,
      "step": 1681
    },
    {
      "epoch": 0.2673501420595657,
      "grad_norm": 0.45855292677879333,
      "learning_rate": 8.594194571146175e-06,
      "loss": 0.1557,
      "step": 1682
    },
    {
      "epoch": 0.26750908982535615,
      "grad_norm": 0.49657300114631653,
      "learning_rate": 8.592404548866123e-06,
      "loss": 0.173,
      "step": 1683
    },
    {
      "epoch": 0.2676680375911466,
      "grad_norm": 0.5397112369537354,
      "learning_rate": 8.590613574358907e-06,
      "loss": 0.1769,
      "step": 1684
    },
    {
      "epoch": 0.26782698535693705,
      "grad_norm": 0.49963170289993286,
      "learning_rate": 8.588821648099252e-06,
      "loss": 0.2088,
      "step": 1685
    },
    {
      "epoch": 0.26798593312272756,
      "grad_norm": 1.1072558164596558,
      "learning_rate": 8.587028770562143e-06,
      "loss": 0.363,
      "step": 1686
    },
    {
      "epoch": 0.268144880888518,
      "grad_norm": 0.5511714816093445,
      "learning_rate": 8.585234942222806e-06,
      "loss": 0.276,
      "step": 1687
    },
    {
      "epoch": 0.26830382865430846,
      "grad_norm": 0.5405194163322449,
      "learning_rate": 8.583440163556732e-06,
      "loss": 0.2156,
      "step": 1688
    },
    {
      "epoch": 0.26846277642009897,
      "grad_norm": 0.546301543712616,
      "learning_rate": 8.581644435039652e-06,
      "loss": 0.2606,
      "step": 1689
    },
    {
      "epoch": 0.2686217241858894,
      "grad_norm": 0.5448230504989624,
      "learning_rate": 8.579847757147555e-06,
      "loss": 0.2506,
      "step": 1690
    },
    {
      "epoch": 0.2687806719516799,
      "grad_norm": 0.5170615911483765,
      "learning_rate": 8.578050130356683e-06,
      "loss": 0.2177,
      "step": 1691
    },
    {
      "epoch": 0.2689396197174703,
      "grad_norm": 0.5287893414497375,
      "learning_rate": 8.576251555143524e-06,
      "loss": 0.2648,
      "step": 1692
    },
    {
      "epoch": 0.26909856748326083,
      "grad_norm": 0.5396268367767334,
      "learning_rate": 8.574452031984824e-06,
      "loss": 0.234,
      "step": 1693
    },
    {
      "epoch": 0.2692575152490513,
      "grad_norm": 0.5742026567459106,
      "learning_rate": 8.572651561357575e-06,
      "loss": 0.1554,
      "step": 1694
    },
    {
      "epoch": 0.26941646301484173,
      "grad_norm": 0.5759708285331726,
      "learning_rate": 8.570850143739022e-06,
      "loss": 0.3174,
      "step": 1695
    },
    {
      "epoch": 0.26957541078063224,
      "grad_norm": 0.5677143931388855,
      "learning_rate": 8.56904777960666e-06,
      "loss": 0.2672,
      "step": 1696
    },
    {
      "epoch": 0.2697343585464227,
      "grad_norm": 0.5507476329803467,
      "learning_rate": 8.567244469438238e-06,
      "loss": 0.2315,
      "step": 1697
    },
    {
      "epoch": 0.26989330631221314,
      "grad_norm": 0.9411851167678833,
      "learning_rate": 8.565440213711753e-06,
      "loss": 0.2025,
      "step": 1698
    },
    {
      "epoch": 0.2700522540780036,
      "grad_norm": 0.4950725734233856,
      "learning_rate": 8.563635012905451e-06,
      "loss": 0.22,
      "step": 1699
    },
    {
      "epoch": 0.2702112018437941,
      "grad_norm": 0.5223279595375061,
      "learning_rate": 8.561828867497834e-06,
      "loss": 0.1906,
      "step": 1700
    },
    {
      "epoch": 0.27037014960958455,
      "grad_norm": 1.1334655284881592,
      "learning_rate": 8.56002177796765e-06,
      "loss": 0.1963,
      "step": 1701
    },
    {
      "epoch": 0.270529097375375,
      "grad_norm": 0.4815037250518799,
      "learning_rate": 8.558213744793898e-06,
      "loss": 0.1542,
      "step": 1702
    },
    {
      "epoch": 0.2706880451411655,
      "grad_norm": 0.6225048303604126,
      "learning_rate": 8.556404768455828e-06,
      "loss": 0.3535,
      "step": 1703
    },
    {
      "epoch": 0.27084699290695596,
      "grad_norm": 0.5729461908340454,
      "learning_rate": 8.554594849432939e-06,
      "loss": 0.3069,
      "step": 1704
    },
    {
      "epoch": 0.2710059406727464,
      "grad_norm": 0.5434084534645081,
      "learning_rate": 8.552783988204982e-06,
      "loss": 0.2212,
      "step": 1705
    },
    {
      "epoch": 0.27116488843853687,
      "grad_norm": 0.5276513695716858,
      "learning_rate": 8.550972185251954e-06,
      "loss": 0.2265,
      "step": 1706
    },
    {
      "epoch": 0.2713238362043274,
      "grad_norm": 0.4934368431568146,
      "learning_rate": 8.549159441054105e-06,
      "loss": 0.1834,
      "step": 1707
    },
    {
      "epoch": 0.2714827839701178,
      "grad_norm": 0.5099357962608337,
      "learning_rate": 8.547345756091931e-06,
      "loss": 0.1947,
      "step": 1708
    },
    {
      "epoch": 0.2716417317359083,
      "grad_norm": 0.5765897631645203,
      "learning_rate": 8.545531130846185e-06,
      "loss": 0.1856,
      "step": 1709
    },
    {
      "epoch": 0.2718006795016987,
      "grad_norm": 0.830711841583252,
      "learning_rate": 8.543715565797861e-06,
      "loss": 0.3182,
      "step": 1710
    },
    {
      "epoch": 0.27195962726748923,
      "grad_norm": 0.6479224562644958,
      "learning_rate": 8.541899061428202e-06,
      "loss": 0.3917,
      "step": 1711
    },
    {
      "epoch": 0.2721185750332797,
      "grad_norm": 0.5195010900497437,
      "learning_rate": 8.540081618218707e-06,
      "loss": 0.2752,
      "step": 1712
    },
    {
      "epoch": 0.27227752279907014,
      "grad_norm": 0.5249391198158264,
      "learning_rate": 8.538263236651119e-06,
      "loss": 0.2292,
      "step": 1713
    },
    {
      "epoch": 0.27243647056486064,
      "grad_norm": 0.5572656393051147,
      "learning_rate": 8.536443917207429e-06,
      "loss": 0.227,
      "step": 1714
    },
    {
      "epoch": 0.2725954183306511,
      "grad_norm": 0.5828709006309509,
      "learning_rate": 8.53462366036988e-06,
      "loss": 0.2714,
      "step": 1715
    },
    {
      "epoch": 0.27275436609644155,
      "grad_norm": 0.5086220502853394,
      "learning_rate": 8.532802466620962e-06,
      "loss": 0.2008,
      "step": 1716
    },
    {
      "epoch": 0.272913313862232,
      "grad_norm": 0.693773090839386,
      "learning_rate": 8.530980336443412e-06,
      "loss": 0.3153,
      "step": 1717
    },
    {
      "epoch": 0.2730722616280225,
      "grad_norm": 0.510931670665741,
      "learning_rate": 8.529157270320215e-06,
      "loss": 0.1854,
      "step": 1718
    },
    {
      "epoch": 0.27323120939381296,
      "grad_norm": 0.5564698576927185,
      "learning_rate": 8.527333268734607e-06,
      "loss": 0.2968,
      "step": 1719
    },
    {
      "epoch": 0.2733901571596034,
      "grad_norm": 0.5034552216529846,
      "learning_rate": 8.525508332170069e-06,
      "loss": 0.2008,
      "step": 1720
    },
    {
      "epoch": 0.2735491049253939,
      "grad_norm": 0.690106213092804,
      "learning_rate": 8.523682461110332e-06,
      "loss": 0.1994,
      "step": 1721
    },
    {
      "epoch": 0.27370805269118437,
      "grad_norm": 0.6330745220184326,
      "learning_rate": 8.521855656039373e-06,
      "loss": 0.2729,
      "step": 1722
    },
    {
      "epoch": 0.2738670004569748,
      "grad_norm": 0.604586660861969,
      "learning_rate": 8.52002791744142e-06,
      "loss": 0.2634,
      "step": 1723
    },
    {
      "epoch": 0.27402594822276527,
      "grad_norm": 0.4812650680541992,
      "learning_rate": 8.518199245800941e-06,
      "loss": 0.1863,
      "step": 1724
    },
    {
      "epoch": 0.2741848959885558,
      "grad_norm": 0.46085822582244873,
      "learning_rate": 8.516369641602662e-06,
      "loss": 0.1422,
      "step": 1725
    },
    {
      "epoch": 0.27434384375434623,
      "grad_norm": 0.551013708114624,
      "learning_rate": 8.514539105331547e-06,
      "loss": 0.2644,
      "step": 1726
    },
    {
      "epoch": 0.2745027915201367,
      "grad_norm": 0.4598372280597687,
      "learning_rate": 8.512707637472808e-06,
      "loss": 0.1512,
      "step": 1727
    },
    {
      "epoch": 0.2746617392859272,
      "grad_norm": 0.5263043642044067,
      "learning_rate": 8.510875238511911e-06,
      "loss": 0.1495,
      "step": 1728
    },
    {
      "epoch": 0.27482068705171764,
      "grad_norm": 0.7206934094429016,
      "learning_rate": 8.50904190893456e-06,
      "loss": 0.2889,
      "step": 1729
    },
    {
      "epoch": 0.2749796348175081,
      "grad_norm": 0.5423019528388977,
      "learning_rate": 8.507207649226715e-06,
      "loss": 0.2028,
      "step": 1730
    },
    {
      "epoch": 0.27513858258329854,
      "grad_norm": 0.520129919052124,
      "learning_rate": 8.505372459874572e-06,
      "loss": 0.2541,
      "step": 1731
    },
    {
      "epoch": 0.27529753034908905,
      "grad_norm": 0.5250970721244812,
      "learning_rate": 8.503536341364582e-06,
      "loss": 0.2106,
      "step": 1732
    },
    {
      "epoch": 0.2754564781148795,
      "grad_norm": 0.5317034721374512,
      "learning_rate": 8.501699294183436e-06,
      "loss": 0.2736,
      "step": 1733
    },
    {
      "epoch": 0.27561542588066995,
      "grad_norm": 0.5521312952041626,
      "learning_rate": 8.499861318818078e-06,
      "loss": 0.2345,
      "step": 1734
    },
    {
      "epoch": 0.27577437364646046,
      "grad_norm": 0.6730238199234009,
      "learning_rate": 8.498022415755693e-06,
      "loss": 0.4229,
      "step": 1735
    },
    {
      "epoch": 0.2759333214122509,
      "grad_norm": 0.5944596529006958,
      "learning_rate": 8.496182585483712e-06,
      "loss": 0.3007,
      "step": 1736
    },
    {
      "epoch": 0.27609226917804136,
      "grad_norm": 0.5448088645935059,
      "learning_rate": 8.494341828489812e-06,
      "loss": 0.2717,
      "step": 1737
    },
    {
      "epoch": 0.2762512169438318,
      "grad_norm": 0.5422099232673645,
      "learning_rate": 8.49250014526192e-06,
      "loss": 0.257,
      "step": 1738
    },
    {
      "epoch": 0.2764101647096223,
      "grad_norm": 0.5727573037147522,
      "learning_rate": 8.490657536288203e-06,
      "loss": 0.3145,
      "step": 1739
    },
    {
      "epoch": 0.27656911247541277,
      "grad_norm": 0.6380591988563538,
      "learning_rate": 8.488814002057074e-06,
      "loss": 0.2272,
      "step": 1740
    },
    {
      "epoch": 0.2767280602412032,
      "grad_norm": 0.5297829508781433,
      "learning_rate": 8.486969543057197e-06,
      "loss": 0.156,
      "step": 1741
    },
    {
      "epoch": 0.27688700800699373,
      "grad_norm": 0.6334342360496521,
      "learning_rate": 8.485124159777473e-06,
      "loss": 0.3884,
      "step": 1742
    },
    {
      "epoch": 0.2770459557727842,
      "grad_norm": 0.5517545938491821,
      "learning_rate": 8.483277852707053e-06,
      "loss": 0.2729,
      "step": 1743
    },
    {
      "epoch": 0.27720490353857463,
      "grad_norm": 0.4861569106578827,
      "learning_rate": 8.481430622335332e-06,
      "loss": 0.1881,
      "step": 1744
    },
    {
      "epoch": 0.2773638513043651,
      "grad_norm": 0.6293493509292603,
      "learning_rate": 8.479582469151947e-06,
      "loss": 0.37,
      "step": 1745
    },
    {
      "epoch": 0.2775227990701556,
      "grad_norm": 0.6126071810722351,
      "learning_rate": 8.477733393646787e-06,
      "loss": 0.2871,
      "step": 1746
    },
    {
      "epoch": 0.27768174683594604,
      "grad_norm": 0.562752902507782,
      "learning_rate": 8.475883396309977e-06,
      "loss": 0.1897,
      "step": 1747
    },
    {
      "epoch": 0.2778406946017365,
      "grad_norm": 0.6393338441848755,
      "learning_rate": 8.474032477631889e-06,
      "loss": 0.336,
      "step": 1748
    },
    {
      "epoch": 0.27799964236752694,
      "grad_norm": 0.5429549813270569,
      "learning_rate": 8.472180638103143e-06,
      "loss": 0.2382,
      "step": 1749
    },
    {
      "epoch": 0.27815859013331745,
      "grad_norm": 1.2683284282684326,
      "learning_rate": 8.4703278782146e-06,
      "loss": 0.315,
      "step": 1750
    },
    {
      "epoch": 0.2783175378991079,
      "grad_norm": 0.5792576670646667,
      "learning_rate": 8.468474198457362e-06,
      "loss": 0.231,
      "step": 1751
    },
    {
      "epoch": 0.27847648566489835,
      "grad_norm": 0.5975004434585571,
      "learning_rate": 8.46661959932278e-06,
      "loss": 0.2856,
      "step": 1752
    },
    {
      "epoch": 0.27863543343068886,
      "grad_norm": 0.4357234537601471,
      "learning_rate": 8.464764081302448e-06,
      "loss": 0.1844,
      "step": 1753
    },
    {
      "epoch": 0.2787943811964793,
      "grad_norm": 0.4770280718803406,
      "learning_rate": 8.462907644888198e-06,
      "loss": 0.1751,
      "step": 1754
    },
    {
      "epoch": 0.27895332896226976,
      "grad_norm": 0.47167158126831055,
      "learning_rate": 8.461050290572114e-06,
      "loss": 0.1352,
      "step": 1755
    },
    {
      "epoch": 0.2791122767280602,
      "grad_norm": 0.575156033039093,
      "learning_rate": 8.459192018846519e-06,
      "loss": 0.3109,
      "step": 1756
    },
    {
      "epoch": 0.2792712244938507,
      "grad_norm": 0.5965328812599182,
      "learning_rate": 8.457332830203975e-06,
      "loss": 0.2566,
      "step": 1757
    },
    {
      "epoch": 0.2794301722596412,
      "grad_norm": 0.4979826509952545,
      "learning_rate": 8.455472725137295e-06,
      "loss": 0.179,
      "step": 1758
    },
    {
      "epoch": 0.2795891200254316,
      "grad_norm": 0.6436582803726196,
      "learning_rate": 8.45361170413953e-06,
      "loss": 0.1875,
      "step": 1759
    },
    {
      "epoch": 0.27974806779122213,
      "grad_norm": 0.5861795544624329,
      "learning_rate": 8.451749767703975e-06,
      "loss": 0.3292,
      "step": 1760
    },
    {
      "epoch": 0.2799070155570126,
      "grad_norm": 0.5273479223251343,
      "learning_rate": 8.449886916324168e-06,
      "loss": 0.2314,
      "step": 1761
    },
    {
      "epoch": 0.28006596332280304,
      "grad_norm": 0.5480231642723083,
      "learning_rate": 8.448023150493884e-06,
      "loss": 0.2633,
      "step": 1762
    },
    {
      "epoch": 0.2802249110885935,
      "grad_norm": 0.5317584276199341,
      "learning_rate": 8.446158470707155e-06,
      "loss": 0.2134,
      "step": 1763
    },
    {
      "epoch": 0.280383858854384,
      "grad_norm": 0.536564290523529,
      "learning_rate": 8.444292877458238e-06,
      "loss": 0.2217,
      "step": 1764
    },
    {
      "epoch": 0.28054280662017445,
      "grad_norm": 0.651350200176239,
      "learning_rate": 8.44242637124164e-06,
      "loss": 0.0821,
      "step": 1765
    },
    {
      "epoch": 0.2807017543859649,
      "grad_norm": 0.5676723122596741,
      "learning_rate": 8.440558952552116e-06,
      "loss": 0.277,
      "step": 1766
    },
    {
      "epoch": 0.2808607021517554,
      "grad_norm": 0.687997043132782,
      "learning_rate": 8.43869062188465e-06,
      "loss": 0.3444,
      "step": 1767
    },
    {
      "epoch": 0.28101964991754586,
      "grad_norm": 0.5908805727958679,
      "learning_rate": 8.436821379734478e-06,
      "loss": 0.275,
      "step": 1768
    },
    {
      "epoch": 0.2811785976833363,
      "grad_norm": 0.5550975203514099,
      "learning_rate": 8.434951226597074e-06,
      "loss": 0.2827,
      "step": 1769
    },
    {
      "epoch": 0.28133754544912676,
      "grad_norm": 0.6373823285102844,
      "learning_rate": 8.43308016296815e-06,
      "loss": 0.2816,
      "step": 1770
    },
    {
      "epoch": 0.28149649321491726,
      "grad_norm": 0.6129891872406006,
      "learning_rate": 8.43120818934367e-06,
      "loss": 0.2079,
      "step": 1771
    },
    {
      "epoch": 0.2816554409807077,
      "grad_norm": 0.5752809643745422,
      "learning_rate": 8.429335306219824e-06,
      "loss": 0.2871,
      "step": 1772
    },
    {
      "epoch": 0.28181438874649817,
      "grad_norm": 0.6071001291275024,
      "learning_rate": 8.427461514093056e-06,
      "loss": 0.2652,
      "step": 1773
    },
    {
      "epoch": 0.2819733365122887,
      "grad_norm": 0.5406356453895569,
      "learning_rate": 8.425586813460045e-06,
      "loss": 0.2789,
      "step": 1774
    },
    {
      "epoch": 0.2821322842780791,
      "grad_norm": 0.47542425990104675,
      "learning_rate": 8.42371120481771e-06,
      "loss": 0.1952,
      "step": 1775
    },
    {
      "epoch": 0.2822912320438696,
      "grad_norm": 0.7156396508216858,
      "learning_rate": 8.421834688663215e-06,
      "loss": 0.2066,
      "step": 1776
    },
    {
      "epoch": 0.28245017980966003,
      "grad_norm": 0.561008632183075,
      "learning_rate": 8.419957265493961e-06,
      "loss": 0.3598,
      "step": 1777
    },
    {
      "epoch": 0.28260912757545054,
      "grad_norm": 0.5777062773704529,
      "learning_rate": 8.418078935807592e-06,
      "loss": 0.2708,
      "step": 1778
    },
    {
      "epoch": 0.282768075341241,
      "grad_norm": 0.505031168460846,
      "learning_rate": 8.41619970010199e-06,
      "loss": 0.2181,
      "step": 1779
    },
    {
      "epoch": 0.28292702310703144,
      "grad_norm": 0.5117903351783752,
      "learning_rate": 8.414319558875276e-06,
      "loss": 0.2304,
      "step": 1780
    },
    {
      "epoch": 0.28308597087282195,
      "grad_norm": 0.5491676330566406,
      "learning_rate": 8.412438512625817e-06,
      "loss": 0.2056,
      "step": 1781
    },
    {
      "epoch": 0.2832449186386124,
      "grad_norm": 0.5872340798377991,
      "learning_rate": 8.410556561852212e-06,
      "loss": 0.351,
      "step": 1782
    },
    {
      "epoch": 0.28340386640440285,
      "grad_norm": 0.4357656240463257,
      "learning_rate": 8.408673707053305e-06,
      "loss": 0.1376,
      "step": 1783
    },
    {
      "epoch": 0.2835628141701933,
      "grad_norm": 0.5891596078872681,
      "learning_rate": 8.40678994872818e-06,
      "loss": 0.3005,
      "step": 1784
    },
    {
      "epoch": 0.2837217619359838,
      "grad_norm": 0.6180495619773865,
      "learning_rate": 8.404905287376158e-06,
      "loss": 0.3212,
      "step": 1785
    },
    {
      "epoch": 0.28388070970177426,
      "grad_norm": 0.8395090699195862,
      "learning_rate": 8.403019723496796e-06,
      "loss": 0.2232,
      "step": 1786
    },
    {
      "epoch": 0.2840396574675647,
      "grad_norm": 0.5755735039710999,
      "learning_rate": 8.401133257589902e-06,
      "loss": 0.2746,
      "step": 1787
    },
    {
      "epoch": 0.28419860523335516,
      "grad_norm": 0.4820261597633362,
      "learning_rate": 8.39924589015551e-06,
      "loss": 0.2004,
      "step": 1788
    },
    {
      "epoch": 0.28435755299914567,
      "grad_norm": 0.559602677822113,
      "learning_rate": 8.397357621693898e-06,
      "loss": 0.2501,
      "step": 1789
    },
    {
      "epoch": 0.2845165007649361,
      "grad_norm": 0.4130895137786865,
      "learning_rate": 8.395468452705587e-06,
      "loss": 0.1115,
      "step": 1790
    },
    {
      "epoch": 0.28467544853072657,
      "grad_norm": 0.6166699528694153,
      "learning_rate": 8.39357838369133e-06,
      "loss": 0.2711,
      "step": 1791
    },
    {
      "epoch": 0.2848343962965171,
      "grad_norm": 0.5075017809867859,
      "learning_rate": 8.391687415152124e-06,
      "loss": 0.1995,
      "step": 1792
    },
    {
      "epoch": 0.28499334406230753,
      "grad_norm": 0.531755268573761,
      "learning_rate": 8.3897955475892e-06,
      "loss": 0.1253,
      "step": 1793
    },
    {
      "epoch": 0.285152291828098,
      "grad_norm": 0.5287200212478638,
      "learning_rate": 8.387902781504027e-06,
      "loss": 0.2074,
      "step": 1794
    },
    {
      "epoch": 0.28531123959388843,
      "grad_norm": 0.485983282327652,
      "learning_rate": 8.386009117398321e-06,
      "loss": 0.1817,
      "step": 1795
    },
    {
      "epoch": 0.28547018735967894,
      "grad_norm": 0.4452035129070282,
      "learning_rate": 8.384114555774026e-06,
      "loss": 0.1829,
      "step": 1796
    },
    {
      "epoch": 0.2856291351254694,
      "grad_norm": 0.5388805866241455,
      "learning_rate": 8.382219097133323e-06,
      "loss": 0.1881,
      "step": 1797
    },
    {
      "epoch": 0.28578808289125984,
      "grad_norm": 0.3952474594116211,
      "learning_rate": 8.380322741978644e-06,
      "loss": 0.1214,
      "step": 1798
    },
    {
      "epoch": 0.28594703065705035,
      "grad_norm": 0.5442200899124146,
      "learning_rate": 8.378425490812643e-06,
      "loss": 0.2435,
      "step": 1799
    },
    {
      "epoch": 0.2861059784228408,
      "grad_norm": 0.597750186920166,
      "learning_rate": 8.376527344138222e-06,
      "loss": 0.2714,
      "step": 1800
    },
    {
      "epoch": 0.28626492618863125,
      "grad_norm": 0.556053638458252,
      "learning_rate": 8.374628302458512e-06,
      "loss": 0.2703,
      "step": 1801
    },
    {
      "epoch": 0.2864238739544217,
      "grad_norm": 0.4250299036502838,
      "learning_rate": 8.37272836627689e-06,
      "loss": 0.1435,
      "step": 1802
    },
    {
      "epoch": 0.2865828217202122,
      "grad_norm": 0.5356810688972473,
      "learning_rate": 8.370827536096966e-06,
      "loss": 0.1936,
      "step": 1803
    },
    {
      "epoch": 0.28674176948600266,
      "grad_norm": 0.3965713381767273,
      "learning_rate": 8.368925812422585e-06,
      "loss": 0.123,
      "step": 1804
    },
    {
      "epoch": 0.2869007172517931,
      "grad_norm": 0.6675944924354553,
      "learning_rate": 8.367023195757831e-06,
      "loss": 0.2836,
      "step": 1805
    },
    {
      "epoch": 0.2870596650175836,
      "grad_norm": 0.5933548212051392,
      "learning_rate": 8.365119686607027e-06,
      "loss": 0.3148,
      "step": 1806
    },
    {
      "epoch": 0.28721861278337407,
      "grad_norm": 0.6027814149856567,
      "learning_rate": 8.363215285474727e-06,
      "loss": 0.3146,
      "step": 1807
    },
    {
      "epoch": 0.2873775605491645,
      "grad_norm": 0.4487139582633972,
      "learning_rate": 8.361309992865728e-06,
      "loss": 0.145,
      "step": 1808
    },
    {
      "epoch": 0.287536508314955,
      "grad_norm": 0.47239866852760315,
      "learning_rate": 8.359403809285054e-06,
      "loss": 0.1882,
      "step": 1809
    },
    {
      "epoch": 0.2876954560807455,
      "grad_norm": 0.634253740310669,
      "learning_rate": 8.357496735237976e-06,
      "loss": 0.2718,
      "step": 1810
    },
    {
      "epoch": 0.28785440384653593,
      "grad_norm": 0.5603408813476562,
      "learning_rate": 8.355588771229996e-06,
      "loss": 0.2803,
      "step": 1811
    },
    {
      "epoch": 0.2880133516123264,
      "grad_norm": 0.5723888278007507,
      "learning_rate": 8.353679917766848e-06,
      "loss": 0.3211,
      "step": 1812
    },
    {
      "epoch": 0.2881722993781169,
      "grad_norm": 0.5685182809829712,
      "learning_rate": 8.35177017535451e-06,
      "loss": 0.2895,
      "step": 1813
    },
    {
      "epoch": 0.28833124714390734,
      "grad_norm": 0.5947210788726807,
      "learning_rate": 8.349859544499188e-06,
      "loss": 0.3562,
      "step": 1814
    },
    {
      "epoch": 0.2884901949096978,
      "grad_norm": 0.5492290258407593,
      "learning_rate": 8.347948025707331e-06,
      "loss": 0.2245,
      "step": 1815
    },
    {
      "epoch": 0.28864914267548825,
      "grad_norm": 0.524135947227478,
      "learning_rate": 8.346035619485613e-06,
      "loss": 0.2696,
      "step": 1816
    },
    {
      "epoch": 0.28880809044127875,
      "grad_norm": 0.44554194808006287,
      "learning_rate": 8.344122326340955e-06,
      "loss": 0.1659,
      "step": 1817
    },
    {
      "epoch": 0.2889670382070692,
      "grad_norm": 0.5896626114845276,
      "learning_rate": 8.342208146780504e-06,
      "loss": 0.2997,
      "step": 1818
    },
    {
      "epoch": 0.28912598597285966,
      "grad_norm": 0.5354045629501343,
      "learning_rate": 8.340293081311647e-06,
      "loss": 0.2662,
      "step": 1819
    },
    {
      "epoch": 0.28928493373865016,
      "grad_norm": 0.5597719550132751,
      "learning_rate": 8.338377130442005e-06,
      "loss": 0.2429,
      "step": 1820
    },
    {
      "epoch": 0.2894438815044406,
      "grad_norm": 0.5048293471336365,
      "learning_rate": 8.336460294679431e-06,
      "loss": 0.2188,
      "step": 1821
    },
    {
      "epoch": 0.28960282927023107,
      "grad_norm": 0.5517431497573853,
      "learning_rate": 8.334542574532016e-06,
      "loss": 0.2794,
      "step": 1822
    },
    {
      "epoch": 0.2897617770360215,
      "grad_norm": 0.636771023273468,
      "learning_rate": 8.332623970508084e-06,
      "loss": 0.2816,
      "step": 1823
    },
    {
      "epoch": 0.289920724801812,
      "grad_norm": 0.5829641222953796,
      "learning_rate": 8.330704483116191e-06,
      "loss": 0.2126,
      "step": 1824
    },
    {
      "epoch": 0.2900796725676025,
      "grad_norm": 0.47875916957855225,
      "learning_rate": 8.328784112865133e-06,
      "loss": 0.2331,
      "step": 1825
    },
    {
      "epoch": 0.2902386203333929,
      "grad_norm": 0.5034970045089722,
      "learning_rate": 8.326862860263933e-06,
      "loss": 0.221,
      "step": 1826
    },
    {
      "epoch": 0.2903975680991834,
      "grad_norm": 0.501237154006958,
      "learning_rate": 8.324940725821853e-06,
      "loss": 0.1931,
      "step": 1827
    },
    {
      "epoch": 0.2905565158649739,
      "grad_norm": 0.5466356873512268,
      "learning_rate": 8.323017710048387e-06,
      "loss": 0.3256,
      "step": 1828
    },
    {
      "epoch": 0.29071546363076434,
      "grad_norm": 0.5688852071762085,
      "learning_rate": 8.321093813453261e-06,
      "loss": 0.2821,
      "step": 1829
    },
    {
      "epoch": 0.2908744113965548,
      "grad_norm": 0.5711376070976257,
      "learning_rate": 8.319169036546438e-06,
      "loss": 0.258,
      "step": 1830
    },
    {
      "epoch": 0.2910333591623453,
      "grad_norm": 0.532112181186676,
      "learning_rate": 8.317243379838112e-06,
      "loss": 0.1681,
      "step": 1831
    },
    {
      "epoch": 0.29119230692813575,
      "grad_norm": 0.5816795229911804,
      "learning_rate": 8.31531684383871e-06,
      "loss": 0.3644,
      "step": 1832
    },
    {
      "epoch": 0.2913512546939262,
      "grad_norm": 0.517844021320343,
      "learning_rate": 8.313389429058895e-06,
      "loss": 0.2253,
      "step": 1833
    },
    {
      "epoch": 0.29151020245971665,
      "grad_norm": 0.48643559217453003,
      "learning_rate": 8.311461136009558e-06,
      "loss": 0.1915,
      "step": 1834
    },
    {
      "epoch": 0.29166915022550716,
      "grad_norm": 0.5654454231262207,
      "learning_rate": 8.309531965201826e-06,
      "loss": 0.2396,
      "step": 1835
    },
    {
      "epoch": 0.2918280979912976,
      "grad_norm": 0.45736071467399597,
      "learning_rate": 8.30760191714706e-06,
      "loss": 0.1753,
      "step": 1836
    },
    {
      "epoch": 0.29198704575708806,
      "grad_norm": 0.5526443719863892,
      "learning_rate": 8.305670992356847e-06,
      "loss": 0.2699,
      "step": 1837
    },
    {
      "epoch": 0.29214599352287857,
      "grad_norm": 0.5641478300094604,
      "learning_rate": 8.303739191343016e-06,
      "loss": 0.3179,
      "step": 1838
    },
    {
      "epoch": 0.292304941288669,
      "grad_norm": 0.44316181540489197,
      "learning_rate": 8.301806514617622e-06,
      "loss": 0.1603,
      "step": 1839
    },
    {
      "epoch": 0.29246388905445947,
      "grad_norm": 0.43332967162132263,
      "learning_rate": 8.299872962692952e-06,
      "loss": 0.1301,
      "step": 1840
    },
    {
      "epoch": 0.2926228368202499,
      "grad_norm": 0.6486460566520691,
      "learning_rate": 8.29793853608153e-06,
      "loss": 0.4044,
      "step": 1841
    },
    {
      "epoch": 0.29278178458604043,
      "grad_norm": 0.5028712749481201,
      "learning_rate": 8.296003235296101e-06,
      "loss": 0.2335,
      "step": 1842
    },
    {
      "epoch": 0.2929407323518309,
      "grad_norm": 0.5144928693771362,
      "learning_rate": 8.294067060849658e-06,
      "loss": 0.2672,
      "step": 1843
    },
    {
      "epoch": 0.29309968011762133,
      "grad_norm": 0.4190758764743805,
      "learning_rate": 8.292130013255409e-06,
      "loss": 0.157,
      "step": 1844
    },
    {
      "epoch": 0.29325862788341184,
      "grad_norm": 0.4825766086578369,
      "learning_rate": 8.290192093026805e-06,
      "loss": 0.2182,
      "step": 1845
    },
    {
      "epoch": 0.2934175756492023,
      "grad_norm": 0.5773682594299316,
      "learning_rate": 8.288253300677524e-06,
      "loss": 0.2695,
      "step": 1846
    },
    {
      "epoch": 0.29357652341499274,
      "grad_norm": 0.6045773029327393,
      "learning_rate": 8.286313636721474e-06,
      "loss": 0.1756,
      "step": 1847
    },
    {
      "epoch": 0.2937354711807832,
      "grad_norm": 0.7287729978561401,
      "learning_rate": 8.284373101672798e-06,
      "loss": 0.2479,
      "step": 1848
    },
    {
      "epoch": 0.2938944189465737,
      "grad_norm": 0.5664336085319519,
      "learning_rate": 8.282431696045865e-06,
      "loss": 0.3101,
      "step": 1849
    },
    {
      "epoch": 0.29405336671236415,
      "grad_norm": 0.83517986536026,
      "learning_rate": 8.280489420355277e-06,
      "loss": 0.2436,
      "step": 1850
    },
    {
      "epoch": 0.2942123144781546,
      "grad_norm": 0.5464299917221069,
      "learning_rate": 8.27854627511587e-06,
      "loss": 0.2035,
      "step": 1851
    },
    {
      "epoch": 0.2943712622439451,
      "grad_norm": 0.6328369379043579,
      "learning_rate": 8.276602260842704e-06,
      "loss": 0.3359,
      "step": 1852
    },
    {
      "epoch": 0.29453021000973556,
      "grad_norm": 0.6539053320884705,
      "learning_rate": 8.274657378051073e-06,
      "loss": 0.36,
      "step": 1853
    },
    {
      "epoch": 0.294689157775526,
      "grad_norm": 0.5254008173942566,
      "learning_rate": 8.272711627256501e-06,
      "loss": 0.2955,
      "step": 1854
    },
    {
      "epoch": 0.29484810554131646,
      "grad_norm": 0.5869500637054443,
      "learning_rate": 8.270765008974746e-06,
      "loss": 0.2618,
      "step": 1855
    },
    {
      "epoch": 0.29500705330710697,
      "grad_norm": 0.6832646131515503,
      "learning_rate": 8.268817523721785e-06,
      "loss": 0.1981,
      "step": 1856
    },
    {
      "epoch": 0.2951660010728974,
      "grad_norm": 0.5649880766868591,
      "learning_rate": 8.266869172013835e-06,
      "loss": 0.3183,
      "step": 1857
    },
    {
      "epoch": 0.2953249488386879,
      "grad_norm": 0.5333748459815979,
      "learning_rate": 8.264919954367343e-06,
      "loss": 0.2609,
      "step": 1858
    },
    {
      "epoch": 0.2954838966044784,
      "grad_norm": 0.5967424511909485,
      "learning_rate": 8.262969871298975e-06,
      "loss": 0.2873,
      "step": 1859
    },
    {
      "epoch": 0.29564284437026883,
      "grad_norm": 0.5470840334892273,
      "learning_rate": 8.261018923325637e-06,
      "loss": 0.2015,
      "step": 1860
    },
    {
      "epoch": 0.2958017921360593,
      "grad_norm": 0.5396189093589783,
      "learning_rate": 8.25906711096446e-06,
      "loss": 0.2799,
      "step": 1861
    },
    {
      "epoch": 0.29596073990184973,
      "grad_norm": 0.6613153219223022,
      "learning_rate": 8.257114434732807e-06,
      "loss": 0.4008,
      "step": 1862
    },
    {
      "epoch": 0.29611968766764024,
      "grad_norm": 0.5983449220657349,
      "learning_rate": 8.255160895148263e-06,
      "loss": 0.3156,
      "step": 1863
    },
    {
      "epoch": 0.2962786354334307,
      "grad_norm": 0.4665263891220093,
      "learning_rate": 8.25320649272865e-06,
      "loss": 0.1616,
      "step": 1864
    },
    {
      "epoch": 0.29643758319922114,
      "grad_norm": 0.4952101409435272,
      "learning_rate": 8.251251227992014e-06,
      "loss": 0.2215,
      "step": 1865
    },
    {
      "epoch": 0.2965965309650116,
      "grad_norm": 0.5808700919151306,
      "learning_rate": 8.24929510145663e-06,
      "loss": 0.309,
      "step": 1866
    },
    {
      "epoch": 0.2967554787308021,
      "grad_norm": 0.5607306361198425,
      "learning_rate": 8.247338113641003e-06,
      "loss": 0.3277,
      "step": 1867
    },
    {
      "epoch": 0.29691442649659255,
      "grad_norm": 0.5398544073104858,
      "learning_rate": 8.245380265063866e-06,
      "loss": 0.2257,
      "step": 1868
    },
    {
      "epoch": 0.297073374262383,
      "grad_norm": 0.36884814500808716,
      "learning_rate": 8.243421556244179e-06,
      "loss": 0.0898,
      "step": 1869
    },
    {
      "epoch": 0.2972323220281735,
      "grad_norm": 0.5659093856811523,
      "learning_rate": 8.24146198770113e-06,
      "loss": 0.3051,
      "step": 1870
    },
    {
      "epoch": 0.29739126979396396,
      "grad_norm": 0.5743104219436646,
      "learning_rate": 8.239501559954138e-06,
      "loss": 0.2766,
      "step": 1871
    },
    {
      "epoch": 0.2975502175597544,
      "grad_norm": 0.5627820491790771,
      "learning_rate": 8.237540273522844e-06,
      "loss": 0.2796,
      "step": 1872
    },
    {
      "epoch": 0.29770916532554487,
      "grad_norm": 0.5877711772918701,
      "learning_rate": 8.235578128927123e-06,
      "loss": 0.3242,
      "step": 1873
    },
    {
      "epoch": 0.2978681130913354,
      "grad_norm": 0.521327555179596,
      "learning_rate": 8.233615126687072e-06,
      "loss": 0.2557,
      "step": 1874
    },
    {
      "epoch": 0.2980270608571258,
      "grad_norm": 0.6282927989959717,
      "learning_rate": 8.23165126732302e-06,
      "loss": 0.3553,
      "step": 1875
    },
    {
      "epoch": 0.2981860086229163,
      "grad_norm": 0.4764215350151062,
      "learning_rate": 8.229686551355518e-06,
      "loss": 0.2146,
      "step": 1876
    },
    {
      "epoch": 0.2983449563887068,
      "grad_norm": 0.6458415985107422,
      "learning_rate": 8.227720979305349e-06,
      "loss": 0.3423,
      "step": 1877
    },
    {
      "epoch": 0.29850390415449723,
      "grad_norm": 0.6163012385368347,
      "learning_rate": 8.225754551693522e-06,
      "loss": 0.3749,
      "step": 1878
    },
    {
      "epoch": 0.2986628519202877,
      "grad_norm": 0.6513305902481079,
      "learning_rate": 8.223787269041266e-06,
      "loss": 0.1188,
      "step": 1879
    },
    {
      "epoch": 0.29882179968607814,
      "grad_norm": 0.5684623718261719,
      "learning_rate": 8.22181913187005e-06,
      "loss": 0.3013,
      "step": 1880
    },
    {
      "epoch": 0.29898074745186864,
      "grad_norm": 0.5989816784858704,
      "learning_rate": 8.219850140701557e-06,
      "loss": 0.3124,
      "step": 1881
    },
    {
      "epoch": 0.2991396952176591,
      "grad_norm": 0.6993605494499207,
      "learning_rate": 8.217880296057703e-06,
      "loss": 0.2104,
      "step": 1882
    },
    {
      "epoch": 0.29929864298344955,
      "grad_norm": 0.4884563386440277,
      "learning_rate": 8.215909598460627e-06,
      "loss": 0.1769,
      "step": 1883
    },
    {
      "epoch": 0.29945759074924005,
      "grad_norm": 2.456888198852539,
      "learning_rate": 8.213938048432697e-06,
      "loss": 0.2017,
      "step": 1884
    },
    {
      "epoch": 0.2996165385150305,
      "grad_norm": 0.6232550144195557,
      "learning_rate": 8.211965646496504e-06,
      "loss": 0.3011,
      "step": 1885
    },
    {
      "epoch": 0.29977548628082096,
      "grad_norm": 0.6421113610267639,
      "learning_rate": 8.209992393174868e-06,
      "loss": 0.3267,
      "step": 1886
    },
    {
      "epoch": 0.2999344340466114,
      "grad_norm": 0.40416958928108215,
      "learning_rate": 8.208018288990832e-06,
      "loss": 0.1108,
      "step": 1887
    },
    {
      "epoch": 0.3000933818124019,
      "grad_norm": 0.6065694689750671,
      "learning_rate": 8.206043334467666e-06,
      "loss": 0.2919,
      "step": 1888
    },
    {
      "epoch": 0.30025232957819237,
      "grad_norm": 0.5668420791625977,
      "learning_rate": 8.204067530128863e-06,
      "loss": 0.269,
      "step": 1889
    },
    {
      "epoch": 0.3004112773439828,
      "grad_norm": 0.5961307883262634,
      "learning_rate": 8.202090876498144e-06,
      "loss": 0.2755,
      "step": 1890
    },
    {
      "epoch": 0.3005702251097733,
      "grad_norm": 0.7115463614463806,
      "learning_rate": 8.200113374099457e-06,
      "loss": 0.3299,
      "step": 1891
    },
    {
      "epoch": 0.3007291728755638,
      "grad_norm": 0.5299967527389526,
      "learning_rate": 8.198135023456968e-06,
      "loss": 0.2002,
      "step": 1892
    },
    {
      "epoch": 0.30088812064135423,
      "grad_norm": 0.6059843301773071,
      "learning_rate": 8.196155825095073e-06,
      "loss": 0.2997,
      "step": 1893
    },
    {
      "epoch": 0.3010470684071447,
      "grad_norm": 0.6013801097869873,
      "learning_rate": 8.194175779538394e-06,
      "loss": 0.3303,
      "step": 1894
    },
    {
      "epoch": 0.3012060161729352,
      "grad_norm": 0.6011247038841248,
      "learning_rate": 8.192194887311776e-06,
      "loss": 0.2467,
      "step": 1895
    },
    {
      "epoch": 0.30136496393872564,
      "grad_norm": 0.5038831830024719,
      "learning_rate": 8.190213148940282e-06,
      "loss": 0.2477,
      "step": 1896
    },
    {
      "epoch": 0.3015239117045161,
      "grad_norm": 0.5545185208320618,
      "learning_rate": 8.188230564949212e-06,
      "loss": 0.2307,
      "step": 1897
    },
    {
      "epoch": 0.3016828594703066,
      "grad_norm": 0.48683562874794006,
      "learning_rate": 8.186247135864078e-06,
      "loss": 0.2114,
      "step": 1898
    },
    {
      "epoch": 0.30184180723609705,
      "grad_norm": 0.6066649556159973,
      "learning_rate": 8.184262862210624e-06,
      "loss": 0.2343,
      "step": 1899
    },
    {
      "epoch": 0.3020007550018875,
      "grad_norm": 0.5726026892662048,
      "learning_rate": 8.182277744514815e-06,
      "loss": 0.2748,
      "step": 1900
    },
    {
      "epoch": 0.30215970276767795,
      "grad_norm": 0.5614754557609558,
      "learning_rate": 8.180291783302838e-06,
      "loss": 0.2354,
      "step": 1901
    },
    {
      "epoch": 0.30231865053346846,
      "grad_norm": 0.5788703560829163,
      "learning_rate": 8.178304979101108e-06,
      "loss": 0.2687,
      "step": 1902
    },
    {
      "epoch": 0.3024775982992589,
      "grad_norm": 0.4869212210178375,
      "learning_rate": 8.176317332436257e-06,
      "loss": 0.2207,
      "step": 1903
    },
    {
      "epoch": 0.30263654606504936,
      "grad_norm": 0.5687143802642822,
      "learning_rate": 8.17432884383515e-06,
      "loss": 0.2222,
      "step": 1904
    },
    {
      "epoch": 0.3027954938308398,
      "grad_norm": 0.5987101197242737,
      "learning_rate": 8.172339513824863e-06,
      "loss": 0.209,
      "step": 1905
    },
    {
      "epoch": 0.3029544415966303,
      "grad_norm": 0.8154991865158081,
      "learning_rate": 8.170349342932703e-06,
      "loss": 0.2307,
      "step": 1906
    },
    {
      "epoch": 0.30311338936242077,
      "grad_norm": 0.5456303954124451,
      "learning_rate": 8.168358331686201e-06,
      "loss": 0.1957,
      "step": 1907
    },
    {
      "epoch": 0.3032723371282112,
      "grad_norm": 0.5953679084777832,
      "learning_rate": 8.166366480613107e-06,
      "loss": 0.285,
      "step": 1908
    },
    {
      "epoch": 0.30343128489400173,
      "grad_norm": 0.6820387840270996,
      "learning_rate": 8.164373790241391e-06,
      "loss": 0.3585,
      "step": 1909
    },
    {
      "epoch": 0.3035902326597922,
      "grad_norm": 0.49354761838912964,
      "learning_rate": 8.162380261099255e-06,
      "loss": 0.1477,
      "step": 1910
    },
    {
      "epoch": 0.30374918042558263,
      "grad_norm": 0.9577805399894714,
      "learning_rate": 8.160385893715113e-06,
      "loss": 0.1924,
      "step": 1911
    },
    {
      "epoch": 0.3039081281913731,
      "grad_norm": 0.6482130289077759,
      "learning_rate": 8.158390688617607e-06,
      "loss": 0.3161,
      "step": 1912
    },
    {
      "epoch": 0.3040670759571636,
      "grad_norm": 0.5804356932640076,
      "learning_rate": 8.1563946463356e-06,
      "loss": 0.2203,
      "step": 1913
    },
    {
      "epoch": 0.30422602372295404,
      "grad_norm": 0.5757278203964233,
      "learning_rate": 8.154397767398175e-06,
      "loss": 0.2309,
      "step": 1914
    },
    {
      "epoch": 0.3043849714887445,
      "grad_norm": 0.6288727521896362,
      "learning_rate": 8.15240005233464e-06,
      "loss": 0.3127,
      "step": 1915
    },
    {
      "epoch": 0.304543919254535,
      "grad_norm": 0.606049656867981,
      "learning_rate": 8.150401501674521e-06,
      "loss": 0.2855,
      "step": 1916
    },
    {
      "epoch": 0.30470286702032545,
      "grad_norm": 0.5007564425468445,
      "learning_rate": 8.14840211594757e-06,
      "loss": 0.2113,
      "step": 1917
    },
    {
      "epoch": 0.3048618147861159,
      "grad_norm": 0.5148934721946716,
      "learning_rate": 8.146401895683758e-06,
      "loss": 0.1863,
      "step": 1918
    },
    {
      "epoch": 0.30502076255190635,
      "grad_norm": 0.6290088295936584,
      "learning_rate": 8.144400841413271e-06,
      "loss": 0.2725,
      "step": 1919
    },
    {
      "epoch": 0.30517971031769686,
      "grad_norm": 0.705864667892456,
      "learning_rate": 8.142398953666531e-06,
      "loss": 0.232,
      "step": 1920
    },
    {
      "epoch": 0.3053386580834873,
      "grad_norm": 0.48953911662101746,
      "learning_rate": 8.140396232974164e-06,
      "loss": 0.1617,
      "step": 1921
    },
    {
      "epoch": 0.30549760584927776,
      "grad_norm": 1.1375905275344849,
      "learning_rate": 8.13839267986703e-06,
      "loss": 0.0992,
      "step": 1922
    },
    {
      "epoch": 0.30565655361506827,
      "grad_norm": 0.5699871182441711,
      "learning_rate": 8.136388294876204e-06,
      "loss": 0.2062,
      "step": 1923
    },
    {
      "epoch": 0.3058155013808587,
      "grad_norm": 0.5475327968597412,
      "learning_rate": 8.134383078532976e-06,
      "loss": 0.2482,
      "step": 1924
    },
    {
      "epoch": 0.3059744491466492,
      "grad_norm": 0.6262905597686768,
      "learning_rate": 8.132377031368871e-06,
      "loss": 0.2344,
      "step": 1925
    },
    {
      "epoch": 0.3061333969124396,
      "grad_norm": 0.8103602528572083,
      "learning_rate": 8.13037015391562e-06,
      "loss": 0.1367,
      "step": 1926
    },
    {
      "epoch": 0.30629234467823013,
      "grad_norm": 0.5728987455368042,
      "learning_rate": 8.12836244670518e-06,
      "loss": 0.2697,
      "step": 1927
    },
    {
      "epoch": 0.3064512924440206,
      "grad_norm": 0.9053500890731812,
      "learning_rate": 8.126353910269729e-06,
      "loss": 0.2159,
      "step": 1928
    },
    {
      "epoch": 0.30661024020981104,
      "grad_norm": 1.847286581993103,
      "learning_rate": 8.124344545141663e-06,
      "loss": 0.231,
      "step": 1929
    },
    {
      "epoch": 0.30676918797560154,
      "grad_norm": 0.5157938599586487,
      "learning_rate": 8.122334351853597e-06,
      "loss": 0.2242,
      "step": 1930
    },
    {
      "epoch": 0.306928135741392,
      "grad_norm": 0.8489388823509216,
      "learning_rate": 8.120323330938367e-06,
      "loss": 0.1735,
      "step": 1931
    },
    {
      "epoch": 0.30708708350718245,
      "grad_norm": 0.5725012421607971,
      "learning_rate": 8.118311482929028e-06,
      "loss": 0.3187,
      "step": 1932
    },
    {
      "epoch": 0.3072460312729729,
      "grad_norm": 0.8634095788002014,
      "learning_rate": 8.116298808358856e-06,
      "loss": 0.1618,
      "step": 1933
    },
    {
      "epoch": 0.3074049790387634,
      "grad_norm": 1.7453693151474,
      "learning_rate": 8.114285307761341e-06,
      "loss": 0.1763,
      "step": 1934
    },
    {
      "epoch": 0.30756392680455386,
      "grad_norm": 0.6497169137001038,
      "learning_rate": 8.112270981670196e-06,
      "loss": 0.2536,
      "step": 1935
    },
    {
      "epoch": 0.3077228745703443,
      "grad_norm": 0.4964582920074463,
      "learning_rate": 8.110255830619352e-06,
      "loss": 0.2009,
      "step": 1936
    },
    {
      "epoch": 0.3078818223361348,
      "grad_norm": 0.6095663905143738,
      "learning_rate": 8.10823985514296e-06,
      "loss": 0.1657,
      "step": 1937
    },
    {
      "epoch": 0.30804077010192527,
      "grad_norm": 0.5026999115943909,
      "learning_rate": 8.106223055775387e-06,
      "loss": 0.1724,
      "step": 1938
    },
    {
      "epoch": 0.3081997178677157,
      "grad_norm": 0.4438256621360779,
      "learning_rate": 8.10420543305122e-06,
      "loss": 0.1091,
      "step": 1939
    },
    {
      "epoch": 0.30835866563350617,
      "grad_norm": 0.6038092374801636,
      "learning_rate": 8.102186987505266e-06,
      "loss": 0.3146,
      "step": 1940
    },
    {
      "epoch": 0.3085176133992967,
      "grad_norm": 0.6990886330604553,
      "learning_rate": 8.10016771967254e-06,
      "loss": 0.3524,
      "step": 1941
    },
    {
      "epoch": 0.3086765611650871,
      "grad_norm": 0.5735041499137878,
      "learning_rate": 8.098147630088294e-06,
      "loss": 0.1305,
      "step": 1942
    },
    {
      "epoch": 0.3088355089308776,
      "grad_norm": 0.6120731830596924,
      "learning_rate": 8.096126719287976e-06,
      "loss": 0.3221,
      "step": 1943
    },
    {
      "epoch": 0.3089944566966681,
      "grad_norm": 0.4800774157047272,
      "learning_rate": 8.09410498780727e-06,
      "loss": 0.1916,
      "step": 1944
    },
    {
      "epoch": 0.30915340446245854,
      "grad_norm": 0.5382590889930725,
      "learning_rate": 8.092082436182067e-06,
      "loss": 0.2619,
      "step": 1945
    },
    {
      "epoch": 0.309312352228249,
      "grad_norm": 0.5182527303695679,
      "learning_rate": 8.090059064948479e-06,
      "loss": 0.1826,
      "step": 1946
    },
    {
      "epoch": 0.30947129999403944,
      "grad_norm": 0.48336106538772583,
      "learning_rate": 8.088034874642834e-06,
      "loss": 0.1505,
      "step": 1947
    },
    {
      "epoch": 0.30963024775982995,
      "grad_norm": 0.49488162994384766,
      "learning_rate": 8.086009865801676e-06,
      "loss": 0.2293,
      "step": 1948
    },
    {
      "epoch": 0.3097891955256204,
      "grad_norm": 0.627551794052124,
      "learning_rate": 8.083984038961771e-06,
      "loss": 0.2611,
      "step": 1949
    },
    {
      "epoch": 0.30994814329141085,
      "grad_norm": 0.6196744441986084,
      "learning_rate": 8.081957394660096e-06,
      "loss": 0.2803,
      "step": 1950
    },
    {
      "epoch": 0.3101070910572013,
      "grad_norm": 0.8098450303077698,
      "learning_rate": 8.079929933433848e-06,
      "loss": 0.2272,
      "step": 1951
    },
    {
      "epoch": 0.3102660388229918,
      "grad_norm": 0.5831685662269592,
      "learning_rate": 8.077901655820442e-06,
      "loss": 0.2625,
      "step": 1952
    },
    {
      "epoch": 0.31042498658878226,
      "grad_norm": 0.531266987323761,
      "learning_rate": 8.075872562357502e-06,
      "loss": 0.1674,
      "step": 1953
    },
    {
      "epoch": 0.3105839343545727,
      "grad_norm": 0.8491377830505371,
      "learning_rate": 8.073842653582876e-06,
      "loss": 0.2757,
      "step": 1954
    },
    {
      "epoch": 0.3107428821203632,
      "grad_norm": 0.6310631036758423,
      "learning_rate": 8.071811930034624e-06,
      "loss": 0.2294,
      "step": 1955
    },
    {
      "epoch": 0.31090182988615367,
      "grad_norm": 0.581706702709198,
      "learning_rate": 8.069780392251026e-06,
      "loss": 0.2667,
      "step": 1956
    },
    {
      "epoch": 0.3110607776519441,
      "grad_norm": 0.5511679649353027,
      "learning_rate": 8.067748040770574e-06,
      "loss": 0.254,
      "step": 1957
    },
    {
      "epoch": 0.31121972541773457,
      "grad_norm": 0.5122643709182739,
      "learning_rate": 8.065714876131976e-06,
      "loss": 0.2034,
      "step": 1958
    },
    {
      "epoch": 0.3113786731835251,
      "grad_norm": 0.5352256894111633,
      "learning_rate": 8.063680898874158e-06,
      "loss": 0.2348,
      "step": 1959
    },
    {
      "epoch": 0.31153762094931553,
      "grad_norm": 0.526678204536438,
      "learning_rate": 8.06164610953626e-06,
      "loss": 0.1992,
      "step": 1960
    },
    {
      "epoch": 0.311696568715106,
      "grad_norm": 0.6811268329620361,
      "learning_rate": 8.059610508657634e-06,
      "loss": 0.2143,
      "step": 1961
    },
    {
      "epoch": 0.3118555164808965,
      "grad_norm": 0.5184306502342224,
      "learning_rate": 8.057574096777854e-06,
      "loss": 0.1758,
      "step": 1962
    },
    {
      "epoch": 0.31201446424668694,
      "grad_norm": 0.6995025873184204,
      "learning_rate": 8.055536874436702e-06,
      "loss": 0.3068,
      "step": 1963
    },
    {
      "epoch": 0.3121734120124774,
      "grad_norm": 0.6044344305992126,
      "learning_rate": 8.053498842174181e-06,
      "loss": 0.0781,
      "step": 1964
    },
    {
      "epoch": 0.31233235977826784,
      "grad_norm": 0.5809381008148193,
      "learning_rate": 8.051460000530501e-06,
      "loss": 0.3301,
      "step": 1965
    },
    {
      "epoch": 0.31249130754405835,
      "grad_norm": 0.614234983921051,
      "learning_rate": 8.049420350046097e-06,
      "loss": 0.3095,
      "step": 1966
    },
    {
      "epoch": 0.3126502553098488,
      "grad_norm": 0.6143724918365479,
      "learning_rate": 8.04737989126161e-06,
      "loss": 0.2557,
      "step": 1967
    },
    {
      "epoch": 0.31280920307563925,
      "grad_norm": 0.5000016093254089,
      "learning_rate": 8.0453386247179e-06,
      "loss": 0.2443,
      "step": 1968
    },
    {
      "epoch": 0.31296815084142976,
      "grad_norm": 0.6425303220748901,
      "learning_rate": 8.043296550956035e-06,
      "loss": 0.2554,
      "step": 1969
    },
    {
      "epoch": 0.3131270986072202,
      "grad_norm": 0.5500687956809998,
      "learning_rate": 8.041253670517302e-06,
      "loss": 0.1778,
      "step": 1970
    },
    {
      "epoch": 0.31328604637301066,
      "grad_norm": 0.4620128870010376,
      "learning_rate": 8.039209983943201e-06,
      "loss": 0.1233,
      "step": 1971
    },
    {
      "epoch": 0.3134449941388011,
      "grad_norm": 0.578348696231842,
      "learning_rate": 8.037165491775448e-06,
      "loss": 0.2028,
      "step": 1972
    },
    {
      "epoch": 0.3136039419045916,
      "grad_norm": 0.46786612272262573,
      "learning_rate": 8.035120194555967e-06,
      "loss": 0.141,
      "step": 1973
    },
    {
      "epoch": 0.3137628896703821,
      "grad_norm": 0.517761766910553,
      "learning_rate": 8.0330740928269e-06,
      "loss": 0.2104,
      "step": 1974
    },
    {
      "epoch": 0.3139218374361725,
      "grad_norm": 0.6311025619506836,
      "learning_rate": 8.031027187130598e-06,
      "loss": 0.3521,
      "step": 1975
    },
    {
      "epoch": 0.31408078520196303,
      "grad_norm": 0.5181496143341064,
      "learning_rate": 8.028979478009632e-06,
      "loss": 0.2103,
      "step": 1976
    },
    {
      "epoch": 0.3142397329677535,
      "grad_norm": 0.5629250407218933,
      "learning_rate": 8.026930966006778e-06,
      "loss": 0.2597,
      "step": 1977
    },
    {
      "epoch": 0.31439868073354393,
      "grad_norm": 0.5840385556221008,
      "learning_rate": 8.024881651665031e-06,
      "loss": 0.2887,
      "step": 1978
    },
    {
      "epoch": 0.3145576284993344,
      "grad_norm": 0.4986248314380646,
      "learning_rate": 8.022831535527596e-06,
      "loss": 0.1797,
      "step": 1979
    },
    {
      "epoch": 0.3147165762651249,
      "grad_norm": 0.5348337292671204,
      "learning_rate": 8.020780618137889e-06,
      "loss": 0.2618,
      "step": 1980
    },
    {
      "epoch": 0.31487552403091534,
      "grad_norm": 0.561119794845581,
      "learning_rate": 8.01872890003954e-06,
      "loss": 0.2224,
      "step": 1981
    },
    {
      "epoch": 0.3150344717967058,
      "grad_norm": 0.5261144638061523,
      "learning_rate": 8.016676381776394e-06,
      "loss": 0.2296,
      "step": 1982
    },
    {
      "epoch": 0.3151934195624963,
      "grad_norm": 0.6062135696411133,
      "learning_rate": 8.014623063892504e-06,
      "loss": 0.3428,
      "step": 1983
    },
    {
      "epoch": 0.31535236732828675,
      "grad_norm": 0.49280279874801636,
      "learning_rate": 8.012568946932136e-06,
      "loss": 0.2175,
      "step": 1984
    },
    {
      "epoch": 0.3155113150940772,
      "grad_norm": 0.42164716124534607,
      "learning_rate": 8.010514031439766e-06,
      "loss": 0.1323,
      "step": 1985
    },
    {
      "epoch": 0.31567026285986766,
      "grad_norm": 0.5230472683906555,
      "learning_rate": 8.008458317960088e-06,
      "loss": 0.2748,
      "step": 1986
    },
    {
      "epoch": 0.31582921062565816,
      "grad_norm": 0.5361524820327759,
      "learning_rate": 8.006401807038003e-06,
      "loss": 0.2244,
      "step": 1987
    },
    {
      "epoch": 0.3159881583914486,
      "grad_norm": 0.5412015914916992,
      "learning_rate": 8.00434449921862e-06,
      "loss": 0.2641,
      "step": 1988
    },
    {
      "epoch": 0.31614710615723907,
      "grad_norm": 0.5972484350204468,
      "learning_rate": 8.002286395047267e-06,
      "loss": 0.2798,
      "step": 1989
    },
    {
      "epoch": 0.3163060539230295,
      "grad_norm": 0.5005331039428711,
      "learning_rate": 8.000227495069477e-06,
      "loss": 0.2519,
      "step": 1990
    },
    {
      "epoch": 0.31646500168882,
      "grad_norm": 0.5251731276512146,
      "learning_rate": 7.998167799830997e-06,
      "loss": 0.2774,
      "step": 1991
    },
    {
      "epoch": 0.3166239494546105,
      "grad_norm": 0.5467069149017334,
      "learning_rate": 7.996107309877783e-06,
      "loss": 0.2977,
      "step": 1992
    },
    {
      "epoch": 0.3167828972204009,
      "grad_norm": 0.5507413148880005,
      "learning_rate": 7.994046025756001e-06,
      "loss": 0.1992,
      "step": 1993
    },
    {
      "epoch": 0.31694184498619143,
      "grad_norm": 0.5294443964958191,
      "learning_rate": 7.991983948012033e-06,
      "loss": 0.2241,
      "step": 1994
    },
    {
      "epoch": 0.3171007927519819,
      "grad_norm": 0.578432023525238,
      "learning_rate": 7.989921077192464e-06,
      "loss": 0.2885,
      "step": 1995
    },
    {
      "epoch": 0.31725974051777234,
      "grad_norm": 0.5844245553016663,
      "learning_rate": 7.987857413844094e-06,
      "loss": 0.228,
      "step": 1996
    },
    {
      "epoch": 0.3174186882835628,
      "grad_norm": 0.5799883604049683,
      "learning_rate": 7.985792958513932e-06,
      "loss": 0.3519,
      "step": 1997
    },
    {
      "epoch": 0.3175776360493533,
      "grad_norm": 0.5364368557929993,
      "learning_rate": 7.983727711749194e-06,
      "loss": 0.2955,
      "step": 1998
    },
    {
      "epoch": 0.31773658381514375,
      "grad_norm": 0.5219990611076355,
      "learning_rate": 7.981661674097312e-06,
      "loss": 0.157,
      "step": 1999
    },
    {
      "epoch": 0.3178955315809342,
      "grad_norm": 0.4337891936302185,
      "learning_rate": 7.979594846105921e-06,
      "loss": 0.162,
      "step": 2000
    },
    {
      "epoch": 0.3180544793467247,
      "grad_norm": 0.549568235874176,
      "learning_rate": 7.97752722832287e-06,
      "loss": 0.2354,
      "step": 2001
    },
    {
      "epoch": 0.31821342711251516,
      "grad_norm": 0.5192674398422241,
      "learning_rate": 7.975458821296217e-06,
      "loss": 0.2718,
      "step": 2002
    },
    {
      "epoch": 0.3183723748783056,
      "grad_norm": 0.5906934142112732,
      "learning_rate": 7.973389625574225e-06,
      "loss": 0.3583,
      "step": 2003
    },
    {
      "epoch": 0.31853132264409606,
      "grad_norm": 0.47573256492614746,
      "learning_rate": 7.97131964170537e-06,
      "loss": 0.1616,
      "step": 2004
    },
    {
      "epoch": 0.31869027040988657,
      "grad_norm": 0.4924202263355255,
      "learning_rate": 7.969248870238338e-06,
      "loss": 0.1937,
      "step": 2005
    },
    {
      "epoch": 0.318849218175677,
      "grad_norm": 0.591038167476654,
      "learning_rate": 7.96717731172202e-06,
      "loss": 0.2846,
      "step": 2006
    },
    {
      "epoch": 0.31900816594146747,
      "grad_norm": 0.5835007429122925,
      "learning_rate": 7.965104966705518e-06,
      "loss": 0.27,
      "step": 2007
    },
    {
      "epoch": 0.319167113707258,
      "grad_norm": 0.6133306622505188,
      "learning_rate": 7.96303183573814e-06,
      "loss": 0.3466,
      "step": 2008
    },
    {
      "epoch": 0.31932606147304843,
      "grad_norm": 0.5941030383110046,
      "learning_rate": 7.960957919369408e-06,
      "loss": 0.3267,
      "step": 2009
    },
    {
      "epoch": 0.3194850092388389,
      "grad_norm": 0.5678000450134277,
      "learning_rate": 7.958883218149044e-06,
      "loss": 0.292,
      "step": 2010
    },
    {
      "epoch": 0.31964395700462933,
      "grad_norm": 0.5040793418884277,
      "learning_rate": 7.956807732626986e-06,
      "loss": 0.1968,
      "step": 2011
    },
    {
      "epoch": 0.31980290477041984,
      "grad_norm": 0.5921862721443176,
      "learning_rate": 7.954731463353373e-06,
      "loss": 0.2655,
      "step": 2012
    },
    {
      "epoch": 0.3199618525362103,
      "grad_norm": 0.5068542957305908,
      "learning_rate": 7.95265441087856e-06,
      "loss": 0.2067,
      "step": 2013
    },
    {
      "epoch": 0.32012080030200074,
      "grad_norm": 1.893305778503418,
      "learning_rate": 7.950576575753098e-06,
      "loss": 0.1673,
      "step": 2014
    },
    {
      "epoch": 0.32027974806779125,
      "grad_norm": 0.4539680778980255,
      "learning_rate": 7.948497958527757e-06,
      "loss": 0.1532,
      "step": 2015
    },
    {
      "epoch": 0.3204386958335817,
      "grad_norm": 0.5585792064666748,
      "learning_rate": 7.946418559753509e-06,
      "loss": 0.2569,
      "step": 2016
    },
    {
      "epoch": 0.32059764359937215,
      "grad_norm": 0.5884061455726624,
      "learning_rate": 7.944338379981532e-06,
      "loss": 0.3152,
      "step": 2017
    },
    {
      "epoch": 0.3207565913651626,
      "grad_norm": 0.516182541847229,
      "learning_rate": 7.942257419763212e-06,
      "loss": 0.2149,
      "step": 2018
    },
    {
      "epoch": 0.3209155391309531,
      "grad_norm": 0.6649456024169922,
      "learning_rate": 7.940175679650145e-06,
      "loss": 0.1501,
      "step": 2019
    },
    {
      "epoch": 0.32107448689674356,
      "grad_norm": 0.5728618502616882,
      "learning_rate": 7.93809316019413e-06,
      "loss": 0.2824,
      "step": 2020
    },
    {
      "epoch": 0.321233434662534,
      "grad_norm": 0.5692519545555115,
      "learning_rate": 7.936009861947174e-06,
      "loss": 0.2493,
      "step": 2021
    },
    {
      "epoch": 0.3213923824283245,
      "grad_norm": 0.6749657988548279,
      "learning_rate": 7.933925785461487e-06,
      "loss": 0.3714,
      "step": 2022
    },
    {
      "epoch": 0.32155133019411497,
      "grad_norm": 0.4789474904537201,
      "learning_rate": 7.931840931289493e-06,
      "loss": 0.2098,
      "step": 2023
    },
    {
      "epoch": 0.3217102779599054,
      "grad_norm": 0.5233579277992249,
      "learning_rate": 7.929755299983817e-06,
      "loss": 0.1792,
      "step": 2024
    },
    {
      "epoch": 0.3218692257256959,
      "grad_norm": 0.4881138205528259,
      "learning_rate": 7.927668892097288e-06,
      "loss": 0.1881,
      "step": 2025
    },
    {
      "epoch": 0.3220281734914864,
      "grad_norm": 0.5069741606712341,
      "learning_rate": 7.925581708182945e-06,
      "loss": 0.2048,
      "step": 2026
    },
    {
      "epoch": 0.32218712125727683,
      "grad_norm": 1.2297859191894531,
      "learning_rate": 7.923493748794033e-06,
      "loss": 0.2514,
      "step": 2027
    },
    {
      "epoch": 0.3223460690230673,
      "grad_norm": 0.5371013283729553,
      "learning_rate": 7.921405014483998e-06,
      "loss": 0.2572,
      "step": 2028
    },
    {
      "epoch": 0.32250501678885773,
      "grad_norm": 0.5683290958404541,
      "learning_rate": 7.919315505806493e-06,
      "loss": 0.3162,
      "step": 2029
    },
    {
      "epoch": 0.32266396455464824,
      "grad_norm": 0.6119759678840637,
      "learning_rate": 7.91722522331538e-06,
      "loss": 0.2711,
      "step": 2030
    },
    {
      "epoch": 0.3228229123204387,
      "grad_norm": 0.5948400497436523,
      "learning_rate": 7.915134167564724e-06,
      "loss": 0.3286,
      "step": 2031
    },
    {
      "epoch": 0.32298186008622914,
      "grad_norm": 0.5432063341140747,
      "learning_rate": 7.913042339108794e-06,
      "loss": 0.2672,
      "step": 2032
    },
    {
      "epoch": 0.32314080785201965,
      "grad_norm": 0.6414403319358826,
      "learning_rate": 7.91094973850206e-06,
      "loss": 0.2741,
      "step": 2033
    },
    {
      "epoch": 0.3232997556178101,
      "grad_norm": 0.6035951972007751,
      "learning_rate": 7.908856366299206e-06,
      "loss": 0.3299,
      "step": 2034
    },
    {
      "epoch": 0.32345870338360055,
      "grad_norm": 0.637790322303772,
      "learning_rate": 7.906762223055115e-06,
      "loss": 0.2995,
      "step": 2035
    },
    {
      "epoch": 0.323617651149391,
      "grad_norm": 0.6197163462638855,
      "learning_rate": 7.904667309324874e-06,
      "loss": 0.3362,
      "step": 2036
    },
    {
      "epoch": 0.3237765989151815,
      "grad_norm": 0.6433846950531006,
      "learning_rate": 7.902571625663773e-06,
      "loss": 0.3808,
      "step": 2037
    },
    {
      "epoch": 0.32393554668097196,
      "grad_norm": 0.4257296025753021,
      "learning_rate": 7.90047517262731e-06,
      "loss": 0.1478,
      "step": 2038
    },
    {
      "epoch": 0.3240944944467624,
      "grad_norm": 0.5115353465080261,
      "learning_rate": 7.898377950771187e-06,
      "loss": 0.2496,
      "step": 2039
    },
    {
      "epoch": 0.3242534422125529,
      "grad_norm": 0.6809743642807007,
      "learning_rate": 7.896279960651304e-06,
      "loss": 0.3948,
      "step": 2040
    },
    {
      "epoch": 0.3244123899783434,
      "grad_norm": 0.5405633449554443,
      "learning_rate": 7.894181202823772e-06,
      "loss": 0.302,
      "step": 2041
    },
    {
      "epoch": 0.3245713377441338,
      "grad_norm": 0.6113837957382202,
      "learning_rate": 7.892081677844899e-06,
      "loss": 0.3891,
      "step": 2042
    },
    {
      "epoch": 0.3247302855099243,
      "grad_norm": 0.5047128200531006,
      "learning_rate": 7.889981386271202e-06,
      "loss": 0.2229,
      "step": 2043
    },
    {
      "epoch": 0.3248892332757148,
      "grad_norm": 0.5237105488777161,
      "learning_rate": 7.887880328659397e-06,
      "loss": 0.2514,
      "step": 2044
    },
    {
      "epoch": 0.32504818104150524,
      "grad_norm": 0.7790926694869995,
      "learning_rate": 7.885778505566404e-06,
      "loss": 0.2757,
      "step": 2045
    },
    {
      "epoch": 0.3252071288072957,
      "grad_norm": 0.6162935495376587,
      "learning_rate": 7.883675917549349e-06,
      "loss": 0.3837,
      "step": 2046
    },
    {
      "epoch": 0.3253660765730862,
      "grad_norm": 0.43821144104003906,
      "learning_rate": 7.881572565165556e-06,
      "loss": 0.182,
      "step": 2047
    },
    {
      "epoch": 0.32552502433887665,
      "grad_norm": 0.5460807085037231,
      "learning_rate": 7.879468448972553e-06,
      "loss": 0.2293,
      "step": 2048
    },
    {
      "epoch": 0.3256839721046671,
      "grad_norm": 0.4872174859046936,
      "learning_rate": 7.877363569528076e-06,
      "loss": 0.1896,
      "step": 2049
    },
    {
      "epoch": 0.32584291987045755,
      "grad_norm": 0.5219380855560303,
      "learning_rate": 7.875257927390053e-06,
      "loss": 0.2644,
      "step": 2050
    },
    {
      "epoch": 0.32600186763624805,
      "grad_norm": 0.57786625623703,
      "learning_rate": 7.873151523116625e-06,
      "loss": 0.2695,
      "step": 2051
    },
    {
      "epoch": 0.3261608154020385,
      "grad_norm": 0.644726037979126,
      "learning_rate": 7.871044357266124e-06,
      "loss": 0.2608,
      "step": 2052
    },
    {
      "epoch": 0.32631976316782896,
      "grad_norm": 0.485126256942749,
      "learning_rate": 7.868936430397095e-06,
      "loss": 0.2248,
      "step": 2053
    },
    {
      "epoch": 0.32647871093361946,
      "grad_norm": 0.6495401859283447,
      "learning_rate": 7.866827743068279e-06,
      "loss": 0.3753,
      "step": 2054
    },
    {
      "epoch": 0.3266376586994099,
      "grad_norm": 0.4779009521007538,
      "learning_rate": 7.864718295838615e-06,
      "loss": 0.2139,
      "step": 2055
    },
    {
      "epoch": 0.32679660646520037,
      "grad_norm": 0.4829981029033661,
      "learning_rate": 7.86260808926725e-06,
      "loss": 0.1335,
      "step": 2056
    },
    {
      "epoch": 0.3269555542309908,
      "grad_norm": 0.4978695213794708,
      "learning_rate": 7.860497123913531e-06,
      "loss": 0.2022,
      "step": 2057
    },
    {
      "epoch": 0.3271145019967813,
      "grad_norm": 0.42437565326690674,
      "learning_rate": 7.858385400337002e-06,
      "loss": 0.1515,
      "step": 2058
    },
    {
      "epoch": 0.3272734497625718,
      "grad_norm": 0.43597376346588135,
      "learning_rate": 7.856272919097412e-06,
      "loss": 0.1395,
      "step": 2059
    },
    {
      "epoch": 0.32743239752836223,
      "grad_norm": 0.46622931957244873,
      "learning_rate": 7.854159680754711e-06,
      "loss": 0.2062,
      "step": 2060
    },
    {
      "epoch": 0.32759134529415274,
      "grad_norm": 0.5552346110343933,
      "learning_rate": 7.852045685869046e-06,
      "loss": 0.2633,
      "step": 2061
    },
    {
      "epoch": 0.3277502930599432,
      "grad_norm": 0.665460467338562,
      "learning_rate": 7.84993093500077e-06,
      "loss": 0.3653,
      "step": 2062
    },
    {
      "epoch": 0.32790924082573364,
      "grad_norm": 0.4973861277103424,
      "learning_rate": 7.847815428710428e-06,
      "loss": 0.1655,
      "step": 2063
    },
    {
      "epoch": 0.3280681885915241,
      "grad_norm": 0.6574528813362122,
      "learning_rate": 7.845699167558776e-06,
      "loss": 0.3919,
      "step": 2064
    },
    {
      "epoch": 0.3282271363573146,
      "grad_norm": 0.7671462297439575,
      "learning_rate": 7.84358215210676e-06,
      "loss": 0.3114,
      "step": 2065
    },
    {
      "epoch": 0.32838608412310505,
      "grad_norm": 0.6000462770462036,
      "learning_rate": 7.841464382915534e-06,
      "loss": 0.3476,
      "step": 2066
    },
    {
      "epoch": 0.3285450318888955,
      "grad_norm": 0.5707135200500488,
      "learning_rate": 7.839345860546448e-06,
      "loss": 0.2818,
      "step": 2067
    },
    {
      "epoch": 0.32870397965468595,
      "grad_norm": 0.5863335728645325,
      "learning_rate": 7.83722658556105e-06,
      "loss": 0.3095,
      "step": 2068
    },
    {
      "epoch": 0.32886292742047646,
      "grad_norm": 0.5245867967605591,
      "learning_rate": 7.835106558521091e-06,
      "loss": 0.2259,
      "step": 2069
    },
    {
      "epoch": 0.3290218751862669,
      "grad_norm": 0.547565221786499,
      "learning_rate": 7.832985779988518e-06,
      "loss": 0.2431,
      "step": 2070
    },
    {
      "epoch": 0.32918082295205736,
      "grad_norm": 0.5378380417823792,
      "learning_rate": 7.830864250525481e-06,
      "loss": 0.1739,
      "step": 2071
    },
    {
      "epoch": 0.32933977071784787,
      "grad_norm": 0.4555354714393616,
      "learning_rate": 7.828741970694325e-06,
      "loss": 0.1653,
      "step": 2072
    },
    {
      "epoch": 0.3294987184836383,
      "grad_norm": 0.6196807026863098,
      "learning_rate": 7.826618941057597e-06,
      "loss": 0.3259,
      "step": 2073
    },
    {
      "epoch": 0.32965766624942877,
      "grad_norm": 0.4609191119670868,
      "learning_rate": 7.824495162178045e-06,
      "loss": 0.1531,
      "step": 2074
    },
    {
      "epoch": 0.3298166140152192,
      "grad_norm": 0.5564417839050293,
      "learning_rate": 7.822370634618605e-06,
      "loss": 0.3107,
      "step": 2075
    },
    {
      "epoch": 0.32997556178100973,
      "grad_norm": 0.5209745764732361,
      "learning_rate": 7.820245358942424e-06,
      "loss": 0.204,
      "step": 2076
    },
    {
      "epoch": 0.3301345095468002,
      "grad_norm": 0.5873117446899414,
      "learning_rate": 7.818119335712841e-06,
      "loss": 0.2894,
      "step": 2077
    },
    {
      "epoch": 0.33029345731259063,
      "grad_norm": 0.5424597859382629,
      "learning_rate": 7.815992565493396e-06,
      "loss": 0.2591,
      "step": 2078
    },
    {
      "epoch": 0.33045240507838114,
      "grad_norm": 0.552329421043396,
      "learning_rate": 7.81386504884782e-06,
      "loss": 0.2722,
      "step": 2079
    },
    {
      "epoch": 0.3306113528441716,
      "grad_norm": 0.6628072261810303,
      "learning_rate": 7.81173678634005e-06,
      "loss": 0.2991,
      "step": 2080
    },
    {
      "epoch": 0.33077030060996204,
      "grad_norm": 0.573754608631134,
      "learning_rate": 7.809607778534221e-06,
      "loss": 0.2776,
      "step": 2081
    },
    {
      "epoch": 0.3309292483757525,
      "grad_norm": 0.48200225830078125,
      "learning_rate": 7.807478025994656e-06,
      "loss": 0.1694,
      "step": 2082
    },
    {
      "epoch": 0.331088196141543,
      "grad_norm": 0.6140085458755493,
      "learning_rate": 7.805347529285884e-06,
      "loss": 0.3278,
      "step": 2083
    },
    {
      "epoch": 0.33124714390733345,
      "grad_norm": 0.46930575370788574,
      "learning_rate": 7.803216288972634e-06,
      "loss": 0.1851,
      "step": 2084
    },
    {
      "epoch": 0.3314060916731239,
      "grad_norm": 0.6163879632949829,
      "learning_rate": 7.80108430561982e-06,
      "loss": 0.3742,
      "step": 2085
    },
    {
      "epoch": 0.3315650394389144,
      "grad_norm": 0.5426827669143677,
      "learning_rate": 7.798951579792562e-06,
      "loss": 0.2111,
      "step": 2086
    },
    {
      "epoch": 0.33172398720470486,
      "grad_norm": 0.5399254560470581,
      "learning_rate": 7.796818112056176e-06,
      "loss": 0.2831,
      "step": 2087
    },
    {
      "epoch": 0.3318829349704953,
      "grad_norm": 0.46807196736335754,
      "learning_rate": 7.794683902976175e-06,
      "loss": 0.1472,
      "step": 2088
    },
    {
      "epoch": 0.33204188273628576,
      "grad_norm": 0.5090685486793518,
      "learning_rate": 7.792548953118264e-06,
      "loss": 0.2046,
      "step": 2089
    },
    {
      "epoch": 0.33220083050207627,
      "grad_norm": 0.5273039937019348,
      "learning_rate": 7.790413263048346e-06,
      "loss": 0.1928,
      "step": 2090
    },
    {
      "epoch": 0.3323597782678667,
      "grad_norm": 0.43315020203590393,
      "learning_rate": 7.788276833332527e-06,
      "loss": 0.1563,
      "step": 2091
    },
    {
      "epoch": 0.3325187260336572,
      "grad_norm": 0.5708996653556824,
      "learning_rate": 7.786139664537098e-06,
      "loss": 0.3154,
      "step": 2092
    },
    {
      "epoch": 0.3326776737994477,
      "grad_norm": 0.5509404540061951,
      "learning_rate": 7.784001757228556e-06,
      "loss": 0.2378,
      "step": 2093
    },
    {
      "epoch": 0.33283662156523813,
      "grad_norm": 0.4713984727859497,
      "learning_rate": 7.781863111973586e-06,
      "loss": 0.1728,
      "step": 2094
    },
    {
      "epoch": 0.3329955693310286,
      "grad_norm": 0.4831896424293518,
      "learning_rate": 7.779723729339072e-06,
      "loss": 0.1469,
      "step": 2095
    },
    {
      "epoch": 0.33315451709681904,
      "grad_norm": 0.4089731276035309,
      "learning_rate": 7.777583609892096e-06,
      "loss": 0.1288,
      "step": 2096
    },
    {
      "epoch": 0.33331346486260954,
      "grad_norm": 0.6430926322937012,
      "learning_rate": 7.775442754199929e-06,
      "loss": 0.3585,
      "step": 2097
    },
    {
      "epoch": 0.3334724126284,
      "grad_norm": 0.5338001251220703,
      "learning_rate": 7.773301162830044e-06,
      "loss": 0.1912,
      "step": 2098
    },
    {
      "epoch": 0.33363136039419045,
      "grad_norm": 0.5087518692016602,
      "learning_rate": 7.771158836350105e-06,
      "loss": 0.1445,
      "step": 2099
    },
    {
      "epoch": 0.33379030815998095,
      "grad_norm": 0.6049320101737976,
      "learning_rate": 7.76901577532797e-06,
      "loss": 0.2724,
      "step": 2100
    },
    {
      "epoch": 0.3339492559257714,
      "grad_norm": 0.4100015163421631,
      "learning_rate": 7.766871980331694e-06,
      "loss": 0.1284,
      "step": 2101
    },
    {
      "epoch": 0.33410820369156186,
      "grad_norm": 0.5094391107559204,
      "learning_rate": 7.764727451929527e-06,
      "loss": 0.2805,
      "step": 2102
    },
    {
      "epoch": 0.3342671514573523,
      "grad_norm": 0.5029551386833191,
      "learning_rate": 7.762582190689912e-06,
      "loss": 0.2074,
      "step": 2103
    },
    {
      "epoch": 0.3344260992231428,
      "grad_norm": 0.66868656873703,
      "learning_rate": 7.760436197181484e-06,
      "loss": 0.2871,
      "step": 2104
    },
    {
      "epoch": 0.33458504698893327,
      "grad_norm": 0.6396355628967285,
      "learning_rate": 7.758289471973077e-06,
      "loss": 0.3382,
      "step": 2105
    },
    {
      "epoch": 0.3347439947547237,
      "grad_norm": 0.5234202742576599,
      "learning_rate": 7.75614201563372e-06,
      "loss": 0.1914,
      "step": 2106
    },
    {
      "epoch": 0.33490294252051417,
      "grad_norm": 0.528251051902771,
      "learning_rate": 7.753993828732624e-06,
      "loss": 0.2083,
      "step": 2107
    },
    {
      "epoch": 0.3350618902863047,
      "grad_norm": 0.5879419445991516,
      "learning_rate": 7.751844911839207e-06,
      "loss": 0.2186,
      "step": 2108
    },
    {
      "epoch": 0.3352208380520951,
      "grad_norm": 0.5965697169303894,
      "learning_rate": 7.749695265523076e-06,
      "loss": 0.2695,
      "step": 2109
    },
    {
      "epoch": 0.3353797858178856,
      "grad_norm": 0.5700950622558594,
      "learning_rate": 7.747544890354031e-06,
      "loss": 0.2998,
      "step": 2110
    },
    {
      "epoch": 0.3355387335836761,
      "grad_norm": 0.6037167906761169,
      "learning_rate": 7.745393786902063e-06,
      "loss": 0.1824,
      "step": 2111
    },
    {
      "epoch": 0.33569768134946654,
      "grad_norm": 0.494123637676239,
      "learning_rate": 7.743241955737359e-06,
      "loss": 0.2588,
      "step": 2112
    },
    {
      "epoch": 0.335856629115257,
      "grad_norm": 0.535201907157898,
      "learning_rate": 7.7410893974303e-06,
      "loss": 0.193,
      "step": 2113
    },
    {
      "epoch": 0.33601557688104744,
      "grad_norm": 0.45902231335639954,
      "learning_rate": 7.738936112551454e-06,
      "loss": 0.1645,
      "step": 2114
    },
    {
      "epoch": 0.33617452464683795,
      "grad_norm": 0.5748307108879089,
      "learning_rate": 7.736782101671587e-06,
      "loss": 0.2938,
      "step": 2115
    },
    {
      "epoch": 0.3363334724126284,
      "grad_norm": 0.4844602346420288,
      "learning_rate": 7.734627365361657e-06,
      "loss": 0.2299,
      "step": 2116
    },
    {
      "epoch": 0.33649242017841885,
      "grad_norm": 0.6654638051986694,
      "learning_rate": 7.73247190419281e-06,
      "loss": 0.2054,
      "step": 2117
    },
    {
      "epoch": 0.33665136794420936,
      "grad_norm": 0.5409534573554993,
      "learning_rate": 7.730315718736393e-06,
      "loss": 0.2296,
      "step": 2118
    },
    {
      "epoch": 0.3368103157099998,
      "grad_norm": 0.5309320092201233,
      "learning_rate": 7.728158809563932e-06,
      "loss": 0.2505,
      "step": 2119
    },
    {
      "epoch": 0.33696926347579026,
      "grad_norm": 0.7010146975517273,
      "learning_rate": 7.726001177247156e-06,
      "loss": 0.2105,
      "step": 2120
    },
    {
      "epoch": 0.3371282112415807,
      "grad_norm": 0.5909522771835327,
      "learning_rate": 7.723842822357982e-06,
      "loss": 0.2405,
      "step": 2121
    },
    {
      "epoch": 0.3372871590073712,
      "grad_norm": 0.5219799876213074,
      "learning_rate": 7.721683745468516e-06,
      "loss": 0.2668,
      "step": 2122
    },
    {
      "epoch": 0.33744610677316167,
      "grad_norm": 0.5572021007537842,
      "learning_rate": 7.71952394715106e-06,
      "loss": 0.2649,
      "step": 2123
    },
    {
      "epoch": 0.3376050545389521,
      "grad_norm": 0.5180166363716125,
      "learning_rate": 7.717363427978103e-06,
      "loss": 0.2526,
      "step": 2124
    },
    {
      "epoch": 0.3377640023047426,
      "grad_norm": 0.5804458856582642,
      "learning_rate": 7.715202188522326e-06,
      "loss": 0.3221,
      "step": 2125
    },
    {
      "epoch": 0.3379229500705331,
      "grad_norm": 0.5040653944015503,
      "learning_rate": 7.713040229356607e-06,
      "loss": 0.1777,
      "step": 2126
    },
    {
      "epoch": 0.33808189783632353,
      "grad_norm": 0.5340226292610168,
      "learning_rate": 7.710877551054004e-06,
      "loss": 0.1603,
      "step": 2127
    },
    {
      "epoch": 0.338240845602114,
      "grad_norm": 0.5475817918777466,
      "learning_rate": 7.708714154187774e-06,
      "loss": 0.2078,
      "step": 2128
    },
    {
      "epoch": 0.3383997933679045,
      "grad_norm": 0.6180537939071655,
      "learning_rate": 7.70655003933136e-06,
      "loss": 0.3283,
      "step": 2129
    },
    {
      "epoch": 0.33855874113369494,
      "grad_norm": 0.5497373342514038,
      "learning_rate": 7.704385207058398e-06,
      "loss": 0.2996,
      "step": 2130
    },
    {
      "epoch": 0.3387176888994854,
      "grad_norm": 0.5821864008903503,
      "learning_rate": 7.702219657942712e-06,
      "loss": 0.3407,
      "step": 2131
    },
    {
      "epoch": 0.3388766366652759,
      "grad_norm": 0.6159987449645996,
      "learning_rate": 7.70005339255832e-06,
      "loss": 0.2632,
      "step": 2132
    },
    {
      "epoch": 0.33903558443106635,
      "grad_norm": 0.6094716191291809,
      "learning_rate": 7.697886411479422e-06,
      "loss": 0.3696,
      "step": 2133
    },
    {
      "epoch": 0.3391945321968568,
      "grad_norm": 0.5658413171768188,
      "learning_rate": 7.69571871528042e-06,
      "loss": 0.3373,
      "step": 2134
    },
    {
      "epoch": 0.33935347996264725,
      "grad_norm": 0.696415901184082,
      "learning_rate": 7.693550304535892e-06,
      "loss": 0.3176,
      "step": 2135
    },
    {
      "epoch": 0.33951242772843776,
      "grad_norm": 0.4969130754470825,
      "learning_rate": 7.691381179820614e-06,
      "loss": 0.2397,
      "step": 2136
    },
    {
      "epoch": 0.3396713754942282,
      "grad_norm": 0.5440787076950073,
      "learning_rate": 7.68921134170955e-06,
      "loss": 0.2149,
      "step": 2137
    },
    {
      "epoch": 0.33983032326001866,
      "grad_norm": 0.47071897983551025,
      "learning_rate": 7.687040790777851e-06,
      "loss": 0.1925,
      "step": 2138
    },
    {
      "epoch": 0.33998927102580917,
      "grad_norm": 0.5745652318000793,
      "learning_rate": 7.684869527600856e-06,
      "loss": 0.2411,
      "step": 2139
    },
    {
      "epoch": 0.3401482187915996,
      "grad_norm": 0.5413548946380615,
      "learning_rate": 7.682697552754098e-06,
      "loss": 0.2344,
      "step": 2140
    },
    {
      "epoch": 0.3403071665573901,
      "grad_norm": 0.5683740973472595,
      "learning_rate": 7.680524866813295e-06,
      "loss": 0.1913,
      "step": 2141
    },
    {
      "epoch": 0.3404661143231805,
      "grad_norm": 0.5652021169662476,
      "learning_rate": 7.67835147035435e-06,
      "loss": 0.2102,
      "step": 2142
    },
    {
      "epoch": 0.34062506208897103,
      "grad_norm": 0.9690009951591492,
      "learning_rate": 7.676177363953364e-06,
      "loss": 0.2442,
      "step": 2143
    },
    {
      "epoch": 0.3407840098547615,
      "grad_norm": 0.6239073276519775,
      "learning_rate": 7.674002548186617e-06,
      "loss": 0.2922,
      "step": 2144
    },
    {
      "epoch": 0.34094295762055193,
      "grad_norm": 0.655790388584137,
      "learning_rate": 7.67182702363058e-06,
      "loss": 0.2804,
      "step": 2145
    },
    {
      "epoch": 0.3411019053863424,
      "grad_norm": 0.49064692854881287,
      "learning_rate": 7.669650790861914e-06,
      "loss": 0.1452,
      "step": 2146
    },
    {
      "epoch": 0.3412608531521329,
      "grad_norm": 0.5787665843963623,
      "learning_rate": 7.667473850457466e-06,
      "loss": 0.1738,
      "step": 2147
    },
    {
      "epoch": 0.34141980091792334,
      "grad_norm": 0.493604451417923,
      "learning_rate": 7.66529620299427e-06,
      "loss": 0.1987,
      "step": 2148
    },
    {
      "epoch": 0.3415787486837138,
      "grad_norm": 0.5009629130363464,
      "learning_rate": 7.663117849049546e-06,
      "loss": 0.213,
      "step": 2149
    },
    {
      "epoch": 0.3417376964495043,
      "grad_norm": 0.522226095199585,
      "learning_rate": 7.660938789200708e-06,
      "loss": 0.2495,
      "step": 2150
    },
    {
      "epoch": 0.34189664421529475,
      "grad_norm": 0.6026880145072937,
      "learning_rate": 7.658759024025349e-06,
      "loss": 0.2984,
      "step": 2151
    },
    {
      "epoch": 0.3420555919810852,
      "grad_norm": 0.5600235462188721,
      "learning_rate": 7.656578554101253e-06,
      "loss": 0.2151,
      "step": 2152
    },
    {
      "epoch": 0.34221453974687566,
      "grad_norm": 0.6153326630592346,
      "learning_rate": 7.65439738000639e-06,
      "loss": 0.307,
      "step": 2153
    },
    {
      "epoch": 0.34237348751266616,
      "grad_norm": 0.5620616674423218,
      "learning_rate": 7.652215502318915e-06,
      "loss": 0.2372,
      "step": 2154
    },
    {
      "epoch": 0.3425324352784566,
      "grad_norm": 0.5125136375427246,
      "learning_rate": 7.650032921617179e-06,
      "loss": 0.2276,
      "step": 2155
    },
    {
      "epoch": 0.34269138304424707,
      "grad_norm": 0.49149730801582336,
      "learning_rate": 7.647849638479702e-06,
      "loss": 0.1879,
      "step": 2156
    },
    {
      "epoch": 0.3428503308100376,
      "grad_norm": 0.5770450830459595,
      "learning_rate": 7.645665653485205e-06,
      "loss": 0.2144,
      "step": 2157
    },
    {
      "epoch": 0.343009278575828,
      "grad_norm": 0.5267269611358643,
      "learning_rate": 7.64348096721259e-06,
      "loss": 0.2004,
      "step": 2158
    },
    {
      "epoch": 0.3431682263416185,
      "grad_norm": 0.5452372431755066,
      "learning_rate": 7.641295580240942e-06,
      "loss": 0.2585,
      "step": 2159
    },
    {
      "epoch": 0.34332717410740893,
      "grad_norm": 0.48686808347702026,
      "learning_rate": 7.639109493149537e-06,
      "loss": 0.1837,
      "step": 2160
    },
    {
      "epoch": 0.34348612187319943,
      "grad_norm": 0.48621904850006104,
      "learning_rate": 7.636922706517835e-06,
      "loss": 0.2015,
      "step": 2161
    },
    {
      "epoch": 0.3436450696389899,
      "grad_norm": 0.5435501933097839,
      "learning_rate": 7.634735220925477e-06,
      "loss": 0.248,
      "step": 2162
    },
    {
      "epoch": 0.34380401740478034,
      "grad_norm": 0.4821493327617645,
      "learning_rate": 7.632547036952296e-06,
      "loss": 0.2225,
      "step": 2163
    },
    {
      "epoch": 0.34396296517057084,
      "grad_norm": 0.577170193195343,
      "learning_rate": 7.630358155178304e-06,
      "loss": 0.2839,
      "step": 2164
    },
    {
      "epoch": 0.3441219129363613,
      "grad_norm": 0.5734341740608215,
      "learning_rate": 7.628168576183703e-06,
      "loss": 0.1936,
      "step": 2165
    },
    {
      "epoch": 0.34428086070215175,
      "grad_norm": 0.6045935153961182,
      "learning_rate": 7.625978300548877e-06,
      "loss": 0.2886,
      "step": 2166
    },
    {
      "epoch": 0.3444398084679422,
      "grad_norm": 0.6093034148216248,
      "learning_rate": 7.623787328854397e-06,
      "loss": 0.3264,
      "step": 2167
    },
    {
      "epoch": 0.3445987562337327,
      "grad_norm": 0.5559900999069214,
      "learning_rate": 7.621595661681015e-06,
      "loss": 0.3313,
      "step": 2168
    },
    {
      "epoch": 0.34475770399952316,
      "grad_norm": 0.4895966053009033,
      "learning_rate": 7.6194032996096685e-06,
      "loss": 0.1736,
      "step": 2169
    },
    {
      "epoch": 0.3449166517653136,
      "grad_norm": 0.5849277377128601,
      "learning_rate": 7.617210243221481e-06,
      "loss": 0.3064,
      "step": 2170
    },
    {
      "epoch": 0.3450755995311041,
      "grad_norm": 0.5478425025939941,
      "learning_rate": 7.61501649309776e-06,
      "loss": 0.263,
      "step": 2171
    },
    {
      "epoch": 0.34523454729689457,
      "grad_norm": 0.5616825819015503,
      "learning_rate": 7.612822049819995e-06,
      "loss": 0.3211,
      "step": 2172
    },
    {
      "epoch": 0.345393495062685,
      "grad_norm": 0.5302000045776367,
      "learning_rate": 7.610626913969859e-06,
      "loss": 0.2598,
      "step": 2173
    },
    {
      "epoch": 0.34555244282847547,
      "grad_norm": 0.5909892916679382,
      "learning_rate": 7.608431086129209e-06,
      "loss": 0.2334,
      "step": 2174
    },
    {
      "epoch": 0.345711390594266,
      "grad_norm": 0.5028486847877502,
      "learning_rate": 7.606234566880089e-06,
      "loss": 0.2432,
      "step": 2175
    },
    {
      "epoch": 0.34587033836005643,
      "grad_norm": 0.5018454790115356,
      "learning_rate": 7.604037356804721e-06,
      "loss": 0.2206,
      "step": 2176
    },
    {
      "epoch": 0.3460292861258469,
      "grad_norm": 0.5519821643829346,
      "learning_rate": 7.601839456485514e-06,
      "loss": 0.2768,
      "step": 2177
    },
    {
      "epoch": 0.3461882338916374,
      "grad_norm": 0.5438482761383057,
      "learning_rate": 7.599640866505058e-06,
      "loss": 0.2632,
      "step": 2178
    },
    {
      "epoch": 0.34634718165742784,
      "grad_norm": 0.5047954320907593,
      "learning_rate": 7.5974415874461234e-06,
      "loss": 0.2094,
      "step": 2179
    },
    {
      "epoch": 0.3465061294232183,
      "grad_norm": 0.5345211029052734,
      "learning_rate": 7.595241619891672e-06,
      "loss": 0.2416,
      "step": 2180
    },
    {
      "epoch": 0.34666507718900874,
      "grad_norm": 0.552118718624115,
      "learning_rate": 7.593040964424836e-06,
      "loss": 0.2771,
      "step": 2181
    },
    {
      "epoch": 0.34682402495479925,
      "grad_norm": 0.5293721556663513,
      "learning_rate": 7.59083962162894e-06,
      "loss": 0.2242,
      "step": 2182
    },
    {
      "epoch": 0.3469829727205897,
      "grad_norm": 0.565061092376709,
      "learning_rate": 7.588637592087485e-06,
      "loss": 0.3033,
      "step": 2183
    },
    {
      "epoch": 0.34714192048638015,
      "grad_norm": 0.572306215763092,
      "learning_rate": 7.5864348763841555e-06,
      "loss": 0.3269,
      "step": 2184
    },
    {
      "epoch": 0.34730086825217066,
      "grad_norm": 0.5706289410591125,
      "learning_rate": 7.5842314751028214e-06,
      "loss": 0.2634,
      "step": 2185
    },
    {
      "epoch": 0.3474598160179611,
      "grad_norm": 0.6267337799072266,
      "learning_rate": 7.582027388827526e-06,
      "loss": 0.3375,
      "step": 2186
    },
    {
      "epoch": 0.34761876378375156,
      "grad_norm": 0.9369015693664551,
      "learning_rate": 7.579822618142505e-06,
      "loss": 0.1883,
      "step": 2187
    },
    {
      "epoch": 0.347777711549542,
      "grad_norm": 0.5586346387863159,
      "learning_rate": 7.577617163632168e-06,
      "loss": 0.2091,
      "step": 2188
    },
    {
      "epoch": 0.3479366593153325,
      "grad_norm": 0.44326016306877136,
      "learning_rate": 7.575411025881106e-06,
      "loss": 0.1276,
      "step": 2189
    },
    {
      "epoch": 0.34809560708112297,
      "grad_norm": 0.5294219255447388,
      "learning_rate": 7.573204205474094e-06,
      "loss": 0.2683,
      "step": 2190
    },
    {
      "epoch": 0.3482545548469134,
      "grad_norm": 0.5719911456108093,
      "learning_rate": 7.570996702996087e-06,
      "loss": 0.204,
      "step": 2191
    },
    {
      "epoch": 0.3484135026127039,
      "grad_norm": 0.5847774744033813,
      "learning_rate": 7.568788519032219e-06,
      "loss": 0.3091,
      "step": 2192
    },
    {
      "epoch": 0.3485724503784944,
      "grad_norm": 0.6159095764160156,
      "learning_rate": 7.5665796541678106e-06,
      "loss": 0.3273,
      "step": 2193
    },
    {
      "epoch": 0.34873139814428483,
      "grad_norm": 0.42018529772758484,
      "learning_rate": 7.564370108988354e-06,
      "loss": 0.1535,
      "step": 2194
    },
    {
      "epoch": 0.3488903459100753,
      "grad_norm": 0.5940858721733093,
      "learning_rate": 7.562159884079529e-06,
      "loss": 0.296,
      "step": 2195
    },
    {
      "epoch": 0.3490492936758658,
      "grad_norm": 0.5631340146064758,
      "learning_rate": 7.559948980027189e-06,
      "loss": 0.2249,
      "step": 2196
    },
    {
      "epoch": 0.34920824144165624,
      "grad_norm": 0.48042118549346924,
      "learning_rate": 7.557737397417376e-06,
      "loss": 0.1408,
      "step": 2197
    },
    {
      "epoch": 0.3493671892074467,
      "grad_norm": 0.5106433033943176,
      "learning_rate": 7.555525136836306e-06,
      "loss": 0.2239,
      "step": 2198
    },
    {
      "epoch": 0.34952613697323714,
      "grad_norm": 0.502774715423584,
      "learning_rate": 7.553312198870373e-06,
      "loss": 0.2065,
      "step": 2199
    },
    {
      "epoch": 0.34968508473902765,
      "grad_norm": 0.5923418402671814,
      "learning_rate": 7.551098584106156e-06,
      "loss": 0.3139,
      "step": 2200
    },
    {
      "epoch": 0.3498440325048181,
      "grad_norm": 0.581157922744751,
      "learning_rate": 7.548884293130412e-06,
      "loss": 0.2968,
      "step": 2201
    },
    {
      "epoch": 0.35000298027060855,
      "grad_norm": 0.46888798475265503,
      "learning_rate": 7.54666932653007e-06,
      "loss": 0.1395,
      "step": 2202
    },
    {
      "epoch": 0.35016192803639906,
      "grad_norm": 0.48078829050064087,
      "learning_rate": 7.5444536848922514e-06,
      "loss": 0.167,
      "step": 2203
    },
    {
      "epoch": 0.3503208758021895,
      "grad_norm": 0.4820045530796051,
      "learning_rate": 7.542237368804245e-06,
      "loss": 0.1959,
      "step": 2204
    },
    {
      "epoch": 0.35047982356797996,
      "grad_norm": 0.4037501811981201,
      "learning_rate": 7.540020378853523e-06,
      "loss": 0.1542,
      "step": 2205
    },
    {
      "epoch": 0.3506387713337704,
      "grad_norm": 0.614746630191803,
      "learning_rate": 7.537802715627738e-06,
      "loss": 0.3562,
      "step": 2206
    },
    {
      "epoch": 0.3507977190995609,
      "grad_norm": 0.5198779702186584,
      "learning_rate": 7.535584379714717e-06,
      "loss": 0.2297,
      "step": 2207
    },
    {
      "epoch": 0.3509566668653514,
      "grad_norm": 0.46510976552963257,
      "learning_rate": 7.533365371702468e-06,
      "loss": 0.185,
      "step": 2208
    },
    {
      "epoch": 0.3511156146311418,
      "grad_norm": 0.5251335501670837,
      "learning_rate": 7.531145692179174e-06,
      "loss": 0.267,
      "step": 2209
    },
    {
      "epoch": 0.35127456239693233,
      "grad_norm": 0.4391632676124573,
      "learning_rate": 7.5289253417332006e-06,
      "loss": 0.1604,
      "step": 2210
    },
    {
      "epoch": 0.3514335101627228,
      "grad_norm": 0.49204835295677185,
      "learning_rate": 7.526704320953091e-06,
      "loss": 0.1674,
      "step": 2211
    },
    {
      "epoch": 0.35159245792851324,
      "grad_norm": 0.6262364387512207,
      "learning_rate": 7.524482630427559e-06,
      "loss": 0.3015,
      "step": 2212
    },
    {
      "epoch": 0.3517514056943037,
      "grad_norm": 0.5486863851547241,
      "learning_rate": 7.522260270745504e-06,
      "loss": 0.2333,
      "step": 2213
    },
    {
      "epoch": 0.3519103534600942,
      "grad_norm": 0.5906814336776733,
      "learning_rate": 7.520037242496e-06,
      "loss": 0.2284,
      "step": 2214
    },
    {
      "epoch": 0.35206930122588465,
      "grad_norm": 0.5097073316574097,
      "learning_rate": 7.517813546268298e-06,
      "loss": 0.1787,
      "step": 2215
    },
    {
      "epoch": 0.3522282489916751,
      "grad_norm": 0.4998501241207123,
      "learning_rate": 7.515589182651824e-06,
      "loss": 0.1388,
      "step": 2216
    },
    {
      "epoch": 0.3523871967574656,
      "grad_norm": 0.5835851430892944,
      "learning_rate": 7.513364152236185e-06,
      "loss": 0.281,
      "step": 2217
    },
    {
      "epoch": 0.35254614452325606,
      "grad_norm": 0.5897201299667358,
      "learning_rate": 7.5111384556111625e-06,
      "loss": 0.2443,
      "step": 2218
    },
    {
      "epoch": 0.3527050922890465,
      "grad_norm": 0.4574210047721863,
      "learning_rate": 7.5089120933667135e-06,
      "loss": 0.1375,
      "step": 2219
    },
    {
      "epoch": 0.35286404005483696,
      "grad_norm": 0.5177333950996399,
      "learning_rate": 7.506685066092975e-06,
      "loss": 0.2349,
      "step": 2220
    },
    {
      "epoch": 0.35302298782062747,
      "grad_norm": 0.6068536639213562,
      "learning_rate": 7.504457374380255e-06,
      "loss": 0.3253,
      "step": 2221
    },
    {
      "epoch": 0.3531819355864179,
      "grad_norm": 1.7675260305404663,
      "learning_rate": 7.502229018819043e-06,
      "loss": 0.1946,
      "step": 2222
    },
    {
      "epoch": 0.35334088335220837,
      "grad_norm": 0.3722681701183319,
      "learning_rate": 7.500000000000001e-06,
      "loss": 0.0652,
      "step": 2223
    },
    {
      "epoch": 0.3534998311179989,
      "grad_norm": 0.4798663556575775,
      "learning_rate": 7.497770318513968e-06,
      "loss": 0.1627,
      "step": 2224
    },
    {
      "epoch": 0.3536587788837893,
      "grad_norm": 0.4823114275932312,
      "learning_rate": 7.4955399749519575e-06,
      "loss": 0.1965,
      "step": 2225
    },
    {
      "epoch": 0.3538177266495798,
      "grad_norm": 0.6606878638267517,
      "learning_rate": 7.493308969905162e-06,
      "loss": 0.2629,
      "step": 2226
    },
    {
      "epoch": 0.35397667441537023,
      "grad_norm": 0.49105849862098694,
      "learning_rate": 7.491077303964946e-06,
      "loss": 0.1714,
      "step": 2227
    },
    {
      "epoch": 0.35413562218116074,
      "grad_norm": 0.5566512942314148,
      "learning_rate": 7.488844977722849e-06,
      "loss": 0.2108,
      "step": 2228
    },
    {
      "epoch": 0.3542945699469512,
      "grad_norm": 0.5645028352737427,
      "learning_rate": 7.486611991770586e-06,
      "loss": 0.2988,
      "step": 2229
    },
    {
      "epoch": 0.35445351771274164,
      "grad_norm": 0.5103816390037537,
      "learning_rate": 7.48437834670005e-06,
      "loss": 0.2321,
      "step": 2230
    },
    {
      "epoch": 0.3546124654785321,
      "grad_norm": 0.7720112800598145,
      "learning_rate": 7.482144043103303e-06,
      "loss": 0.4304,
      "step": 2231
    },
    {
      "epoch": 0.3547714132443226,
      "grad_norm": 0.6516614556312561,
      "learning_rate": 7.479909081572587e-06,
      "loss": 0.2836,
      "step": 2232
    },
    {
      "epoch": 0.35493036101011305,
      "grad_norm": 0.47194772958755493,
      "learning_rate": 7.477673462700317e-06,
      "loss": 0.1493,
      "step": 2233
    },
    {
      "epoch": 0.3550893087759035,
      "grad_norm": 0.534184455871582,
      "learning_rate": 7.475437187079079e-06,
      "loss": 0.2461,
      "step": 2234
    },
    {
      "epoch": 0.355248256541694,
      "grad_norm": 1.709423303604126,
      "learning_rate": 7.473200255301635e-06,
      "loss": 0.3158,
      "step": 2235
    },
    {
      "epoch": 0.35540720430748446,
      "grad_norm": 0.4674370586872101,
      "learning_rate": 7.470962667960923e-06,
      "loss": 0.2118,
      "step": 2236
    },
    {
      "epoch": 0.3555661520732749,
      "grad_norm": 0.5705550909042358,
      "learning_rate": 7.468724425650054e-06,
      "loss": 0.278,
      "step": 2237
    },
    {
      "epoch": 0.35572509983906536,
      "grad_norm": 0.5738219618797302,
      "learning_rate": 7.466485528962309e-06,
      "loss": 0.2633,
      "step": 2238
    },
    {
      "epoch": 0.35588404760485587,
      "grad_norm": 0.5582069158554077,
      "learning_rate": 7.464245978491147e-06,
      "loss": 0.2668,
      "step": 2239
    },
    {
      "epoch": 0.3560429953706463,
      "grad_norm": 0.5868937969207764,
      "learning_rate": 7.462005774830198e-06,
      "loss": 0.3159,
      "step": 2240
    },
    {
      "epoch": 0.35620194313643677,
      "grad_norm": 0.6724932789802551,
      "learning_rate": 7.459764918573264e-06,
      "loss": 0.2753,
      "step": 2241
    },
    {
      "epoch": 0.3563608909022273,
      "grad_norm": 1.1523373126983643,
      "learning_rate": 7.457523410314326e-06,
      "loss": 0.2902,
      "step": 2242
    },
    {
      "epoch": 0.35651983866801773,
      "grad_norm": 0.4431668519973755,
      "learning_rate": 7.45528125064753e-06,
      "loss": 0.1239,
      "step": 2243
    },
    {
      "epoch": 0.3566787864338082,
      "grad_norm": 0.532185435295105,
      "learning_rate": 7.453038440167198e-06,
      "loss": 0.1454,
      "step": 2244
    },
    {
      "epoch": 0.35683773419959863,
      "grad_norm": 0.4973836839199066,
      "learning_rate": 7.450794979467824e-06,
      "loss": 0.2473,
      "step": 2245
    },
    {
      "epoch": 0.35699668196538914,
      "grad_norm": 0.6203692555427551,
      "learning_rate": 7.4485508691440775e-06,
      "loss": 0.2607,
      "step": 2246
    },
    {
      "epoch": 0.3571556297311796,
      "grad_norm": 0.5369874835014343,
      "learning_rate": 7.446306109790798e-06,
      "loss": 0.2655,
      "step": 2247
    },
    {
      "epoch": 0.35731457749697004,
      "grad_norm": 0.42281386256217957,
      "learning_rate": 7.444060702002993e-06,
      "loss": 0.1338,
      "step": 2248
    },
    {
      "epoch": 0.35747352526276055,
      "grad_norm": 0.574735701084137,
      "learning_rate": 7.441814646375848e-06,
      "loss": 0.2382,
      "step": 2249
    },
    {
      "epoch": 0.357632473028551,
      "grad_norm": 0.5289998054504395,
      "learning_rate": 7.4395679435047175e-06,
      "loss": 0.2678,
      "step": 2250
    },
    {
      "epoch": 0.35779142079434145,
      "grad_norm": 0.4680386483669281,
      "learning_rate": 7.437320593985127e-06,
      "loss": 0.1921,
      "step": 2251
    },
    {
      "epoch": 0.3579503685601319,
      "grad_norm": 0.5247832536697388,
      "learning_rate": 7.435072598412776e-06,
      "loss": 0.1617,
      "step": 2252
    },
    {
      "epoch": 0.3581093163259224,
      "grad_norm": 0.5098535418510437,
      "learning_rate": 7.432823957383533e-06,
      "loss": 0.1587,
      "step": 2253
    },
    {
      "epoch": 0.35826826409171286,
      "grad_norm": 0.6445456147193909,
      "learning_rate": 7.430574671493435e-06,
      "loss": 0.2493,
      "step": 2254
    },
    {
      "epoch": 0.3584272118575033,
      "grad_norm": 0.6155952215194702,
      "learning_rate": 7.4283247413386975e-06,
      "loss": 0.2878,
      "step": 2255
    },
    {
      "epoch": 0.3585861596232938,
      "grad_norm": 0.5655631422996521,
      "learning_rate": 7.426074167515699e-06,
      "loss": 0.1868,
      "step": 2256
    },
    {
      "epoch": 0.3587451073890843,
      "grad_norm": 0.5226098895072937,
      "learning_rate": 7.423822950620993e-06,
      "loss": 0.2353,
      "step": 2257
    },
    {
      "epoch": 0.3589040551548747,
      "grad_norm": 0.6132505536079407,
      "learning_rate": 7.421571091251304e-06,
      "loss": 0.3395,
      "step": 2258
    },
    {
      "epoch": 0.3590630029206652,
      "grad_norm": 0.5924140810966492,
      "learning_rate": 7.419318590003524e-06,
      "loss": 0.2796,
      "step": 2259
    },
    {
      "epoch": 0.3592219506864557,
      "grad_norm": 0.5909954905509949,
      "learning_rate": 7.417065447474714e-06,
      "loss": 0.2425,
      "step": 2260
    },
    {
      "epoch": 0.35938089845224613,
      "grad_norm": 0.6160353422164917,
      "learning_rate": 7.414811664262109e-06,
      "loss": 0.4429,
      "step": 2261
    },
    {
      "epoch": 0.3595398462180366,
      "grad_norm": 0.5441137552261353,
      "learning_rate": 7.4125572409631144e-06,
      "loss": 0.284,
      "step": 2262
    },
    {
      "epoch": 0.3596987939838271,
      "grad_norm": 0.5667852759361267,
      "learning_rate": 7.4103021781753e-06,
      "loss": 0.2497,
      "step": 2263
    },
    {
      "epoch": 0.35985774174961754,
      "grad_norm": 0.5485639572143555,
      "learning_rate": 7.408046476496409e-06,
      "loss": 0.266,
      "step": 2264
    },
    {
      "epoch": 0.360016689515408,
      "grad_norm": 0.565822184085846,
      "learning_rate": 7.405790136524353e-06,
      "loss": 0.2649,
      "step": 2265
    },
    {
      "epoch": 0.36017563728119845,
      "grad_norm": 0.5692663788795471,
      "learning_rate": 7.403533158857212e-06,
      "loss": 0.2431,
      "step": 2266
    },
    {
      "epoch": 0.36033458504698895,
      "grad_norm": 0.4653747081756592,
      "learning_rate": 7.401275544093238e-06,
      "loss": 0.2032,
      "step": 2267
    },
    {
      "epoch": 0.3604935328127794,
      "grad_norm": 0.5103868842124939,
      "learning_rate": 7.399017292830848e-06,
      "loss": 0.1805,
      "step": 2268
    },
    {
      "epoch": 0.36065248057856986,
      "grad_norm": 0.5398397445678711,
      "learning_rate": 7.396758405668628e-06,
      "loss": 0.2428,
      "step": 2269
    },
    {
      "epoch": 0.3608114283443603,
      "grad_norm": 0.49111810326576233,
      "learning_rate": 7.394498883205338e-06,
      "loss": 0.2106,
      "step": 2270
    },
    {
      "epoch": 0.3609703761101508,
      "grad_norm": 0.46870937943458557,
      "learning_rate": 7.392238726039897e-06,
      "loss": 0.2178,
      "step": 2271
    },
    {
      "epoch": 0.36112932387594127,
      "grad_norm": 0.5872557163238525,
      "learning_rate": 7.389977934771404e-06,
      "loss": 0.2166,
      "step": 2272
    },
    {
      "epoch": 0.3612882716417317,
      "grad_norm": 0.6750974059104919,
      "learning_rate": 7.387716509999117e-06,
      "loss": 0.3909,
      "step": 2273
    },
    {
      "epoch": 0.3614472194075222,
      "grad_norm": 0.5051482319831848,
      "learning_rate": 7.385454452322461e-06,
      "loss": 0.1937,
      "step": 2274
    },
    {
      "epoch": 0.3616061671733127,
      "grad_norm": 0.49745672941207886,
      "learning_rate": 7.383191762341038e-06,
      "loss": 0.2379,
      "step": 2275
    },
    {
      "epoch": 0.3617651149391031,
      "grad_norm": 0.5517135262489319,
      "learning_rate": 7.380928440654606e-06,
      "loss": 0.2725,
      "step": 2276
    },
    {
      "epoch": 0.3619240627048936,
      "grad_norm": 0.49036887288093567,
      "learning_rate": 7.3786644878631035e-06,
      "loss": 0.1519,
      "step": 2277
    },
    {
      "epoch": 0.3620830104706841,
      "grad_norm": 0.5786277055740356,
      "learning_rate": 7.376399904566624e-06,
      "loss": 0.2828,
      "step": 2278
    },
    {
      "epoch": 0.36224195823647454,
      "grad_norm": 0.5821734070777893,
      "learning_rate": 7.374134691365435e-06,
      "loss": 0.2198,
      "step": 2279
    },
    {
      "epoch": 0.362400906002265,
      "grad_norm": 0.460973858833313,
      "learning_rate": 7.37186884885997e-06,
      "loss": 0.2021,
      "step": 2280
    },
    {
      "epoch": 0.3625598537680555,
      "grad_norm": 0.6062942147254944,
      "learning_rate": 7.3696023776508256e-06,
      "loss": 0.3377,
      "step": 2281
    },
    {
      "epoch": 0.36271880153384595,
      "grad_norm": 0.5532700419425964,
      "learning_rate": 7.367335278338772e-06,
      "loss": 0.2332,
      "step": 2282
    },
    {
      "epoch": 0.3628777492996364,
      "grad_norm": 0.4448586404323578,
      "learning_rate": 7.365067551524739e-06,
      "loss": 0.1784,
      "step": 2283
    },
    {
      "epoch": 0.36303669706542685,
      "grad_norm": 0.700706958770752,
      "learning_rate": 7.362799197809828e-06,
      "loss": 0.3123,
      "step": 2284
    },
    {
      "epoch": 0.36319564483121736,
      "grad_norm": 0.4288439452648163,
      "learning_rate": 7.3605302177953045e-06,
      "loss": 0.152,
      "step": 2285
    },
    {
      "epoch": 0.3633545925970078,
      "grad_norm": 0.4950600564479828,
      "learning_rate": 7.358260612082596e-06,
      "loss": 0.2174,
      "step": 2286
    },
    {
      "epoch": 0.36351354036279826,
      "grad_norm": 0.5676868557929993,
      "learning_rate": 7.355990381273302e-06,
      "loss": 0.3003,
      "step": 2287
    },
    {
      "epoch": 0.36367248812858877,
      "grad_norm": 0.541853666305542,
      "learning_rate": 7.353719525969187e-06,
      "loss": 0.2612,
      "step": 2288
    },
    {
      "epoch": 0.3638314358943792,
      "grad_norm": 0.4423753321170807,
      "learning_rate": 7.3514480467721786e-06,
      "loss": 0.1546,
      "step": 2289
    },
    {
      "epoch": 0.36399038366016967,
      "grad_norm": 0.5853062868118286,
      "learning_rate": 7.349175944284368e-06,
      "loss": 0.2426,
      "step": 2290
    },
    {
      "epoch": 0.3641493314259601,
      "grad_norm": 0.586818516254425,
      "learning_rate": 7.346903219108014e-06,
      "loss": 0.2958,
      "step": 2291
    },
    {
      "epoch": 0.36430827919175063,
      "grad_norm": 0.511672854423523,
      "learning_rate": 7.344629871845545e-06,
      "loss": 0.1831,
      "step": 2292
    },
    {
      "epoch": 0.3644672269575411,
      "grad_norm": 0.46533575654029846,
      "learning_rate": 7.342355903099546e-06,
      "loss": 0.2348,
      "step": 2293
    },
    {
      "epoch": 0.36462617472333153,
      "grad_norm": 0.4701520800590515,
      "learning_rate": 7.340081313472772e-06,
      "loss": 0.1297,
      "step": 2294
    },
    {
      "epoch": 0.36478512248912204,
      "grad_norm": 0.5916034579277039,
      "learning_rate": 7.3378061035681415e-06,
      "loss": 0.3776,
      "step": 2295
    },
    {
      "epoch": 0.3649440702549125,
      "grad_norm": 0.4660817086696625,
      "learning_rate": 7.335530273988736e-06,
      "loss": 0.1504,
      "step": 2296
    },
    {
      "epoch": 0.36510301802070294,
      "grad_norm": 0.6282473802566528,
      "learning_rate": 7.333253825337803e-06,
      "loss": 0.327,
      "step": 2297
    },
    {
      "epoch": 0.3652619657864934,
      "grad_norm": 0.566740095615387,
      "learning_rate": 7.3309767582187526e-06,
      "loss": 0.1873,
      "step": 2298
    },
    {
      "epoch": 0.3654209135522839,
      "grad_norm": 0.5886595249176025,
      "learning_rate": 7.328699073235163e-06,
      "loss": 0.259,
      "step": 2299
    },
    {
      "epoch": 0.36557986131807435,
      "grad_norm": 0.5229446291923523,
      "learning_rate": 7.326420770990767e-06,
      "loss": 0.2334,
      "step": 2300
    },
    {
      "epoch": 0.3657388090838648,
      "grad_norm": 0.6523699164390564,
      "learning_rate": 7.324141852089473e-06,
      "loss": 0.2433,
      "step": 2301
    },
    {
      "epoch": 0.3658977568496553,
      "grad_norm": 0.5988563895225525,
      "learning_rate": 7.321862317135343e-06,
      "loss": 0.1452,
      "step": 2302
    },
    {
      "epoch": 0.36605670461544576,
      "grad_norm": 0.5840233564376831,
      "learning_rate": 7.319582166732607e-06,
      "loss": 0.2904,
      "step": 2303
    },
    {
      "epoch": 0.3662156523812362,
      "grad_norm": 0.4966670274734497,
      "learning_rate": 7.317301401485657e-06,
      "loss": 0.1879,
      "step": 2304
    },
    {
      "epoch": 0.36637460014702666,
      "grad_norm": 0.4963042438030243,
      "learning_rate": 7.315020021999048e-06,
      "loss": 0.1925,
      "step": 2305
    },
    {
      "epoch": 0.36653354791281717,
      "grad_norm": 0.6295244693756104,
      "learning_rate": 7.3127380288775e-06,
      "loss": 0.394,
      "step": 2306
    },
    {
      "epoch": 0.3666924956786076,
      "grad_norm": 0.4969775676727295,
      "learning_rate": 7.3104554227258895e-06,
      "loss": 0.2181,
      "step": 2307
    },
    {
      "epoch": 0.3668514434443981,
      "grad_norm": 0.5127283930778503,
      "learning_rate": 7.308172204149262e-06,
      "loss": 0.2411,
      "step": 2308
    },
    {
      "epoch": 0.3670103912101885,
      "grad_norm": 0.5416955947875977,
      "learning_rate": 7.305888373752825e-06,
      "loss": 0.2683,
      "step": 2309
    },
    {
      "epoch": 0.36716933897597903,
      "grad_norm": 0.48367205262184143,
      "learning_rate": 7.3036039321419425e-06,
      "loss": 0.1856,
      "step": 2310
    },
    {
      "epoch": 0.3673282867417695,
      "grad_norm": 0.6124307513237,
      "learning_rate": 7.3013188799221456e-06,
      "loss": 0.2586,
      "step": 2311
    },
    {
      "epoch": 0.36748723450755993,
      "grad_norm": 0.5338801741600037,
      "learning_rate": 7.299033217699126e-06,
      "loss": 0.2141,
      "step": 2312
    },
    {
      "epoch": 0.36764618227335044,
      "grad_norm": 0.6129606366157532,
      "learning_rate": 7.296746946078737e-06,
      "loss": 0.2685,
      "step": 2313
    },
    {
      "epoch": 0.3678051300391409,
      "grad_norm": 0.5473065376281738,
      "learning_rate": 7.2944600656669915e-06,
      "loss": 0.2838,
      "step": 2314
    },
    {
      "epoch": 0.36796407780493134,
      "grad_norm": 0.5333669781684875,
      "learning_rate": 7.292172577070069e-06,
      "loss": 0.2201,
      "step": 2315
    },
    {
      "epoch": 0.3681230255707218,
      "grad_norm": 0.496528297662735,
      "learning_rate": 7.289884480894304e-06,
      "loss": 0.2356,
      "step": 2316
    },
    {
      "epoch": 0.3682819733365123,
      "grad_norm": 0.5029296875,
      "learning_rate": 7.287595777746195e-06,
      "loss": 0.2036,
      "step": 2317
    },
    {
      "epoch": 0.36844092110230275,
      "grad_norm": 0.5355055928230286,
      "learning_rate": 7.285306468232402e-06,
      "loss": 0.2512,
      "step": 2318
    },
    {
      "epoch": 0.3685998688680932,
      "grad_norm": 0.4978620111942291,
      "learning_rate": 7.283016552959745e-06,
      "loss": 0.2465,
      "step": 2319
    },
    {
      "epoch": 0.3687588166338837,
      "grad_norm": 0.6186308264732361,
      "learning_rate": 7.280726032535204e-06,
      "loss": 0.3145,
      "step": 2320
    },
    {
      "epoch": 0.36891776439967416,
      "grad_norm": 0.448342889547348,
      "learning_rate": 7.27843490756592e-06,
      "loss": 0.198,
      "step": 2321
    },
    {
      "epoch": 0.3690767121654646,
      "grad_norm": 0.5562493205070496,
      "learning_rate": 7.276143178659195e-06,
      "loss": 0.1866,
      "step": 2322
    },
    {
      "epoch": 0.36923565993125507,
      "grad_norm": 0.5004945397377014,
      "learning_rate": 7.273850846422489e-06,
      "loss": 0.204,
      "step": 2323
    },
    {
      "epoch": 0.3693946076970456,
      "grad_norm": 0.5396159887313843,
      "learning_rate": 7.271557911463424e-06,
      "loss": 0.2629,
      "step": 2324
    },
    {
      "epoch": 0.369553555462836,
      "grad_norm": 0.5026243925094604,
      "learning_rate": 7.269264374389781e-06,
      "loss": 0.2181,
      "step": 2325
    },
    {
      "epoch": 0.3697125032286265,
      "grad_norm": 0.5359874963760376,
      "learning_rate": 7.2669702358095e-06,
      "loss": 0.2543,
      "step": 2326
    },
    {
      "epoch": 0.369871450994417,
      "grad_norm": 0.511694610118866,
      "learning_rate": 7.26467549633068e-06,
      "loss": 0.2225,
      "step": 2327
    },
    {
      "epoch": 0.37003039876020744,
      "grad_norm": 0.39625126123428345,
      "learning_rate": 7.262380156561582e-06,
      "loss": 0.1211,
      "step": 2328
    },
    {
      "epoch": 0.3701893465259979,
      "grad_norm": 0.7332577109336853,
      "learning_rate": 7.260084217110624e-06,
      "loss": 0.3946,
      "step": 2329
    },
    {
      "epoch": 0.37034829429178834,
      "grad_norm": 0.5484784841537476,
      "learning_rate": 7.257787678586383e-06,
      "loss": 0.2248,
      "step": 2330
    },
    {
      "epoch": 0.37050724205757884,
      "grad_norm": 0.3913235664367676,
      "learning_rate": 7.255490541597594e-06,
      "loss": 0.1285,
      "step": 2331
    },
    {
      "epoch": 0.3706661898233693,
      "grad_norm": 0.4591972231864929,
      "learning_rate": 7.253192806753155e-06,
      "loss": 0.1606,
      "step": 2332
    },
    {
      "epoch": 0.37082513758915975,
      "grad_norm": 0.5369386076927185,
      "learning_rate": 7.250894474662116e-06,
      "loss": 0.2738,
      "step": 2333
    },
    {
      "epoch": 0.37098408535495025,
      "grad_norm": 0.5379475951194763,
      "learning_rate": 7.24859554593369e-06,
      "loss": 0.2741,
      "step": 2334
    },
    {
      "epoch": 0.3711430331207407,
      "grad_norm": 0.4608996510505676,
      "learning_rate": 7.246296021177246e-06,
      "loss": 0.1795,
      "step": 2335
    },
    {
      "epoch": 0.37130198088653116,
      "grad_norm": 0.5351063013076782,
      "learning_rate": 7.243995901002312e-06,
      "loss": 0.2993,
      "step": 2336
    },
    {
      "epoch": 0.3714609286523216,
      "grad_norm": 0.5857369899749756,
      "learning_rate": 7.2416951860185735e-06,
      "loss": 0.2961,
      "step": 2337
    },
    {
      "epoch": 0.3716198764181121,
      "grad_norm": 0.5288525223731995,
      "learning_rate": 7.239393876835873e-06,
      "loss": 0.2246,
      "step": 2338
    },
    {
      "epoch": 0.37177882418390257,
      "grad_norm": 0.5316582918167114,
      "learning_rate": 7.237091974064213e-06,
      "loss": 0.2503,
      "step": 2339
    },
    {
      "epoch": 0.371937771949693,
      "grad_norm": 0.42429783940315247,
      "learning_rate": 7.2347894783137485e-06,
      "loss": 0.1338,
      "step": 2340
    },
    {
      "epoch": 0.3720967197154835,
      "grad_norm": 0.6195095181465149,
      "learning_rate": 7.232486390194797e-06,
      "loss": 0.3586,
      "step": 2341
    },
    {
      "epoch": 0.372255667481274,
      "grad_norm": 0.4798351526260376,
      "learning_rate": 7.230182710317832e-06,
      "loss": 0.1507,
      "step": 2342
    },
    {
      "epoch": 0.37241461524706443,
      "grad_norm": 0.5191611051559448,
      "learning_rate": 7.2278784392934775e-06,
      "loss": 0.1709,
      "step": 2343
    },
    {
      "epoch": 0.3725735630128549,
      "grad_norm": 0.6810075640678406,
      "learning_rate": 7.225573577732525e-06,
      "loss": 0.3071,
      "step": 2344
    },
    {
      "epoch": 0.3727325107786454,
      "grad_norm": 0.47931715846061707,
      "learning_rate": 7.2232681262459146e-06,
      "loss": 0.1761,
      "step": 2345
    },
    {
      "epoch": 0.37289145854443584,
      "grad_norm": 0.5205914974212646,
      "learning_rate": 7.220962085444743e-06,
      "loss": 0.2532,
      "step": 2346
    },
    {
      "epoch": 0.3730504063102263,
      "grad_norm": 0.5345061421394348,
      "learning_rate": 7.218655455940266e-06,
      "loss": 0.2279,
      "step": 2347
    },
    {
      "epoch": 0.37320935407601674,
      "grad_norm": 0.5100586414337158,
      "learning_rate": 7.216348238343895e-06,
      "loss": 0.2292,
      "step": 2348
    },
    {
      "epoch": 0.37336830184180725,
      "grad_norm": 0.5526929497718811,
      "learning_rate": 7.2140404332671986e-06,
      "loss": 0.3076,
      "step": 2349
    },
    {
      "epoch": 0.3735272496075977,
      "grad_norm": 0.5074141621589661,
      "learning_rate": 7.211732041321896e-06,
      "loss": 0.2509,
      "step": 2350
    },
    {
      "epoch": 0.37368619737338815,
      "grad_norm": 0.48771941661834717,
      "learning_rate": 7.209423063119867e-06,
      "loss": 0.1847,
      "step": 2351
    },
    {
      "epoch": 0.37384514513917866,
      "grad_norm": 0.5648067593574524,
      "learning_rate": 7.207113499273146e-06,
      "loss": 0.2416,
      "step": 2352
    },
    {
      "epoch": 0.3740040929049691,
      "grad_norm": 0.5767899751663208,
      "learning_rate": 7.204803350393918e-06,
      "loss": 0.3214,
      "step": 2353
    },
    {
      "epoch": 0.37416304067075956,
      "grad_norm": 0.5391522645950317,
      "learning_rate": 7.202492617094532e-06,
      "loss": 0.128,
      "step": 2354
    },
    {
      "epoch": 0.37432198843655,
      "grad_norm": 0.49977990984916687,
      "learning_rate": 7.200181299987483e-06,
      "loss": 0.1859,
      "step": 2355
    },
    {
      "epoch": 0.3744809362023405,
      "grad_norm": 0.5448631644248962,
      "learning_rate": 7.197869399685424e-06,
      "loss": 0.2249,
      "step": 2356
    },
    {
      "epoch": 0.37463988396813097,
      "grad_norm": 0.38877272605895996,
      "learning_rate": 7.195556916801167e-06,
      "loss": 0.127,
      "step": 2357
    },
    {
      "epoch": 0.3747988317339214,
      "grad_norm": 0.6291415095329285,
      "learning_rate": 7.19324385194767e-06,
      "loss": 0.1597,
      "step": 2358
    },
    {
      "epoch": 0.37495777949971193,
      "grad_norm": 0.5466011166572571,
      "learning_rate": 7.190930205738052e-06,
      "loss": 0.229,
      "step": 2359
    },
    {
      "epoch": 0.3751167272655024,
      "grad_norm": 0.6101992726325989,
      "learning_rate": 7.188615978785583e-06,
      "loss": 0.2731,
      "step": 2360
    },
    {
      "epoch": 0.37527567503129283,
      "grad_norm": 0.4623733460903168,
      "learning_rate": 7.186301171703689e-06,
      "loss": 0.1575,
      "step": 2361
    },
    {
      "epoch": 0.3754346227970833,
      "grad_norm": 0.6934924125671387,
      "learning_rate": 7.183985785105947e-06,
      "loss": 0.3459,
      "step": 2362
    },
    {
      "epoch": 0.3755935705628738,
      "grad_norm": 0.529984712600708,
      "learning_rate": 7.181669819606088e-06,
      "loss": 0.2424,
      "step": 2363
    },
    {
      "epoch": 0.37575251832866424,
      "grad_norm": 0.6335564851760864,
      "learning_rate": 7.179353275818002e-06,
      "loss": 0.2834,
      "step": 2364
    },
    {
      "epoch": 0.3759114660944547,
      "grad_norm": 0.5409423112869263,
      "learning_rate": 7.177036154355722e-06,
      "loss": 0.2109,
      "step": 2365
    },
    {
      "epoch": 0.3760704138602452,
      "grad_norm": 0.5476053953170776,
      "learning_rate": 7.174718455833445e-06,
      "loss": 0.1673,
      "step": 2366
    },
    {
      "epoch": 0.37622936162603565,
      "grad_norm": 0.45862171053886414,
      "learning_rate": 7.172400180865514e-06,
      "loss": 0.1785,
      "step": 2367
    },
    {
      "epoch": 0.3763883093918261,
      "grad_norm": 0.6307150721549988,
      "learning_rate": 7.170081330066425e-06,
      "loss": 0.3643,
      "step": 2368
    },
    {
      "epoch": 0.37654725715761656,
      "grad_norm": 0.6139988303184509,
      "learning_rate": 7.167761904050831e-06,
      "loss": 0.3456,
      "step": 2369
    },
    {
      "epoch": 0.37670620492340706,
      "grad_norm": 0.5859392285346985,
      "learning_rate": 7.1654419034335344e-06,
      "loss": 0.3487,
      "step": 2370
    },
    {
      "epoch": 0.3768651526891975,
      "grad_norm": 0.510419487953186,
      "learning_rate": 7.1631213288294896e-06,
      "loss": 0.1995,
      "step": 2371
    },
    {
      "epoch": 0.37702410045498796,
      "grad_norm": 0.7856103181838989,
      "learning_rate": 7.1608001808538045e-06,
      "loss": 0.1544,
      "step": 2372
    },
    {
      "epoch": 0.37718304822077847,
      "grad_norm": 0.4491943418979645,
      "learning_rate": 7.158478460121735e-06,
      "loss": 0.1423,
      "step": 2373
    },
    {
      "epoch": 0.3773419959865689,
      "grad_norm": 0.6022464036941528,
      "learning_rate": 7.1561561672486975e-06,
      "loss": 0.2484,
      "step": 2374
    },
    {
      "epoch": 0.3775009437523594,
      "grad_norm": 0.47817474603652954,
      "learning_rate": 7.1538333028502516e-06,
      "loss": 0.2051,
      "step": 2375
    },
    {
      "epoch": 0.3776598915181498,
      "grad_norm": 0.44908425211906433,
      "learning_rate": 7.1515098675421125e-06,
      "loss": 0.1336,
      "step": 2376
    },
    {
      "epoch": 0.37781883928394033,
      "grad_norm": 0.5347625613212585,
      "learning_rate": 7.149185861940145e-06,
      "loss": 0.2412,
      "step": 2377
    },
    {
      "epoch": 0.3779777870497308,
      "grad_norm": 0.6218034625053406,
      "learning_rate": 7.146861286660367e-06,
      "loss": 0.2074,
      "step": 2378
    },
    {
      "epoch": 0.37813673481552124,
      "grad_norm": 0.47003617882728577,
      "learning_rate": 7.144536142318945e-06,
      "loss": 0.1699,
      "step": 2379
    },
    {
      "epoch": 0.37829568258131174,
      "grad_norm": 0.6097994446754456,
      "learning_rate": 7.142210429532197e-06,
      "loss": 0.3366,
      "step": 2380
    },
    {
      "epoch": 0.3784546303471022,
      "grad_norm": 0.5928688645362854,
      "learning_rate": 7.139884148916596e-06,
      "loss": 0.2772,
      "step": 2381
    },
    {
      "epoch": 0.37861357811289265,
      "grad_norm": 0.49907323718070984,
      "learning_rate": 7.1375573010887564e-06,
      "loss": 0.1239,
      "step": 2382
    },
    {
      "epoch": 0.3787725258786831,
      "grad_norm": 0.6981870532035828,
      "learning_rate": 7.135229886665452e-06,
      "loss": 0.2828,
      "step": 2383
    },
    {
      "epoch": 0.3789314736444736,
      "grad_norm": 0.5113604068756104,
      "learning_rate": 7.132901906263603e-06,
      "loss": 0.1844,
      "step": 2384
    },
    {
      "epoch": 0.37909042141026406,
      "grad_norm": 0.5260878205299377,
      "learning_rate": 7.130573360500277e-06,
      "loss": 0.1894,
      "step": 2385
    },
    {
      "epoch": 0.3792493691760545,
      "grad_norm": 0.49778684973716736,
      "learning_rate": 7.128244249992696e-06,
      "loss": 0.2278,
      "step": 2386
    },
    {
      "epoch": 0.37940831694184496,
      "grad_norm": 0.5563356280326843,
      "learning_rate": 7.125914575358231e-06,
      "loss": 0.3285,
      "step": 2387
    },
    {
      "epoch": 0.37956726470763547,
      "grad_norm": 0.568001389503479,
      "learning_rate": 7.123584337214399e-06,
      "loss": 0.3128,
      "step": 2388
    },
    {
      "epoch": 0.3797262124734259,
      "grad_norm": 0.542870819568634,
      "learning_rate": 7.121253536178871e-06,
      "loss": 0.223,
      "step": 2389
    },
    {
      "epoch": 0.37988516023921637,
      "grad_norm": 0.595787763595581,
      "learning_rate": 7.1189221728694625e-06,
      "loss": 0.3752,
      "step": 2390
    },
    {
      "epoch": 0.3800441080050069,
      "grad_norm": 0.5303601026535034,
      "learning_rate": 7.116590247904144e-06,
      "loss": 0.2399,
      "step": 2391
    },
    {
      "epoch": 0.3802030557707973,
      "grad_norm": 0.4861966669559479,
      "learning_rate": 7.114257761901028e-06,
      "loss": 0.205,
      "step": 2392
    },
    {
      "epoch": 0.3803620035365878,
      "grad_norm": 0.6238936185836792,
      "learning_rate": 7.11192471547838e-06,
      "loss": 0.3412,
      "step": 2393
    },
    {
      "epoch": 0.38052095130237823,
      "grad_norm": 0.545307993888855,
      "learning_rate": 7.109591109254614e-06,
      "loss": 0.3144,
      "step": 2394
    },
    {
      "epoch": 0.38067989906816874,
      "grad_norm": 0.5107808709144592,
      "learning_rate": 7.107256943848291e-06,
      "loss": 0.2304,
      "step": 2395
    },
    {
      "epoch": 0.3808388468339592,
      "grad_norm": 0.6331672072410583,
      "learning_rate": 7.10492221987812e-06,
      "loss": 0.3235,
      "step": 2396
    },
    {
      "epoch": 0.38099779459974964,
      "grad_norm": 0.5478257536888123,
      "learning_rate": 7.102586937962961e-06,
      "loss": 0.2689,
      "step": 2397
    },
    {
      "epoch": 0.38115674236554015,
      "grad_norm": 0.629574179649353,
      "learning_rate": 7.100251098721817e-06,
      "loss": 0.1623,
      "step": 2398
    },
    {
      "epoch": 0.3813156901313306,
      "grad_norm": 0.5232910513877869,
      "learning_rate": 7.097914702773843e-06,
      "loss": 0.242,
      "step": 2399
    },
    {
      "epoch": 0.38147463789712105,
      "grad_norm": 0.6570578813552856,
      "learning_rate": 7.095577750738339e-06,
      "loss": 0.2308,
      "step": 2400
    },
    {
      "epoch": 0.3816335856629115,
      "grad_norm": 0.7338618040084839,
      "learning_rate": 7.093240243234756e-06,
      "loss": 0.1583,
      "step": 2401
    },
    {
      "epoch": 0.381792533428702,
      "grad_norm": 0.4708763659000397,
      "learning_rate": 7.090902180882686e-06,
      "loss": 0.154,
      "step": 2402
    },
    {
      "epoch": 0.38195148119449246,
      "grad_norm": 0.47001904249191284,
      "learning_rate": 7.088563564301874e-06,
      "loss": 0.1878,
      "step": 2403
    },
    {
      "epoch": 0.3821104289602829,
      "grad_norm": 0.5600433349609375,
      "learning_rate": 7.086224394112209e-06,
      "loss": 0.2059,
      "step": 2404
    },
    {
      "epoch": 0.3822693767260734,
      "grad_norm": 0.6249786019325256,
      "learning_rate": 7.083884670933727e-06,
      "loss": 0.3285,
      "step": 2405
    },
    {
      "epoch": 0.38242832449186387,
      "grad_norm": 0.6916513442993164,
      "learning_rate": 7.081544395386611e-06,
      "loss": 0.2238,
      "step": 2406
    },
    {
      "epoch": 0.3825872722576543,
      "grad_norm": 0.5893607139587402,
      "learning_rate": 7.079203568091192e-06,
      "loss": 0.2666,
      "step": 2407
    },
    {
      "epoch": 0.38274622002344477,
      "grad_norm": 0.5385224223136902,
      "learning_rate": 7.076862189667944e-06,
      "loss": 0.1786,
      "step": 2408
    },
    {
      "epoch": 0.3829051677892353,
      "grad_norm": 0.6108713150024414,
      "learning_rate": 7.074520260737487e-06,
      "loss": 0.2818,
      "step": 2409
    },
    {
      "epoch": 0.38306411555502573,
      "grad_norm": 0.5037696957588196,
      "learning_rate": 7.072177781920591e-06,
      "loss": 0.2283,
      "step": 2410
    },
    {
      "epoch": 0.3832230633208162,
      "grad_norm": 0.5674890279769897,
      "learning_rate": 7.06983475383817e-06,
      "loss": 0.2641,
      "step": 2411
    },
    {
      "epoch": 0.3833820110866067,
      "grad_norm": 0.7024082541465759,
      "learning_rate": 7.067491177111282e-06,
      "loss": 0.2436,
      "step": 2412
    },
    {
      "epoch": 0.38354095885239714,
      "grad_norm": 0.5453474521636963,
      "learning_rate": 7.0651470523611295e-06,
      "loss": 0.1976,
      "step": 2413
    },
    {
      "epoch": 0.3836999066181876,
      "grad_norm": 0.705405592918396,
      "learning_rate": 7.0628023802090665e-06,
      "loss": 0.2267,
      "step": 2414
    },
    {
      "epoch": 0.38385885438397804,
      "grad_norm": 0.5095039010047913,
      "learning_rate": 7.060457161276581e-06,
      "loss": 0.1857,
      "step": 2415
    },
    {
      "epoch": 0.38401780214976855,
      "grad_norm": 0.5736060738563538,
      "learning_rate": 7.0581113961853194e-06,
      "loss": 0.2746,
      "step": 2416
    },
    {
      "epoch": 0.384176749915559,
      "grad_norm": 0.5941095352172852,
      "learning_rate": 7.0557650855570645e-06,
      "loss": 0.2553,
      "step": 2417
    },
    {
      "epoch": 0.38433569768134945,
      "grad_norm": 0.5272926688194275,
      "learning_rate": 7.053418230013742e-06,
      "loss": 0.2645,
      "step": 2418
    },
    {
      "epoch": 0.38449464544713996,
      "grad_norm": 0.5135871171951294,
      "learning_rate": 7.051070830177429e-06,
      "loss": 0.1681,
      "step": 2419
    },
    {
      "epoch": 0.3846535932129304,
      "grad_norm": 0.4723559617996216,
      "learning_rate": 7.04872288667034e-06,
      "loss": 0.164,
      "step": 2420
    },
    {
      "epoch": 0.38481254097872086,
      "grad_norm": 0.42538079619407654,
      "learning_rate": 7.046374400114842e-06,
      "loss": 0.1071,
      "step": 2421
    },
    {
      "epoch": 0.3849714887445113,
      "grad_norm": 0.5243700742721558,
      "learning_rate": 7.044025371133435e-06,
      "loss": 0.2443,
      "step": 2422
    },
    {
      "epoch": 0.3851304365103018,
      "grad_norm": 0.4632890820503235,
      "learning_rate": 7.04167580034877e-06,
      "loss": 0.2026,
      "step": 2423
    },
    {
      "epoch": 0.3852893842760923,
      "grad_norm": 0.6433631777763367,
      "learning_rate": 7.039325688383645e-06,
      "loss": 0.1884,
      "step": 2424
    },
    {
      "epoch": 0.3854483320418827,
      "grad_norm": 0.5716114640235901,
      "learning_rate": 7.03697503586099e-06,
      "loss": 0.2272,
      "step": 2425
    },
    {
      "epoch": 0.38560727980767323,
      "grad_norm": 0.5091009140014648,
      "learning_rate": 7.0346238434038904e-06,
      "loss": 0.1943,
      "step": 2426
    },
    {
      "epoch": 0.3857662275734637,
      "grad_norm": 0.580322802066803,
      "learning_rate": 7.032272111635565e-06,
      "loss": 0.1759,
      "step": 2427
    },
    {
      "epoch": 0.38592517533925413,
      "grad_norm": 0.534226655960083,
      "learning_rate": 7.0299198411793835e-06,
      "loss": 0.2239,
      "step": 2428
    },
    {
      "epoch": 0.3860841231050446,
      "grad_norm": 0.5092568397521973,
      "learning_rate": 7.027567032658851e-06,
      "loss": 0.2132,
      "step": 2429
    },
    {
      "epoch": 0.3862430708708351,
      "grad_norm": 0.5112943053245544,
      "learning_rate": 7.0252136866976205e-06,
      "loss": 0.245,
      "step": 2430
    },
    {
      "epoch": 0.38640201863662554,
      "grad_norm": 0.49816152453422546,
      "learning_rate": 7.022859803919488e-06,
      "loss": 0.1837,
      "step": 2431
    },
    {
      "epoch": 0.386560966402416,
      "grad_norm": 0.6015326976776123,
      "learning_rate": 7.020505384948385e-06,
      "loss": 0.34,
      "step": 2432
    },
    {
      "epoch": 0.38671991416820645,
      "grad_norm": 0.5150583982467651,
      "learning_rate": 7.018150430408394e-06,
      "loss": 0.2801,
      "step": 2433
    },
    {
      "epoch": 0.38687886193399695,
      "grad_norm": 0.4766100347042084,
      "learning_rate": 7.015794940923736e-06,
      "loss": 0.2283,
      "step": 2434
    },
    {
      "epoch": 0.3870378096997874,
      "grad_norm": 0.556868851184845,
      "learning_rate": 7.013438917118768e-06,
      "loss": 0.3562,
      "step": 2435
    },
    {
      "epoch": 0.38719675746557786,
      "grad_norm": 0.625446081161499,
      "learning_rate": 7.0110823596179975e-06,
      "loss": 0.27,
      "step": 2436
    },
    {
      "epoch": 0.38735570523136836,
      "grad_norm": 0.5402176380157471,
      "learning_rate": 7.008725269046068e-06,
      "loss": 0.2161,
      "step": 2437
    },
    {
      "epoch": 0.3875146529971588,
      "grad_norm": 0.4863499104976654,
      "learning_rate": 7.0063676460277675e-06,
      "loss": 0.2466,
      "step": 2438
    },
    {
      "epoch": 0.38767360076294927,
      "grad_norm": 0.5282183289527893,
      "learning_rate": 7.004009491188023e-06,
      "loss": 0.2006,
      "step": 2439
    },
    {
      "epoch": 0.3878325485287397,
      "grad_norm": 0.6191875338554382,
      "learning_rate": 7.001650805151903e-06,
      "loss": 0.3589,
      "step": 2440
    },
    {
      "epoch": 0.3879914962945302,
      "grad_norm": 0.7367236614227295,
      "learning_rate": 6.999291588544616e-06,
      "loss": 0.2789,
      "step": 2441
    },
    {
      "epoch": 0.3881504440603207,
      "grad_norm": 0.4955202043056488,
      "learning_rate": 6.996931841991511e-06,
      "loss": 0.2328,
      "step": 2442
    },
    {
      "epoch": 0.3883093918261111,
      "grad_norm": 0.49302875995635986,
      "learning_rate": 6.994571566118083e-06,
      "loss": 0.2508,
      "step": 2443
    },
    {
      "epoch": 0.38846833959190163,
      "grad_norm": 0.5134149789810181,
      "learning_rate": 6.992210761549959e-06,
      "loss": 0.2347,
      "step": 2444
    },
    {
      "epoch": 0.3886272873576921,
      "grad_norm": 0.6019093990325928,
      "learning_rate": 6.989849428912908e-06,
      "loss": 0.315,
      "step": 2445
    },
    {
      "epoch": 0.38878623512348254,
      "grad_norm": 0.5604161024093628,
      "learning_rate": 6.987487568832847e-06,
      "loss": 0.2801,
      "step": 2446
    },
    {
      "epoch": 0.388945182889273,
      "grad_norm": 0.5895451903343201,
      "learning_rate": 6.9851251819358215e-06,
      "loss": 0.3599,
      "step": 2447
    },
    {
      "epoch": 0.3891041306550635,
      "grad_norm": 0.7605812549591064,
      "learning_rate": 6.982762268848024e-06,
      "loss": 0.265,
      "step": 2448
    },
    {
      "epoch": 0.38926307842085395,
      "grad_norm": 0.5713865160942078,
      "learning_rate": 6.980398830195785e-06,
      "loss": 0.277,
      "step": 2449
    },
    {
      "epoch": 0.3894220261866444,
      "grad_norm": 0.5063382387161255,
      "learning_rate": 6.978034866605572e-06,
      "loss": 0.2544,
      "step": 2450
    },
    {
      "epoch": 0.3895809739524349,
      "grad_norm": 0.49183395504951477,
      "learning_rate": 6.975670378703993e-06,
      "loss": 0.1601,
      "step": 2451
    },
    {
      "epoch": 0.38973992171822536,
      "grad_norm": 0.7125767469406128,
      "learning_rate": 6.973305367117796e-06,
      "loss": 0.2376,
      "step": 2452
    },
    {
      "epoch": 0.3898988694840158,
      "grad_norm": 0.5102143883705139,
      "learning_rate": 6.9709398324738685e-06,
      "loss": 0.1429,
      "step": 2453
    },
    {
      "epoch": 0.39005781724980626,
      "grad_norm": 0.6184199452400208,
      "learning_rate": 6.968573775399234e-06,
      "loss": 0.2634,
      "step": 2454
    },
    {
      "epoch": 0.39021676501559677,
      "grad_norm": 0.5215727686882019,
      "learning_rate": 6.966207196521052e-06,
      "loss": 0.2123,
      "step": 2455
    },
    {
      "epoch": 0.3903757127813872,
      "grad_norm": 0.5328004956245422,
      "learning_rate": 6.963840096466631e-06,
      "loss": 0.2277,
      "step": 2456
    },
    {
      "epoch": 0.39053466054717767,
      "grad_norm": 0.7772988677024841,
      "learning_rate": 6.961472475863406e-06,
      "loss": 0.348,
      "step": 2457
    },
    {
      "epoch": 0.3906936083129682,
      "grad_norm": 0.4990501403808594,
      "learning_rate": 6.959104335338954e-06,
      "loss": 0.216,
      "step": 2458
    },
    {
      "epoch": 0.39085255607875863,
      "grad_norm": 0.5900589227676392,
      "learning_rate": 6.9567356755209945e-06,
      "loss": 0.1909,
      "step": 2459
    },
    {
      "epoch": 0.3910115038445491,
      "grad_norm": 0.5025132298469543,
      "learning_rate": 6.954366497037377e-06,
      "loss": 0.1932,
      "step": 2460
    },
    {
      "epoch": 0.39117045161033953,
      "grad_norm": 0.4973074197769165,
      "learning_rate": 6.951996800516093e-06,
      "loss": 0.1517,
      "step": 2461
    },
    {
      "epoch": 0.39132939937613004,
      "grad_norm": 0.552348256111145,
      "learning_rate": 6.949626586585271e-06,
      "loss": 0.2143,
      "step": 2462
    },
    {
      "epoch": 0.3914883471419205,
      "grad_norm": 0.5718070268630981,
      "learning_rate": 6.947255855873176e-06,
      "loss": 0.2796,
      "step": 2463
    },
    {
      "epoch": 0.39164729490771094,
      "grad_norm": 0.5028918385505676,
      "learning_rate": 6.944884609008209e-06,
      "loss": 0.2062,
      "step": 2464
    },
    {
      "epoch": 0.39180624267350145,
      "grad_norm": 0.6164074540138245,
      "learning_rate": 6.942512846618909e-06,
      "loss": 0.3687,
      "step": 2465
    },
    {
      "epoch": 0.3919651904392919,
      "grad_norm": 0.5947449803352356,
      "learning_rate": 6.940140569333953e-06,
      "loss": 0.2889,
      "step": 2466
    },
    {
      "epoch": 0.39212413820508235,
      "grad_norm": 0.510293185710907,
      "learning_rate": 6.9377677777821504e-06,
      "loss": 0.273,
      "step": 2467
    },
    {
      "epoch": 0.3922830859708728,
      "grad_norm": 0.5954266786575317,
      "learning_rate": 6.935394472592451e-06,
      "loss": 0.2949,
      "step": 2468
    },
    {
      "epoch": 0.3924420337366633,
      "grad_norm": 0.5764382481575012,
      "learning_rate": 6.933020654393941e-06,
      "loss": 0.3966,
      "step": 2469
    },
    {
      "epoch": 0.39260098150245376,
      "grad_norm": 0.5471831560134888,
      "learning_rate": 6.9306463238158365e-06,
      "loss": 0.3293,
      "step": 2470
    },
    {
      "epoch": 0.3927599292682442,
      "grad_norm": 0.5356845259666443,
      "learning_rate": 6.928271481487497e-06,
      "loss": 0.2421,
      "step": 2471
    },
    {
      "epoch": 0.39291887703403466,
      "grad_norm": 0.6643743515014648,
      "learning_rate": 6.925896128038412e-06,
      "loss": 0.205,
      "step": 2472
    },
    {
      "epoch": 0.39307782479982517,
      "grad_norm": 0.578000009059906,
      "learning_rate": 6.923520264098212e-06,
      "loss": 0.3293,
      "step": 2473
    },
    {
      "epoch": 0.3932367725656156,
      "grad_norm": 0.6070025563240051,
      "learning_rate": 6.9211438902966575e-06,
      "loss": 0.2923,
      "step": 2474
    },
    {
      "epoch": 0.3933957203314061,
      "grad_norm": 0.5161739587783813,
      "learning_rate": 6.918767007263646e-06,
      "loss": 0.1825,
      "step": 2475
    },
    {
      "epoch": 0.3935546680971966,
      "grad_norm": 0.4702317714691162,
      "learning_rate": 6.916389615629211e-06,
      "loss": 0.2246,
      "step": 2476
    },
    {
      "epoch": 0.39371361586298703,
      "grad_norm": 0.5217572450637817,
      "learning_rate": 6.914011716023521e-06,
      "loss": 0.2848,
      "step": 2477
    },
    {
      "epoch": 0.3938725636287775,
      "grad_norm": 0.550707221031189,
      "learning_rate": 6.911633309076876e-06,
      "loss": 0.239,
      "step": 2478
    },
    {
      "epoch": 0.39403151139456793,
      "grad_norm": 0.45792531967163086,
      "learning_rate": 6.909254395419714e-06,
      "loss": 0.1398,
      "step": 2479
    },
    {
      "epoch": 0.39419045916035844,
      "grad_norm": 0.5050297975540161,
      "learning_rate": 6.906874975682607e-06,
      "loss": 0.1934,
      "step": 2480
    },
    {
      "epoch": 0.3943494069261489,
      "grad_norm": 0.5253093242645264,
      "learning_rate": 6.904495050496258e-06,
      "loss": 0.2116,
      "step": 2481
    },
    {
      "epoch": 0.39450835469193934,
      "grad_norm": 0.5016345977783203,
      "learning_rate": 6.902114620491507e-06,
      "loss": 0.2947,
      "step": 2482
    },
    {
      "epoch": 0.39466730245772985,
      "grad_norm": 0.6195586323738098,
      "learning_rate": 6.899733686299329e-06,
      "loss": 0.2334,
      "step": 2483
    },
    {
      "epoch": 0.3948262502235203,
      "grad_norm": 0.5278523564338684,
      "learning_rate": 6.897352248550828e-06,
      "loss": 0.2557,
      "step": 2484
    },
    {
      "epoch": 0.39498519798931075,
      "grad_norm": 0.5323238968849182,
      "learning_rate": 6.894970307877243e-06,
      "loss": 0.2414,
      "step": 2485
    },
    {
      "epoch": 0.3951441457551012,
      "grad_norm": 2.069974184036255,
      "learning_rate": 6.892587864909952e-06,
      "loss": 0.1163,
      "step": 2486
    },
    {
      "epoch": 0.3953030935208917,
      "grad_norm": 0.843311607837677,
      "learning_rate": 6.8902049202804574e-06,
      "loss": 0.2369,
      "step": 2487
    },
    {
      "epoch": 0.39546204128668216,
      "grad_norm": 0.5304098129272461,
      "learning_rate": 6.887821474620401e-06,
      "loss": 0.2236,
      "step": 2488
    },
    {
      "epoch": 0.3956209890524726,
      "grad_norm": 0.5045549869537354,
      "learning_rate": 6.885437528561554e-06,
      "loss": 0.1757,
      "step": 2489
    },
    {
      "epoch": 0.3957799368182631,
      "grad_norm": 0.583636999130249,
      "learning_rate": 6.883053082735821e-06,
      "loss": 0.2446,
      "step": 2490
    },
    {
      "epoch": 0.3959388845840536,
      "grad_norm": 0.5753623247146606,
      "learning_rate": 6.880668137775239e-06,
      "loss": 0.2526,
      "step": 2491
    },
    {
      "epoch": 0.396097832349844,
      "grad_norm": 0.5349584221839905,
      "learning_rate": 6.87828269431198e-06,
      "loss": 0.2031,
      "step": 2492
    },
    {
      "epoch": 0.3962567801156345,
      "grad_norm": 0.5017743706703186,
      "learning_rate": 6.875896752978345e-06,
      "loss": 0.202,
      "step": 2493
    },
    {
      "epoch": 0.396415727881425,
      "grad_norm": 0.49911820888519287,
      "learning_rate": 6.873510314406766e-06,
      "loss": 0.1877,
      "step": 2494
    },
    {
      "epoch": 0.39657467564721544,
      "grad_norm": 0.5325130224227905,
      "learning_rate": 6.8711233792298106e-06,
      "loss": 0.1991,
      "step": 2495
    },
    {
      "epoch": 0.3967336234130059,
      "grad_norm": 0.5794374942779541,
      "learning_rate": 6.868735948080176e-06,
      "loss": 0.2746,
      "step": 2496
    },
    {
      "epoch": 0.3968925711787964,
      "grad_norm": 0.6513997316360474,
      "learning_rate": 6.86634802159069e-06,
      "loss": 0.3032,
      "step": 2497
    },
    {
      "epoch": 0.39705151894458685,
      "grad_norm": 0.6017306447029114,
      "learning_rate": 6.863959600394312e-06,
      "loss": 0.2083,
      "step": 2498
    },
    {
      "epoch": 0.3972104667103773,
      "grad_norm": 0.43753930926322937,
      "learning_rate": 6.861570685124135e-06,
      "loss": 0.1753,
      "step": 2499
    },
    {
      "epoch": 0.39736941447616775,
      "grad_norm": 0.5394954085350037,
      "learning_rate": 6.8591812764133815e-06,
      "loss": 0.2421,
      "step": 2500
    },
    {
      "epoch": 0.39752836224195826,
      "grad_norm": 0.5745665431022644,
      "learning_rate": 6.8567913748954015e-06,
      "loss": 0.3478,
      "step": 2501
    },
    {
      "epoch": 0.3976873100077487,
      "grad_norm": 0.4498405158519745,
      "learning_rate": 6.85440098120368e-06,
      "loss": 0.1116,
      "step": 2502
    },
    {
      "epoch": 0.39784625777353916,
      "grad_norm": 0.5319715142250061,
      "learning_rate": 6.852010095971833e-06,
      "loss": 0.2555,
      "step": 2503
    },
    {
      "epoch": 0.39800520553932967,
      "grad_norm": 0.5990139245986938,
      "learning_rate": 6.849618719833601e-06,
      "loss": 0.2608,
      "step": 2504
    },
    {
      "epoch": 0.3981641533051201,
      "grad_norm": 0.5516331791877747,
      "learning_rate": 6.847226853422863e-06,
      "loss": 0.2462,
      "step": 2505
    },
    {
      "epoch": 0.39832310107091057,
      "grad_norm": 0.5618568658828735,
      "learning_rate": 6.844834497373619e-06,
      "loss": 0.3246,
      "step": 2506
    },
    {
      "epoch": 0.398482048836701,
      "grad_norm": 0.5453822016716003,
      "learning_rate": 6.842441652320005e-06,
      "loss": 0.2943,
      "step": 2507
    },
    {
      "epoch": 0.3986409966024915,
      "grad_norm": 0.5642033219337463,
      "learning_rate": 6.840048318896284e-06,
      "loss": 0.2651,
      "step": 2508
    },
    {
      "epoch": 0.398799944368282,
      "grad_norm": 0.5497780442237854,
      "learning_rate": 6.837654497736851e-06,
      "loss": 0.2276,
      "step": 2509
    },
    {
      "epoch": 0.39895889213407243,
      "grad_norm": 0.5624015927314758,
      "learning_rate": 6.835260189476228e-06,
      "loss": 0.2604,
      "step": 2510
    },
    {
      "epoch": 0.3991178398998629,
      "grad_norm": 0.5134715437889099,
      "learning_rate": 6.832865394749065e-06,
      "loss": 0.23,
      "step": 2511
    },
    {
      "epoch": 0.3992767876656534,
      "grad_norm": 0.4818979799747467,
      "learning_rate": 6.830470114190144e-06,
      "loss": 0.2144,
      "step": 2512
    },
    {
      "epoch": 0.39943573543144384,
      "grad_norm": 0.5469121932983398,
      "learning_rate": 6.828074348434375e-06,
      "loss": 0.2433,
      "step": 2513
    },
    {
      "epoch": 0.3995946831972343,
      "grad_norm": 0.588100790977478,
      "learning_rate": 6.825678098116793e-06,
      "loss": 0.3159,
      "step": 2514
    },
    {
      "epoch": 0.3997536309630248,
      "grad_norm": 0.4829265773296356,
      "learning_rate": 6.823281363872567e-06,
      "loss": 0.2046,
      "step": 2515
    },
    {
      "epoch": 0.39991257872881525,
      "grad_norm": 0.43876761198043823,
      "learning_rate": 6.820884146336992e-06,
      "loss": 0.1411,
      "step": 2516
    },
    {
      "epoch": 0.4000715264946057,
      "grad_norm": 0.5245718359947205,
      "learning_rate": 6.8184864461454866e-06,
      "loss": 0.2137,
      "step": 2517
    },
    {
      "epoch": 0.40023047426039615,
      "grad_norm": 0.5484700202941895,
      "learning_rate": 6.816088263933609e-06,
      "loss": 0.2176,
      "step": 2518
    },
    {
      "epoch": 0.40038942202618666,
      "grad_norm": 0.5816709995269775,
      "learning_rate": 6.81368960033703e-06,
      "loss": 0.2923,
      "step": 2519
    },
    {
      "epoch": 0.4005483697919771,
      "grad_norm": 0.5685619115829468,
      "learning_rate": 6.811290455991561e-06,
      "loss": 0.2991,
      "step": 2520
    },
    {
      "epoch": 0.40070731755776756,
      "grad_norm": 0.4854196012020111,
      "learning_rate": 6.808890831533134e-06,
      "loss": 0.2185,
      "step": 2521
    },
    {
      "epoch": 0.40086626532355807,
      "grad_norm": 0.537781298160553,
      "learning_rate": 6.806490727597808e-06,
      "loss": 0.2859,
      "step": 2522
    },
    {
      "epoch": 0.4010252130893485,
      "grad_norm": 0.6153531670570374,
      "learning_rate": 6.804090144821772e-06,
      "loss": 0.3599,
      "step": 2523
    },
    {
      "epoch": 0.40118416085513897,
      "grad_norm": 0.5581701397895813,
      "learning_rate": 6.801689083841341e-06,
      "loss": 0.2359,
      "step": 2524
    },
    {
      "epoch": 0.4013431086209294,
      "grad_norm": 0.4676170349121094,
      "learning_rate": 6.799287545292958e-06,
      "loss": 0.1789,
      "step": 2525
    },
    {
      "epoch": 0.40150205638671993,
      "grad_norm": 0.6088384389877319,
      "learning_rate": 6.7968855298131885e-06,
      "loss": 0.3187,
      "step": 2526
    },
    {
      "epoch": 0.4016610041525104,
      "grad_norm": 0.4928722083568573,
      "learning_rate": 6.794483038038726e-06,
      "loss": 0.1723,
      "step": 2527
    },
    {
      "epoch": 0.40181995191830083,
      "grad_norm": 0.5264471769332886,
      "learning_rate": 6.792080070606397e-06,
      "loss": 0.2642,
      "step": 2528
    },
    {
      "epoch": 0.40197889968409134,
      "grad_norm": 0.47767534852027893,
      "learning_rate": 6.7896766281531435e-06,
      "loss": 0.21,
      "step": 2529
    },
    {
      "epoch": 0.4021378474498818,
      "grad_norm": 0.5166181325912476,
      "learning_rate": 6.787272711316039e-06,
      "loss": 0.247,
      "step": 2530
    },
    {
      "epoch": 0.40229679521567224,
      "grad_norm": 0.5789550542831421,
      "learning_rate": 6.784868320732284e-06,
      "loss": 0.3116,
      "step": 2531
    },
    {
      "epoch": 0.4024557429814627,
      "grad_norm": 0.513028085231781,
      "learning_rate": 6.7824634570392004e-06,
      "loss": 0.1995,
      "step": 2532
    },
    {
      "epoch": 0.4026146907472532,
      "grad_norm": 0.5652971267700195,
      "learning_rate": 6.780058120874238e-06,
      "loss": 0.2689,
      "step": 2533
    },
    {
      "epoch": 0.40277363851304365,
      "grad_norm": 0.5498369932174683,
      "learning_rate": 6.7776523128749725e-06,
      "loss": 0.3106,
      "step": 2534
    },
    {
      "epoch": 0.4029325862788341,
      "grad_norm": 0.6111355423927307,
      "learning_rate": 6.775246033679105e-06,
      "loss": 0.3523,
      "step": 2535
    },
    {
      "epoch": 0.4030915340446246,
      "grad_norm": 0.5132028460502625,
      "learning_rate": 6.772839283924457e-06,
      "loss": 0.1863,
      "step": 2536
    },
    {
      "epoch": 0.40325048181041506,
      "grad_norm": 0.5330893993377686,
      "learning_rate": 6.770432064248979e-06,
      "loss": 0.2173,
      "step": 2537
    },
    {
      "epoch": 0.4034094295762055,
      "grad_norm": 0.5903679132461548,
      "learning_rate": 6.768024375290747e-06,
      "loss": 0.3185,
      "step": 2538
    },
    {
      "epoch": 0.40356837734199597,
      "grad_norm": 0.5617511868476868,
      "learning_rate": 6.765616217687957e-06,
      "loss": 0.2807,
      "step": 2539
    },
    {
      "epoch": 0.40372732510778647,
      "grad_norm": 0.40186840295791626,
      "learning_rate": 6.763207592078933e-06,
      "loss": 0.0936,
      "step": 2540
    },
    {
      "epoch": 0.4038862728735769,
      "grad_norm": 0.65059894323349,
      "learning_rate": 6.760798499102121e-06,
      "loss": 0.3736,
      "step": 2541
    },
    {
      "epoch": 0.4040452206393674,
      "grad_norm": 0.4720681607723236,
      "learning_rate": 6.758388939396092e-06,
      "loss": 0.1823,
      "step": 2542
    },
    {
      "epoch": 0.4042041684051579,
      "grad_norm": 0.5129292011260986,
      "learning_rate": 6.755978913599539e-06,
      "loss": 0.1769,
      "step": 2543
    },
    {
      "epoch": 0.40436311617094833,
      "grad_norm": 0.5067500472068787,
      "learning_rate": 6.753568422351282e-06,
      "loss": 0.1687,
      "step": 2544
    },
    {
      "epoch": 0.4045220639367388,
      "grad_norm": 0.5425107479095459,
      "learning_rate": 6.751157466290262e-06,
      "loss": 0.2312,
      "step": 2545
    },
    {
      "epoch": 0.40468101170252924,
      "grad_norm": 0.5550954937934875,
      "learning_rate": 6.748746046055541e-06,
      "loss": 0.278,
      "step": 2546
    },
    {
      "epoch": 0.40483995946831974,
      "grad_norm": 0.5210565328598022,
      "learning_rate": 6.7463341622863074e-06,
      "loss": 0.1999,
      "step": 2547
    },
    {
      "epoch": 0.4049989072341102,
      "grad_norm": 0.5075308084487915,
      "learning_rate": 6.743921815621875e-06,
      "loss": 0.2367,
      "step": 2548
    },
    {
      "epoch": 0.40515785499990065,
      "grad_norm": 0.6054734587669373,
      "learning_rate": 6.74150900670167e-06,
      "loss": 0.3126,
      "step": 2549
    },
    {
      "epoch": 0.4053168027656911,
      "grad_norm": 0.5026442408561707,
      "learning_rate": 6.739095736165253e-06,
      "loss": 0.1654,
      "step": 2550
    },
    {
      "epoch": 0.4054757505314816,
      "grad_norm": 0.48785650730133057,
      "learning_rate": 6.7366820046523015e-06,
      "loss": 0.2229,
      "step": 2551
    },
    {
      "epoch": 0.40563469829727206,
      "grad_norm": 0.6407054662704468,
      "learning_rate": 6.734267812802615e-06,
      "loss": 0.331,
      "step": 2552
    },
    {
      "epoch": 0.4057936460630625,
      "grad_norm": 0.4720814824104309,
      "learning_rate": 6.7318531612561145e-06,
      "loss": 0.2265,
      "step": 2553
    },
    {
      "epoch": 0.405952593828853,
      "grad_norm": 0.5676679611206055,
      "learning_rate": 6.729438050652843e-06,
      "loss": 0.2656,
      "step": 2554
    },
    {
      "epoch": 0.40611154159464347,
      "grad_norm": 0.5673658847808838,
      "learning_rate": 6.727022481632971e-06,
      "loss": 0.2577,
      "step": 2555
    },
    {
      "epoch": 0.4062704893604339,
      "grad_norm": 0.5607154965400696,
      "learning_rate": 6.724606454836782e-06,
      "loss": 0.3054,
      "step": 2556
    },
    {
      "epoch": 0.40642943712622437,
      "grad_norm": 0.5156606435775757,
      "learning_rate": 6.722189970904683e-06,
      "loss": 0.271,
      "step": 2557
    },
    {
      "epoch": 0.4065883848920149,
      "grad_norm": 0.5380526185035706,
      "learning_rate": 6.719773030477208e-06,
      "loss": 0.2998,
      "step": 2558
    },
    {
      "epoch": 0.4067473326578053,
      "grad_norm": 0.5995612144470215,
      "learning_rate": 6.717355634195004e-06,
      "loss": 0.3196,
      "step": 2559
    },
    {
      "epoch": 0.4069062804235958,
      "grad_norm": 0.4418754577636719,
      "learning_rate": 6.714937782698844e-06,
      "loss": 0.2013,
      "step": 2560
    },
    {
      "epoch": 0.4070652281893863,
      "grad_norm": 0.4981676936149597,
      "learning_rate": 6.7125194766296195e-06,
      "loss": 0.2297,
      "step": 2561
    },
    {
      "epoch": 0.40722417595517674,
      "grad_norm": 0.7986191511154175,
      "learning_rate": 6.710100716628345e-06,
      "loss": 0.2245,
      "step": 2562
    },
    {
      "epoch": 0.4073831237209672,
      "grad_norm": 0.49631837010383606,
      "learning_rate": 6.707681503336151e-06,
      "loss": 0.1311,
      "step": 2563
    },
    {
      "epoch": 0.40754207148675764,
      "grad_norm": 0.4912720024585724,
      "learning_rate": 6.705261837394292e-06,
      "loss": 0.2093,
      "step": 2564
    },
    {
      "epoch": 0.40770101925254815,
      "grad_norm": 0.5054716467857361,
      "learning_rate": 6.702841719444141e-06,
      "loss": 0.1926,
      "step": 2565
    },
    {
      "epoch": 0.4078599670183386,
      "grad_norm": 0.46274879574775696,
      "learning_rate": 6.70042115012719e-06,
      "loss": 0.1912,
      "step": 2566
    },
    {
      "epoch": 0.40801891478412905,
      "grad_norm": 0.6364355087280273,
      "learning_rate": 6.698000130085052e-06,
      "loss": 0.372,
      "step": 2567
    },
    {
      "epoch": 0.40817786254991956,
      "grad_norm": 0.528450608253479,
      "learning_rate": 6.695578659959461e-06,
      "loss": 0.2305,
      "step": 2568
    },
    {
      "epoch": 0.40833681031571,
      "grad_norm": 0.582148015499115,
      "learning_rate": 6.693156740392265e-06,
      "loss": 0.2366,
      "step": 2569
    },
    {
      "epoch": 0.40849575808150046,
      "grad_norm": 0.5358114242553711,
      "learning_rate": 6.6907343720254355e-06,
      "loss": 0.2043,
      "step": 2570
    },
    {
      "epoch": 0.4086547058472909,
      "grad_norm": 0.4786851406097412,
      "learning_rate": 6.688311555501064e-06,
      "loss": 0.2039,
      "step": 2571
    },
    {
      "epoch": 0.4088136536130814,
      "grad_norm": 0.53067547082901,
      "learning_rate": 6.6858882914613575e-06,
      "loss": 0.2252,
      "step": 2572
    },
    {
      "epoch": 0.40897260137887187,
      "grad_norm": 0.49716445803642273,
      "learning_rate": 6.683464580548642e-06,
      "loss": 0.1557,
      "step": 2573
    },
    {
      "epoch": 0.4091315491446623,
      "grad_norm": 0.5193912386894226,
      "learning_rate": 6.681040423405363e-06,
      "loss": 0.2322,
      "step": 2574
    },
    {
      "epoch": 0.40929049691045283,
      "grad_norm": 0.5188702344894409,
      "learning_rate": 6.678615820674085e-06,
      "loss": 0.1802,
      "step": 2575
    },
    {
      "epoch": 0.4094494446762433,
      "grad_norm": 0.5288170576095581,
      "learning_rate": 6.6761907729974886e-06,
      "loss": 0.2278,
      "step": 2576
    },
    {
      "epoch": 0.40960839244203373,
      "grad_norm": 0.6899314522743225,
      "learning_rate": 6.673765281018373e-06,
      "loss": 0.4369,
      "step": 2577
    },
    {
      "epoch": 0.4097673402078242,
      "grad_norm": 0.5124777555465698,
      "learning_rate": 6.671339345379658e-06,
      "loss": 0.2017,
      "step": 2578
    },
    {
      "epoch": 0.4099262879736147,
      "grad_norm": 0.6124240756034851,
      "learning_rate": 6.668912966724377e-06,
      "loss": 0.3648,
      "step": 2579
    },
    {
      "epoch": 0.41008523573940514,
      "grad_norm": 0.53609699010849,
      "learning_rate": 6.6664861456956805e-06,
      "loss": 0.2748,
      "step": 2580
    },
    {
      "epoch": 0.4102441835051956,
      "grad_norm": 0.5750259757041931,
      "learning_rate": 6.664058882936841e-06,
      "loss": 0.3657,
      "step": 2581
    },
    {
      "epoch": 0.4104031312709861,
      "grad_norm": 0.5000319480895996,
      "learning_rate": 6.661631179091247e-06,
      "loss": 0.2136,
      "step": 2582
    },
    {
      "epoch": 0.41056207903677655,
      "grad_norm": 0.4900519847869873,
      "learning_rate": 6.659203034802397e-06,
      "loss": 0.2293,
      "step": 2583
    },
    {
      "epoch": 0.410721026802567,
      "grad_norm": 0.4843622148036957,
      "learning_rate": 6.656774450713914e-06,
      "loss": 0.1911,
      "step": 2584
    },
    {
      "epoch": 0.41087997456835745,
      "grad_norm": 0.5345390439033508,
      "learning_rate": 6.654345427469537e-06,
      "loss": 0.254,
      "step": 2585
    },
    {
      "epoch": 0.41103892233414796,
      "grad_norm": 0.45796525478363037,
      "learning_rate": 6.651915965713115e-06,
      "loss": 0.1701,
      "step": 2586
    },
    {
      "epoch": 0.4111978700999384,
      "grad_norm": 0.5048332810401917,
      "learning_rate": 6.649486066088622e-06,
      "loss": 0.1876,
      "step": 2587
    },
    {
      "epoch": 0.41135681786572886,
      "grad_norm": 0.505783200263977,
      "learning_rate": 6.6470557292401416e-06,
      "loss": 0.1474,
      "step": 2588
    },
    {
      "epoch": 0.4115157656315193,
      "grad_norm": 0.48390519618988037,
      "learning_rate": 6.644624955811873e-06,
      "loss": 0.2137,
      "step": 2589
    },
    {
      "epoch": 0.4116747133973098,
      "grad_norm": 0.5138680338859558,
      "learning_rate": 6.64219374644814e-06,
      "loss": 0.2108,
      "step": 2590
    },
    {
      "epoch": 0.4118336611631003,
      "grad_norm": 0.5695987939834595,
      "learning_rate": 6.639762101793369e-06,
      "loss": 0.2589,
      "step": 2591
    },
    {
      "epoch": 0.4119926089288907,
      "grad_norm": 0.4925333857536316,
      "learning_rate": 6.637330022492112e-06,
      "loss": 0.2039,
      "step": 2592
    },
    {
      "epoch": 0.41215155669468123,
      "grad_norm": 0.5803413987159729,
      "learning_rate": 6.6348975091890315e-06,
      "loss": 0.3298,
      "step": 2593
    },
    {
      "epoch": 0.4123105044604717,
      "grad_norm": 0.6940470337867737,
      "learning_rate": 6.632464562528906e-06,
      "loss": 0.3226,
      "step": 2594
    },
    {
      "epoch": 0.41246945222626213,
      "grad_norm": 0.43028753995895386,
      "learning_rate": 6.630031183156628e-06,
      "loss": 0.1803,
      "step": 2595
    },
    {
      "epoch": 0.4126283999920526,
      "grad_norm": 0.6019209027290344,
      "learning_rate": 6.6275973717172046e-06,
      "loss": 0.2345,
      "step": 2596
    },
    {
      "epoch": 0.4127873477578431,
      "grad_norm": 0.4827191233634949,
      "learning_rate": 6.625163128855763e-06,
      "loss": 0.1769,
      "step": 2597
    },
    {
      "epoch": 0.41294629552363354,
      "grad_norm": 0.5609534978866577,
      "learning_rate": 6.622728455217536e-06,
      "loss": 0.2827,
      "step": 2598
    },
    {
      "epoch": 0.413105243289424,
      "grad_norm": 0.524294376373291,
      "learning_rate": 6.620293351447875e-06,
      "loss": 0.1961,
      "step": 2599
    },
    {
      "epoch": 0.4132641910552145,
      "grad_norm": 0.48573848605155945,
      "learning_rate": 6.617857818192248e-06,
      "loss": 0.1775,
      "step": 2600
    },
    {
      "epoch": 0.41342313882100495,
      "grad_norm": 0.5724292993545532,
      "learning_rate": 6.615421856096231e-06,
      "loss": 0.264,
      "step": 2601
    },
    {
      "epoch": 0.4135820865867954,
      "grad_norm": 0.5076021552085876,
      "learning_rate": 6.612985465805519e-06,
      "loss": 0.2169,
      "step": 2602
    },
    {
      "epoch": 0.41374103435258586,
      "grad_norm": 0.9745751619338989,
      "learning_rate": 6.610548647965916e-06,
      "loss": 0.2548,
      "step": 2603
    },
    {
      "epoch": 0.41389998211837636,
      "grad_norm": 0.5611639618873596,
      "learning_rate": 6.6081114032233425e-06,
      "loss": 0.2499,
      "step": 2604
    },
    {
      "epoch": 0.4140589298841668,
      "grad_norm": 0.6194932460784912,
      "learning_rate": 6.605673732223833e-06,
      "loss": 0.1924,
      "step": 2605
    },
    {
      "epoch": 0.41421787764995727,
      "grad_norm": 0.48386555910110474,
      "learning_rate": 6.6032356356135275e-06,
      "loss": 0.1956,
      "step": 2606
    },
    {
      "epoch": 0.4143768254157478,
      "grad_norm": 0.5564587116241455,
      "learning_rate": 6.6007971140386915e-06,
      "loss": 0.2165,
      "step": 2607
    },
    {
      "epoch": 0.4145357731815382,
      "grad_norm": 0.6559991240501404,
      "learning_rate": 6.598358168145692e-06,
      "loss": 0.2589,
      "step": 2608
    },
    {
      "epoch": 0.4146947209473287,
      "grad_norm": 0.6229847073554993,
      "learning_rate": 6.5959187985810125e-06,
      "loss": 0.375,
      "step": 2609
    },
    {
      "epoch": 0.41485366871311913,
      "grad_norm": 0.5933274626731873,
      "learning_rate": 6.593479005991251e-06,
      "loss": 0.3015,
      "step": 2610
    },
    {
      "epoch": 0.41501261647890964,
      "grad_norm": 0.48444241285324097,
      "learning_rate": 6.591038791023113e-06,
      "loss": 0.1752,
      "step": 2611
    },
    {
      "epoch": 0.4151715642447001,
      "grad_norm": 0.5322245955467224,
      "learning_rate": 6.58859815432342e-06,
      "loss": 0.3219,
      "step": 2612
    },
    {
      "epoch": 0.41533051201049054,
      "grad_norm": 0.6350180506706238,
      "learning_rate": 6.586157096539105e-06,
      "loss": 0.3163,
      "step": 2613
    },
    {
      "epoch": 0.41548945977628104,
      "grad_norm": 0.6308924555778503,
      "learning_rate": 6.5837156183172095e-06,
      "loss": 0.3646,
      "step": 2614
    },
    {
      "epoch": 0.4156484075420715,
      "grad_norm": 0.5807312726974487,
      "learning_rate": 6.581273720304887e-06,
      "loss": 0.3856,
      "step": 2615
    },
    {
      "epoch": 0.41580735530786195,
      "grad_norm": 0.6323837637901306,
      "learning_rate": 6.578831403149406e-06,
      "loss": 0.2286,
      "step": 2616
    },
    {
      "epoch": 0.4159663030736524,
      "grad_norm": 0.547181248664856,
      "learning_rate": 6.576388667498143e-06,
      "loss": 0.2702,
      "step": 2617
    },
    {
      "epoch": 0.4161252508394429,
      "grad_norm": 0.6057066917419434,
      "learning_rate": 6.573945513998588e-06,
      "loss": 0.3117,
      "step": 2618
    },
    {
      "epoch": 0.41628419860523336,
      "grad_norm": 0.5264146327972412,
      "learning_rate": 6.571501943298335e-06,
      "loss": 0.2155,
      "step": 2619
    },
    {
      "epoch": 0.4164431463710238,
      "grad_norm": 0.5039330124855042,
      "learning_rate": 6.5690579560450984e-06,
      "loss": 0.2241,
      "step": 2620
    },
    {
      "epoch": 0.4166020941368143,
      "grad_norm": 0.5391701459884644,
      "learning_rate": 6.566613552886696e-06,
      "loss": 0.3026,
      "step": 2621
    },
    {
      "epoch": 0.41676104190260477,
      "grad_norm": 1.7207847833633423,
      "learning_rate": 6.564168734471057e-06,
      "loss": 0.1828,
      "step": 2622
    },
    {
      "epoch": 0.4169199896683952,
      "grad_norm": 0.44417160749435425,
      "learning_rate": 6.5617235014462235e-06,
      "loss": 0.1693,
      "step": 2623
    },
    {
      "epoch": 0.41707893743418567,
      "grad_norm": 0.5236338376998901,
      "learning_rate": 6.559277854460343e-06,
      "loss": 0.2864,
      "step": 2624
    },
    {
      "epoch": 0.4172378851999762,
      "grad_norm": 0.4500955045223236,
      "learning_rate": 6.556831794161678e-06,
      "loss": 0.1947,
      "step": 2625
    },
    {
      "epoch": 0.41739683296576663,
      "grad_norm": 0.49239274859428406,
      "learning_rate": 6.554385321198596e-06,
      "loss": 0.1741,
      "step": 2626
    },
    {
      "epoch": 0.4175557807315571,
      "grad_norm": 0.7262259125709534,
      "learning_rate": 6.551938436219578e-06,
      "loss": 0.3574,
      "step": 2627
    },
    {
      "epoch": 0.41771472849734753,
      "grad_norm": 0.5932160019874573,
      "learning_rate": 6.549491139873211e-06,
      "loss": 0.2769,
      "step": 2628
    },
    {
      "epoch": 0.41787367626313804,
      "grad_norm": 0.5431103110313416,
      "learning_rate": 6.54704343280819e-06,
      "loss": 0.3088,
      "step": 2629
    },
    {
      "epoch": 0.4180326240289285,
      "grad_norm": 0.5967527031898499,
      "learning_rate": 6.5445953156733235e-06,
      "loss": 0.379,
      "step": 2630
    },
    {
      "epoch": 0.41819157179471894,
      "grad_norm": 0.5641193389892578,
      "learning_rate": 6.542146789117524e-06,
      "loss": 0.3036,
      "step": 2631
    },
    {
      "epoch": 0.41835051956050945,
      "grad_norm": 0.6231501698493958,
      "learning_rate": 6.539697853789816e-06,
      "loss": 0.2646,
      "step": 2632
    },
    {
      "epoch": 0.4185094673262999,
      "grad_norm": 0.527351975440979,
      "learning_rate": 6.537248510339331e-06,
      "loss": 0.2428,
      "step": 2633
    },
    {
      "epoch": 0.41866841509209035,
      "grad_norm": 0.577819287776947,
      "learning_rate": 6.534798759415307e-06,
      "loss": 0.241,
      "step": 2634
    },
    {
      "epoch": 0.4188273628578808,
      "grad_norm": 0.8293860554695129,
      "learning_rate": 6.532348601667093e-06,
      "loss": 0.2064,
      "step": 2635
    },
    {
      "epoch": 0.4189863106236713,
      "grad_norm": 0.5172043442726135,
      "learning_rate": 6.529898037744144e-06,
      "loss": 0.1699,
      "step": 2636
    },
    {
      "epoch": 0.41914525838946176,
      "grad_norm": 0.6417711973190308,
      "learning_rate": 6.527447068296026e-06,
      "loss": 0.2995,
      "step": 2637
    },
    {
      "epoch": 0.4193042061552522,
      "grad_norm": 0.6251210570335388,
      "learning_rate": 6.5249956939724046e-06,
      "loss": 0.2956,
      "step": 2638
    },
    {
      "epoch": 0.4194631539210427,
      "grad_norm": 0.6278614401817322,
      "learning_rate": 6.522543915423061e-06,
      "loss": 0.1809,
      "step": 2639
    },
    {
      "epoch": 0.41962210168683317,
      "grad_norm": 0.4470592439174652,
      "learning_rate": 6.520091733297879e-06,
      "loss": 0.1482,
      "step": 2640
    },
    {
      "epoch": 0.4197810494526236,
      "grad_norm": 0.4961167573928833,
      "learning_rate": 6.51763914824685e-06,
      "loss": 0.2142,
      "step": 2641
    },
    {
      "epoch": 0.4199399972184141,
      "grad_norm": 0.5385138988494873,
      "learning_rate": 6.515186160920075e-06,
      "loss": 0.2527,
      "step": 2642
    },
    {
      "epoch": 0.4200989449842046,
      "grad_norm": 0.5868781805038452,
      "learning_rate": 6.512732771967758e-06,
      "loss": 0.2078,
      "step": 2643
    },
    {
      "epoch": 0.42025789274999503,
      "grad_norm": 0.5422062873840332,
      "learning_rate": 6.510278982040212e-06,
      "loss": 0.2143,
      "step": 2644
    },
    {
      "epoch": 0.4204168405157855,
      "grad_norm": 0.5155906081199646,
      "learning_rate": 6.507824791787855e-06,
      "loss": 0.2055,
      "step": 2645
    },
    {
      "epoch": 0.420575788281576,
      "grad_norm": 0.5324442982673645,
      "learning_rate": 6.50537020186121e-06,
      "loss": 0.2543,
      "step": 2646
    },
    {
      "epoch": 0.42073473604736644,
      "grad_norm": 0.4561372399330139,
      "learning_rate": 6.502915212910908e-06,
      "loss": 0.1373,
      "step": 2647
    },
    {
      "epoch": 0.4208936838131569,
      "grad_norm": 0.48222169280052185,
      "learning_rate": 6.500459825587686e-06,
      "loss": 0.2433,
      "step": 2648
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 0.5942028760910034,
      "learning_rate": 6.498004040542385e-06,
      "loss": 0.3587,
      "step": 2649
    },
    {
      "epoch": 0.42121157934473785,
      "grad_norm": 0.5166971683502197,
      "learning_rate": 6.495547858425952e-06,
      "loss": 0.2038,
      "step": 2650
    },
    {
      "epoch": 0.4213705271105283,
      "grad_norm": 0.6236987113952637,
      "learning_rate": 6.493091279889439e-06,
      "loss": 0.3547,
      "step": 2651
    },
    {
      "epoch": 0.42152947487631875,
      "grad_norm": 0.49388623237609863,
      "learning_rate": 6.490634305584003e-06,
      "loss": 0.2515,
      "step": 2652
    },
    {
      "epoch": 0.42168842264210926,
      "grad_norm": 0.6169031858444214,
      "learning_rate": 6.4881769361609085e-06,
      "loss": 0.2856,
      "step": 2653
    },
    {
      "epoch": 0.4218473704078997,
      "grad_norm": 0.5626468658447266,
      "learning_rate": 6.485719172271521e-06,
      "loss": 0.3053,
      "step": 2654
    },
    {
      "epoch": 0.42200631817369016,
      "grad_norm": 0.5011707544326782,
      "learning_rate": 6.483261014567311e-06,
      "loss": 0.25,
      "step": 2655
    },
    {
      "epoch": 0.4221652659394806,
      "grad_norm": 0.5889855027198792,
      "learning_rate": 6.480802463699857e-06,
      "loss": 0.3701,
      "step": 2656
    },
    {
      "epoch": 0.4223242137052711,
      "grad_norm": 0.3964214324951172,
      "learning_rate": 6.478343520320838e-06,
      "loss": 0.1349,
      "step": 2657
    },
    {
      "epoch": 0.4224831614710616,
      "grad_norm": 0.5221256613731384,
      "learning_rate": 6.475884185082035e-06,
      "loss": 0.2778,
      "step": 2658
    },
    {
      "epoch": 0.422642109236852,
      "grad_norm": 0.5645655393600464,
      "learning_rate": 6.4734244586353435e-06,
      "loss": 0.2063,
      "step": 2659
    },
    {
      "epoch": 0.42280105700264253,
      "grad_norm": 0.5176453590393066,
      "learning_rate": 6.470964341632749e-06,
      "loss": 0.2102,
      "step": 2660
    },
    {
      "epoch": 0.422960004768433,
      "grad_norm": 0.5049626231193542,
      "learning_rate": 6.4685038347263495e-06,
      "loss": 0.2082,
      "step": 2661
    },
    {
      "epoch": 0.42311895253422344,
      "grad_norm": 0.5465547442436218,
      "learning_rate": 6.466042938568342e-06,
      "loss": 0.1943,
      "step": 2662
    },
    {
      "epoch": 0.4232779003000139,
      "grad_norm": 0.6428521871566772,
      "learning_rate": 6.463581653811031e-06,
      "loss": 0.3618,
      "step": 2663
    },
    {
      "epoch": 0.4234368480658044,
      "grad_norm": 0.4916437864303589,
      "learning_rate": 6.4611199811068196e-06,
      "loss": 0.2214,
      "step": 2664
    },
    {
      "epoch": 0.42359579583159485,
      "grad_norm": 0.5369724631309509,
      "learning_rate": 6.458657921108213e-06,
      "loss": 0.1731,
      "step": 2665
    },
    {
      "epoch": 0.4237547435973853,
      "grad_norm": 0.5155112743377686,
      "learning_rate": 6.456195474467827e-06,
      "loss": 0.1967,
      "step": 2666
    },
    {
      "epoch": 0.42391369136317575,
      "grad_norm": 0.5335700511932373,
      "learning_rate": 6.453732641838372e-06,
      "loss": 0.2589,
      "step": 2667
    },
    {
      "epoch": 0.42407263912896626,
      "grad_norm": 0.5468564629554749,
      "learning_rate": 6.45126942387266e-06,
      "loss": 0.1767,
      "step": 2668
    },
    {
      "epoch": 0.4242315868947567,
      "grad_norm": 0.5266352891921997,
      "learning_rate": 6.448805821223614e-06,
      "loss": 0.2026,
      "step": 2669
    },
    {
      "epoch": 0.42439053466054716,
      "grad_norm": 0.4900125563144684,
      "learning_rate": 6.4463418345442495e-06,
      "loss": 0.2189,
      "step": 2670
    },
    {
      "epoch": 0.42454948242633767,
      "grad_norm": 0.5494673252105713,
      "learning_rate": 6.443877464487687e-06,
      "loss": 0.2351,
      "step": 2671
    },
    {
      "epoch": 0.4247084301921281,
      "grad_norm": 0.4424917697906494,
      "learning_rate": 6.441412711707154e-06,
      "loss": 0.1517,
      "step": 2672
    },
    {
      "epoch": 0.42486737795791857,
      "grad_norm": 0.5259275436401367,
      "learning_rate": 6.4389475768559675e-06,
      "loss": 0.2332,
      "step": 2673
    },
    {
      "epoch": 0.425026325723709,
      "grad_norm": 0.6912602186203003,
      "learning_rate": 6.436482060587559e-06,
      "loss": 0.1636,
      "step": 2674
    },
    {
      "epoch": 0.4251852734894995,
      "grad_norm": 0.4886968433856964,
      "learning_rate": 6.434016163555452e-06,
      "loss": 0.2378,
      "step": 2675
    },
    {
      "epoch": 0.42534422125529,
      "grad_norm": 0.5113148093223572,
      "learning_rate": 6.431549886413274e-06,
      "loss": 0.2,
      "step": 2676
    },
    {
      "epoch": 0.42550316902108043,
      "grad_norm": 0.4923417568206787,
      "learning_rate": 6.429083229814755e-06,
      "loss": 0.1995,
      "step": 2677
    },
    {
      "epoch": 0.42566211678687094,
      "grad_norm": 0.5147587060928345,
      "learning_rate": 6.426616194413722e-06,
      "loss": 0.1946,
      "step": 2678
    },
    {
      "epoch": 0.4258210645526614,
      "grad_norm": 0.6256073117256165,
      "learning_rate": 6.4241487808641044e-06,
      "loss": 0.2906,
      "step": 2679
    },
    {
      "epoch": 0.42598001231845184,
      "grad_norm": 0.5545192956924438,
      "learning_rate": 6.421680989819933e-06,
      "loss": 0.2729,
      "step": 2680
    },
    {
      "epoch": 0.4261389600842423,
      "grad_norm": 0.5560026168823242,
      "learning_rate": 6.419212821935334e-06,
      "loss": 0.2642,
      "step": 2681
    },
    {
      "epoch": 0.4262979078500328,
      "grad_norm": 0.5945405960083008,
      "learning_rate": 6.416744277864541e-06,
      "loss": 0.2509,
      "step": 2682
    },
    {
      "epoch": 0.42645685561582325,
      "grad_norm": 0.5028010606765747,
      "learning_rate": 6.414275358261879e-06,
      "loss": 0.186,
      "step": 2683
    },
    {
      "epoch": 0.4266158033816137,
      "grad_norm": 0.5179349184036255,
      "learning_rate": 6.41180606378178e-06,
      "loss": 0.1971,
      "step": 2684
    },
    {
      "epoch": 0.4267747511474042,
      "grad_norm": 0.3878782093524933,
      "learning_rate": 6.409336395078771e-06,
      "loss": 0.1413,
      "step": 2685
    },
    {
      "epoch": 0.42693369891319466,
      "grad_norm": 0.5589978098869324,
      "learning_rate": 6.4068663528074786e-06,
      "loss": 0.302,
      "step": 2686
    },
    {
      "epoch": 0.4270926466789851,
      "grad_norm": 0.4989555776119232,
      "learning_rate": 6.4043959376226285e-06,
      "loss": 0.1747,
      "step": 2687
    },
    {
      "epoch": 0.42725159444477556,
      "grad_norm": 0.4812672734260559,
      "learning_rate": 6.401925150179045e-06,
      "loss": 0.177,
      "step": 2688
    },
    {
      "epoch": 0.42741054221056607,
      "grad_norm": 0.4336528480052948,
      "learning_rate": 6.399453991131655e-06,
      "loss": 0.1429,
      "step": 2689
    },
    {
      "epoch": 0.4275694899763565,
      "grad_norm": 0.5214705467224121,
      "learning_rate": 6.39698246113548e-06,
      "loss": 0.2226,
      "step": 2690
    },
    {
      "epoch": 0.42772843774214697,
      "grad_norm": 0.600455105304718,
      "learning_rate": 6.394510560845637e-06,
      "loss": 0.3095,
      "step": 2691
    },
    {
      "epoch": 0.4278873855079375,
      "grad_norm": 0.4329037368297577,
      "learning_rate": 6.392038290917348e-06,
      "loss": 0.1669,
      "step": 2692
    },
    {
      "epoch": 0.42804633327372793,
      "grad_norm": 0.48847055435180664,
      "learning_rate": 6.389565652005929e-06,
      "loss": 0.1995,
      "step": 2693
    },
    {
      "epoch": 0.4282052810395184,
      "grad_norm": 0.4998648166656494,
      "learning_rate": 6.387092644766795e-06,
      "loss": 0.1866,
      "step": 2694
    },
    {
      "epoch": 0.42836422880530883,
      "grad_norm": 0.5020745992660522,
      "learning_rate": 6.384619269855457e-06,
      "loss": 0.2231,
      "step": 2695
    },
    {
      "epoch": 0.42852317657109934,
      "grad_norm": 0.5122014284133911,
      "learning_rate": 6.382145527927524e-06,
      "loss": 0.2078,
      "step": 2696
    },
    {
      "epoch": 0.4286821243368898,
      "grad_norm": 0.5046776533126831,
      "learning_rate": 6.379671419638703e-06,
      "loss": 0.2053,
      "step": 2697
    },
    {
      "epoch": 0.42884107210268024,
      "grad_norm": 0.3861390948295593,
      "learning_rate": 6.3771969456448e-06,
      "loss": 0.1062,
      "step": 2698
    },
    {
      "epoch": 0.42900001986847075,
      "grad_norm": 0.5066115856170654,
      "learning_rate": 6.374722106601717e-06,
      "loss": 0.2091,
      "step": 2699
    },
    {
      "epoch": 0.4291589676342612,
      "grad_norm": 0.5383874773979187,
      "learning_rate": 6.372246903165445e-06,
      "loss": 0.2041,
      "step": 2700
    },
    {
      "epoch": 0.42931791540005165,
      "grad_norm": 0.5556057691574097,
      "learning_rate": 6.369771335992085e-06,
      "loss": 0.2133,
      "step": 2701
    },
    {
      "epoch": 0.4294768631658421,
      "grad_norm": 0.5174638628959656,
      "learning_rate": 6.367295405737825e-06,
      "loss": 0.2683,
      "step": 2702
    },
    {
      "epoch": 0.4296358109316326,
      "grad_norm": 0.5229465961456299,
      "learning_rate": 6.3648191130589524e-06,
      "loss": 0.2237,
      "step": 2703
    },
    {
      "epoch": 0.42979475869742306,
      "grad_norm": 0.5971742868423462,
      "learning_rate": 6.362342458611849e-06,
      "loss": 0.3711,
      "step": 2704
    },
    {
      "epoch": 0.4299537064632135,
      "grad_norm": 0.49897512793540955,
      "learning_rate": 6.359865443052995e-06,
      "loss": 0.2065,
      "step": 2705
    },
    {
      "epoch": 0.430112654229004,
      "grad_norm": 0.5194665193557739,
      "learning_rate": 6.357388067038964e-06,
      "loss": 0.2552,
      "step": 2706
    },
    {
      "epoch": 0.4302716019947945,
      "grad_norm": 0.48618221282958984,
      "learning_rate": 6.354910331226427e-06,
      "loss": 0.1899,
      "step": 2707
    },
    {
      "epoch": 0.4304305497605849,
      "grad_norm": 0.40937015414237976,
      "learning_rate": 6.352432236272149e-06,
      "loss": 0.1521,
      "step": 2708
    },
    {
      "epoch": 0.4305894975263754,
      "grad_norm": 0.4975436329841614,
      "learning_rate": 6.349953782832991e-06,
      "loss": 0.1999,
      "step": 2709
    },
    {
      "epoch": 0.4307484452921659,
      "grad_norm": 0.5493690371513367,
      "learning_rate": 6.347474971565909e-06,
      "loss": 0.2381,
      "step": 2710
    },
    {
      "epoch": 0.43090739305795633,
      "grad_norm": 0.4837915301322937,
      "learning_rate": 6.344995803127952e-06,
      "loss": 0.1473,
      "step": 2711
    },
    {
      "epoch": 0.4310663408237468,
      "grad_norm": 0.5845387578010559,
      "learning_rate": 6.342516278176268e-06,
      "loss": 0.3027,
      "step": 2712
    },
    {
      "epoch": 0.43122528858953724,
      "grad_norm": 0.5982565879821777,
      "learning_rate": 6.340036397368094e-06,
      "loss": 0.3087,
      "step": 2713
    },
    {
      "epoch": 0.43138423635532774,
      "grad_norm": 0.5680881142616272,
      "learning_rate": 6.337556161360765e-06,
      "loss": 0.2936,
      "step": 2714
    },
    {
      "epoch": 0.4315431841211182,
      "grad_norm": 0.7454057931900024,
      "learning_rate": 6.335075570811708e-06,
      "loss": 0.2568,
      "step": 2715
    },
    {
      "epoch": 0.43170213188690865,
      "grad_norm": 0.523800790309906,
      "learning_rate": 6.33259462637845e-06,
      "loss": 0.1853,
      "step": 2716
    },
    {
      "epoch": 0.43186107965269915,
      "grad_norm": 0.5259407162666321,
      "learning_rate": 6.330113328718601e-06,
      "loss": 0.249,
      "step": 2717
    },
    {
      "epoch": 0.4320200274184896,
      "grad_norm": 0.5552576780319214,
      "learning_rate": 6.327631678489874e-06,
      "loss": 0.2152,
      "step": 2718
    },
    {
      "epoch": 0.43217897518428006,
      "grad_norm": 0.6461744904518127,
      "learning_rate": 6.325149676350071e-06,
      "loss": 0.2223,
      "step": 2719
    },
    {
      "epoch": 0.4323379229500705,
      "grad_norm": 0.4905839264392853,
      "learning_rate": 6.322667322957088e-06,
      "loss": 0.1876,
      "step": 2720
    },
    {
      "epoch": 0.432496870715861,
      "grad_norm": 0.5439057350158691,
      "learning_rate": 6.320184618968915e-06,
      "loss": 0.2103,
      "step": 2721
    },
    {
      "epoch": 0.43265581848165147,
      "grad_norm": 0.6596855521202087,
      "learning_rate": 6.317701565043637e-06,
      "loss": 0.3199,
      "step": 2722
    },
    {
      "epoch": 0.4328147662474419,
      "grad_norm": 0.6131588220596313,
      "learning_rate": 6.3152181618394234e-06,
      "loss": 0.2616,
      "step": 2723
    },
    {
      "epoch": 0.4329737140132324,
      "grad_norm": 0.4750622510910034,
      "learning_rate": 6.312734410014546e-06,
      "loss": 0.1684,
      "step": 2724
    },
    {
      "epoch": 0.4331326617790229,
      "grad_norm": 0.6533181071281433,
      "learning_rate": 6.310250310227364e-06,
      "loss": 0.1554,
      "step": 2725
    },
    {
      "epoch": 0.4332916095448133,
      "grad_norm": 0.44775474071502686,
      "learning_rate": 6.307765863136331e-06,
      "loss": 0.1326,
      "step": 2726
    },
    {
      "epoch": 0.4334505573106038,
      "grad_norm": 0.6175675988197327,
      "learning_rate": 6.305281069399989e-06,
      "loss": 0.2454,
      "step": 2727
    },
    {
      "epoch": 0.4336095050763943,
      "grad_norm": 0.5193935632705688,
      "learning_rate": 6.302795929676976e-06,
      "loss": 0.2074,
      "step": 2728
    },
    {
      "epoch": 0.43376845284218474,
      "grad_norm": 0.4973507225513458,
      "learning_rate": 6.30031044462602e-06,
      "loss": 0.2083,
      "step": 2729
    },
    {
      "epoch": 0.4339274006079752,
      "grad_norm": 0.7261388897895813,
      "learning_rate": 6.29782461490594e-06,
      "loss": 0.1616,
      "step": 2730
    },
    {
      "epoch": 0.4340863483737657,
      "grad_norm": 0.49409329891204834,
      "learning_rate": 6.295338441175647e-06,
      "loss": 0.2019,
      "step": 2731
    },
    {
      "epoch": 0.43424529613955615,
      "grad_norm": 0.4669812023639679,
      "learning_rate": 6.2928519240941435e-06,
      "loss": 0.1455,
      "step": 2732
    },
    {
      "epoch": 0.4344042439053466,
      "grad_norm": 0.6413713693618774,
      "learning_rate": 6.290365064320521e-06,
      "loss": 0.2915,
      "step": 2733
    },
    {
      "epoch": 0.43456319167113705,
      "grad_norm": 0.5451453924179077,
      "learning_rate": 6.287877862513965e-06,
      "loss": 0.2554,
      "step": 2734
    },
    {
      "epoch": 0.43472213943692756,
      "grad_norm": 0.6062155365943909,
      "learning_rate": 6.285390319333751e-06,
      "loss": 0.3094,
      "step": 2735
    },
    {
      "epoch": 0.434881087202718,
      "grad_norm": 0.5661605596542358,
      "learning_rate": 6.282902435439242e-06,
      "loss": 0.3218,
      "step": 2736
    },
    {
      "epoch": 0.43504003496850846,
      "grad_norm": 0.5918679237365723,
      "learning_rate": 6.280414211489895e-06,
      "loss": 0.2698,
      "step": 2737
    },
    {
      "epoch": 0.43519898273429897,
      "grad_norm": 0.5573946833610535,
      "learning_rate": 6.277925648145255e-06,
      "loss": 0.2449,
      "step": 2738
    },
    {
      "epoch": 0.4353579305000894,
      "grad_norm": 0.5711442232131958,
      "learning_rate": 6.275436746064957e-06,
      "loss": 0.1246,
      "step": 2739
    },
    {
      "epoch": 0.43551687826587987,
      "grad_norm": 0.5075598955154419,
      "learning_rate": 6.272947505908725e-06,
      "loss": 0.1722,
      "step": 2740
    },
    {
      "epoch": 0.4356758260316703,
      "grad_norm": 0.6137943863868713,
      "learning_rate": 6.270457928336379e-06,
      "loss": 0.3562,
      "step": 2741
    },
    {
      "epoch": 0.43583477379746083,
      "grad_norm": 0.44477394223213196,
      "learning_rate": 6.267968014007819e-06,
      "loss": 0.1573,
      "step": 2742
    },
    {
      "epoch": 0.4359937215632513,
      "grad_norm": 0.47345808148384094,
      "learning_rate": 6.2654777635830385e-06,
      "loss": 0.1805,
      "step": 2743
    },
    {
      "epoch": 0.43615266932904173,
      "grad_norm": 0.5067006945610046,
      "learning_rate": 6.262987177722122e-06,
      "loss": 0.2524,
      "step": 2744
    },
    {
      "epoch": 0.43631161709483224,
      "grad_norm": 0.4786413311958313,
      "learning_rate": 6.26049625708524e-06,
      "loss": 0.1648,
      "step": 2745
    },
    {
      "epoch": 0.4364705648606227,
      "grad_norm": 0.5988893508911133,
      "learning_rate": 6.258005002332655e-06,
      "loss": 0.2704,
      "step": 2746
    },
    {
      "epoch": 0.43662951262641314,
      "grad_norm": 0.49753934144973755,
      "learning_rate": 6.255513414124712e-06,
      "loss": 0.1951,
      "step": 2747
    },
    {
      "epoch": 0.4367884603922036,
      "grad_norm": 0.5772903561592102,
      "learning_rate": 6.253021493121852e-06,
      "loss": 0.188,
      "step": 2748
    },
    {
      "epoch": 0.4369474081579941,
      "grad_norm": 0.5971224308013916,
      "learning_rate": 6.250529239984598e-06,
      "loss": 0.2667,
      "step": 2749
    },
    {
      "epoch": 0.43710635592378455,
      "grad_norm": 0.5109513998031616,
      "learning_rate": 6.248036655373565e-06,
      "loss": 0.2136,
      "step": 2750
    },
    {
      "epoch": 0.437265303689575,
      "grad_norm": 0.41980138421058655,
      "learning_rate": 6.245543739949455e-06,
      "loss": 0.1724,
      "step": 2751
    },
    {
      "epoch": 0.43742425145536545,
      "grad_norm": 0.6033914089202881,
      "learning_rate": 6.243050494373055e-06,
      "loss": 0.3493,
      "step": 2752
    },
    {
      "epoch": 0.43758319922115596,
      "grad_norm": 0.6178041696548462,
      "learning_rate": 6.240556919305242e-06,
      "loss": 0.2992,
      "step": 2753
    },
    {
      "epoch": 0.4377421469869464,
      "grad_norm": 0.5421412587165833,
      "learning_rate": 6.238063015406982e-06,
      "loss": 0.2659,
      "step": 2754
    },
    {
      "epoch": 0.43790109475273686,
      "grad_norm": 0.5029823184013367,
      "learning_rate": 6.235568783339324e-06,
      "loss": 0.2047,
      "step": 2755
    },
    {
      "epoch": 0.43806004251852737,
      "grad_norm": 0.5871187448501587,
      "learning_rate": 6.233074223763409e-06,
      "loss": 0.3117,
      "step": 2756
    },
    {
      "epoch": 0.4382189902843178,
      "grad_norm": 0.571935772895813,
      "learning_rate": 6.2305793373404564e-06,
      "loss": 0.2744,
      "step": 2757
    },
    {
      "epoch": 0.4383779380501083,
      "grad_norm": 0.5461594462394714,
      "learning_rate": 6.228084124731783e-06,
      "loss": 0.283,
      "step": 2758
    },
    {
      "epoch": 0.4385368858158987,
      "grad_norm": 0.5563580989837646,
      "learning_rate": 6.225588586598786e-06,
      "loss": 0.307,
      "step": 2759
    },
    {
      "epoch": 0.43869583358168923,
      "grad_norm": 0.4965442419052124,
      "learning_rate": 6.223092723602946e-06,
      "loss": 0.2093,
      "step": 2760
    },
    {
      "epoch": 0.4388547813474797,
      "grad_norm": 0.44507598876953125,
      "learning_rate": 6.220596536405838e-06,
      "loss": 0.1351,
      "step": 2761
    },
    {
      "epoch": 0.43901372911327013,
      "grad_norm": 0.5209103226661682,
      "learning_rate": 6.218100025669117e-06,
      "loss": 0.2038,
      "step": 2762
    },
    {
      "epoch": 0.43917267687906064,
      "grad_norm": 0.4888423979282379,
      "learning_rate": 6.215603192054523e-06,
      "loss": 0.2219,
      "step": 2763
    },
    {
      "epoch": 0.4393316246448511,
      "grad_norm": 0.43596920371055603,
      "learning_rate": 6.213106036223886e-06,
      "loss": 0.1373,
      "step": 2764
    },
    {
      "epoch": 0.43949057241064154,
      "grad_norm": 0.5570422410964966,
      "learning_rate": 6.2106085588391185e-06,
      "loss": 0.272,
      "step": 2765
    },
    {
      "epoch": 0.439649520176432,
      "grad_norm": 0.578108012676239,
      "learning_rate": 6.208110760562218e-06,
      "loss": 0.2693,
      "step": 2766
    },
    {
      "epoch": 0.4398084679422225,
      "grad_norm": 0.6427735090255737,
      "learning_rate": 6.20561264205527e-06,
      "loss": 0.4021,
      "step": 2767
    },
    {
      "epoch": 0.43996741570801295,
      "grad_norm": 0.46892017126083374,
      "learning_rate": 6.20311420398044e-06,
      "loss": 0.171,
      "step": 2768
    },
    {
      "epoch": 0.4401263634738034,
      "grad_norm": 0.5367841720581055,
      "learning_rate": 6.2006154469999824e-06,
      "loss": 0.2683,
      "step": 2769
    },
    {
      "epoch": 0.4402853112395939,
      "grad_norm": 0.5205785036087036,
      "learning_rate": 6.198116371776233e-06,
      "loss": 0.2265,
      "step": 2770
    },
    {
      "epoch": 0.44044425900538436,
      "grad_norm": 0.5313063263893127,
      "learning_rate": 6.195616978971618e-06,
      "loss": 0.2526,
      "step": 2771
    },
    {
      "epoch": 0.4406032067711748,
      "grad_norm": 0.4801177680492401,
      "learning_rate": 6.1931172692486405e-06,
      "loss": 0.2026,
      "step": 2772
    },
    {
      "epoch": 0.44076215453696527,
      "grad_norm": 7.805179119110107,
      "learning_rate": 6.190617243269889e-06,
      "loss": 0.1157,
      "step": 2773
    },
    {
      "epoch": 0.4409211023027558,
      "grad_norm": 0.5246073603630066,
      "learning_rate": 6.18811690169804e-06,
      "loss": 0.2319,
      "step": 2774
    },
    {
      "epoch": 0.4410800500685462,
      "grad_norm": 0.6015518307685852,
      "learning_rate": 6.185616245195849e-06,
      "loss": 0.2478,
      "step": 2775
    },
    {
      "epoch": 0.4412389978343367,
      "grad_norm": 0.6242238879203796,
      "learning_rate": 6.1831152744261595e-06,
      "loss": 0.3828,
      "step": 2776
    },
    {
      "epoch": 0.4413979456001272,
      "grad_norm": 0.5800283551216125,
      "learning_rate": 6.180613990051895e-06,
      "loss": 0.2736,
      "step": 2777
    },
    {
      "epoch": 0.44155689336591764,
      "grad_norm": 0.557598888874054,
      "learning_rate": 6.178112392736061e-06,
      "loss": 0.1572,
      "step": 2778
    },
    {
      "epoch": 0.4417158411317081,
      "grad_norm": 0.47861096262931824,
      "learning_rate": 6.17561048314175e-06,
      "loss": 0.1643,
      "step": 2779
    },
    {
      "epoch": 0.44187478889749854,
      "grad_norm": 0.47977709770202637,
      "learning_rate": 6.173108261932134e-06,
      "loss": 0.1668,
      "step": 2780
    },
    {
      "epoch": 0.44203373666328905,
      "grad_norm": 0.5026708841323853,
      "learning_rate": 6.17060572977047e-06,
      "loss": 0.2077,
      "step": 2781
    },
    {
      "epoch": 0.4421926844290795,
      "grad_norm": 0.466428279876709,
      "learning_rate": 6.168102887320096e-06,
      "loss": 0.1802,
      "step": 2782
    },
    {
      "epoch": 0.44235163219486995,
      "grad_norm": 0.49935173988342285,
      "learning_rate": 6.1655997352444294e-06,
      "loss": 0.1909,
      "step": 2783
    },
    {
      "epoch": 0.44251057996066046,
      "grad_norm": 0.5814638733863831,
      "learning_rate": 6.163096274206978e-06,
      "loss": 0.2695,
      "step": 2784
    },
    {
      "epoch": 0.4426695277264509,
      "grad_norm": 0.5334354639053345,
      "learning_rate": 6.1605925048713215e-06,
      "loss": 0.199,
      "step": 2785
    },
    {
      "epoch": 0.44282847549224136,
      "grad_norm": 0.4117569029331207,
      "learning_rate": 6.158088427901128e-06,
      "loss": 0.1336,
      "step": 2786
    },
    {
      "epoch": 0.4429874232580318,
      "grad_norm": 0.48235800862312317,
      "learning_rate": 6.155584043960145e-06,
      "loss": 0.1772,
      "step": 2787
    },
    {
      "epoch": 0.4431463710238223,
      "grad_norm": 0.4366362988948822,
      "learning_rate": 6.153079353712201e-06,
      "loss": 0.1643,
      "step": 2788
    },
    {
      "epoch": 0.44330531878961277,
      "grad_norm": 0.3987222909927368,
      "learning_rate": 6.150574357821209e-06,
      "loss": 0.1052,
      "step": 2789
    },
    {
      "epoch": 0.4434642665554032,
      "grad_norm": 0.9798489809036255,
      "learning_rate": 6.1480690569511545e-06,
      "loss": 0.2617,
      "step": 2790
    },
    {
      "epoch": 0.44362321432119367,
      "grad_norm": 0.5001435875892639,
      "learning_rate": 6.1455634517661165e-06,
      "loss": 0.2383,
      "step": 2791
    },
    {
      "epoch": 0.4437821620869842,
      "grad_norm": 0.5335325002670288,
      "learning_rate": 6.143057542930242e-06,
      "loss": 0.2051,
      "step": 2792
    },
    {
      "epoch": 0.44394110985277463,
      "grad_norm": 0.6170535087585449,
      "learning_rate": 6.140551331107767e-06,
      "loss": 0.32,
      "step": 2793
    },
    {
      "epoch": 0.4441000576185651,
      "grad_norm": 0.505408525466919,
      "learning_rate": 6.138044816963006e-06,
      "loss": 0.2129,
      "step": 2794
    },
    {
      "epoch": 0.4442590053843556,
      "grad_norm": 0.6894533634185791,
      "learning_rate": 6.13553800116035e-06,
      "loss": 0.3204,
      "step": 2795
    },
    {
      "epoch": 0.44441795315014604,
      "grad_norm": 0.5717663168907166,
      "learning_rate": 6.1330308843642735e-06,
      "loss": 0.3353,
      "step": 2796
    },
    {
      "epoch": 0.4445769009159365,
      "grad_norm": 0.5404378771781921,
      "learning_rate": 6.130523467239331e-06,
      "loss": 0.288,
      "step": 2797
    },
    {
      "epoch": 0.44473584868172694,
      "grad_norm": 0.49706077575683594,
      "learning_rate": 6.128015750450155e-06,
      "loss": 0.2322,
      "step": 2798
    },
    {
      "epoch": 0.44489479644751745,
      "grad_norm": 0.6837922930717468,
      "learning_rate": 6.125507734661458e-06,
      "loss": 0.2703,
      "step": 2799
    },
    {
      "epoch": 0.4450537442133079,
      "grad_norm": 0.5138063430786133,
      "learning_rate": 6.122999420538029e-06,
      "loss": 0.2125,
      "step": 2800
    },
    {
      "epoch": 0.44521269197909835,
      "grad_norm": 0.524711549282074,
      "learning_rate": 6.120490808744744e-06,
      "loss": 0.264,
      "step": 2801
    },
    {
      "epoch": 0.44537163974488886,
      "grad_norm": 0.5120261311531067,
      "learning_rate": 6.11798189994655e-06,
      "loss": 0.2289,
      "step": 2802
    },
    {
      "epoch": 0.4455305875106793,
      "grad_norm": 0.48860201239585876,
      "learning_rate": 6.115472694808474e-06,
      "loss": 0.1535,
      "step": 2803
    },
    {
      "epoch": 0.44568953527646976,
      "grad_norm": 0.4523245394229889,
      "learning_rate": 6.112963193995626e-06,
      "loss": 0.1779,
      "step": 2804
    },
    {
      "epoch": 0.4458484830422602,
      "grad_norm": 0.5438622236251831,
      "learning_rate": 6.110453398173188e-06,
      "loss": 0.283,
      "step": 2805
    },
    {
      "epoch": 0.4460074308080507,
      "grad_norm": 0.5310704112052917,
      "learning_rate": 6.107943308006425e-06,
      "loss": 0.2334,
      "step": 2806
    },
    {
      "epoch": 0.44616637857384117,
      "grad_norm": 0.5641940832138062,
      "learning_rate": 6.105432924160679e-06,
      "loss": 0.2716,
      "step": 2807
    },
    {
      "epoch": 0.4463253263396316,
      "grad_norm": 0.5031200051307678,
      "learning_rate": 6.1029222473013705e-06,
      "loss": 0.219,
      "step": 2808
    },
    {
      "epoch": 0.44648427410542213,
      "grad_norm": 0.47426164150238037,
      "learning_rate": 6.100411278093995e-06,
      "loss": 0.2135,
      "step": 2809
    },
    {
      "epoch": 0.4466432218712126,
      "grad_norm": 0.6035692691802979,
      "learning_rate": 6.097900017204126e-06,
      "loss": 0.3365,
      "step": 2810
    },
    {
      "epoch": 0.44680216963700303,
      "grad_norm": 0.6475494503974915,
      "learning_rate": 6.095388465297418e-06,
      "loss": 0.4092,
      "step": 2811
    },
    {
      "epoch": 0.4469611174027935,
      "grad_norm": 0.4466668963432312,
      "learning_rate": 6.092876623039599e-06,
      "loss": 0.1897,
      "step": 2812
    },
    {
      "epoch": 0.447120065168584,
      "grad_norm": 0.5221976637840271,
      "learning_rate": 6.090364491096473e-06,
      "loss": 0.2316,
      "step": 2813
    },
    {
      "epoch": 0.44727901293437444,
      "grad_norm": 0.5041887760162354,
      "learning_rate": 6.087852070133926e-06,
      "loss": 0.1806,
      "step": 2814
    },
    {
      "epoch": 0.4474379607001649,
      "grad_norm": 0.5192129015922546,
      "learning_rate": 6.085339360817916e-06,
      "loss": 0.2451,
      "step": 2815
    },
    {
      "epoch": 0.4475969084659554,
      "grad_norm": 0.6077147126197815,
      "learning_rate": 6.082826363814477e-06,
      "loss": 0.3499,
      "step": 2816
    },
    {
      "epoch": 0.44775585623174585,
      "grad_norm": 0.49450135231018066,
      "learning_rate": 6.080313079789723e-06,
      "loss": 0.2403,
      "step": 2817
    },
    {
      "epoch": 0.4479148039975363,
      "grad_norm": 0.4527025520801544,
      "learning_rate": 6.077799509409843e-06,
      "loss": 0.1768,
      "step": 2818
    },
    {
      "epoch": 0.44807375176332676,
      "grad_norm": 0.4891681671142578,
      "learning_rate": 6.0752856533411e-06,
      "loss": 0.2049,
      "step": 2819
    },
    {
      "epoch": 0.44823269952911726,
      "grad_norm": 0.4011523127555847,
      "learning_rate": 6.072771512249832e-06,
      "loss": 0.1162,
      "step": 2820
    },
    {
      "epoch": 0.4483916472949077,
      "grad_norm": 0.5606576800346375,
      "learning_rate": 6.070257086802458e-06,
      "loss": 0.3057,
      "step": 2821
    },
    {
      "epoch": 0.44855059506069817,
      "grad_norm": 0.48998576402664185,
      "learning_rate": 6.067742377665464e-06,
      "loss": 0.2283,
      "step": 2822
    },
    {
      "epoch": 0.44870954282648867,
      "grad_norm": 0.5659196972846985,
      "learning_rate": 6.0652273855054225e-06,
      "loss": 0.3119,
      "step": 2823
    },
    {
      "epoch": 0.4488684905922791,
      "grad_norm": 0.5656660199165344,
      "learning_rate": 6.062712110988968e-06,
      "loss": 0.3297,
      "step": 2824
    },
    {
      "epoch": 0.4490274383580696,
      "grad_norm": 0.5372885465621948,
      "learning_rate": 6.060196554782819e-06,
      "loss": 0.1743,
      "step": 2825
    },
    {
      "epoch": 0.44918638612386,
      "grad_norm": 0.47762686014175415,
      "learning_rate": 6.0576807175537654e-06,
      "loss": 0.1857,
      "step": 2826
    },
    {
      "epoch": 0.44934533388965053,
      "grad_norm": 0.5118066668510437,
      "learning_rate": 6.055164599968674e-06,
      "loss": 0.2431,
      "step": 2827
    },
    {
      "epoch": 0.449504281655441,
      "grad_norm": 0.48034390807151794,
      "learning_rate": 6.052648202694481e-06,
      "loss": 0.2043,
      "step": 2828
    },
    {
      "epoch": 0.44966322942123144,
      "grad_norm": 0.5548771023750305,
      "learning_rate": 6.050131526398202e-06,
      "loss": 0.2668,
      "step": 2829
    },
    {
      "epoch": 0.4498221771870219,
      "grad_norm": 0.4528188705444336,
      "learning_rate": 6.047614571746923e-06,
      "loss": 0.1884,
      "step": 2830
    },
    {
      "epoch": 0.4499811249528124,
      "grad_norm": 0.5001948475837708,
      "learning_rate": 6.045097339407806e-06,
      "loss": 0.21,
      "step": 2831
    },
    {
      "epoch": 0.45014007271860285,
      "grad_norm": 0.554143488407135,
      "learning_rate": 6.042579830048083e-06,
      "loss": 0.2649,
      "step": 2832
    },
    {
      "epoch": 0.4502990204843933,
      "grad_norm": 0.48736727237701416,
      "learning_rate": 6.0400620443350675e-06,
      "loss": 0.1695,
      "step": 2833
    },
    {
      "epoch": 0.4504579682501838,
      "grad_norm": 0.5411237478256226,
      "learning_rate": 6.037543982936138e-06,
      "loss": 0.2558,
      "step": 2834
    },
    {
      "epoch": 0.45061691601597426,
      "grad_norm": 0.4693056344985962,
      "learning_rate": 6.035025646518747e-06,
      "loss": 0.1981,
      "step": 2835
    },
    {
      "epoch": 0.4507758637817647,
      "grad_norm": 0.5211236476898193,
      "learning_rate": 6.032507035750424e-06,
      "loss": 0.2037,
      "step": 2836
    },
    {
      "epoch": 0.45093481154755516,
      "grad_norm": 0.5799643397331238,
      "learning_rate": 6.02998815129877e-06,
      "loss": 0.2902,
      "step": 2837
    },
    {
      "epoch": 0.45109375931334567,
      "grad_norm": 0.9603546261787415,
      "learning_rate": 6.027468993831457e-06,
      "loss": 0.1402,
      "step": 2838
    },
    {
      "epoch": 0.4512527070791361,
      "grad_norm": 0.5727162957191467,
      "learning_rate": 6.024949564016227e-06,
      "loss": 0.3421,
      "step": 2839
    },
    {
      "epoch": 0.45141165484492657,
      "grad_norm": 0.50937819480896,
      "learning_rate": 6.022429862520901e-06,
      "loss": 0.1825,
      "step": 2840
    },
    {
      "epoch": 0.4515706026107171,
      "grad_norm": 0.5658518075942993,
      "learning_rate": 6.019909890013367e-06,
      "loss": 0.2826,
      "step": 2841
    },
    {
      "epoch": 0.4517295503765075,
      "grad_norm": 0.5395532250404358,
      "learning_rate": 6.017389647161585e-06,
      "loss": 0.1815,
      "step": 2842
    },
    {
      "epoch": 0.451888498142298,
      "grad_norm": 0.4987106919288635,
      "learning_rate": 6.014869134633589e-06,
      "loss": 0.2006,
      "step": 2843
    },
    {
      "epoch": 0.45204744590808843,
      "grad_norm": 0.6194213032722473,
      "learning_rate": 6.012348353097484e-06,
      "loss": 0.3664,
      "step": 2844
    },
    {
      "epoch": 0.45220639367387894,
      "grad_norm": 0.40744999051094055,
      "learning_rate": 6.009827303221442e-06,
      "loss": 0.1513,
      "step": 2845
    },
    {
      "epoch": 0.4523653414396694,
      "grad_norm": 0.45576509833335876,
      "learning_rate": 6.007305985673712e-06,
      "loss": 0.1767,
      "step": 2846
    },
    {
      "epoch": 0.45252428920545984,
      "grad_norm": 0.55286705493927,
      "learning_rate": 6.004784401122613e-06,
      "loss": 0.2236,
      "step": 2847
    },
    {
      "epoch": 0.45268323697125035,
      "grad_norm": 0.4797969460487366,
      "learning_rate": 6.0022625502365306e-06,
      "loss": 0.1869,
      "step": 2848
    },
    {
      "epoch": 0.4528421847370408,
      "grad_norm": 0.48140573501586914,
      "learning_rate": 5.999740433683926e-06,
      "loss": 0.1886,
      "step": 2849
    },
    {
      "epoch": 0.45300113250283125,
      "grad_norm": 0.507233202457428,
      "learning_rate": 5.997218052133327e-06,
      "loss": 0.2216,
      "step": 2850
    },
    {
      "epoch": 0.4531600802686217,
      "grad_norm": 0.5230522751808167,
      "learning_rate": 5.994695406253333e-06,
      "loss": 0.2239,
      "step": 2851
    },
    {
      "epoch": 0.4533190280344122,
      "grad_norm": 0.5873012542724609,
      "learning_rate": 5.992172496712614e-06,
      "loss": 0.2773,
      "step": 2852
    },
    {
      "epoch": 0.45347797580020266,
      "grad_norm": 0.4038287103176117,
      "learning_rate": 5.9896493241799115e-06,
      "loss": 0.1061,
      "step": 2853
    },
    {
      "epoch": 0.4536369235659931,
      "grad_norm": 0.46008631587028503,
      "learning_rate": 5.987125889324032e-06,
      "loss": 0.1461,
      "step": 2854
    },
    {
      "epoch": 0.4537958713317836,
      "grad_norm": 0.48430028557777405,
      "learning_rate": 5.984602192813855e-06,
      "loss": 0.1865,
      "step": 2855
    },
    {
      "epoch": 0.45395481909757407,
      "grad_norm": 0.6540657877922058,
      "learning_rate": 5.98207823531833e-06,
      "loss": 0.2919,
      "step": 2856
    },
    {
      "epoch": 0.4541137668633645,
      "grad_norm": 0.4976271986961365,
      "learning_rate": 5.979554017506474e-06,
      "loss": 0.2112,
      "step": 2857
    },
    {
      "epoch": 0.45427271462915497,
      "grad_norm": 0.5740038156509399,
      "learning_rate": 5.977029540047371e-06,
      "loss": 0.318,
      "step": 2858
    },
    {
      "epoch": 0.4544316623949455,
      "grad_norm": 0.9086101055145264,
      "learning_rate": 5.974504803610178e-06,
      "loss": 0.2554,
      "step": 2859
    },
    {
      "epoch": 0.45459061016073593,
      "grad_norm": 0.47523820400238037,
      "learning_rate": 5.97197980886412e-06,
      "loss": 0.1878,
      "step": 2860
    },
    {
      "epoch": 0.4547495579265264,
      "grad_norm": 0.4442968964576721,
      "learning_rate": 5.9694545564784865e-06,
      "loss": 0.1712,
      "step": 2861
    },
    {
      "epoch": 0.4549085056923169,
      "grad_norm": 0.5839635729789734,
      "learning_rate": 5.966929047122641e-06,
      "loss": 0.3137,
      "step": 2862
    },
    {
      "epoch": 0.45506745345810734,
      "grad_norm": 0.4989303946495056,
      "learning_rate": 5.964403281466009e-06,
      "loss": 0.1937,
      "step": 2863
    },
    {
      "epoch": 0.4552264012238978,
      "grad_norm": 0.5283628106117249,
      "learning_rate": 5.961877260178089e-06,
      "loss": 0.2236,
      "step": 2864
    },
    {
      "epoch": 0.45538534898968824,
      "grad_norm": 0.5000706315040588,
      "learning_rate": 5.959350983928446e-06,
      "loss": 0.2259,
      "step": 2865
    },
    {
      "epoch": 0.45554429675547875,
      "grad_norm": 0.4922396242618561,
      "learning_rate": 5.956824453386711e-06,
      "loss": 0.2329,
      "step": 2866
    },
    {
      "epoch": 0.4557032445212692,
      "grad_norm": 0.5386063456535339,
      "learning_rate": 5.954297669222584e-06,
      "loss": 0.192,
      "step": 2867
    },
    {
      "epoch": 0.45586219228705965,
      "grad_norm": 0.5330843329429626,
      "learning_rate": 5.95177063210583e-06,
      "loss": 0.2067,
      "step": 2868
    },
    {
      "epoch": 0.4560211400528501,
      "grad_norm": 0.5682266354560852,
      "learning_rate": 5.949243342706284e-06,
      "loss": 0.262,
      "step": 2869
    },
    {
      "epoch": 0.4561800878186406,
      "grad_norm": 0.5162901282310486,
      "learning_rate": 5.946715801693846e-06,
      "loss": 0.2262,
      "step": 2870
    },
    {
      "epoch": 0.45633903558443106,
      "grad_norm": 0.5687230229377747,
      "learning_rate": 5.944188009738483e-06,
      "loss": 0.2649,
      "step": 2871
    },
    {
      "epoch": 0.4564979833502215,
      "grad_norm": 0.5771787166595459,
      "learning_rate": 5.941659967510229e-06,
      "loss": 0.3132,
      "step": 2872
    },
    {
      "epoch": 0.456656931116012,
      "grad_norm": 0.5007452964782715,
      "learning_rate": 5.939131675679186e-06,
      "loss": 0.1711,
      "step": 2873
    },
    {
      "epoch": 0.4568158788818025,
      "grad_norm": 0.47722166776657104,
      "learning_rate": 5.936603134915517e-06,
      "loss": 0.2284,
      "step": 2874
    },
    {
      "epoch": 0.4569748266475929,
      "grad_norm": 0.3976351320743561,
      "learning_rate": 5.934074345889456e-06,
      "loss": 0.1129,
      "step": 2875
    },
    {
      "epoch": 0.4571337744133834,
      "grad_norm": 0.39060166478157043,
      "learning_rate": 5.9315453092713e-06,
      "loss": 0.1334,
      "step": 2876
    },
    {
      "epoch": 0.4572927221791739,
      "grad_norm": 0.4002891480922699,
      "learning_rate": 5.929016025731413e-06,
      "loss": 0.1221,
      "step": 2877
    },
    {
      "epoch": 0.45745166994496433,
      "grad_norm": 0.5930883884429932,
      "learning_rate": 5.926486495940225e-06,
      "loss": 0.2992,
      "step": 2878
    },
    {
      "epoch": 0.4576106177107548,
      "grad_norm": 0.6193838119506836,
      "learning_rate": 5.923956720568229e-06,
      "loss": 0.2165,
      "step": 2879
    },
    {
      "epoch": 0.4577695654765453,
      "grad_norm": 0.4870176911354065,
      "learning_rate": 5.921426700285986e-06,
      "loss": 0.226,
      "step": 2880
    },
    {
      "epoch": 0.45792851324233574,
      "grad_norm": 0.5294445157051086,
      "learning_rate": 5.918896435764119e-06,
      "loss": 0.2395,
      "step": 2881
    },
    {
      "epoch": 0.4580874610081262,
      "grad_norm": 0.47110265493392944,
      "learning_rate": 5.916365927673316e-06,
      "loss": 0.2653,
      "step": 2882
    },
    {
      "epoch": 0.45824640877391665,
      "grad_norm": 0.6312529444694519,
      "learning_rate": 5.913835176684335e-06,
      "loss": 0.3939,
      "step": 2883
    },
    {
      "epoch": 0.45840535653970715,
      "grad_norm": 0.46796712279319763,
      "learning_rate": 5.91130418346799e-06,
      "loss": 0.1682,
      "step": 2884
    },
    {
      "epoch": 0.4585643043054976,
      "grad_norm": 0.5247225165367126,
      "learning_rate": 5.908772948695164e-06,
      "loss": 0.2274,
      "step": 2885
    },
    {
      "epoch": 0.45872325207128806,
      "grad_norm": 0.5262272357940674,
      "learning_rate": 5.9062414730368056e-06,
      "loss": 0.2516,
      "step": 2886
    },
    {
      "epoch": 0.45888219983707856,
      "grad_norm": 0.5625988841056824,
      "learning_rate": 5.903709757163922e-06,
      "loss": 0.265,
      "step": 2887
    },
    {
      "epoch": 0.459041147602869,
      "grad_norm": 0.4502124786376953,
      "learning_rate": 5.901177801747588e-06,
      "loss": 0.2003,
      "step": 2888
    },
    {
      "epoch": 0.45920009536865947,
      "grad_norm": 0.5079917907714844,
      "learning_rate": 5.898645607458941e-06,
      "loss": 0.2035,
      "step": 2889
    },
    {
      "epoch": 0.4593590431344499,
      "grad_norm": 0.4927302300930023,
      "learning_rate": 5.896113174969183e-06,
      "loss": 0.2076,
      "step": 2890
    },
    {
      "epoch": 0.4595179909002404,
      "grad_norm": 0.5668486952781677,
      "learning_rate": 5.893580504949575e-06,
      "loss": 0.2737,
      "step": 2891
    },
    {
      "epoch": 0.4596769386660309,
      "grad_norm": 0.527651309967041,
      "learning_rate": 5.891047598071446e-06,
      "loss": 0.1609,
      "step": 2892
    },
    {
      "epoch": 0.45983588643182133,
      "grad_norm": 0.438400000333786,
      "learning_rate": 5.888514455006184e-06,
      "loss": 0.144,
      "step": 2893
    },
    {
      "epoch": 0.45999483419761183,
      "grad_norm": 0.5883435010910034,
      "learning_rate": 5.885981076425243e-06,
      "loss": 0.3775,
      "step": 2894
    },
    {
      "epoch": 0.4601537819634023,
      "grad_norm": 0.5186027884483337,
      "learning_rate": 5.883447463000136e-06,
      "loss": 0.1853,
      "step": 2895
    },
    {
      "epoch": 0.46031272972919274,
      "grad_norm": 0.5865258574485779,
      "learning_rate": 5.8809136154024404e-06,
      "loss": 0.3479,
      "step": 2896
    },
    {
      "epoch": 0.4604716774949832,
      "grad_norm": 0.40130335092544556,
      "learning_rate": 5.878379534303795e-06,
      "loss": 0.1633,
      "step": 2897
    },
    {
      "epoch": 0.4606306252607737,
      "grad_norm": 0.620006799697876,
      "learning_rate": 5.8758452203758995e-06,
      "loss": 0.2111,
      "step": 2898
    },
    {
      "epoch": 0.46078957302656415,
      "grad_norm": 0.6381662487983704,
      "learning_rate": 5.873310674290518e-06,
      "loss": 0.3895,
      "step": 2899
    },
    {
      "epoch": 0.4609485207923546,
      "grad_norm": 0.5782510042190552,
      "learning_rate": 5.870775896719474e-06,
      "loss": 0.2702,
      "step": 2900
    },
    {
      "epoch": 0.4611074685581451,
      "grad_norm": 0.5426830649375916,
      "learning_rate": 5.8682408883346535e-06,
      "loss": 0.2298,
      "step": 2901
    },
    {
      "epoch": 0.46126641632393556,
      "grad_norm": 0.8790964484214783,
      "learning_rate": 5.865705649808e-06,
      "loss": 0.2777,
      "step": 2902
    },
    {
      "epoch": 0.461425364089726,
      "grad_norm": 0.4724406898021698,
      "learning_rate": 5.863170181811525e-06,
      "loss": 0.1742,
      "step": 2903
    },
    {
      "epoch": 0.46158431185551646,
      "grad_norm": 0.5108499526977539,
      "learning_rate": 5.860634485017294e-06,
      "loss": 0.2129,
      "step": 2904
    },
    {
      "epoch": 0.46174325962130697,
      "grad_norm": 0.48258018493652344,
      "learning_rate": 5.858098560097438e-06,
      "loss": 0.1734,
      "step": 2905
    },
    {
      "epoch": 0.4619022073870974,
      "grad_norm": 0.4866634011268616,
      "learning_rate": 5.855562407724147e-06,
      "loss": 0.1597,
      "step": 2906
    },
    {
      "epoch": 0.46206115515288787,
      "grad_norm": 0.4821447432041168,
      "learning_rate": 5.8530260285696674e-06,
      "loss": 0.233,
      "step": 2907
    },
    {
      "epoch": 0.4622201029186783,
      "grad_norm": 0.49726712703704834,
      "learning_rate": 5.850489423306311e-06,
      "loss": 0.1852,
      "step": 2908
    },
    {
      "epoch": 0.46237905068446883,
      "grad_norm": 0.5549761056900024,
      "learning_rate": 5.84795259260645e-06,
      "loss": 0.2319,
      "step": 2909
    },
    {
      "epoch": 0.4625379984502593,
      "grad_norm": 0.5029101371765137,
      "learning_rate": 5.845415537142511e-06,
      "loss": 0.2465,
      "step": 2910
    },
    {
      "epoch": 0.46269694621604973,
      "grad_norm": 0.5275334715843201,
      "learning_rate": 5.842878257586983e-06,
      "loss": 0.2014,
      "step": 2911
    },
    {
      "epoch": 0.46285589398184024,
      "grad_norm": 0.6060965061187744,
      "learning_rate": 5.840340754612416e-06,
      "loss": 0.2653,
      "step": 2912
    },
    {
      "epoch": 0.4630148417476307,
      "grad_norm": 0.5484660863876343,
      "learning_rate": 5.837803028891418e-06,
      "loss": 0.2602,
      "step": 2913
    },
    {
      "epoch": 0.46317378951342114,
      "grad_norm": 0.46683692932128906,
      "learning_rate": 5.835265081096653e-06,
      "loss": 0.1152,
      "step": 2914
    },
    {
      "epoch": 0.4633327372792116,
      "grad_norm": 0.4839654266834259,
      "learning_rate": 5.832726911900851e-06,
      "loss": 0.2384,
      "step": 2915
    },
    {
      "epoch": 0.4634916850450021,
      "grad_norm": 1.1620473861694336,
      "learning_rate": 5.830188521976794e-06,
      "loss": 0.2375,
      "step": 2916
    },
    {
      "epoch": 0.46365063281079255,
      "grad_norm": 0.48603835701942444,
      "learning_rate": 5.827649911997323e-06,
      "loss": 0.1726,
      "step": 2917
    },
    {
      "epoch": 0.463809580576583,
      "grad_norm": 0.48922544717788696,
      "learning_rate": 5.825111082635344e-06,
      "loss": 0.1861,
      "step": 2918
    },
    {
      "epoch": 0.4639685283423735,
      "grad_norm": 0.5036674737930298,
      "learning_rate": 5.822572034563812e-06,
      "loss": 0.2421,
      "step": 2919
    },
    {
      "epoch": 0.46412747610816396,
      "grad_norm": 0.7454908490180969,
      "learning_rate": 5.820032768455748e-06,
      "loss": 0.4714,
      "step": 2920
    },
    {
      "epoch": 0.4642864238739544,
      "grad_norm": 0.48573723435401917,
      "learning_rate": 5.817493284984222e-06,
      "loss": 0.1436,
      "step": 2921
    },
    {
      "epoch": 0.46444537163974486,
      "grad_norm": 0.48223504424095154,
      "learning_rate": 5.814953584822373e-06,
      "loss": 0.237,
      "step": 2922
    },
    {
      "epoch": 0.46460431940553537,
      "grad_norm": 0.5216569304466248,
      "learning_rate": 5.812413668643387e-06,
      "loss": 0.2395,
      "step": 2923
    },
    {
      "epoch": 0.4647632671713258,
      "grad_norm": 0.4750829041004181,
      "learning_rate": 5.809873537120511e-06,
      "loss": 0.1988,
      "step": 2924
    },
    {
      "epoch": 0.4649222149371163,
      "grad_norm": 0.3992912769317627,
      "learning_rate": 5.807333190927054e-06,
      "loss": 0.1124,
      "step": 2925
    },
    {
      "epoch": 0.4650811627029068,
      "grad_norm": 0.46920061111450195,
      "learning_rate": 5.804792630736371e-06,
      "loss": 0.1601,
      "step": 2926
    },
    {
      "epoch": 0.46524011046869723,
      "grad_norm": 0.5628772377967834,
      "learning_rate": 5.802251857221886e-06,
      "loss": 0.2836,
      "step": 2927
    },
    {
      "epoch": 0.4653990582344877,
      "grad_norm": 0.4589751362800598,
      "learning_rate": 5.799710871057071e-06,
      "loss": 0.2011,
      "step": 2928
    },
    {
      "epoch": 0.46555800600027814,
      "grad_norm": 0.5798349976539612,
      "learning_rate": 5.797169672915457e-06,
      "loss": 0.2243,
      "step": 2929
    },
    {
      "epoch": 0.46571695376606864,
      "grad_norm": 0.4243532121181488,
      "learning_rate": 5.794628263470632e-06,
      "loss": 0.1582,
      "step": 2930
    },
    {
      "epoch": 0.4658759015318591,
      "grad_norm": 0.5267418622970581,
      "learning_rate": 5.792086643396238e-06,
      "loss": 0.2851,
      "step": 2931
    },
    {
      "epoch": 0.46603484929764954,
      "grad_norm": 0.5789023041725159,
      "learning_rate": 5.789544813365976e-06,
      "loss": 0.2916,
      "step": 2932
    },
    {
      "epoch": 0.46619379706344005,
      "grad_norm": 0.45863351225852966,
      "learning_rate": 5.7870027740536e-06,
      "loss": 0.1955,
      "step": 2933
    },
    {
      "epoch": 0.4663527448292305,
      "grad_norm": 0.5864610075950623,
      "learning_rate": 5.784460526132918e-06,
      "loss": 0.3352,
      "step": 2934
    },
    {
      "epoch": 0.46651169259502095,
      "grad_norm": 2.7842655181884766,
      "learning_rate": 5.7819180702778e-06,
      "loss": 0.339,
      "step": 2935
    },
    {
      "epoch": 0.4666706403608114,
      "grad_norm": 0.4915081858634949,
      "learning_rate": 5.779375407162162e-06,
      "loss": 0.2248,
      "step": 2936
    },
    {
      "epoch": 0.4668295881266019,
      "grad_norm": 0.5857938528060913,
      "learning_rate": 5.776832537459983e-06,
      "loss": 0.3113,
      "step": 2937
    },
    {
      "epoch": 0.46698853589239236,
      "grad_norm": 0.46817538142204285,
      "learning_rate": 5.774289461845292e-06,
      "loss": 0.1244,
      "step": 2938
    },
    {
      "epoch": 0.4671474836581828,
      "grad_norm": 0.5329924821853638,
      "learning_rate": 5.7717461809921724e-06,
      "loss": 0.2072,
      "step": 2939
    },
    {
      "epoch": 0.4673064314239733,
      "grad_norm": 0.5751669406890869,
      "learning_rate": 5.769202695574766e-06,
      "loss": 0.393,
      "step": 2940
    },
    {
      "epoch": 0.4674653791897638,
      "grad_norm": 0.5478829145431519,
      "learning_rate": 5.766659006267266e-06,
      "loss": 0.2293,
      "step": 2941
    },
    {
      "epoch": 0.4676243269555542,
      "grad_norm": 0.47439485788345337,
      "learning_rate": 5.764115113743919e-06,
      "loss": 0.1927,
      "step": 2942
    },
    {
      "epoch": 0.4677832747213447,
      "grad_norm": 0.6014965772628784,
      "learning_rate": 5.761571018679025e-06,
      "loss": 0.3724,
      "step": 2943
    },
    {
      "epoch": 0.4679422224871352,
      "grad_norm": 0.6170319318771362,
      "learning_rate": 5.759026721746943e-06,
      "loss": 0.135,
      "step": 2944
    },
    {
      "epoch": 0.46810117025292564,
      "grad_norm": 0.5405385494232178,
      "learning_rate": 5.75648222362208e-06,
      "loss": 0.2639,
      "step": 2945
    },
    {
      "epoch": 0.4682601180187161,
      "grad_norm": 0.6109224557876587,
      "learning_rate": 5.753937524978895e-06,
      "loss": 0.2767,
      "step": 2946
    },
    {
      "epoch": 0.4684190657845066,
      "grad_norm": 0.6372256278991699,
      "learning_rate": 5.751392626491907e-06,
      "loss": 0.3201,
      "step": 2947
    },
    {
      "epoch": 0.46857801355029705,
      "grad_norm": 0.4927164316177368,
      "learning_rate": 5.748847528835682e-06,
      "loss": 0.2075,
      "step": 2948
    },
    {
      "epoch": 0.4687369613160875,
      "grad_norm": 0.5805454850196838,
      "learning_rate": 5.746302232684843e-06,
      "loss": 0.2552,
      "step": 2949
    },
    {
      "epoch": 0.46889590908187795,
      "grad_norm": 0.45356932282447815,
      "learning_rate": 5.74375673871406e-06,
      "loss": 0.194,
      "step": 2950
    },
    {
      "epoch": 0.46905485684766846,
      "grad_norm": 0.4912305176258087,
      "learning_rate": 5.741211047598062e-06,
      "loss": 0.2314,
      "step": 2951
    },
    {
      "epoch": 0.4692138046134589,
      "grad_norm": 0.48927924036979675,
      "learning_rate": 5.738665160011627e-06,
      "loss": 0.1906,
      "step": 2952
    },
    {
      "epoch": 0.46937275237924936,
      "grad_norm": 0.5365142822265625,
      "learning_rate": 5.736119076629584e-06,
      "loss": 0.2556,
      "step": 2953
    },
    {
      "epoch": 0.4695317001450398,
      "grad_norm": 0.5130022764205933,
      "learning_rate": 5.733572798126814e-06,
      "loss": 0.2176,
      "step": 2954
    },
    {
      "epoch": 0.4696906479108303,
      "grad_norm": 0.5290591716766357,
      "learning_rate": 5.731026325178255e-06,
      "loss": 0.1725,
      "step": 2955
    },
    {
      "epoch": 0.46984959567662077,
      "grad_norm": 0.4984889328479767,
      "learning_rate": 5.7284796584588886e-06,
      "loss": 0.1881,
      "step": 2956
    },
    {
      "epoch": 0.4700085434424112,
      "grad_norm": 0.5259923338890076,
      "learning_rate": 5.725932798643752e-06,
      "loss": 0.2395,
      "step": 2957
    },
    {
      "epoch": 0.4701674912082017,
      "grad_norm": 0.4680986702442169,
      "learning_rate": 5.723385746407937e-06,
      "loss": 0.1621,
      "step": 2958
    },
    {
      "epoch": 0.4703264389739922,
      "grad_norm": 0.6064900159835815,
      "learning_rate": 5.7208385024265764e-06,
      "loss": 0.3484,
      "step": 2959
    },
    {
      "epoch": 0.47048538673978263,
      "grad_norm": 0.5919032692909241,
      "learning_rate": 5.7182910673748644e-06,
      "loss": 0.3682,
      "step": 2960
    },
    {
      "epoch": 0.4706443345055731,
      "grad_norm": 0.5340969562530518,
      "learning_rate": 5.715743441928041e-06,
      "loss": 0.2338,
      "step": 2961
    },
    {
      "epoch": 0.4708032822713636,
      "grad_norm": 0.430245965719223,
      "learning_rate": 5.713195626761396e-06,
      "loss": 0.1378,
      "step": 2962
    },
    {
      "epoch": 0.47096223003715404,
      "grad_norm": 0.5375344753265381,
      "learning_rate": 5.710647622550271e-06,
      "loss": 0.2144,
      "step": 2963
    },
    {
      "epoch": 0.4711211778029445,
      "grad_norm": 0.5629363059997559,
      "learning_rate": 5.708099429970057e-06,
      "loss": 0.1935,
      "step": 2964
    },
    {
      "epoch": 0.471280125568735,
      "grad_norm": 0.43097159266471863,
      "learning_rate": 5.7055510496961965e-06,
      "loss": 0.1744,
      "step": 2965
    },
    {
      "epoch": 0.47143907333452545,
      "grad_norm": 0.5297952890396118,
      "learning_rate": 5.7030024824041785e-06,
      "loss": 0.2567,
      "step": 2966
    },
    {
      "epoch": 0.4715980211003159,
      "grad_norm": 0.5617138743400574,
      "learning_rate": 5.700453728769545e-06,
      "loss": 0.2419,
      "step": 2967
    },
    {
      "epoch": 0.47175696886610635,
      "grad_norm": 0.5684598684310913,
      "learning_rate": 5.697904789467886e-06,
      "loss": 0.3395,
      "step": 2968
    },
    {
      "epoch": 0.47191591663189686,
      "grad_norm": 0.4427378475666046,
      "learning_rate": 5.69535566517484e-06,
      "loss": 0.1612,
      "step": 2969
    },
    {
      "epoch": 0.4720748643976873,
      "grad_norm": 0.5823339223861694,
      "learning_rate": 5.6928063565660955e-06,
      "loss": 0.2693,
      "step": 2970
    },
    {
      "epoch": 0.47223381216347776,
      "grad_norm": 0.5393579602241516,
      "learning_rate": 5.69025686431739e-06,
      "loss": 0.2684,
      "step": 2971
    },
    {
      "epoch": 0.47239275992926827,
      "grad_norm": 0.5388513803482056,
      "learning_rate": 5.687707189104509e-06,
      "loss": 0.2252,
      "step": 2972
    },
    {
      "epoch": 0.4725517076950587,
      "grad_norm": 0.5367342233657837,
      "learning_rate": 5.6851573316032845e-06,
      "loss": 0.316,
      "step": 2973
    },
    {
      "epoch": 0.47271065546084917,
      "grad_norm": 0.5760819911956787,
      "learning_rate": 5.682607292489602e-06,
      "loss": 0.2204,
      "step": 2974
    },
    {
      "epoch": 0.4728696032266396,
      "grad_norm": 0.4343629479408264,
      "learning_rate": 5.6800570724393934e-06,
      "loss": 0.1257,
      "step": 2975
    },
    {
      "epoch": 0.47302855099243013,
      "grad_norm": 0.5268128514289856,
      "learning_rate": 5.677506672128633e-06,
      "loss": 0.2388,
      "step": 2976
    },
    {
      "epoch": 0.4731874987582206,
      "grad_norm": 0.5388391613960266,
      "learning_rate": 5.67495609223335e-06,
      "loss": 0.2548,
      "step": 2977
    },
    {
      "epoch": 0.47334644652401103,
      "grad_norm": 0.48654818534851074,
      "learning_rate": 5.672405333429619e-06,
      "loss": 0.1471,
      "step": 2978
    },
    {
      "epoch": 0.47350539428980154,
      "grad_norm": 0.5693203806877136,
      "learning_rate": 5.669854396393559e-06,
      "loss": 0.3019,
      "step": 2979
    },
    {
      "epoch": 0.473664342055592,
      "grad_norm": 0.5049850940704346,
      "learning_rate": 5.667303281801341e-06,
      "loss": 0.1986,
      "step": 2980
    },
    {
      "epoch": 0.47382328982138244,
      "grad_norm": 0.6282364726066589,
      "learning_rate": 5.664751990329179e-06,
      "loss": 0.3009,
      "step": 2981
    },
    {
      "epoch": 0.4739822375871729,
      "grad_norm": 0.5463889837265015,
      "learning_rate": 5.662200522653338e-06,
      "loss": 0.2818,
      "step": 2982
    },
    {
      "epoch": 0.4741411853529634,
      "grad_norm": 0.593360424041748,
      "learning_rate": 5.659648879450125e-06,
      "loss": 0.3514,
      "step": 2983
    },
    {
      "epoch": 0.47430013311875385,
      "grad_norm": 0.7165932059288025,
      "learning_rate": 5.657097061395896e-06,
      "loss": 0.2858,
      "step": 2984
    },
    {
      "epoch": 0.4744590808845443,
      "grad_norm": 0.7433684468269348,
      "learning_rate": 5.654545069167056e-06,
      "loss": 0.1493,
      "step": 2985
    },
    {
      "epoch": 0.4746180286503348,
      "grad_norm": 0.5185105204582214,
      "learning_rate": 5.651992903440049e-06,
      "loss": 0.1571,
      "step": 2986
    },
    {
      "epoch": 0.47477697641612526,
      "grad_norm": 0.550203800201416,
      "learning_rate": 5.649440564891373e-06,
      "loss": 0.263,
      "step": 2987
    },
    {
      "epoch": 0.4749359241819157,
      "grad_norm": 0.5435806512832642,
      "learning_rate": 5.646888054197568e-06,
      "loss": 0.2192,
      "step": 2988
    },
    {
      "epoch": 0.47509487194770617,
      "grad_norm": 0.4127674698829651,
      "learning_rate": 5.644335372035218e-06,
      "loss": 0.1715,
      "step": 2989
    },
    {
      "epoch": 0.4752538197134967,
      "grad_norm": 0.4315192997455597,
      "learning_rate": 5.641782519080955e-06,
      "loss": 0.1674,
      "step": 2990
    },
    {
      "epoch": 0.4754127674792871,
      "grad_norm": 0.6127698421478271,
      "learning_rate": 5.639229496011456e-06,
      "loss": 0.2948,
      "step": 2991
    },
    {
      "epoch": 0.4755717152450776,
      "grad_norm": 0.5926769971847534,
      "learning_rate": 5.636676303503442e-06,
      "loss": 0.3328,
      "step": 2992
    },
    {
      "epoch": 0.475730663010868,
      "grad_norm": 0.48032212257385254,
      "learning_rate": 5.634122942233678e-06,
      "loss": 0.1905,
      "step": 2993
    },
    {
      "epoch": 0.47588961077665853,
      "grad_norm": 0.48892274498939514,
      "learning_rate": 5.631569412878981e-06,
      "loss": 0.1894,
      "step": 2994
    },
    {
      "epoch": 0.476048558542449,
      "grad_norm": 0.5711713433265686,
      "learning_rate": 5.6290157161162016e-06,
      "loss": 0.335,
      "step": 2995
    },
    {
      "epoch": 0.47620750630823944,
      "grad_norm": 0.5229471921920776,
      "learning_rate": 5.62646185262224e-06,
      "loss": 0.1696,
      "step": 2996
    },
    {
      "epoch": 0.47636645407402994,
      "grad_norm": 0.5676445960998535,
      "learning_rate": 5.623907823074044e-06,
      "loss": 0.2752,
      "step": 2997
    },
    {
      "epoch": 0.4765254018398204,
      "grad_norm": 0.7129921317100525,
      "learning_rate": 5.621353628148599e-06,
      "loss": 0.3172,
      "step": 2998
    },
    {
      "epoch": 0.47668434960561085,
      "grad_norm": 0.47001728415489197,
      "learning_rate": 5.6187992685229384e-06,
      "loss": 0.1967,
      "step": 2999
    },
    {
      "epoch": 0.4768432973714013,
      "grad_norm": 0.4682162404060364,
      "learning_rate": 5.61624474487414e-06,
      "loss": 0.1682,
      "step": 3000
    },
    {
      "epoch": 0.4770022451371918,
      "grad_norm": 0.46975353360176086,
      "learning_rate": 5.613690057879318e-06,
      "loss": 0.132,
      "step": 3001
    },
    {
      "epoch": 0.47716119290298226,
      "grad_norm": 0.5042482614517212,
      "learning_rate": 5.611135208215641e-06,
      "loss": 0.1954,
      "step": 3002
    },
    {
      "epoch": 0.4773201406687727,
      "grad_norm": 0.6160921454429626,
      "learning_rate": 5.60858019656031e-06,
      "loss": 0.3152,
      "step": 3003
    },
    {
      "epoch": 0.4774790884345632,
      "grad_norm": 0.5012695789337158,
      "learning_rate": 5.6060250235905785e-06,
      "loss": 0.1959,
      "step": 3004
    },
    {
      "epoch": 0.47763803620035367,
      "grad_norm": 0.5321857333183289,
      "learning_rate": 5.603469689983735e-06,
      "loss": 0.19,
      "step": 3005
    },
    {
      "epoch": 0.4777969839661441,
      "grad_norm": 0.6653243899345398,
      "learning_rate": 5.600914196417112e-06,
      "loss": 0.3586,
      "step": 3006
    },
    {
      "epoch": 0.47795593173193457,
      "grad_norm": 0.5781517624855042,
      "learning_rate": 5.5983585435680894e-06,
      "loss": 0.3244,
      "step": 3007
    },
    {
      "epoch": 0.4781148794977251,
      "grad_norm": 0.5672399997711182,
      "learning_rate": 5.595802732114085e-06,
      "loss": 0.2402,
      "step": 3008
    },
    {
      "epoch": 0.4782738272635155,
      "grad_norm": 0.637460470199585,
      "learning_rate": 5.593246762732558e-06,
      "loss": 0.1631,
      "step": 3009
    },
    {
      "epoch": 0.478432775029306,
      "grad_norm": 0.48868873715400696,
      "learning_rate": 5.590690636101014e-06,
      "loss": 0.208,
      "step": 3010
    },
    {
      "epoch": 0.4785917227950965,
      "grad_norm": 0.5526959896087646,
      "learning_rate": 5.588134352896994e-06,
      "loss": 0.3138,
      "step": 3011
    },
    {
      "epoch": 0.47875067056088694,
      "grad_norm": 0.5309169888496399,
      "learning_rate": 5.585577913798085e-06,
      "loss": 0.243,
      "step": 3012
    },
    {
      "epoch": 0.4789096183266774,
      "grad_norm": 0.46183153986930847,
      "learning_rate": 5.583021319481915e-06,
      "loss": 0.1872,
      "step": 3013
    },
    {
      "epoch": 0.47906856609246784,
      "grad_norm": 0.5236578583717346,
      "learning_rate": 5.5804645706261515e-06,
      "loss": 0.157,
      "step": 3014
    },
    {
      "epoch": 0.47922751385825835,
      "grad_norm": 0.3689005374908447,
      "learning_rate": 5.577907667908505e-06,
      "loss": 0.1036,
      "step": 3015
    },
    {
      "epoch": 0.4793864616240488,
      "grad_norm": 0.45971769094467163,
      "learning_rate": 5.575350612006722e-06,
      "loss": 0.1863,
      "step": 3016
    },
    {
      "epoch": 0.47954540938983925,
      "grad_norm": 0.5338745713233948,
      "learning_rate": 5.5727934035985975e-06,
      "loss": 0.2406,
      "step": 3017
    },
    {
      "epoch": 0.47970435715562976,
      "grad_norm": 0.40931323170661926,
      "learning_rate": 5.570236043361959e-06,
      "loss": 0.0842,
      "step": 3018
    },
    {
      "epoch": 0.4798633049214202,
      "grad_norm": 0.461763471364975,
      "learning_rate": 5.567678531974681e-06,
      "loss": 0.1532,
      "step": 3019
    },
    {
      "epoch": 0.48002225268721066,
      "grad_norm": 0.48536524176597595,
      "learning_rate": 5.565120870114672e-06,
      "loss": 0.1562,
      "step": 3020
    },
    {
      "epoch": 0.4801812004530011,
      "grad_norm": 0.5399110913276672,
      "learning_rate": 5.562563058459884e-06,
      "loss": 0.2527,
      "step": 3021
    },
    {
      "epoch": 0.4803401482187916,
      "grad_norm": 0.5053855776786804,
      "learning_rate": 5.5600050976883094e-06,
      "loss": 0.1782,
      "step": 3022
    },
    {
      "epoch": 0.48049909598458207,
      "grad_norm": 0.5583042502403259,
      "learning_rate": 5.557446988477977e-06,
      "loss": 0.2715,
      "step": 3023
    },
    {
      "epoch": 0.4806580437503725,
      "grad_norm": 0.49484142661094666,
      "learning_rate": 5.5548887315069575e-06,
      "loss": 0.1169,
      "step": 3024
    },
    {
      "epoch": 0.48081699151616303,
      "grad_norm": 0.5315203070640564,
      "learning_rate": 5.552330327453359e-06,
      "loss": 0.2479,
      "step": 3025
    },
    {
      "epoch": 0.4809759392819535,
      "grad_norm": 0.49615180492401123,
      "learning_rate": 5.5497717769953305e-06,
      "loss": 0.2131,
      "step": 3026
    },
    {
      "epoch": 0.48113488704774393,
      "grad_norm": 0.5203122496604919,
      "learning_rate": 5.5472130808110595e-06,
      "loss": 0.2786,
      "step": 3027
    },
    {
      "epoch": 0.4812938348135344,
      "grad_norm": 0.46904951333999634,
      "learning_rate": 5.5446542395787685e-06,
      "loss": 0.1843,
      "step": 3028
    },
    {
      "epoch": 0.4814527825793249,
      "grad_norm": 0.6681566834449768,
      "learning_rate": 5.542095253976723e-06,
      "loss": 0.4341,
      "step": 3029
    },
    {
      "epoch": 0.48161173034511534,
      "grad_norm": 0.6589584946632385,
      "learning_rate": 5.539536124683227e-06,
      "loss": 0.2589,
      "step": 3030
    },
    {
      "epoch": 0.4817706781109058,
      "grad_norm": 0.49704709649086,
      "learning_rate": 5.536976852376618e-06,
      "loss": 0.2193,
      "step": 3031
    },
    {
      "epoch": 0.48192962587669624,
      "grad_norm": 0.4072805345058441,
      "learning_rate": 5.534417437735273e-06,
      "loss": 0.1048,
      "step": 3032
    },
    {
      "epoch": 0.48208857364248675,
      "grad_norm": 0.7538061738014221,
      "learning_rate": 5.531857881437612e-06,
      "loss": 0.1658,
      "step": 3033
    },
    {
      "epoch": 0.4822475214082772,
      "grad_norm": 0.5389820337295532,
      "learning_rate": 5.529298184162087e-06,
      "loss": 0.1619,
      "step": 3034
    },
    {
      "epoch": 0.48240646917406765,
      "grad_norm": 0.5013943314552307,
      "learning_rate": 5.526738346587186e-06,
      "loss": 0.2398,
      "step": 3035
    },
    {
      "epoch": 0.48256541693985816,
      "grad_norm": 0.5955174565315247,
      "learning_rate": 5.5241783693914395e-06,
      "loss": 0.2438,
      "step": 3036
    },
    {
      "epoch": 0.4827243647056486,
      "grad_norm": 0.6181487441062927,
      "learning_rate": 5.5216182532534134e-06,
      "loss": 0.2794,
      "step": 3037
    },
    {
      "epoch": 0.48288331247143906,
      "grad_norm": 0.5209720134735107,
      "learning_rate": 5.519057998851707e-06,
      "loss": 0.2283,
      "step": 3038
    },
    {
      "epoch": 0.4830422602372295,
      "grad_norm": 0.5071380734443665,
      "learning_rate": 5.516497606864959e-06,
      "loss": 0.1546,
      "step": 3039
    },
    {
      "epoch": 0.48320120800302,
      "grad_norm": 0.5538445711135864,
      "learning_rate": 5.513937077971846e-06,
      "loss": 0.1797,
      "step": 3040
    },
    {
      "epoch": 0.4833601557688105,
      "grad_norm": 0.6633328199386597,
      "learning_rate": 5.511376412851077e-06,
      "loss": 0.442,
      "step": 3041
    },
    {
      "epoch": 0.4835191035346009,
      "grad_norm": 0.5058202147483826,
      "learning_rate": 5.508815612181401e-06,
      "loss": 0.1774,
      "step": 3042
    },
    {
      "epoch": 0.48367805130039143,
      "grad_norm": 0.5724246501922607,
      "learning_rate": 5.506254676641602e-06,
      "loss": 0.2295,
      "step": 3043
    },
    {
      "epoch": 0.4838369990661819,
      "grad_norm": 0.5374630093574524,
      "learning_rate": 5.503693606910496e-06,
      "loss": 0.2649,
      "step": 3044
    },
    {
      "epoch": 0.48399594683197233,
      "grad_norm": 0.4940115213394165,
      "learning_rate": 5.50113240366694e-06,
      "loss": 0.1712,
      "step": 3045
    },
    {
      "epoch": 0.4841548945977628,
      "grad_norm": 0.5364307165145874,
      "learning_rate": 5.498571067589823e-06,
      "loss": 0.247,
      "step": 3046
    },
    {
      "epoch": 0.4843138423635533,
      "grad_norm": 0.5613694190979004,
      "learning_rate": 5.496009599358072e-06,
      "loss": 0.2081,
      "step": 3047
    },
    {
      "epoch": 0.48447279012934374,
      "grad_norm": 0.4966718852519989,
      "learning_rate": 5.493447999650643e-06,
      "loss": 0.2596,
      "step": 3048
    },
    {
      "epoch": 0.4846317378951342,
      "grad_norm": 0.4406951367855072,
      "learning_rate": 5.4908862691465345e-06,
      "loss": 0.1221,
      "step": 3049
    },
    {
      "epoch": 0.4847906856609247,
      "grad_norm": 0.5156393647193909,
      "learning_rate": 5.488324408524777e-06,
      "loss": 0.229,
      "step": 3050
    },
    {
      "epoch": 0.48494963342671515,
      "grad_norm": 0.6053683757781982,
      "learning_rate": 5.48576241846443e-06,
      "loss": 0.3109,
      "step": 3051
    },
    {
      "epoch": 0.4851085811925056,
      "grad_norm": 0.4940124750137329,
      "learning_rate": 5.483200299644597e-06,
      "loss": 0.2118,
      "step": 3052
    },
    {
      "epoch": 0.48526752895829606,
      "grad_norm": 0.45085859298706055,
      "learning_rate": 5.480638052744407e-06,
      "loss": 0.1967,
      "step": 3053
    },
    {
      "epoch": 0.48542647672408656,
      "grad_norm": 0.5391030311584473,
      "learning_rate": 5.478075678443029e-06,
      "loss": 0.2877,
      "step": 3054
    },
    {
      "epoch": 0.485585424489877,
      "grad_norm": 0.4526226818561554,
      "learning_rate": 5.475513177419663e-06,
      "loss": 0.1421,
      "step": 3055
    },
    {
      "epoch": 0.48574437225566747,
      "grad_norm": 0.4779004156589508,
      "learning_rate": 5.472950550353541e-06,
      "loss": 0.1799,
      "step": 3056
    },
    {
      "epoch": 0.485903320021458,
      "grad_norm": 0.515476405620575,
      "learning_rate": 5.470387797923934e-06,
      "loss": 0.2186,
      "step": 3057
    },
    {
      "epoch": 0.4860622677872484,
      "grad_norm": 0.6047559976577759,
      "learning_rate": 5.467824920810139e-06,
      "loss": 0.2412,
      "step": 3058
    },
    {
      "epoch": 0.4862212155530389,
      "grad_norm": 0.4405944347381592,
      "learning_rate": 5.46526191969149e-06,
      "loss": 0.1397,
      "step": 3059
    },
    {
      "epoch": 0.48638016331882933,
      "grad_norm": 0.5767087936401367,
      "learning_rate": 5.462698795247357e-06,
      "loss": 0.3179,
      "step": 3060
    },
    {
      "epoch": 0.48653911108461984,
      "grad_norm": 0.5052759051322937,
      "learning_rate": 5.460135548157134e-06,
      "loss": 0.1977,
      "step": 3061
    },
    {
      "epoch": 0.4866980588504103,
      "grad_norm": 0.5685902833938599,
      "learning_rate": 5.4575721791002566e-06,
      "loss": 0.2459,
      "step": 3062
    },
    {
      "epoch": 0.48685700661620074,
      "grad_norm": 0.536274790763855,
      "learning_rate": 5.4550086887561874e-06,
      "loss": 0.1943,
      "step": 3063
    },
    {
      "epoch": 0.48701595438199125,
      "grad_norm": 0.6575786471366882,
      "learning_rate": 5.4524450778044226e-06,
      "loss": 0.3066,
      "step": 3064
    },
    {
      "epoch": 0.4871749021477817,
      "grad_norm": 0.4958297312259674,
      "learning_rate": 5.449881346924489e-06,
      "loss": 0.2182,
      "step": 3065
    },
    {
      "epoch": 0.48733384991357215,
      "grad_norm": 0.5291483998298645,
      "learning_rate": 5.44731749679595e-06,
      "loss": 0.265,
      "step": 3066
    },
    {
      "epoch": 0.4874927976793626,
      "grad_norm": 0.6832557916641235,
      "learning_rate": 5.444753528098396e-06,
      "loss": 0.2124,
      "step": 3067
    },
    {
      "epoch": 0.4876517454451531,
      "grad_norm": 0.7413736581802368,
      "learning_rate": 5.442189441511447e-06,
      "loss": 0.2751,
      "step": 3068
    },
    {
      "epoch": 0.48781069321094356,
      "grad_norm": 0.703065037727356,
      "learning_rate": 5.4396252377147615e-06,
      "loss": 0.3211,
      "step": 3069
    },
    {
      "epoch": 0.487969640976734,
      "grad_norm": 0.4703281819820404,
      "learning_rate": 5.43706091738802e-06,
      "loss": 0.2083,
      "step": 3070
    },
    {
      "epoch": 0.48812858874252446,
      "grad_norm": 0.48652252554893494,
      "learning_rate": 5.434496481210945e-06,
      "loss": 0.2142,
      "step": 3071
    },
    {
      "epoch": 0.48828753650831497,
      "grad_norm": 0.593956470489502,
      "learning_rate": 5.431931929863277e-06,
      "loss": 0.2274,
      "step": 3072
    },
    {
      "epoch": 0.4884464842741054,
      "grad_norm": 0.5324203968048096,
      "learning_rate": 5.429367264024796e-06,
      "loss": 0.1963,
      "step": 3073
    },
    {
      "epoch": 0.48860543203989587,
      "grad_norm": 0.5027768611907959,
      "learning_rate": 5.426802484375312e-06,
      "loss": 0.2033,
      "step": 3074
    },
    {
      "epoch": 0.4887643798056864,
      "grad_norm": 0.6335700154304504,
      "learning_rate": 5.424237591594658e-06,
      "loss": 0.3531,
      "step": 3075
    },
    {
      "epoch": 0.48892332757147683,
      "grad_norm": 0.5025938749313354,
      "learning_rate": 5.421672586362706e-06,
      "loss": 0.2266,
      "step": 3076
    },
    {
      "epoch": 0.4890822753372673,
      "grad_norm": 0.4419834315776825,
      "learning_rate": 5.419107469359352e-06,
      "loss": 0.1481,
      "step": 3077
    },
    {
      "epoch": 0.48924122310305773,
      "grad_norm": 0.500084638595581,
      "learning_rate": 5.416542241264524e-06,
      "loss": 0.206,
      "step": 3078
    },
    {
      "epoch": 0.48940017086884824,
      "grad_norm": 0.6026813983917236,
      "learning_rate": 5.413976902758179e-06,
      "loss": 0.2928,
      "step": 3079
    },
    {
      "epoch": 0.4895591186346387,
      "grad_norm": 0.4788355231285095,
      "learning_rate": 5.4114114545203025e-06,
      "loss": 0.1862,
      "step": 3080
    },
    {
      "epoch": 0.48971806640042914,
      "grad_norm": 0.5567786693572998,
      "learning_rate": 5.4088458972309085e-06,
      "loss": 0.3232,
      "step": 3081
    },
    {
      "epoch": 0.48987701416621965,
      "grad_norm": 0.6371530294418335,
      "learning_rate": 5.406280231570045e-06,
      "loss": 0.2333,
      "step": 3082
    },
    {
      "epoch": 0.4900359619320101,
      "grad_norm": 0.5212776064872742,
      "learning_rate": 5.403714458217779e-06,
      "loss": 0.2243,
      "step": 3083
    },
    {
      "epoch": 0.49019490969780055,
      "grad_norm": 0.4877068102359772,
      "learning_rate": 5.4011485778542185e-06,
      "loss": 0.1628,
      "step": 3084
    },
    {
      "epoch": 0.490353857463591,
      "grad_norm": 0.520886242389679,
      "learning_rate": 5.398582591159486e-06,
      "loss": 0.2286,
      "step": 3085
    },
    {
      "epoch": 0.4905128052293815,
      "grad_norm": 0.5182390213012695,
      "learning_rate": 5.3960164988137446e-06,
      "loss": 0.2695,
      "step": 3086
    },
    {
      "epoch": 0.49067175299517196,
      "grad_norm": 0.9680128693580627,
      "learning_rate": 5.39345030149718e-06,
      "loss": 0.2737,
      "step": 3087
    },
    {
      "epoch": 0.4908307007609624,
      "grad_norm": 0.4388999938964844,
      "learning_rate": 5.390883999890001e-06,
      "loss": 0.1226,
      "step": 3088
    },
    {
      "epoch": 0.4909896485267529,
      "grad_norm": 0.45521870255470276,
      "learning_rate": 5.388317594672454e-06,
      "loss": 0.1585,
      "step": 3089
    },
    {
      "epoch": 0.49114859629254337,
      "grad_norm": 0.4731297194957733,
      "learning_rate": 5.385751086524806e-06,
      "loss": 0.1814,
      "step": 3090
    },
    {
      "epoch": 0.4913075440583338,
      "grad_norm": 0.5083327889442444,
      "learning_rate": 5.383184476127354e-06,
      "loss": 0.2444,
      "step": 3091
    },
    {
      "epoch": 0.4914664918241243,
      "grad_norm": 0.4857613146305084,
      "learning_rate": 5.380617764160421e-06,
      "loss": 0.2141,
      "step": 3092
    },
    {
      "epoch": 0.4916254395899148,
      "grad_norm": 0.44756531715393066,
      "learning_rate": 5.378050951304356e-06,
      "loss": 0.1746,
      "step": 3093
    },
    {
      "epoch": 0.49178438735570523,
      "grad_norm": 0.6346749067306519,
      "learning_rate": 5.375484038239535e-06,
      "loss": 0.443,
      "step": 3094
    },
    {
      "epoch": 0.4919433351214957,
      "grad_norm": 0.4622464179992676,
      "learning_rate": 5.372917025646365e-06,
      "loss": 0.1956,
      "step": 3095
    },
    {
      "epoch": 0.4921022828872862,
      "grad_norm": 0.5397132635116577,
      "learning_rate": 5.370349914205273e-06,
      "loss": 0.2744,
      "step": 3096
    },
    {
      "epoch": 0.49226123065307664,
      "grad_norm": 0.4985322654247284,
      "learning_rate": 5.3677827045967165e-06,
      "loss": 0.1939,
      "step": 3097
    },
    {
      "epoch": 0.4924201784188671,
      "grad_norm": 0.9180315732955933,
      "learning_rate": 5.365215397501175e-06,
      "loss": 0.2578,
      "step": 3098
    },
    {
      "epoch": 0.49257912618465755,
      "grad_norm": 0.44447800517082214,
      "learning_rate": 5.362647993599159e-06,
      "loss": 0.196,
      "step": 3099
    },
    {
      "epoch": 0.49273807395044805,
      "grad_norm": 0.5387018322944641,
      "learning_rate": 5.360080493571202e-06,
      "loss": 0.2589,
      "step": 3100
    },
    {
      "epoch": 0.4928970217162385,
      "grad_norm": 0.49854329228401184,
      "learning_rate": 5.357512898097859e-06,
      "loss": 0.2118,
      "step": 3101
    },
    {
      "epoch": 0.49305596948202896,
      "grad_norm": 0.4386105537414551,
      "learning_rate": 5.354945207859721e-06,
      "loss": 0.1445,
      "step": 3102
    },
    {
      "epoch": 0.49321491724781946,
      "grad_norm": 0.48879626393318176,
      "learning_rate": 5.352377423537393e-06,
      "loss": 0.1635,
      "step": 3103
    },
    {
      "epoch": 0.4933738650136099,
      "grad_norm": 0.5393232703208923,
      "learning_rate": 5.349809545811509e-06,
      "loss": 0.2206,
      "step": 3104
    },
    {
      "epoch": 0.49353281277940036,
      "grad_norm": 0.6026070713996887,
      "learning_rate": 5.347241575362729e-06,
      "loss": 0.32,
      "step": 3105
    },
    {
      "epoch": 0.4936917605451908,
      "grad_norm": 0.5595979690551758,
      "learning_rate": 5.3446735128717395e-06,
      "loss": 0.291,
      "step": 3106
    },
    {
      "epoch": 0.4938507083109813,
      "grad_norm": 0.49704352021217346,
      "learning_rate": 5.342105359019244e-06,
      "loss": 0.2024,
      "step": 3107
    },
    {
      "epoch": 0.4940096560767718,
      "grad_norm": 0.6576840877532959,
      "learning_rate": 5.3395371144859776e-06,
      "loss": 0.2363,
      "step": 3108
    },
    {
      "epoch": 0.4941686038425622,
      "grad_norm": 0.7910193204879761,
      "learning_rate": 5.336968779952697e-06,
      "loss": 0.1765,
      "step": 3109
    },
    {
      "epoch": 0.4943275516083527,
      "grad_norm": 0.5244587659835815,
      "learning_rate": 5.33440035610018e-06,
      "loss": 0.2024,
      "step": 3110
    },
    {
      "epoch": 0.4944864993741432,
      "grad_norm": 0.5428402423858643,
      "learning_rate": 5.3318318436092335e-06,
      "loss": 0.2762,
      "step": 3111
    },
    {
      "epoch": 0.49464544713993364,
      "grad_norm": 0.3710137605667114,
      "learning_rate": 5.329263243160682e-06,
      "loss": 0.1263,
      "step": 3112
    },
    {
      "epoch": 0.4948043949057241,
      "grad_norm": 0.5447723865509033,
      "learning_rate": 5.3266945554353775e-06,
      "loss": 0.1836,
      "step": 3113
    },
    {
      "epoch": 0.4949633426715146,
      "grad_norm": 0.6237229108810425,
      "learning_rate": 5.324125781114193e-06,
      "loss": 0.3616,
      "step": 3114
    },
    {
      "epoch": 0.49512229043730505,
      "grad_norm": 0.5572422742843628,
      "learning_rate": 5.321556920878027e-06,
      "loss": 0.304,
      "step": 3115
    },
    {
      "epoch": 0.4952812382030955,
      "grad_norm": 0.5295687913894653,
      "learning_rate": 5.3189879754078e-06,
      "loss": 0.2909,
      "step": 3116
    },
    {
      "epoch": 0.49544018596888595,
      "grad_norm": 0.8230293989181519,
      "learning_rate": 5.31641894538445e-06,
      "loss": 0.2209,
      "step": 3117
    },
    {
      "epoch": 0.49559913373467646,
      "grad_norm": 0.5097494125366211,
      "learning_rate": 5.3138498314889446e-06,
      "loss": 0.2875,
      "step": 3118
    },
    {
      "epoch": 0.4957580815004669,
      "grad_norm": 0.6143906116485596,
      "learning_rate": 5.31128063440227e-06,
      "loss": 0.3258,
      "step": 3119
    },
    {
      "epoch": 0.49591702926625736,
      "grad_norm": 0.5615729689598083,
      "learning_rate": 5.3087113548054335e-06,
      "loss": 0.2505,
      "step": 3120
    },
    {
      "epoch": 0.49607597703204787,
      "grad_norm": 0.5325687527656555,
      "learning_rate": 5.3061419933794675e-06,
      "loss": 0.258,
      "step": 3121
    },
    {
      "epoch": 0.4962349247978383,
      "grad_norm": 0.5806746482849121,
      "learning_rate": 5.303572550805426e-06,
      "loss": 0.2732,
      "step": 3122
    },
    {
      "epoch": 0.49639387256362877,
      "grad_norm": 0.49830466508865356,
      "learning_rate": 5.30100302776438e-06,
      "loss": 0.2192,
      "step": 3123
    },
    {
      "epoch": 0.4965528203294192,
      "grad_norm": 0.5354008674621582,
      "learning_rate": 5.298433424937425e-06,
      "loss": 0.2604,
      "step": 3124
    },
    {
      "epoch": 0.4967117680952097,
      "grad_norm": 0.42647072672843933,
      "learning_rate": 5.295863743005678e-06,
      "loss": 0.1639,
      "step": 3125
    },
    {
      "epoch": 0.4968707158610002,
      "grad_norm": 0.5395255088806152,
      "learning_rate": 5.2932939826502775e-06,
      "loss": 0.2938,
      "step": 3126
    },
    {
      "epoch": 0.49702966362679063,
      "grad_norm": 0.6159132719039917,
      "learning_rate": 5.290724144552379e-06,
      "loss": 0.3343,
      "step": 3127
    },
    {
      "epoch": 0.49718861139258114,
      "grad_norm": 0.5250702500343323,
      "learning_rate": 5.288154229393164e-06,
      "loss": 0.228,
      "step": 3128
    },
    {
      "epoch": 0.4973475591583716,
      "grad_norm": 0.7955978512763977,
      "learning_rate": 5.285584237853832e-06,
      "loss": 0.2935,
      "step": 3129
    },
    {
      "epoch": 0.49750650692416204,
      "grad_norm": 0.5434345006942749,
      "learning_rate": 5.283014170615599e-06,
      "loss": 0.2449,
      "step": 3130
    },
    {
      "epoch": 0.4976654546899525,
      "grad_norm": 0.5614580512046814,
      "learning_rate": 5.280444028359707e-06,
      "loss": 0.2393,
      "step": 3131
    },
    {
      "epoch": 0.497824402455743,
      "grad_norm": 0.6450530886650085,
      "learning_rate": 5.277873811767415e-06,
      "loss": 0.378,
      "step": 3132
    },
    {
      "epoch": 0.49798335022153345,
      "grad_norm": 0.43142226338386536,
      "learning_rate": 5.2753035215200025e-06,
      "loss": 0.1278,
      "step": 3133
    },
    {
      "epoch": 0.4981422979873239,
      "grad_norm": 0.43619921803474426,
      "learning_rate": 5.272733158298766e-06,
      "loss": 0.1774,
      "step": 3134
    },
    {
      "epoch": 0.4983012457531144,
      "grad_norm": 0.38315442204475403,
      "learning_rate": 5.270162722785026e-06,
      "loss": 0.1475,
      "step": 3135
    },
    {
      "epoch": 0.49846019351890486,
      "grad_norm": 0.573314368724823,
      "learning_rate": 5.267592215660119e-06,
      "loss": 0.3334,
      "step": 3136
    },
    {
      "epoch": 0.4986191412846953,
      "grad_norm": 0.4783232510089874,
      "learning_rate": 5.2650216376054e-06,
      "loss": 0.1798,
      "step": 3137
    },
    {
      "epoch": 0.49877808905048576,
      "grad_norm": 0.5067286491394043,
      "learning_rate": 5.262450989302243e-06,
      "loss": 0.2154,
      "step": 3138
    },
    {
      "epoch": 0.49893703681627627,
      "grad_norm": 0.5309682488441467,
      "learning_rate": 5.2598802714320465e-06,
      "loss": 0.1767,
      "step": 3139
    },
    {
      "epoch": 0.4990959845820667,
      "grad_norm": 0.45932579040527344,
      "learning_rate": 5.257309484676217e-06,
      "loss": 0.198,
      "step": 3140
    },
    {
      "epoch": 0.49925493234785717,
      "grad_norm": 0.495491623878479,
      "learning_rate": 5.254738629716186e-06,
      "loss": 0.174,
      "step": 3141
    },
    {
      "epoch": 0.4994138801136477,
      "grad_norm": 1.0364741086959839,
      "learning_rate": 5.2521677072334035e-06,
      "loss": 0.3726,
      "step": 3142
    },
    {
      "epoch": 0.49957282787943813,
      "grad_norm": 0.5037484169006348,
      "learning_rate": 5.249596717909334e-06,
      "loss": 0.1951,
      "step": 3143
    },
    {
      "epoch": 0.4997317756452286,
      "grad_norm": 0.5895747542381287,
      "learning_rate": 5.247025662425463e-06,
      "loss": 0.2138,
      "step": 3144
    },
    {
      "epoch": 0.49989072341101903,
      "grad_norm": 0.6621735095977783,
      "learning_rate": 5.244454541463291e-06,
      "loss": 0.4602,
      "step": 3145
    },
    {
      "epoch": 0.5000496711768095,
      "grad_norm": 0.5535413026809692,
      "learning_rate": 5.241883355704337e-06,
      "loss": 0.239,
      "step": 3146
    },
    {
      "epoch": 0.5002086189425999,
      "grad_norm": 0.612648069858551,
      "learning_rate": 5.239312105830135e-06,
      "loss": 0.371,
      "step": 3147
    },
    {
      "epoch": 0.5003675667083904,
      "grad_norm": 0.5974851846694946,
      "learning_rate": 5.2367407925222415e-06,
      "loss": 0.2642,
      "step": 3148
    },
    {
      "epoch": 0.500526514474181,
      "grad_norm": 0.4126199185848236,
      "learning_rate": 5.234169416462225e-06,
      "loss": 0.121,
      "step": 3149
    },
    {
      "epoch": 0.5006854622399713,
      "grad_norm": 0.5405424237251282,
      "learning_rate": 5.231597978331669e-06,
      "loss": 0.2485,
      "step": 3150
    },
    {
      "epoch": 0.5008444100057619,
      "grad_norm": 0.5748146176338196,
      "learning_rate": 5.229026478812182e-06,
      "loss": 0.286,
      "step": 3151
    },
    {
      "epoch": 0.5010033577715524,
      "grad_norm": 0.5031399726867676,
      "learning_rate": 5.226454918585378e-06,
      "loss": 0.1798,
      "step": 3152
    },
    {
      "epoch": 0.5011623055373428,
      "grad_norm": 0.5766169428825378,
      "learning_rate": 5.223883298332894e-06,
      "loss": 0.2919,
      "step": 3153
    },
    {
      "epoch": 0.5013212533031333,
      "grad_norm": 0.526929497718811,
      "learning_rate": 5.221311618736383e-06,
      "loss": 0.204,
      "step": 3154
    },
    {
      "epoch": 0.5014802010689238,
      "grad_norm": 0.6407458186149597,
      "learning_rate": 5.218739880477509e-06,
      "loss": 0.2323,
      "step": 3155
    },
    {
      "epoch": 0.5016391488347142,
      "grad_norm": 0.857849657535553,
      "learning_rate": 5.216168084237956e-06,
      "loss": 0.2025,
      "step": 3156
    },
    {
      "epoch": 0.5017980966005047,
      "grad_norm": 0.4732989966869354,
      "learning_rate": 5.21359623069942e-06,
      "loss": 0.1658,
      "step": 3157
    },
    {
      "epoch": 0.5019570443662952,
      "grad_norm": 0.4336271584033966,
      "learning_rate": 5.211024320543617e-06,
      "loss": 0.1258,
      "step": 3158
    },
    {
      "epoch": 0.5021159921320856,
      "grad_norm": 0.5260167121887207,
      "learning_rate": 5.208452354452275e-06,
      "loss": 0.2569,
      "step": 3159
    },
    {
      "epoch": 0.5022749398978761,
      "grad_norm": 0.4494231641292572,
      "learning_rate": 5.205880333107132e-06,
      "loss": 0.1682,
      "step": 3160
    },
    {
      "epoch": 0.5024338876636665,
      "grad_norm": 0.5562853813171387,
      "learning_rate": 5.203308257189951e-06,
      "loss": 0.2708,
      "step": 3161
    },
    {
      "epoch": 0.502592835429457,
      "grad_norm": 0.412434846162796,
      "learning_rate": 5.2007361273825e-06,
      "loss": 0.125,
      "step": 3162
    },
    {
      "epoch": 0.5027517831952475,
      "grad_norm": 0.5489912033081055,
      "learning_rate": 5.198163944366566e-06,
      "loss": 0.2659,
      "step": 3163
    },
    {
      "epoch": 0.5029107309610379,
      "grad_norm": 0.469381183385849,
      "learning_rate": 5.195591708823953e-06,
      "loss": 0.2019,
      "step": 3164
    },
    {
      "epoch": 0.5030696787268284,
      "grad_norm": 0.49072226881980896,
      "learning_rate": 5.19301942143647e-06,
      "loss": 0.2089,
      "step": 3165
    },
    {
      "epoch": 0.5032286264926189,
      "grad_norm": 0.7737188935279846,
      "learning_rate": 5.19044708288595e-06,
      "loss": 0.2912,
      "step": 3166
    },
    {
      "epoch": 0.5033875742584093,
      "grad_norm": 0.5395157337188721,
      "learning_rate": 5.187874693854228e-06,
      "loss": 0.2907,
      "step": 3167
    },
    {
      "epoch": 0.5035465220241998,
      "grad_norm": 0.5920136570930481,
      "learning_rate": 5.185302255023166e-06,
      "loss": 0.2076,
      "step": 3168
    },
    {
      "epoch": 0.5037054697899903,
      "grad_norm": 0.6091154217720032,
      "learning_rate": 5.182729767074628e-06,
      "loss": 0.3478,
      "step": 3169
    },
    {
      "epoch": 0.5038644175557807,
      "grad_norm": 0.4225921630859375,
      "learning_rate": 5.1801572306904945e-06,
      "loss": 0.1412,
      "step": 3170
    },
    {
      "epoch": 0.5040233653215712,
      "grad_norm": 0.4614892303943634,
      "learning_rate": 5.1775846465526625e-06,
      "loss": 0.16,
      "step": 3171
    },
    {
      "epoch": 0.5041823130873616,
      "grad_norm": 0.48893168568611145,
      "learning_rate": 5.175012015343037e-06,
      "loss": 0.2094,
      "step": 3172
    },
    {
      "epoch": 0.5043412608531521,
      "grad_norm": 0.6297037601470947,
      "learning_rate": 5.172439337743537e-06,
      "loss": 0.2644,
      "step": 3173
    },
    {
      "epoch": 0.5045002086189426,
      "grad_norm": 0.6088495254516602,
      "learning_rate": 5.169866614436095e-06,
      "loss": 0.3493,
      "step": 3174
    },
    {
      "epoch": 0.504659156384733,
      "grad_norm": 0.5377662777900696,
      "learning_rate": 5.167293846102653e-06,
      "loss": 0.2655,
      "step": 3175
    },
    {
      "epoch": 0.5048181041505235,
      "grad_norm": 0.5441144704818726,
      "learning_rate": 5.164721033425166e-06,
      "loss": 0.1929,
      "step": 3176
    },
    {
      "epoch": 0.504977051916314,
      "grad_norm": 0.547580361366272,
      "learning_rate": 5.162148177085604e-06,
      "loss": 0.2506,
      "step": 3177
    },
    {
      "epoch": 0.5051359996821044,
      "grad_norm": 0.45982426404953003,
      "learning_rate": 5.1595752777659445e-06,
      "loss": 0.1609,
      "step": 3178
    },
    {
      "epoch": 0.5052949474478949,
      "grad_norm": 0.41776180267333984,
      "learning_rate": 5.157002336148178e-06,
      "loss": 0.1214,
      "step": 3179
    },
    {
      "epoch": 0.5054538952136854,
      "grad_norm": 0.5307848453521729,
      "learning_rate": 5.154429352914302e-06,
      "loss": 0.2529,
      "step": 3180
    },
    {
      "epoch": 0.5056128429794758,
      "grad_norm": 0.5537868738174438,
      "learning_rate": 5.151856328746334e-06,
      "loss": 0.1681,
      "step": 3181
    },
    {
      "epoch": 0.5057717907452663,
      "grad_norm": 0.4927207827568054,
      "learning_rate": 5.149283264326296e-06,
      "loss": 0.1879,
      "step": 3182
    },
    {
      "epoch": 0.5059307385110569,
      "grad_norm": 0.4944398105144501,
      "learning_rate": 5.14671016033622e-06,
      "loss": 0.1869,
      "step": 3183
    },
    {
      "epoch": 0.5060896862768473,
      "grad_norm": 0.6199739575386047,
      "learning_rate": 5.144137017458154e-06,
      "loss": 0.195,
      "step": 3184
    },
    {
      "epoch": 0.5062486340426378,
      "grad_norm": 0.5743475556373596,
      "learning_rate": 5.1415638363741486e-06,
      "loss": 0.3111,
      "step": 3185
    },
    {
      "epoch": 0.5064075818084282,
      "grad_norm": 0.5530886650085449,
      "learning_rate": 5.1389906177662705e-06,
      "loss": 0.2317,
      "step": 3186
    },
    {
      "epoch": 0.5065665295742187,
      "grad_norm": 0.524617075920105,
      "learning_rate": 5.136417362316594e-06,
      "loss": 0.2242,
      "step": 3187
    },
    {
      "epoch": 0.5067254773400092,
      "grad_norm": 0.5067457556724548,
      "learning_rate": 5.133844070707208e-06,
      "loss": 0.1562,
      "step": 3188
    },
    {
      "epoch": 0.5068844251057996,
      "grad_norm": 0.5294594764709473,
      "learning_rate": 5.131270743620201e-06,
      "loss": 0.3201,
      "step": 3189
    },
    {
      "epoch": 0.5070433728715901,
      "grad_norm": 0.5469392538070679,
      "learning_rate": 5.128697381737676e-06,
      "loss": 0.2333,
      "step": 3190
    },
    {
      "epoch": 0.5072023206373806,
      "grad_norm": 0.517114520072937,
      "learning_rate": 5.126123985741752e-06,
      "loss": 0.1865,
      "step": 3191
    },
    {
      "epoch": 0.507361268403171,
      "grad_norm": 0.5261059999465942,
      "learning_rate": 5.123550556314545e-06,
      "loss": 0.1806,
      "step": 3192
    },
    {
      "epoch": 0.5075202161689615,
      "grad_norm": 0.5495260953903198,
      "learning_rate": 5.120977094138187e-06,
      "loss": 0.2626,
      "step": 3193
    },
    {
      "epoch": 0.507679163934752,
      "grad_norm": 0.5102084279060364,
      "learning_rate": 5.118403599894821e-06,
      "loss": 0.2452,
      "step": 3194
    },
    {
      "epoch": 0.5078381117005424,
      "grad_norm": 0.5285629630088806,
      "learning_rate": 5.115830074266592e-06,
      "loss": 0.231,
      "step": 3195
    },
    {
      "epoch": 0.5079970594663329,
      "grad_norm": 0.6093121767044067,
      "learning_rate": 5.113256517935653e-06,
      "loss": 0.2409,
      "step": 3196
    },
    {
      "epoch": 0.5081560072321234,
      "grad_norm": 0.5760728120803833,
      "learning_rate": 5.110682931584173e-06,
      "loss": 0.2668,
      "step": 3197
    },
    {
      "epoch": 0.5083149549979138,
      "grad_norm": 0.5968970656394958,
      "learning_rate": 5.108109315894325e-06,
      "loss": 0.2797,
      "step": 3198
    },
    {
      "epoch": 0.5084739027637043,
      "grad_norm": 0.6129859685897827,
      "learning_rate": 5.105535671548285e-06,
      "loss": 0.2308,
      "step": 3199
    },
    {
      "epoch": 0.5086328505294947,
      "grad_norm": 0.5098695755004883,
      "learning_rate": 5.102961999228243e-06,
      "loss": 0.169,
      "step": 3200
    },
    {
      "epoch": 0.5087917982952852,
      "grad_norm": 0.534785807132721,
      "learning_rate": 5.100388299616395e-06,
      "loss": 0.2936,
      "step": 3201
    },
    {
      "epoch": 0.5089507460610757,
      "grad_norm": 0.5000715851783752,
      "learning_rate": 5.09781457339494e-06,
      "loss": 0.2318,
      "step": 3202
    },
    {
      "epoch": 0.5091096938268661,
      "grad_norm": 0.6336219310760498,
      "learning_rate": 5.09524082124609e-06,
      "loss": 0.2966,
      "step": 3203
    },
    {
      "epoch": 0.5092686415926566,
      "grad_norm": 0.5261072516441345,
      "learning_rate": 5.092667043852062e-06,
      "loss": 0.213,
      "step": 3204
    },
    {
      "epoch": 0.5094275893584471,
      "grad_norm": 0.5701572299003601,
      "learning_rate": 5.090093241895077e-06,
      "loss": 0.2973,
      "step": 3205
    },
    {
      "epoch": 0.5095865371242375,
      "grad_norm": 0.6229138970375061,
      "learning_rate": 5.087519416057364e-06,
      "loss": 0.3673,
      "step": 3206
    },
    {
      "epoch": 0.509745484890028,
      "grad_norm": 0.5682416558265686,
      "learning_rate": 5.084945567021159e-06,
      "loss": 0.2784,
      "step": 3207
    },
    {
      "epoch": 0.5099044326558185,
      "grad_norm": 0.47018441557884216,
      "learning_rate": 5.0823716954687075e-06,
      "loss": 0.1756,
      "step": 3208
    },
    {
      "epoch": 0.5100633804216089,
      "grad_norm": 0.5483108758926392,
      "learning_rate": 5.079797802082252e-06,
      "loss": 0.2237,
      "step": 3209
    },
    {
      "epoch": 0.5102223281873994,
      "grad_norm": 0.42243316769599915,
      "learning_rate": 5.0772238875440495e-06,
      "loss": 0.117,
      "step": 3210
    },
    {
      "epoch": 0.5103812759531898,
      "grad_norm": 0.47843581438064575,
      "learning_rate": 5.07464995253636e-06,
      "loss": 0.2391,
      "step": 3211
    },
    {
      "epoch": 0.5105402237189803,
      "grad_norm": 0.6571925282478333,
      "learning_rate": 5.0720759977414445e-06,
      "loss": 0.2203,
      "step": 3212
    },
    {
      "epoch": 0.5106991714847708,
      "grad_norm": 0.5763161182403564,
      "learning_rate": 5.069502023841576e-06,
      "loss": 0.277,
      "step": 3213
    },
    {
      "epoch": 0.5108581192505612,
      "grad_norm": 0.5087498426437378,
      "learning_rate": 5.066928031519028e-06,
      "loss": 0.2026,
      "step": 3214
    },
    {
      "epoch": 0.5110170670163517,
      "grad_norm": 0.5151262879371643,
      "learning_rate": 5.064354021456084e-06,
      "loss": 0.2211,
      "step": 3215
    },
    {
      "epoch": 0.5111760147821423,
      "grad_norm": 0.4719698429107666,
      "learning_rate": 5.061779994335023e-06,
      "loss": 0.1539,
      "step": 3216
    },
    {
      "epoch": 0.5113349625479326,
      "grad_norm": 0.541788637638092,
      "learning_rate": 5.059205950838138e-06,
      "loss": 0.2593,
      "step": 3217
    },
    {
      "epoch": 0.5114939103137232,
      "grad_norm": 0.41767770051956177,
      "learning_rate": 5.056631891647721e-06,
      "loss": 0.12,
      "step": 3218
    },
    {
      "epoch": 0.5116528580795137,
      "grad_norm": 0.5676175355911255,
      "learning_rate": 5.054057817446067e-06,
      "loss": 0.2227,
      "step": 3219
    },
    {
      "epoch": 0.5118118058453041,
      "grad_norm": 0.5445553660392761,
      "learning_rate": 5.051483728915485e-06,
      "loss": 0.2894,
      "step": 3220
    },
    {
      "epoch": 0.5119707536110946,
      "grad_norm": 0.6916924715042114,
      "learning_rate": 5.048909626738276e-06,
      "loss": 0.1946,
      "step": 3221
    },
    {
      "epoch": 0.5121297013768851,
      "grad_norm": 0.5514119267463684,
      "learning_rate": 5.046335511596746e-06,
      "loss": 0.2383,
      "step": 3222
    },
    {
      "epoch": 0.5122886491426755,
      "grad_norm": 0.6100499629974365,
      "learning_rate": 5.04376138417321e-06,
      "loss": 0.195,
      "step": 3223
    },
    {
      "epoch": 0.512447596908466,
      "grad_norm": 0.5284963250160217,
      "learning_rate": 5.041187245149985e-06,
      "loss": 0.2185,
      "step": 3224
    },
    {
      "epoch": 0.5126065446742564,
      "grad_norm": 0.4566553831100464,
      "learning_rate": 5.038613095209392e-06,
      "loss": 0.1819,
      "step": 3225
    },
    {
      "epoch": 0.5127654924400469,
      "grad_norm": 0.6277750730514526,
      "learning_rate": 5.036038935033746e-06,
      "loss": 0.2774,
      "step": 3226
    },
    {
      "epoch": 0.5129244402058374,
      "grad_norm": 0.6363366842269897,
      "learning_rate": 5.033464765305375e-06,
      "loss": 0.3119,
      "step": 3227
    },
    {
      "epoch": 0.5130833879716278,
      "grad_norm": 0.4506942629814148,
      "learning_rate": 5.030890586706608e-06,
      "loss": 0.1509,
      "step": 3228
    },
    {
      "epoch": 0.5132423357374183,
      "grad_norm": 0.6361901164054871,
      "learning_rate": 5.028316399919769e-06,
      "loss": 0.3431,
      "step": 3229
    },
    {
      "epoch": 0.5134012835032088,
      "grad_norm": 0.5400270819664001,
      "learning_rate": 5.025742205627195e-06,
      "loss": 0.2226,
      "step": 3230
    },
    {
      "epoch": 0.5135602312689992,
      "grad_norm": 0.5855947732925415,
      "learning_rate": 5.0231680045112174e-06,
      "loss": 0.2972,
      "step": 3231
    },
    {
      "epoch": 0.5137191790347897,
      "grad_norm": 8.803427696228027,
      "learning_rate": 5.020593797254169e-06,
      "loss": 0.1845,
      "step": 3232
    },
    {
      "epoch": 0.5138781268005802,
      "grad_norm": 0.4809904396533966,
      "learning_rate": 5.01801958453839e-06,
      "loss": 0.2138,
      "step": 3233
    },
    {
      "epoch": 0.5140370745663706,
      "grad_norm": 0.5955832600593567,
      "learning_rate": 5.015445367046218e-06,
      "loss": 0.2277,
      "step": 3234
    },
    {
      "epoch": 0.5141960223321611,
      "grad_norm": 0.6056065559387207,
      "learning_rate": 5.012871145459992e-06,
      "loss": 0.3282,
      "step": 3235
    },
    {
      "epoch": 0.5143549700979516,
      "grad_norm": 0.6007680892944336,
      "learning_rate": 5.010296920462052e-06,
      "loss": 0.3263,
      "step": 3236
    },
    {
      "epoch": 0.514513917863742,
      "grad_norm": 0.4860670566558838,
      "learning_rate": 5.00772269273474e-06,
      "loss": 0.1559,
      "step": 3237
    },
    {
      "epoch": 0.5146728656295325,
      "grad_norm": 0.47278326749801636,
      "learning_rate": 5.005148462960399e-06,
      "loss": 0.2345,
      "step": 3238
    },
    {
      "epoch": 0.5148318133953229,
      "grad_norm": 0.5290505886077881,
      "learning_rate": 5.002574231821371e-06,
      "loss": 0.2291,
      "step": 3239
    },
    {
      "epoch": 0.5149907611611134,
      "grad_norm": 0.6518834233283997,
      "learning_rate": 5e-06,
      "loss": 0.3001,
      "step": 3240
    },
    {
      "epoch": 0.5151497089269039,
      "grad_norm": 0.5438902378082275,
      "learning_rate": 4.997425768178629e-06,
      "loss": 0.2085,
      "step": 3241
    },
    {
      "epoch": 0.5153086566926943,
      "grad_norm": 0.47631576657295227,
      "learning_rate": 4.994851537039603e-06,
      "loss": 0.1957,
      "step": 3242
    },
    {
      "epoch": 0.5154676044584848,
      "grad_norm": 0.54413902759552,
      "learning_rate": 4.9922773072652615e-06,
      "loss": 0.2754,
      "step": 3243
    },
    {
      "epoch": 0.5156265522242753,
      "grad_norm": 0.49817389249801636,
      "learning_rate": 4.9897030795379495e-06,
      "loss": 0.1609,
      "step": 3244
    },
    {
      "epoch": 0.5157854999900657,
      "grad_norm": 0.5145801305770874,
      "learning_rate": 4.98712885454001e-06,
      "loss": 0.2461,
      "step": 3245
    },
    {
      "epoch": 0.5159444477558562,
      "grad_norm": 0.5511052012443542,
      "learning_rate": 4.984554632953784e-06,
      "loss": 0.2354,
      "step": 3246
    },
    {
      "epoch": 0.5161033955216467,
      "grad_norm": 0.5592179298400879,
      "learning_rate": 4.981980415461611e-06,
      "loss": 0.2464,
      "step": 3247
    },
    {
      "epoch": 0.5162623432874371,
      "grad_norm": 0.4991677403450012,
      "learning_rate": 4.9794062027458315e-06,
      "loss": 0.2406,
      "step": 3248
    },
    {
      "epoch": 0.5164212910532276,
      "grad_norm": 0.5857776403427124,
      "learning_rate": 4.976831995488784e-06,
      "loss": 0.2078,
      "step": 3249
    },
    {
      "epoch": 0.516580238819018,
      "grad_norm": 0.5223214030265808,
      "learning_rate": 4.974257794372806e-06,
      "loss": 0.2761,
      "step": 3250
    },
    {
      "epoch": 0.5167391865848086,
      "grad_norm": 0.4600486755371094,
      "learning_rate": 4.971683600080231e-06,
      "loss": 0.162,
      "step": 3251
    },
    {
      "epoch": 0.5168981343505991,
      "grad_norm": 0.6527121663093567,
      "learning_rate": 4.969109413293395e-06,
      "loss": 0.3782,
      "step": 3252
    },
    {
      "epoch": 0.5170570821163895,
      "grad_norm": 0.4921477437019348,
      "learning_rate": 4.966535234694626e-06,
      "loss": 0.2457,
      "step": 3253
    },
    {
      "epoch": 0.51721602988218,
      "grad_norm": 0.5181100964546204,
      "learning_rate": 4.963961064966256e-06,
      "loss": 0.2224,
      "step": 3254
    },
    {
      "epoch": 0.5173749776479705,
      "grad_norm": 0.5433157682418823,
      "learning_rate": 4.961386904790611e-06,
      "loss": 0.2589,
      "step": 3255
    },
    {
      "epoch": 0.5175339254137609,
      "grad_norm": 0.4079376757144928,
      "learning_rate": 4.9588127548500155e-06,
      "loss": 0.1292,
      "step": 3256
    },
    {
      "epoch": 0.5176928731795514,
      "grad_norm": 0.5391079187393188,
      "learning_rate": 4.956238615826791e-06,
      "loss": 0.2291,
      "step": 3257
    },
    {
      "epoch": 0.5178518209453419,
      "grad_norm": 0.478547602891922,
      "learning_rate": 4.953664488403256e-06,
      "loss": 0.2029,
      "step": 3258
    },
    {
      "epoch": 0.5180107687111323,
      "grad_norm": 0.5853267312049866,
      "learning_rate": 4.951090373261728e-06,
      "loss": 0.2894,
      "step": 3259
    },
    {
      "epoch": 0.5181697164769228,
      "grad_norm": 0.43196290731430054,
      "learning_rate": 4.9485162710845165e-06,
      "loss": 0.162,
      "step": 3260
    },
    {
      "epoch": 0.5183286642427133,
      "grad_norm": 0.44444650411605835,
      "learning_rate": 4.945942182553932e-06,
      "loss": 0.159,
      "step": 3261
    },
    {
      "epoch": 0.5184876120085037,
      "grad_norm": 1.2913892269134521,
      "learning_rate": 4.943368108352282e-06,
      "loss": 0.2098,
      "step": 3262
    },
    {
      "epoch": 0.5186465597742942,
      "grad_norm": 0.5390231609344482,
      "learning_rate": 4.940794049161865e-06,
      "loss": 0.2462,
      "step": 3263
    },
    {
      "epoch": 0.5188055075400846,
      "grad_norm": 0.5864078998565674,
      "learning_rate": 4.9382200056649785e-06,
      "loss": 0.2667,
      "step": 3264
    },
    {
      "epoch": 0.5189644553058751,
      "grad_norm": 0.6798896193504333,
      "learning_rate": 4.9356459785439175e-06,
      "loss": 0.3347,
      "step": 3265
    },
    {
      "epoch": 0.5191234030716656,
      "grad_norm": 0.4960935115814209,
      "learning_rate": 4.933071968480973e-06,
      "loss": 0.1706,
      "step": 3266
    },
    {
      "epoch": 0.519282350837456,
      "grad_norm": 0.5549468398094177,
      "learning_rate": 4.9304979761584256e-06,
      "loss": 0.2403,
      "step": 3267
    },
    {
      "epoch": 0.5194412986032465,
      "grad_norm": 0.5350795984268188,
      "learning_rate": 4.927924002258557e-06,
      "loss": 0.1892,
      "step": 3268
    },
    {
      "epoch": 0.519600246369037,
      "grad_norm": 0.5212097764015198,
      "learning_rate": 4.925350047463643e-06,
      "loss": 0.2722,
      "step": 3269
    },
    {
      "epoch": 0.5197591941348274,
      "grad_norm": 0.5524661540985107,
      "learning_rate": 4.922776112455952e-06,
      "loss": 0.2606,
      "step": 3270
    },
    {
      "epoch": 0.5199181419006179,
      "grad_norm": 0.536135733127594,
      "learning_rate": 4.920202197917749e-06,
      "loss": 0.2747,
      "step": 3271
    },
    {
      "epoch": 0.5200770896664084,
      "grad_norm": 0.5718927979469299,
      "learning_rate": 4.917628304531296e-06,
      "loss": 0.3017,
      "step": 3272
    },
    {
      "epoch": 0.5202360374321988,
      "grad_norm": 0.6968759894371033,
      "learning_rate": 4.915054432978842e-06,
      "loss": 0.2105,
      "step": 3273
    },
    {
      "epoch": 0.5203949851979893,
      "grad_norm": 0.5122972130775452,
      "learning_rate": 4.912480583942638e-06,
      "loss": 0.1809,
      "step": 3274
    },
    {
      "epoch": 0.5205539329637798,
      "grad_norm": 0.511722207069397,
      "learning_rate": 4.909906758104926e-06,
      "loss": 0.213,
      "step": 3275
    },
    {
      "epoch": 0.5207128807295702,
      "grad_norm": 0.5238012075424194,
      "learning_rate": 4.90733295614794e-06,
      "loss": 0.2185,
      "step": 3276
    },
    {
      "epoch": 0.5208718284953607,
      "grad_norm": 0.49973264336586,
      "learning_rate": 4.904759178753911e-06,
      "loss": 0.2024,
      "step": 3277
    },
    {
      "epoch": 0.5210307762611511,
      "grad_norm": 0.5893753170967102,
      "learning_rate": 4.902185426605061e-06,
      "loss": 0.3591,
      "step": 3278
    },
    {
      "epoch": 0.5211897240269416,
      "grad_norm": 0.5978924632072449,
      "learning_rate": 4.899611700383608e-06,
      "loss": 0.2572,
      "step": 3279
    },
    {
      "epoch": 0.5213486717927321,
      "grad_norm": 0.5680232048034668,
      "learning_rate": 4.8970380007717585e-06,
      "loss": 0.3088,
      "step": 3280
    },
    {
      "epoch": 0.5215076195585225,
      "grad_norm": 0.5501759648323059,
      "learning_rate": 4.894464328451716e-06,
      "loss": 0.2603,
      "step": 3281
    },
    {
      "epoch": 0.521666567324313,
      "grad_norm": 0.5277655124664307,
      "learning_rate": 4.891890684105678e-06,
      "loss": 0.2086,
      "step": 3282
    },
    {
      "epoch": 0.5218255150901036,
      "grad_norm": 0.5759816765785217,
      "learning_rate": 4.8893170684158275e-06,
      "loss": 0.3336,
      "step": 3283
    },
    {
      "epoch": 0.521984462855894,
      "grad_norm": 0.5382137298583984,
      "learning_rate": 4.8867434820643475e-06,
      "loss": 0.1922,
      "step": 3284
    },
    {
      "epoch": 0.5221434106216845,
      "grad_norm": 0.6123144030570984,
      "learning_rate": 4.884169925733409e-06,
      "loss": 0.2739,
      "step": 3285
    },
    {
      "epoch": 0.522302358387475,
      "grad_norm": 0.4471812844276428,
      "learning_rate": 4.881596400105182e-06,
      "loss": 0.137,
      "step": 3286
    },
    {
      "epoch": 0.5224613061532654,
      "grad_norm": 0.4844256639480591,
      "learning_rate": 4.8790229058618134e-06,
      "loss": 0.1883,
      "step": 3287
    },
    {
      "epoch": 0.5226202539190559,
      "grad_norm": 0.589242696762085,
      "learning_rate": 4.876449443685457e-06,
      "loss": 0.3272,
      "step": 3288
    },
    {
      "epoch": 0.5227792016848463,
      "grad_norm": 0.4216846525669098,
      "learning_rate": 4.873876014258251e-06,
      "loss": 0.1342,
      "step": 3289
    },
    {
      "epoch": 0.5229381494506368,
      "grad_norm": 0.5787250995635986,
      "learning_rate": 4.8713026182623255e-06,
      "loss": 0.2777,
      "step": 3290
    },
    {
      "epoch": 0.5230970972164273,
      "grad_norm": 0.5443066358566284,
      "learning_rate": 4.868729256379802e-06,
      "loss": 0.2666,
      "step": 3291
    },
    {
      "epoch": 0.5232560449822177,
      "grad_norm": 0.45618370175361633,
      "learning_rate": 4.866155929292795e-06,
      "loss": 0.1306,
      "step": 3292
    },
    {
      "epoch": 0.5234149927480082,
      "grad_norm": 0.5350465774536133,
      "learning_rate": 4.8635826376834064e-06,
      "loss": 0.2467,
      "step": 3293
    },
    {
      "epoch": 0.5235739405137987,
      "grad_norm": 0.5304281711578369,
      "learning_rate": 4.86100938223373e-06,
      "loss": 0.2442,
      "step": 3294
    },
    {
      "epoch": 0.5237328882795891,
      "grad_norm": 0.5074048042297363,
      "learning_rate": 4.858436163625852e-06,
      "loss": 0.2462,
      "step": 3295
    },
    {
      "epoch": 0.5238918360453796,
      "grad_norm": 0.4493080973625183,
      "learning_rate": 4.855862982541849e-06,
      "loss": 0.153,
      "step": 3296
    },
    {
      "epoch": 0.5240507838111701,
      "grad_norm": 0.5018129944801331,
      "learning_rate": 4.8532898396637815e-06,
      "loss": 0.2219,
      "step": 3297
    },
    {
      "epoch": 0.5242097315769605,
      "grad_norm": 0.5211396813392639,
      "learning_rate": 4.850716735673705e-06,
      "loss": 0.2547,
      "step": 3298
    },
    {
      "epoch": 0.524368679342751,
      "grad_norm": 0.5800965428352356,
      "learning_rate": 4.848143671253668e-06,
      "loss": 0.181,
      "step": 3299
    },
    {
      "epoch": 0.5245276271085415,
      "grad_norm": 0.47774842381477356,
      "learning_rate": 4.845570647085699e-06,
      "loss": 0.2015,
      "step": 3300
    },
    {
      "epoch": 0.5246865748743319,
      "grad_norm": 0.5667636394500732,
      "learning_rate": 4.8429976638518235e-06,
      "loss": 0.2753,
      "step": 3301
    },
    {
      "epoch": 0.5248455226401224,
      "grad_norm": 0.43653005361557007,
      "learning_rate": 4.840424722234058e-06,
      "loss": 0.1355,
      "step": 3302
    },
    {
      "epoch": 0.5250044704059128,
      "grad_norm": 0.530646800994873,
      "learning_rate": 4.837851822914397e-06,
      "loss": 0.2464,
      "step": 3303
    },
    {
      "epoch": 0.5251634181717033,
      "grad_norm": 0.5531535148620605,
      "learning_rate": 4.835278966574835e-06,
      "loss": 0.3286,
      "step": 3304
    },
    {
      "epoch": 0.5253223659374938,
      "grad_norm": 0.5064755082130432,
      "learning_rate": 4.832706153897348e-06,
      "loss": 0.2558,
      "step": 3305
    },
    {
      "epoch": 0.5254813137032842,
      "grad_norm": 0.49111613631248474,
      "learning_rate": 4.830133385563908e-06,
      "loss": 0.2242,
      "step": 3306
    },
    {
      "epoch": 0.5256402614690747,
      "grad_norm": 0.42904356122016907,
      "learning_rate": 4.827560662256465e-06,
      "loss": 0.1476,
      "step": 3307
    },
    {
      "epoch": 0.5257992092348652,
      "grad_norm": 0.5026419162750244,
      "learning_rate": 4.824987984656963e-06,
      "loss": 0.2748,
      "step": 3308
    },
    {
      "epoch": 0.5259581570006556,
      "grad_norm": 0.6245490312576294,
      "learning_rate": 4.822415353447339e-06,
      "loss": 0.1239,
      "step": 3309
    },
    {
      "epoch": 0.5261171047664461,
      "grad_norm": 0.5134860873222351,
      "learning_rate": 4.819842769309507e-06,
      "loss": 0.2603,
      "step": 3310
    },
    {
      "epoch": 0.5262760525322366,
      "grad_norm": 0.5249584913253784,
      "learning_rate": 4.817270232925373e-06,
      "loss": 0.194,
      "step": 3311
    },
    {
      "epoch": 0.526435000298027,
      "grad_norm": 0.43253853917121887,
      "learning_rate": 4.814697744976835e-06,
      "loss": 0.1306,
      "step": 3312
    },
    {
      "epoch": 0.5265939480638175,
      "grad_norm": 0.4870811402797699,
      "learning_rate": 4.812125306145774e-06,
      "loss": 0.2151,
      "step": 3313
    },
    {
      "epoch": 0.526752895829608,
      "grad_norm": 0.3954811990261078,
      "learning_rate": 4.809552917114052e-06,
      "loss": 0.1512,
      "step": 3314
    },
    {
      "epoch": 0.5269118435953984,
      "grad_norm": 0.5099299550056458,
      "learning_rate": 4.80698057856353e-06,
      "loss": 0.2235,
      "step": 3315
    },
    {
      "epoch": 0.527070791361189,
      "grad_norm": 0.5906830430030823,
      "learning_rate": 4.80440829117605e-06,
      "loss": 0.222,
      "step": 3316
    },
    {
      "epoch": 0.5272297391269793,
      "grad_norm": 0.5855280160903931,
      "learning_rate": 4.8018360556334345e-06,
      "loss": 0.3002,
      "step": 3317
    },
    {
      "epoch": 0.5273886868927699,
      "grad_norm": 0.4946368336677551,
      "learning_rate": 4.799263872617501e-06,
      "loss": 0.1831,
      "step": 3318
    },
    {
      "epoch": 0.5275476346585604,
      "grad_norm": 0.5331438183784485,
      "learning_rate": 4.796691742810052e-06,
      "loss": 0.2808,
      "step": 3319
    },
    {
      "epoch": 0.5277065824243508,
      "grad_norm": 0.5528132319450378,
      "learning_rate": 4.79411966689287e-06,
      "loss": 0.2412,
      "step": 3320
    },
    {
      "epoch": 0.5278655301901413,
      "grad_norm": 0.5425854921340942,
      "learning_rate": 4.791547645547727e-06,
      "loss": 0.2667,
      "step": 3321
    },
    {
      "epoch": 0.5280244779559318,
      "grad_norm": 0.6137734651565552,
      "learning_rate": 4.788975679456383e-06,
      "loss": 0.3978,
      "step": 3322
    },
    {
      "epoch": 0.5281834257217222,
      "grad_norm": 0.4567168653011322,
      "learning_rate": 4.786403769300581e-06,
      "loss": 0.1632,
      "step": 3323
    },
    {
      "epoch": 0.5283423734875127,
      "grad_norm": 0.515183687210083,
      "learning_rate": 4.783831915762045e-06,
      "loss": 0.2247,
      "step": 3324
    },
    {
      "epoch": 0.5285013212533032,
      "grad_norm": 0.5705588459968567,
      "learning_rate": 4.7812601195224916e-06,
      "loss": 0.3088,
      "step": 3325
    },
    {
      "epoch": 0.5286602690190936,
      "grad_norm": 0.6074380278587341,
      "learning_rate": 4.77868838126362e-06,
      "loss": 0.2493,
      "step": 3326
    },
    {
      "epoch": 0.5288192167848841,
      "grad_norm": 0.5809094905853271,
      "learning_rate": 4.7761167016671064e-06,
      "loss": 0.2636,
      "step": 3327
    },
    {
      "epoch": 0.5289781645506746,
      "grad_norm": 0.5404080152511597,
      "learning_rate": 4.773545081414623e-06,
      "loss": 0.2684,
      "step": 3328
    },
    {
      "epoch": 0.529137112316465,
      "grad_norm": 0.5126743316650391,
      "learning_rate": 4.770973521187821e-06,
      "loss": 0.21,
      "step": 3329
    },
    {
      "epoch": 0.5292960600822555,
      "grad_norm": 0.5380602478981018,
      "learning_rate": 4.768402021668332e-06,
      "loss": 0.2795,
      "step": 3330
    },
    {
      "epoch": 0.5294550078480459,
      "grad_norm": 0.4732273519039154,
      "learning_rate": 4.765830583537777e-06,
      "loss": 0.122,
      "step": 3331
    },
    {
      "epoch": 0.5296139556138364,
      "grad_norm": 0.5744640827178955,
      "learning_rate": 4.763259207477759e-06,
      "loss": 0.3016,
      "step": 3332
    },
    {
      "epoch": 0.5297729033796269,
      "grad_norm": 0.4767884910106659,
      "learning_rate": 4.760687894169867e-06,
      "loss": 0.1899,
      "step": 3333
    },
    {
      "epoch": 0.5299318511454173,
      "grad_norm": 0.6095517873764038,
      "learning_rate": 4.7581166442956645e-06,
      "loss": 0.2865,
      "step": 3334
    },
    {
      "epoch": 0.5300907989112078,
      "grad_norm": 0.5015092492103577,
      "learning_rate": 4.75554545853671e-06,
      "loss": 0.2133,
      "step": 3335
    },
    {
      "epoch": 0.5302497466769983,
      "grad_norm": 0.49434131383895874,
      "learning_rate": 4.7529743375745395e-06,
      "loss": 0.1874,
      "step": 3336
    },
    {
      "epoch": 0.5304086944427887,
      "grad_norm": 0.945659875869751,
      "learning_rate": 4.7504032820906665e-06,
      "loss": 0.1678,
      "step": 3337
    },
    {
      "epoch": 0.5305676422085792,
      "grad_norm": 0.44880661368370056,
      "learning_rate": 4.747832292766597e-06,
      "loss": 0.1901,
      "step": 3338
    },
    {
      "epoch": 0.5307265899743697,
      "grad_norm": 0.5329851508140564,
      "learning_rate": 4.7452613702838166e-06,
      "loss": 0.2193,
      "step": 3339
    },
    {
      "epoch": 0.5308855377401601,
      "grad_norm": 0.46127015352249146,
      "learning_rate": 4.742690515323785e-06,
      "loss": 0.155,
      "step": 3340
    },
    {
      "epoch": 0.5310444855059506,
      "grad_norm": 0.5728345513343811,
      "learning_rate": 4.740119728567956e-06,
      "loss": 0.2688,
      "step": 3341
    },
    {
      "epoch": 0.531203433271741,
      "grad_norm": 0.5372447371482849,
      "learning_rate": 4.737549010697757e-06,
      "loss": 0.2466,
      "step": 3342
    },
    {
      "epoch": 0.5313623810375315,
      "grad_norm": 0.8655921220779419,
      "learning_rate": 4.734978362394602e-06,
      "loss": 0.2355,
      "step": 3343
    },
    {
      "epoch": 0.531521328803322,
      "grad_norm": 0.5357239842414856,
      "learning_rate": 4.732407784339883e-06,
      "loss": 0.1948,
      "step": 3344
    },
    {
      "epoch": 0.5316802765691124,
      "grad_norm": 0.5732468962669373,
      "learning_rate": 4.729837277214975e-06,
      "loss": 0.2433,
      "step": 3345
    },
    {
      "epoch": 0.5318392243349029,
      "grad_norm": 0.39321404695510864,
      "learning_rate": 4.7272668417012365e-06,
      "loss": 0.1234,
      "step": 3346
    },
    {
      "epoch": 0.5319981721006934,
      "grad_norm": 0.4876675009727478,
      "learning_rate": 4.724696478479999e-06,
      "loss": 0.2216,
      "step": 3347
    },
    {
      "epoch": 0.5321571198664838,
      "grad_norm": 0.6709086298942566,
      "learning_rate": 4.722126188232586e-06,
      "loss": 0.3726,
      "step": 3348
    },
    {
      "epoch": 0.5323160676322743,
      "grad_norm": 0.5369250774383545,
      "learning_rate": 4.719555971640295e-06,
      "loss": 0.3009,
      "step": 3349
    },
    {
      "epoch": 0.5324750153980649,
      "grad_norm": 0.5592074394226074,
      "learning_rate": 4.716985829384402e-06,
      "loss": 0.2391,
      "step": 3350
    },
    {
      "epoch": 0.5326339631638553,
      "grad_norm": 0.5609788298606873,
      "learning_rate": 4.7144157621461694e-06,
      "loss": 0.2273,
      "step": 3351
    },
    {
      "epoch": 0.5327929109296458,
      "grad_norm": 0.4551652669906616,
      "learning_rate": 4.711845770606836e-06,
      "loss": 0.1352,
      "step": 3352
    },
    {
      "epoch": 0.5329518586954363,
      "grad_norm": 0.49107304215431213,
      "learning_rate": 4.7092758554476215e-06,
      "loss": 0.188,
      "step": 3353
    },
    {
      "epoch": 0.5331108064612267,
      "grad_norm": 0.4808650314807892,
      "learning_rate": 4.706706017349723e-06,
      "loss": 0.1505,
      "step": 3354
    },
    {
      "epoch": 0.5332697542270172,
      "grad_norm": 0.779511034488678,
      "learning_rate": 4.7041362569943225e-06,
      "loss": 0.2746,
      "step": 3355
    },
    {
      "epoch": 0.5334287019928076,
      "grad_norm": 0.5506216287612915,
      "learning_rate": 4.7015665750625775e-06,
      "loss": 0.2392,
      "step": 3356
    },
    {
      "epoch": 0.5335876497585981,
      "grad_norm": 0.5460010170936584,
      "learning_rate": 4.698996972235622e-06,
      "loss": 0.2664,
      "step": 3357
    },
    {
      "epoch": 0.5337465975243886,
      "grad_norm": 0.5565343499183655,
      "learning_rate": 4.696427449194576e-06,
      "loss": 0.2866,
      "step": 3358
    },
    {
      "epoch": 0.533905545290179,
      "grad_norm": 0.5189923644065857,
      "learning_rate": 4.693858006620535e-06,
      "loss": 0.1349,
      "step": 3359
    },
    {
      "epoch": 0.5340644930559695,
      "grad_norm": 0.6151730418205261,
      "learning_rate": 4.691288645194567e-06,
      "loss": 0.2987,
      "step": 3360
    },
    {
      "epoch": 0.53422344082176,
      "grad_norm": 0.46993768215179443,
      "learning_rate": 4.688719365597732e-06,
      "loss": 0.2042,
      "step": 3361
    },
    {
      "epoch": 0.5343823885875504,
      "grad_norm": 0.5376845002174377,
      "learning_rate": 4.686150168511056e-06,
      "loss": 0.2369,
      "step": 3362
    },
    {
      "epoch": 0.5345413363533409,
      "grad_norm": 0.5000195503234863,
      "learning_rate": 4.683581054615551e-06,
      "loss": 0.2302,
      "step": 3363
    },
    {
      "epoch": 0.5347002841191314,
      "grad_norm": 0.5449484586715698,
      "learning_rate": 4.6810120245922015e-06,
      "loss": 0.16,
      "step": 3364
    },
    {
      "epoch": 0.5348592318849218,
      "grad_norm": 0.5094104409217834,
      "learning_rate": 4.678443079121973e-06,
      "loss": 0.2168,
      "step": 3365
    },
    {
      "epoch": 0.5350181796507123,
      "grad_norm": 0.5240576863288879,
      "learning_rate": 4.6758742188858074e-06,
      "loss": 0.2554,
      "step": 3366
    },
    {
      "epoch": 0.5351771274165028,
      "grad_norm": 0.5140102505683899,
      "learning_rate": 4.673305444564623e-06,
      "loss": 0.1994,
      "step": 3367
    },
    {
      "epoch": 0.5353360751822932,
      "grad_norm": 0.4929094910621643,
      "learning_rate": 4.670736756839319e-06,
      "loss": 0.1793,
      "step": 3368
    },
    {
      "epoch": 0.5354950229480837,
      "grad_norm": 0.46306145191192627,
      "learning_rate": 4.668168156390769e-06,
      "loss": 0.1485,
      "step": 3369
    },
    {
      "epoch": 0.5356539707138741,
      "grad_norm": 0.5382392406463623,
      "learning_rate": 4.66559964389982e-06,
      "loss": 0.2529,
      "step": 3370
    },
    {
      "epoch": 0.5358129184796646,
      "grad_norm": 0.6411842107772827,
      "learning_rate": 4.6630312200473045e-06,
      "loss": 0.3306,
      "step": 3371
    },
    {
      "epoch": 0.5359718662454551,
      "grad_norm": 0.6007295846939087,
      "learning_rate": 4.660462885514022e-06,
      "loss": 0.2002,
      "step": 3372
    },
    {
      "epoch": 0.5361308140112455,
      "grad_norm": 0.5016671419143677,
      "learning_rate": 4.6578946409807565e-06,
      "loss": 0.1459,
      "step": 3373
    },
    {
      "epoch": 0.536289761777036,
      "grad_norm": 0.577483057975769,
      "learning_rate": 4.655326487128262e-06,
      "loss": 0.3248,
      "step": 3374
    },
    {
      "epoch": 0.5364487095428265,
      "grad_norm": 0.5279541015625,
      "learning_rate": 4.652758424637271e-06,
      "loss": 0.2682,
      "step": 3375
    },
    {
      "epoch": 0.5366076573086169,
      "grad_norm": 0.5486986637115479,
      "learning_rate": 4.650190454188492e-06,
      "loss": 0.2668,
      "step": 3376
    },
    {
      "epoch": 0.5367666050744074,
      "grad_norm": 0.4895649254322052,
      "learning_rate": 4.6476225764626095e-06,
      "loss": 0.221,
      "step": 3377
    },
    {
      "epoch": 0.5369255528401979,
      "grad_norm": 0.48553821444511414,
      "learning_rate": 4.64505479214028e-06,
      "loss": 0.174,
      "step": 3378
    },
    {
      "epoch": 0.5370845006059883,
      "grad_norm": 0.6864731907844543,
      "learning_rate": 4.6424871019021415e-06,
      "loss": 0.3663,
      "step": 3379
    },
    {
      "epoch": 0.5372434483717788,
      "grad_norm": 0.4855853319168091,
      "learning_rate": 4.639919506428801e-06,
      "loss": 0.1804,
      "step": 3380
    },
    {
      "epoch": 0.5374023961375692,
      "grad_norm": 0.44590502977371216,
      "learning_rate": 4.637352006400842e-06,
      "loss": 0.1265,
      "step": 3381
    },
    {
      "epoch": 0.5375613439033597,
      "grad_norm": 0.5209818482398987,
      "learning_rate": 4.634784602498826e-06,
      "loss": 0.235,
      "step": 3382
    },
    {
      "epoch": 0.5377202916691503,
      "grad_norm": 0.43604087829589844,
      "learning_rate": 4.632217295403286e-06,
      "loss": 0.1801,
      "step": 3383
    },
    {
      "epoch": 0.5378792394349406,
      "grad_norm": 0.4902920424938202,
      "learning_rate": 4.629650085794728e-06,
      "loss": 0.1978,
      "step": 3384
    },
    {
      "epoch": 0.5380381872007312,
      "grad_norm": 0.5428280830383301,
      "learning_rate": 4.627082974353636e-06,
      "loss": 0.2979,
      "step": 3385
    },
    {
      "epoch": 0.5381971349665217,
      "grad_norm": 0.4560631811618805,
      "learning_rate": 4.6245159617604655e-06,
      "loss": 0.16,
      "step": 3386
    },
    {
      "epoch": 0.5383560827323121,
      "grad_norm": 0.5090429782867432,
      "learning_rate": 4.621949048695646e-06,
      "loss": 0.2113,
      "step": 3387
    },
    {
      "epoch": 0.5385150304981026,
      "grad_norm": 0.4865317642688751,
      "learning_rate": 4.61938223583958e-06,
      "loss": 0.1906,
      "step": 3388
    },
    {
      "epoch": 0.5386739782638931,
      "grad_norm": 0.6187344193458557,
      "learning_rate": 4.6168155238726465e-06,
      "loss": 0.2965,
      "step": 3389
    },
    {
      "epoch": 0.5388329260296835,
      "grad_norm": 0.5452756881713867,
      "learning_rate": 4.6142489134751945e-06,
      "loss": 0.2647,
      "step": 3390
    },
    {
      "epoch": 0.538991873795474,
      "grad_norm": 0.491462379693985,
      "learning_rate": 4.611682405327547e-06,
      "loss": 0.1792,
      "step": 3391
    },
    {
      "epoch": 0.5391508215612645,
      "grad_norm": 0.49884310364723206,
      "learning_rate": 4.60911600011e-06,
      "loss": 0.1838,
      "step": 3392
    },
    {
      "epoch": 0.5393097693270549,
      "grad_norm": 0.48191961646080017,
      "learning_rate": 4.606549698502824e-06,
      "loss": 0.225,
      "step": 3393
    },
    {
      "epoch": 0.5394687170928454,
      "grad_norm": 0.5003264546394348,
      "learning_rate": 4.603983501186256e-06,
      "loss": 0.2311,
      "step": 3394
    },
    {
      "epoch": 0.5396276648586358,
      "grad_norm": 0.5120129585266113,
      "learning_rate": 4.601417408840515e-06,
      "loss": 0.1938,
      "step": 3395
    },
    {
      "epoch": 0.5397866126244263,
      "grad_norm": 0.5273181796073914,
      "learning_rate": 4.598851422145785e-06,
      "loss": 0.2438,
      "step": 3396
    },
    {
      "epoch": 0.5399455603902168,
      "grad_norm": 0.45281946659088135,
      "learning_rate": 4.596285541782222e-06,
      "loss": 0.1314,
      "step": 3397
    },
    {
      "epoch": 0.5401045081560072,
      "grad_norm": 0.5411784052848816,
      "learning_rate": 4.593719768429957e-06,
      "loss": 0.2292,
      "step": 3398
    },
    {
      "epoch": 0.5402634559217977,
      "grad_norm": 0.5096748471260071,
      "learning_rate": 4.5911541027690914e-06,
      "loss": 0.1739,
      "step": 3399
    },
    {
      "epoch": 0.5404224036875882,
      "grad_norm": 0.5820490121841431,
      "learning_rate": 4.588588545479699e-06,
      "loss": 0.2721,
      "step": 3400
    },
    {
      "epoch": 0.5405813514533786,
      "grad_norm": 0.4033746123313904,
      "learning_rate": 4.586023097241822e-06,
      "loss": 0.1688,
      "step": 3401
    },
    {
      "epoch": 0.5407402992191691,
      "grad_norm": 0.5590469837188721,
      "learning_rate": 4.583457758735477e-06,
      "loss": 0.295,
      "step": 3402
    },
    {
      "epoch": 0.5408992469849596,
      "grad_norm": 0.48465240001678467,
      "learning_rate": 4.580892530640649e-06,
      "loss": 0.2031,
      "step": 3403
    },
    {
      "epoch": 0.54105819475075,
      "grad_norm": 0.4973238706588745,
      "learning_rate": 4.578327413637296e-06,
      "loss": 0.1771,
      "step": 3404
    },
    {
      "epoch": 0.5412171425165405,
      "grad_norm": 0.5558680891990662,
      "learning_rate": 4.575762408405343e-06,
      "loss": 0.261,
      "step": 3405
    },
    {
      "epoch": 0.541376090282331,
      "grad_norm": 0.37098369002342224,
      "learning_rate": 4.573197515624691e-06,
      "loss": 0.0981,
      "step": 3406
    },
    {
      "epoch": 0.5415350380481214,
      "grad_norm": 0.5859982967376709,
      "learning_rate": 4.570632735975205e-06,
      "loss": 0.249,
      "step": 3407
    },
    {
      "epoch": 0.5416939858139119,
      "grad_norm": 0.5164512991905212,
      "learning_rate": 4.568068070136725e-06,
      "loss": 0.182,
      "step": 3408
    },
    {
      "epoch": 0.5418529335797023,
      "grad_norm": 0.508155882358551,
      "learning_rate": 4.565503518789057e-06,
      "loss": 0.2253,
      "step": 3409
    },
    {
      "epoch": 0.5420118813454928,
      "grad_norm": 0.5126981139183044,
      "learning_rate": 4.5629390826119805e-06,
      "loss": 0.2117,
      "step": 3410
    },
    {
      "epoch": 0.5421708291112833,
      "grad_norm": 0.6877104640007019,
      "learning_rate": 4.56037476228524e-06,
      "loss": 0.2658,
      "step": 3411
    },
    {
      "epoch": 0.5423297768770737,
      "grad_norm": 0.5400446653366089,
      "learning_rate": 4.557810558488553e-06,
      "loss": 0.2468,
      "step": 3412
    },
    {
      "epoch": 0.5424887246428642,
      "grad_norm": 0.6075038313865662,
      "learning_rate": 4.555246471901606e-06,
      "loss": 0.299,
      "step": 3413
    },
    {
      "epoch": 0.5426476724086547,
      "grad_norm": 0.45109128952026367,
      "learning_rate": 4.5526825032040504e-06,
      "loss": 0.1502,
      "step": 3414
    },
    {
      "epoch": 0.5428066201744451,
      "grad_norm": 0.5234346985816956,
      "learning_rate": 4.550118653075511e-06,
      "loss": 0.1997,
      "step": 3415
    },
    {
      "epoch": 0.5429655679402356,
      "grad_norm": 0.5941581130027771,
      "learning_rate": 4.547554922195579e-06,
      "loss": 0.2432,
      "step": 3416
    },
    {
      "epoch": 0.5431245157060262,
      "grad_norm": 0.4834268093109131,
      "learning_rate": 4.544991311243815e-06,
      "loss": 0.1797,
      "step": 3417
    },
    {
      "epoch": 0.5432834634718166,
      "grad_norm": 0.5659939050674438,
      "learning_rate": 4.542427820899745e-06,
      "loss": 0.2981,
      "step": 3418
    },
    {
      "epoch": 0.5434424112376071,
      "grad_norm": 0.5203485488891602,
      "learning_rate": 4.5398644518428675e-06,
      "loss": 0.246,
      "step": 3419
    },
    {
      "epoch": 0.5436013590033975,
      "grad_norm": 0.5757006406784058,
      "learning_rate": 4.537301204752647e-06,
      "loss": 0.3387,
      "step": 3420
    },
    {
      "epoch": 0.543760306769188,
      "grad_norm": 0.4688066244125366,
      "learning_rate": 4.5347380803085115e-06,
      "loss": 0.1334,
      "step": 3421
    },
    {
      "epoch": 0.5439192545349785,
      "grad_norm": 0.36999937891960144,
      "learning_rate": 4.532175079189864e-06,
      "loss": 0.116,
      "step": 3422
    },
    {
      "epoch": 0.5440782023007689,
      "grad_norm": 0.4342867434024811,
      "learning_rate": 4.529612202076069e-06,
      "loss": 0.1732,
      "step": 3423
    },
    {
      "epoch": 0.5442371500665594,
      "grad_norm": 0.4886847734451294,
      "learning_rate": 4.52704944964646e-06,
      "loss": 0.1877,
      "step": 3424
    },
    {
      "epoch": 0.5443960978323499,
      "grad_norm": 0.5899854302406311,
      "learning_rate": 4.524486822580339e-06,
      "loss": 0.308,
      "step": 3425
    },
    {
      "epoch": 0.5445550455981403,
      "grad_norm": 0.5156998634338379,
      "learning_rate": 4.521924321556973e-06,
      "loss": 0.2243,
      "step": 3426
    },
    {
      "epoch": 0.5447139933639308,
      "grad_norm": 0.4743078947067261,
      "learning_rate": 4.519361947255595e-06,
      "loss": 0.1512,
      "step": 3427
    },
    {
      "epoch": 0.5448729411297213,
      "grad_norm": 0.5839501619338989,
      "learning_rate": 4.5167997003554056e-06,
      "loss": 0.2785,
      "step": 3428
    },
    {
      "epoch": 0.5450318888955117,
      "grad_norm": 0.564354419708252,
      "learning_rate": 4.514237581535571e-06,
      "loss": 0.2022,
      "step": 3429
    },
    {
      "epoch": 0.5451908366613022,
      "grad_norm": 0.5209395885467529,
      "learning_rate": 4.5116755914752266e-06,
      "loss": 0.2397,
      "step": 3430
    },
    {
      "epoch": 0.5453497844270927,
      "grad_norm": 0.5328291654586792,
      "learning_rate": 4.509113730853466e-06,
      "loss": 0.3131,
      "step": 3431
    },
    {
      "epoch": 0.5455087321928831,
      "grad_norm": 0.5369642972946167,
      "learning_rate": 4.506552000349358e-06,
      "loss": 0.2157,
      "step": 3432
    },
    {
      "epoch": 0.5456676799586736,
      "grad_norm": 0.5200125575065613,
      "learning_rate": 4.503990400641931e-06,
      "loss": 0.1614,
      "step": 3433
    },
    {
      "epoch": 0.545826627724464,
      "grad_norm": 0.41513800621032715,
      "learning_rate": 4.5014289324101775e-06,
      "loss": 0.14,
      "step": 3434
    },
    {
      "epoch": 0.5459855754902545,
      "grad_norm": 0.48013636469841003,
      "learning_rate": 4.498867596333061e-06,
      "loss": 0.1697,
      "step": 3435
    },
    {
      "epoch": 0.546144523256045,
      "grad_norm": 0.6087367534637451,
      "learning_rate": 4.496306393089505e-06,
      "loss": 0.315,
      "step": 3436
    },
    {
      "epoch": 0.5463034710218354,
      "grad_norm": 0.5527359843254089,
      "learning_rate": 4.4937453233584e-06,
      "loss": 0.2134,
      "step": 3437
    },
    {
      "epoch": 0.5464624187876259,
      "grad_norm": 0.6244651079177856,
      "learning_rate": 4.4911843878186e-06,
      "loss": 0.3486,
      "step": 3438
    },
    {
      "epoch": 0.5466213665534164,
      "grad_norm": 0.48056113719940186,
      "learning_rate": 4.4886235871489234e-06,
      "loss": 0.1641,
      "step": 3439
    },
    {
      "epoch": 0.5467803143192068,
      "grad_norm": 0.43100473284721375,
      "learning_rate": 4.486062922028156e-06,
      "loss": 0.1167,
      "step": 3440
    },
    {
      "epoch": 0.5469392620849973,
      "grad_norm": 0.6186766028404236,
      "learning_rate": 4.4835023931350425e-06,
      "loss": 0.3594,
      "step": 3441
    },
    {
      "epoch": 0.5470982098507878,
      "grad_norm": 0.4693749248981476,
      "learning_rate": 4.480942001148294e-06,
      "loss": 0.1649,
      "step": 3442
    },
    {
      "epoch": 0.5472571576165782,
      "grad_norm": 0.49796658754348755,
      "learning_rate": 4.478381746746589e-06,
      "loss": 0.2215,
      "step": 3443
    },
    {
      "epoch": 0.5474161053823687,
      "grad_norm": 0.593993604183197,
      "learning_rate": 4.475821630608561e-06,
      "loss": 0.2776,
      "step": 3444
    },
    {
      "epoch": 0.5475750531481592,
      "grad_norm": 0.45188289880752563,
      "learning_rate": 4.473261653412815e-06,
      "loss": 0.1589,
      "step": 3445
    },
    {
      "epoch": 0.5477340009139496,
      "grad_norm": 0.5757846832275391,
      "learning_rate": 4.470701815837915e-06,
      "loss": 0.281,
      "step": 3446
    },
    {
      "epoch": 0.5478929486797401,
      "grad_norm": 0.412168949842453,
      "learning_rate": 4.468142118562389e-06,
      "loss": 0.1423,
      "step": 3447
    },
    {
      "epoch": 0.5480518964455305,
      "grad_norm": 0.5049692988395691,
      "learning_rate": 4.4655825622647276e-06,
      "loss": 0.2262,
      "step": 3448
    },
    {
      "epoch": 0.548210844211321,
      "grad_norm": 0.5214672684669495,
      "learning_rate": 4.463023147623383e-06,
      "loss": 0.2106,
      "step": 3449
    },
    {
      "epoch": 0.5483697919771116,
      "grad_norm": 0.5298697352409363,
      "learning_rate": 4.460463875316775e-06,
      "loss": 0.2616,
      "step": 3450
    },
    {
      "epoch": 0.548528739742902,
      "grad_norm": 0.5413413643836975,
      "learning_rate": 4.457904746023278e-06,
      "loss": 0.1842,
      "step": 3451
    },
    {
      "epoch": 0.5486876875086925,
      "grad_norm": 0.5740050673484802,
      "learning_rate": 4.455345760421233e-06,
      "loss": 0.2419,
      "step": 3452
    },
    {
      "epoch": 0.548846635274483,
      "grad_norm": 0.5981044173240662,
      "learning_rate": 4.452786919188943e-06,
      "loss": 0.174,
      "step": 3453
    },
    {
      "epoch": 0.5490055830402734,
      "grad_norm": 0.5676069259643555,
      "learning_rate": 4.450228223004671e-06,
      "loss": 0.2682,
      "step": 3454
    },
    {
      "epoch": 0.5491645308060639,
      "grad_norm": 0.6019299626350403,
      "learning_rate": 4.447669672546642e-06,
      "loss": 0.3282,
      "step": 3455
    },
    {
      "epoch": 0.5493234785718544,
      "grad_norm": 0.8281601071357727,
      "learning_rate": 4.4451112684930424e-06,
      "loss": 0.1993,
      "step": 3456
    },
    {
      "epoch": 0.5494824263376448,
      "grad_norm": 0.5621729493141174,
      "learning_rate": 4.442553011522025e-06,
      "loss": 0.2737,
      "step": 3457
    },
    {
      "epoch": 0.5496413741034353,
      "grad_norm": 0.5923771262168884,
      "learning_rate": 4.439994902311692e-06,
      "loss": 0.3082,
      "step": 3458
    },
    {
      "epoch": 0.5498003218692257,
      "grad_norm": 0.42155173420906067,
      "learning_rate": 4.437436941540116e-06,
      "loss": 0.0921,
      "step": 3459
    },
    {
      "epoch": 0.5499592696350162,
      "grad_norm": 0.39248645305633545,
      "learning_rate": 4.43487912988533e-06,
      "loss": 0.1382,
      "step": 3460
    },
    {
      "epoch": 0.5501182174008067,
      "grad_norm": 0.553533673286438,
      "learning_rate": 4.4323214680253215e-06,
      "loss": 0.2053,
      "step": 3461
    },
    {
      "epoch": 0.5502771651665971,
      "grad_norm": 0.5134909152984619,
      "learning_rate": 4.429763956638042e-06,
      "loss": 0.1596,
      "step": 3462
    },
    {
      "epoch": 0.5504361129323876,
      "grad_norm": 0.46664977073669434,
      "learning_rate": 4.427206596401405e-06,
      "loss": 0.183,
      "step": 3463
    },
    {
      "epoch": 0.5505950606981781,
      "grad_norm": 0.7287634611129761,
      "learning_rate": 4.42464938799328e-06,
      "loss": 0.2742,
      "step": 3464
    },
    {
      "epoch": 0.5507540084639685,
      "grad_norm": 0.4713895916938782,
      "learning_rate": 4.422092332091497e-06,
      "loss": 0.1759,
      "step": 3465
    },
    {
      "epoch": 0.550912956229759,
      "grad_norm": 0.4446321725845337,
      "learning_rate": 4.4195354293738484e-06,
      "loss": 0.14,
      "step": 3466
    },
    {
      "epoch": 0.5510719039955495,
      "grad_norm": 0.595703125,
      "learning_rate": 4.416978680518087e-06,
      "loss": 0.3103,
      "step": 3467
    },
    {
      "epoch": 0.5512308517613399,
      "grad_norm": 0.5120447278022766,
      "learning_rate": 4.414422086201916e-06,
      "loss": 0.2147,
      "step": 3468
    },
    {
      "epoch": 0.5513897995271304,
      "grad_norm": 0.5660278797149658,
      "learning_rate": 4.4118656471030065e-06,
      "loss": 0.263,
      "step": 3469
    },
    {
      "epoch": 0.5515487472929209,
      "grad_norm": 0.45337897539138794,
      "learning_rate": 4.409309363898989e-06,
      "loss": 0.1415,
      "step": 3470
    },
    {
      "epoch": 0.5517076950587113,
      "grad_norm": 0.6453650593757629,
      "learning_rate": 4.4067532372674434e-06,
      "loss": 0.3494,
      "step": 3471
    },
    {
      "epoch": 0.5518666428245018,
      "grad_norm": 0.4735560417175293,
      "learning_rate": 4.404197267885915e-06,
      "loss": 0.1747,
      "step": 3472
    },
    {
      "epoch": 0.5520255905902922,
      "grad_norm": 0.5251826643943787,
      "learning_rate": 4.401641456431912e-06,
      "loss": 0.261,
      "step": 3473
    },
    {
      "epoch": 0.5521845383560827,
      "grad_norm": 0.48630207777023315,
      "learning_rate": 4.399085803582889e-06,
      "loss": 0.192,
      "step": 3474
    },
    {
      "epoch": 0.5523434861218732,
      "grad_norm": 0.6216387152671814,
      "learning_rate": 4.396530310016267e-06,
      "loss": 0.38,
      "step": 3475
    },
    {
      "epoch": 0.5525024338876636,
      "grad_norm": 0.49984830617904663,
      "learning_rate": 4.393974976409422e-06,
      "loss": 0.1906,
      "step": 3476
    },
    {
      "epoch": 0.5526613816534541,
      "grad_norm": 0.5875828862190247,
      "learning_rate": 4.391419803439691e-06,
      "loss": 0.2928,
      "step": 3477
    },
    {
      "epoch": 0.5528203294192446,
      "grad_norm": 0.583623468875885,
      "learning_rate": 4.38886479178436e-06,
      "loss": 0.1488,
      "step": 3478
    },
    {
      "epoch": 0.552979277185035,
      "grad_norm": 0.513005256652832,
      "learning_rate": 4.3863099421206816e-06,
      "loss": 0.208,
      "step": 3479
    },
    {
      "epoch": 0.5531382249508255,
      "grad_norm": 0.513746976852417,
      "learning_rate": 4.3837552551258634e-06,
      "loss": 0.2528,
      "step": 3480
    },
    {
      "epoch": 0.553297172716616,
      "grad_norm": 0.42204299569129944,
      "learning_rate": 4.381200731477062e-06,
      "loss": 0.1489,
      "step": 3481
    },
    {
      "epoch": 0.5534561204824064,
      "grad_norm": 0.5675254464149475,
      "learning_rate": 4.378646371851401e-06,
      "loss": 0.2252,
      "step": 3482
    },
    {
      "epoch": 0.553615068248197,
      "grad_norm": 0.4936748743057251,
      "learning_rate": 4.3760921769259585e-06,
      "loss": 0.1813,
      "step": 3483
    },
    {
      "epoch": 0.5537740160139875,
      "grad_norm": 0.5654940605163574,
      "learning_rate": 4.373538147377762e-06,
      "loss": 0.2875,
      "step": 3484
    },
    {
      "epoch": 0.5539329637797779,
      "grad_norm": 0.5516909956932068,
      "learning_rate": 4.370984283883799e-06,
      "loss": 0.1353,
      "step": 3485
    },
    {
      "epoch": 0.5540919115455684,
      "grad_norm": 0.591539740562439,
      "learning_rate": 4.3684305871210195e-06,
      "loss": 0.2438,
      "step": 3486
    },
    {
      "epoch": 0.5542508593113588,
      "grad_norm": 0.5261844992637634,
      "learning_rate": 4.365877057766323e-06,
      "loss": 0.2567,
      "step": 3487
    },
    {
      "epoch": 0.5544098070771493,
      "grad_norm": 0.5989975929260254,
      "learning_rate": 4.363323696496559e-06,
      "loss": 0.3616,
      "step": 3488
    },
    {
      "epoch": 0.5545687548429398,
      "grad_norm": 0.5575577020645142,
      "learning_rate": 4.360770503988545e-06,
      "loss": 0.1518,
      "step": 3489
    },
    {
      "epoch": 0.5547277026087302,
      "grad_norm": 0.5619036555290222,
      "learning_rate": 4.3582174809190485e-06,
      "loss": 0.2883,
      "step": 3490
    },
    {
      "epoch": 0.5548866503745207,
      "grad_norm": 0.44929632544517517,
      "learning_rate": 4.355664627964783e-06,
      "loss": 0.1641,
      "step": 3491
    },
    {
      "epoch": 0.5550455981403112,
      "grad_norm": 0.6045956015586853,
      "learning_rate": 4.353111945802433e-06,
      "loss": 0.315,
      "step": 3492
    },
    {
      "epoch": 0.5552045459061016,
      "grad_norm": 0.5395299196243286,
      "learning_rate": 4.350559435108629e-06,
      "loss": 0.2806,
      "step": 3493
    },
    {
      "epoch": 0.5553634936718921,
      "grad_norm": 0.559187114238739,
      "learning_rate": 4.348007096559953e-06,
      "loss": 0.2408,
      "step": 3494
    },
    {
      "epoch": 0.5555224414376826,
      "grad_norm": 0.4807015657424927,
      "learning_rate": 4.345454930832946e-06,
      "loss": 0.1909,
      "step": 3495
    },
    {
      "epoch": 0.555681389203473,
      "grad_norm": 1.4411182403564453,
      "learning_rate": 4.3429029386041046e-06,
      "loss": 0.3803,
      "step": 3496
    },
    {
      "epoch": 0.5558403369692635,
      "grad_norm": 0.4715102016925812,
      "learning_rate": 4.340351120549877e-06,
      "loss": 0.2026,
      "step": 3497
    },
    {
      "epoch": 0.5559992847350539,
      "grad_norm": 0.5844556093215942,
      "learning_rate": 4.337799477346663e-06,
      "loss": 0.3506,
      "step": 3498
    },
    {
      "epoch": 0.5561582325008444,
      "grad_norm": 0.5951293110847473,
      "learning_rate": 4.335248009670821e-06,
      "loss": 0.3351,
      "step": 3499
    },
    {
      "epoch": 0.5563171802666349,
      "grad_norm": 0.5618619322776794,
      "learning_rate": 4.332696718198662e-06,
      "loss": 0.2684,
      "step": 3500
    },
    {
      "epoch": 0.5564761280324253,
      "grad_norm": 0.47191905975341797,
      "learning_rate": 4.3301456036064415e-06,
      "loss": 0.2019,
      "step": 3501
    },
    {
      "epoch": 0.5566350757982158,
      "grad_norm": 0.4750664532184601,
      "learning_rate": 4.3275946665703825e-06,
      "loss": 0.195,
      "step": 3502
    },
    {
      "epoch": 0.5567940235640063,
      "grad_norm": 0.6137012839317322,
      "learning_rate": 4.325043907766652e-06,
      "loss": 0.2346,
      "step": 3503
    },
    {
      "epoch": 0.5569529713297967,
      "grad_norm": 0.4759710729122162,
      "learning_rate": 4.322493327871368e-06,
      "loss": 0.1755,
      "step": 3504
    },
    {
      "epoch": 0.5571119190955872,
      "grad_norm": 0.5134815573692322,
      "learning_rate": 4.319942927560608e-06,
      "loss": 0.2338,
      "step": 3505
    },
    {
      "epoch": 0.5572708668613777,
      "grad_norm": 0.5273992419242859,
      "learning_rate": 4.317392707510397e-06,
      "loss": 0.1952,
      "step": 3506
    },
    {
      "epoch": 0.5574298146271681,
      "grad_norm": 0.5321587324142456,
      "learning_rate": 4.314842668396716e-06,
      "loss": 0.2207,
      "step": 3507
    },
    {
      "epoch": 0.5575887623929586,
      "grad_norm": 0.5323800444602966,
      "learning_rate": 4.312292810895493e-06,
      "loss": 0.1416,
      "step": 3508
    },
    {
      "epoch": 0.5577477101587491,
      "grad_norm": 0.589779794216156,
      "learning_rate": 4.309743135682611e-06,
      "loss": 0.1913,
      "step": 3509
    },
    {
      "epoch": 0.5579066579245395,
      "grad_norm": 0.613663375377655,
      "learning_rate": 4.307193643433907e-06,
      "loss": 0.2119,
      "step": 3510
    },
    {
      "epoch": 0.55806560569033,
      "grad_norm": 0.5914027690887451,
      "learning_rate": 4.304644334825161e-06,
      "loss": 0.3121,
      "step": 3511
    },
    {
      "epoch": 0.5582245534561204,
      "grad_norm": 0.5799861550331116,
      "learning_rate": 4.302095210532115e-06,
      "loss": 0.3076,
      "step": 3512
    },
    {
      "epoch": 0.5583835012219109,
      "grad_norm": 0.5882275104522705,
      "learning_rate": 4.299546271230457e-06,
      "loss": 0.2957,
      "step": 3513
    },
    {
      "epoch": 0.5585424489877014,
      "grad_norm": 0.5430362224578857,
      "learning_rate": 4.296997517595822e-06,
      "loss": 0.2285,
      "step": 3514
    },
    {
      "epoch": 0.5587013967534918,
      "grad_norm": 0.5075207352638245,
      "learning_rate": 4.294448950303804e-06,
      "loss": 0.1807,
      "step": 3515
    },
    {
      "epoch": 0.5588603445192823,
      "grad_norm": 0.5870819091796875,
      "learning_rate": 4.291900570029943e-06,
      "loss": 0.2374,
      "step": 3516
    },
    {
      "epoch": 0.5590192922850729,
      "grad_norm": 0.5119067430496216,
      "learning_rate": 4.28935237744973e-06,
      "loss": 0.1636,
      "step": 3517
    },
    {
      "epoch": 0.5591782400508633,
      "grad_norm": 0.5814160108566284,
      "learning_rate": 4.286804373238605e-06,
      "loss": 0.3052,
      "step": 3518
    },
    {
      "epoch": 0.5593371878166538,
      "grad_norm": 0.5489692091941833,
      "learning_rate": 4.28425655807196e-06,
      "loss": 0.1788,
      "step": 3519
    },
    {
      "epoch": 0.5594961355824443,
      "grad_norm": 0.5867548584938049,
      "learning_rate": 4.281708932625137e-06,
      "loss": 0.2268,
      "step": 3520
    },
    {
      "epoch": 0.5596550833482347,
      "grad_norm": 0.40534254908561707,
      "learning_rate": 4.279161497573424e-06,
      "loss": 0.12,
      "step": 3521
    },
    {
      "epoch": 0.5598140311140252,
      "grad_norm": 0.5524091124534607,
      "learning_rate": 4.276614253592065e-06,
      "loss": 0.2288,
      "step": 3522
    },
    {
      "epoch": 0.5599729788798157,
      "grad_norm": 0.6024539470672607,
      "learning_rate": 4.27406720135625e-06,
      "loss": 0.3248,
      "step": 3523
    },
    {
      "epoch": 0.5601319266456061,
      "grad_norm": 0.49605005979537964,
      "learning_rate": 4.271520341541113e-06,
      "loss": 0.2186,
      "step": 3524
    },
    {
      "epoch": 0.5602908744113966,
      "grad_norm": 0.562255322933197,
      "learning_rate": 4.268973674821747e-06,
      "loss": 0.1921,
      "step": 3525
    },
    {
      "epoch": 0.560449822177187,
      "grad_norm": 0.6101157665252686,
      "learning_rate": 4.266427201873186e-06,
      "loss": 0.1879,
      "step": 3526
    },
    {
      "epoch": 0.5606087699429775,
      "grad_norm": 0.6113722324371338,
      "learning_rate": 4.263880923370418e-06,
      "loss": 0.3409,
      "step": 3527
    },
    {
      "epoch": 0.560767717708768,
      "grad_norm": 0.5312026739120483,
      "learning_rate": 4.261334839988375e-06,
      "loss": 0.2137,
      "step": 3528
    },
    {
      "epoch": 0.5609266654745584,
      "grad_norm": 0.6119275093078613,
      "learning_rate": 4.258788952401938e-06,
      "loss": 0.3407,
      "step": 3529
    },
    {
      "epoch": 0.5610856132403489,
      "grad_norm": 0.6515746712684631,
      "learning_rate": 4.2562432612859415e-06,
      "loss": 0.2229,
      "step": 3530
    },
    {
      "epoch": 0.5612445610061394,
      "grad_norm": 0.6588820219039917,
      "learning_rate": 4.2536977673151594e-06,
      "loss": 0.3436,
      "step": 3531
    },
    {
      "epoch": 0.5614035087719298,
      "grad_norm": 0.6360418796539307,
      "learning_rate": 4.251152471164319e-06,
      "loss": 0.2624,
      "step": 3532
    },
    {
      "epoch": 0.5615624565377203,
      "grad_norm": 0.5317358374595642,
      "learning_rate": 4.248607373508094e-06,
      "loss": 0.227,
      "step": 3533
    },
    {
      "epoch": 0.5617214043035108,
      "grad_norm": 0.5287933945655823,
      "learning_rate": 4.246062475021107e-06,
      "loss": 0.2179,
      "step": 3534
    },
    {
      "epoch": 0.5618803520693012,
      "grad_norm": 0.5711318254470825,
      "learning_rate": 4.243517776377923e-06,
      "loss": 0.2406,
      "step": 3535
    },
    {
      "epoch": 0.5620392998350917,
      "grad_norm": 0.5641912817955017,
      "learning_rate": 4.240973278253057e-06,
      "loss": 0.231,
      "step": 3536
    },
    {
      "epoch": 0.5621982476008821,
      "grad_norm": 0.5466895699501038,
      "learning_rate": 4.2384289813209754e-06,
      "loss": 0.2667,
      "step": 3537
    },
    {
      "epoch": 0.5623571953666726,
      "grad_norm": 0.6231341361999512,
      "learning_rate": 4.2358848862560835e-06,
      "loss": 0.3146,
      "step": 3538
    },
    {
      "epoch": 0.5625161431324631,
      "grad_norm": 0.5223640203475952,
      "learning_rate": 4.233340993732735e-06,
      "loss": 0.2464,
      "step": 3539
    },
    {
      "epoch": 0.5626750908982535,
      "grad_norm": 0.5717605948448181,
      "learning_rate": 4.230797304425235e-06,
      "loss": 0.2586,
      "step": 3540
    },
    {
      "epoch": 0.562834038664044,
      "grad_norm": 0.5838854312896729,
      "learning_rate": 4.228253819007828e-06,
      "loss": 0.2607,
      "step": 3541
    },
    {
      "epoch": 0.5629929864298345,
      "grad_norm": 0.627812385559082,
      "learning_rate": 4.225710538154709e-06,
      "loss": 0.247,
      "step": 3542
    },
    {
      "epoch": 0.5631519341956249,
      "grad_norm": 0.5395358204841614,
      "learning_rate": 4.223167462540018e-06,
      "loss": 0.2505,
      "step": 3543
    },
    {
      "epoch": 0.5633108819614154,
      "grad_norm": 0.4901728332042694,
      "learning_rate": 4.2206245928378385e-06,
      "loss": 0.1976,
      "step": 3544
    },
    {
      "epoch": 0.5634698297272059,
      "grad_norm": 0.5827512145042419,
      "learning_rate": 4.218081929722202e-06,
      "loss": 0.2071,
      "step": 3545
    },
    {
      "epoch": 0.5636287774929963,
      "grad_norm": 0.5913720726966858,
      "learning_rate": 4.2155394738670814e-06,
      "loss": 0.2624,
      "step": 3546
    },
    {
      "epoch": 0.5637877252587868,
      "grad_norm": 0.48358193039894104,
      "learning_rate": 4.212997225946402e-06,
      "loss": 0.1359,
      "step": 3547
    },
    {
      "epoch": 0.5639466730245773,
      "grad_norm": 0.43697720766067505,
      "learning_rate": 4.210455186634025e-06,
      "loss": 0.0695,
      "step": 3548
    },
    {
      "epoch": 0.5641056207903677,
      "grad_norm": 0.5969982147216797,
      "learning_rate": 4.207913356603762e-06,
      "loss": 0.3002,
      "step": 3549
    },
    {
      "epoch": 0.5642645685561583,
      "grad_norm": 0.5339375138282776,
      "learning_rate": 4.20537173652937e-06,
      "loss": 0.2213,
      "step": 3550
    },
    {
      "epoch": 0.5644235163219486,
      "grad_norm": 0.5480391979217529,
      "learning_rate": 4.202830327084544e-06,
      "loss": 0.279,
      "step": 3551
    },
    {
      "epoch": 0.5645824640877392,
      "grad_norm": 0.5887857675552368,
      "learning_rate": 4.20028912894293e-06,
      "loss": 0.3156,
      "step": 3552
    },
    {
      "epoch": 0.5647414118535297,
      "grad_norm": 0.5384809970855713,
      "learning_rate": 4.197748142778115e-06,
      "loss": 0.1926,
      "step": 3553
    },
    {
      "epoch": 0.5649003596193201,
      "grad_norm": 0.5736123323440552,
      "learning_rate": 4.19520736926363e-06,
      "loss": 0.235,
      "step": 3554
    },
    {
      "epoch": 0.5650593073851106,
      "grad_norm": 0.5423092246055603,
      "learning_rate": 4.192666809072948e-06,
      "loss": 0.1875,
      "step": 3555
    },
    {
      "epoch": 0.5652182551509011,
      "grad_norm": 0.5333189368247986,
      "learning_rate": 4.190126462879489e-06,
      "loss": 0.2352,
      "step": 3556
    },
    {
      "epoch": 0.5653772029166915,
      "grad_norm": 0.4848930239677429,
      "learning_rate": 4.187586331356615e-06,
      "loss": 0.2009,
      "step": 3557
    },
    {
      "epoch": 0.565536150682482,
      "grad_norm": 1.3269158601760864,
      "learning_rate": 4.185046415177629e-06,
      "loss": 0.2967,
      "step": 3558
    },
    {
      "epoch": 0.5656950984482725,
      "grad_norm": 0.5423452258110046,
      "learning_rate": 4.182506715015779e-06,
      "loss": 0.2042,
      "step": 3559
    },
    {
      "epoch": 0.5658540462140629,
      "grad_norm": 0.5262419581413269,
      "learning_rate": 4.179967231544254e-06,
      "loss": 0.1678,
      "step": 3560
    },
    {
      "epoch": 0.5660129939798534,
      "grad_norm": 0.5301368832588196,
      "learning_rate": 4.1774279654361895e-06,
      "loss": 0.233,
      "step": 3561
    },
    {
      "epoch": 0.5661719417456439,
      "grad_norm": 0.4914815425872803,
      "learning_rate": 4.174888917364657e-06,
      "loss": 0.1787,
      "step": 3562
    },
    {
      "epoch": 0.5663308895114343,
      "grad_norm": 0.5135653018951416,
      "learning_rate": 4.172350088002677e-06,
      "loss": 0.225,
      "step": 3563
    },
    {
      "epoch": 0.5664898372772248,
      "grad_norm": 0.44361934065818787,
      "learning_rate": 4.1698114780232085e-06,
      "loss": 0.1591,
      "step": 3564
    },
    {
      "epoch": 0.5666487850430152,
      "grad_norm": 0.4891469180583954,
      "learning_rate": 4.167273088099151e-06,
      "loss": 0.1993,
      "step": 3565
    },
    {
      "epoch": 0.5668077328088057,
      "grad_norm": 0.6017791628837585,
      "learning_rate": 4.164734918903348e-06,
      "loss": 0.2889,
      "step": 3566
    },
    {
      "epoch": 0.5669666805745962,
      "grad_norm": 0.5538026094436646,
      "learning_rate": 4.162196971108584e-06,
      "loss": 0.1958,
      "step": 3567
    },
    {
      "epoch": 0.5671256283403866,
      "grad_norm": 0.5864394307136536,
      "learning_rate": 4.159659245387586e-06,
      "loss": 0.3243,
      "step": 3568
    },
    {
      "epoch": 0.5672845761061771,
      "grad_norm": 0.5633760690689087,
      "learning_rate": 4.157121742413018e-06,
      "loss": 0.1811,
      "step": 3569
    },
    {
      "epoch": 0.5674435238719676,
      "grad_norm": 0.3672648072242737,
      "learning_rate": 4.154584462857492e-06,
      "loss": 0.0994,
      "step": 3570
    },
    {
      "epoch": 0.567602471637758,
      "grad_norm": 0.5532171726226807,
      "learning_rate": 4.152047407393553e-06,
      "loss": 0.3051,
      "step": 3571
    },
    {
      "epoch": 0.5677614194035485,
      "grad_norm": 0.5389916896820068,
      "learning_rate": 4.1495105766936896e-06,
      "loss": 0.1922,
      "step": 3572
    },
    {
      "epoch": 0.567920367169339,
      "grad_norm": 0.5337699055671692,
      "learning_rate": 4.146973971430333e-06,
      "loss": 0.1917,
      "step": 3573
    },
    {
      "epoch": 0.5680793149351294,
      "grad_norm": 0.5057640671730042,
      "learning_rate": 4.144437592275855e-06,
      "loss": 0.2117,
      "step": 3574
    },
    {
      "epoch": 0.5682382627009199,
      "grad_norm": 0.5869851112365723,
      "learning_rate": 4.1419014399025635e-06,
      "loss": 0.3445,
      "step": 3575
    },
    {
      "epoch": 0.5683972104667103,
      "grad_norm": 0.41359543800354004,
      "learning_rate": 4.139365514982707e-06,
      "loss": 0.1471,
      "step": 3576
    },
    {
      "epoch": 0.5685561582325008,
      "grad_norm": 0.5078069567680359,
      "learning_rate": 4.136829818188477e-06,
      "loss": 0.2197,
      "step": 3577
    },
    {
      "epoch": 0.5687151059982913,
      "grad_norm": 0.6613240242004395,
      "learning_rate": 4.134294350192002e-06,
      "loss": 0.416,
      "step": 3578
    },
    {
      "epoch": 0.5688740537640817,
      "grad_norm": 0.5262758135795593,
      "learning_rate": 4.131759111665349e-06,
      "loss": 0.2543,
      "step": 3579
    },
    {
      "epoch": 0.5690330015298722,
      "grad_norm": 0.5996812582015991,
      "learning_rate": 4.129224103280528e-06,
      "loss": 0.3483,
      "step": 3580
    },
    {
      "epoch": 0.5691919492956627,
      "grad_norm": 0.4852953851222992,
      "learning_rate": 4.126689325709484e-06,
      "loss": 0.1751,
      "step": 3581
    },
    {
      "epoch": 0.5693508970614531,
      "grad_norm": 0.6618136763572693,
      "learning_rate": 4.124154779624101e-06,
      "loss": 0.3794,
      "step": 3582
    },
    {
      "epoch": 0.5695098448272436,
      "grad_norm": 0.6055418848991394,
      "learning_rate": 4.1216204656962065e-06,
      "loss": 0.3206,
      "step": 3583
    },
    {
      "epoch": 0.5696687925930342,
      "grad_norm": 0.5509957075119019,
      "learning_rate": 4.119086384597561e-06,
      "loss": 0.236,
      "step": 3584
    },
    {
      "epoch": 0.5698277403588246,
      "grad_norm": 0.5030701756477356,
      "learning_rate": 4.116552536999865e-06,
      "loss": 0.1896,
      "step": 3585
    },
    {
      "epoch": 0.5699866881246151,
      "grad_norm": 0.6179508566856384,
      "learning_rate": 4.1140189235747585e-06,
      "loss": 0.1802,
      "step": 3586
    },
    {
      "epoch": 0.5701456358904056,
      "grad_norm": 0.5882815718650818,
      "learning_rate": 4.111485544993817e-06,
      "loss": 0.161,
      "step": 3587
    },
    {
      "epoch": 0.570304583656196,
      "grad_norm": 0.5610165596008301,
      "learning_rate": 4.108952401928556e-06,
      "loss": 0.2527,
      "step": 3588
    },
    {
      "epoch": 0.5704635314219865,
      "grad_norm": 0.5541890263557434,
      "learning_rate": 4.106419495050427e-06,
      "loss": 0.2619,
      "step": 3589
    },
    {
      "epoch": 0.5706224791877769,
      "grad_norm": 0.5421137809753418,
      "learning_rate": 4.10388682503082e-06,
      "loss": 0.2551,
      "step": 3590
    },
    {
      "epoch": 0.5707814269535674,
      "grad_norm": 0.4876924157142639,
      "learning_rate": 4.101354392541061e-06,
      "loss": 0.2164,
      "step": 3591
    },
    {
      "epoch": 0.5709403747193579,
      "grad_norm": 0.5477986335754395,
      "learning_rate": 4.098822198252414e-06,
      "loss": 0.221,
      "step": 3592
    },
    {
      "epoch": 0.5710993224851483,
      "grad_norm": 0.4474468231201172,
      "learning_rate": 4.096290242836079e-06,
      "loss": 0.1389,
      "step": 3593
    },
    {
      "epoch": 0.5712582702509388,
      "grad_norm": 0.484647661447525,
      "learning_rate": 4.093758526963197e-06,
      "loss": 0.17,
      "step": 3594
    },
    {
      "epoch": 0.5714172180167293,
      "grad_norm": 0.535285472869873,
      "learning_rate": 4.091227051304837e-06,
      "loss": 0.1867,
      "step": 3595
    },
    {
      "epoch": 0.5715761657825197,
      "grad_norm": 0.5762213468551636,
      "learning_rate": 4.088695816532011e-06,
      "loss": 0.2889,
      "step": 3596
    },
    {
      "epoch": 0.5717351135483102,
      "grad_norm": 0.4782206118106842,
      "learning_rate": 4.086164823315667e-06,
      "loss": 0.1906,
      "step": 3597
    },
    {
      "epoch": 0.5718940613141007,
      "grad_norm": 0.5377222299575806,
      "learning_rate": 4.083634072326685e-06,
      "loss": 0.1906,
      "step": 3598
    },
    {
      "epoch": 0.5720530090798911,
      "grad_norm": 0.5615992546081543,
      "learning_rate": 4.081103564235883e-06,
      "loss": 0.3217,
      "step": 3599
    },
    {
      "epoch": 0.5722119568456816,
      "grad_norm": 0.5364553332328796,
      "learning_rate": 4.078573299714014e-06,
      "loss": 0.2161,
      "step": 3600
    },
    {
      "epoch": 0.5723709046114721,
      "grad_norm": 0.6580439209938049,
      "learning_rate": 4.076043279431773e-06,
      "loss": 0.3897,
      "step": 3601
    },
    {
      "epoch": 0.5725298523772625,
      "grad_norm": 0.4749353229999542,
      "learning_rate": 4.073513504059777e-06,
      "loss": 0.1647,
      "step": 3602
    },
    {
      "epoch": 0.572688800143053,
      "grad_norm": 0.6317228078842163,
      "learning_rate": 4.070983974268588e-06,
      "loss": 0.2827,
      "step": 3603
    },
    {
      "epoch": 0.5728477479088434,
      "grad_norm": 0.4980687201023102,
      "learning_rate": 4.068454690728702e-06,
      "loss": 0.202,
      "step": 3604
    },
    {
      "epoch": 0.5730066956746339,
      "grad_norm": 0.5068776607513428,
      "learning_rate": 4.065925654110547e-06,
      "loss": 0.1861,
      "step": 3605
    },
    {
      "epoch": 0.5731656434404244,
      "grad_norm": 0.516815721988678,
      "learning_rate": 4.063396865084485e-06,
      "loss": 0.2262,
      "step": 3606
    },
    {
      "epoch": 0.5733245912062148,
      "grad_norm": 0.5239768028259277,
      "learning_rate": 4.0608683243208165e-06,
      "loss": 0.2448,
      "step": 3607
    },
    {
      "epoch": 0.5734835389720053,
      "grad_norm": 0.5198207497596741,
      "learning_rate": 4.0583400324897715e-06,
      "loss": 0.2462,
      "step": 3608
    },
    {
      "epoch": 0.5736424867377958,
      "grad_norm": 0.5805725455284119,
      "learning_rate": 4.055811990261518e-06,
      "loss": 0.3098,
      "step": 3609
    },
    {
      "epoch": 0.5738014345035862,
      "grad_norm": 0.6061739921569824,
      "learning_rate": 4.0532841983061536e-06,
      "loss": 0.2902,
      "step": 3610
    },
    {
      "epoch": 0.5739603822693767,
      "grad_norm": 0.5296319723129272,
      "learning_rate": 4.050756657293718e-06,
      "loss": 0.2421,
      "step": 3611
    },
    {
      "epoch": 0.5741193300351672,
      "grad_norm": 0.5113987326622009,
      "learning_rate": 4.048229367894172e-06,
      "loss": 0.223,
      "step": 3612
    },
    {
      "epoch": 0.5742782778009576,
      "grad_norm": 0.7503150701522827,
      "learning_rate": 4.045702330777417e-06,
      "loss": 0.2573,
      "step": 3613
    },
    {
      "epoch": 0.5744372255667481,
      "grad_norm": 0.5988732576370239,
      "learning_rate": 4.0431755466132905e-06,
      "loss": 0.2379,
      "step": 3614
    },
    {
      "epoch": 0.5745961733325385,
      "grad_norm": 0.8878738880157471,
      "learning_rate": 4.040649016071555e-06,
      "loss": 0.1704,
      "step": 3615
    },
    {
      "epoch": 0.574755121098329,
      "grad_norm": 0.5490215420722961,
      "learning_rate": 4.038122739821912e-06,
      "loss": 0.245,
      "step": 3616
    },
    {
      "epoch": 0.5749140688641196,
      "grad_norm": 0.5011069774627686,
      "learning_rate": 4.0355967185339926e-06,
      "loss": 0.2063,
      "step": 3617
    },
    {
      "epoch": 0.57507301662991,
      "grad_norm": 0.49776411056518555,
      "learning_rate": 4.033070952877362e-06,
      "loss": 0.1849,
      "step": 3618
    },
    {
      "epoch": 0.5752319643957005,
      "grad_norm": 0.514292299747467,
      "learning_rate": 4.030545443521514e-06,
      "loss": 0.1304,
      "step": 3619
    },
    {
      "epoch": 0.575390912161491,
      "grad_norm": 0.5760281682014465,
      "learning_rate": 4.0280201911358805e-06,
      "loss": 0.1928,
      "step": 3620
    },
    {
      "epoch": 0.5755498599272814,
      "grad_norm": 0.4853914976119995,
      "learning_rate": 4.025495196389824e-06,
      "loss": 0.1407,
      "step": 3621
    },
    {
      "epoch": 0.5757088076930719,
      "grad_norm": 0.6276443004608154,
      "learning_rate": 4.022970459952631e-06,
      "loss": 0.3235,
      "step": 3622
    },
    {
      "epoch": 0.5758677554588624,
      "grad_norm": 0.4751271605491638,
      "learning_rate": 4.020445982493527e-06,
      "loss": 0.2085,
      "step": 3623
    },
    {
      "epoch": 0.5760267032246528,
      "grad_norm": 1.391135334968567,
      "learning_rate": 4.017921764681672e-06,
      "loss": 0.1284,
      "step": 3624
    },
    {
      "epoch": 0.5761856509904433,
      "grad_norm": 0.4850456714630127,
      "learning_rate": 4.015397807186146e-06,
      "loss": 0.2034,
      "step": 3625
    },
    {
      "epoch": 0.5763445987562338,
      "grad_norm": 0.5203381776809692,
      "learning_rate": 4.012874110675968e-06,
      "loss": 0.2342,
      "step": 3626
    },
    {
      "epoch": 0.5765035465220242,
      "grad_norm": 0.7741841077804565,
      "learning_rate": 4.010350675820091e-06,
      "loss": 0.1962,
      "step": 3627
    },
    {
      "epoch": 0.5766624942878147,
      "grad_norm": 0.5771936774253845,
      "learning_rate": 4.007827503287387e-06,
      "loss": 0.2443,
      "step": 3628
    },
    {
      "epoch": 0.5768214420536051,
      "grad_norm": 0.498268187046051,
      "learning_rate": 4.005304593746668e-06,
      "loss": 0.1993,
      "step": 3629
    },
    {
      "epoch": 0.5769803898193956,
      "grad_norm": 0.5348607301712036,
      "learning_rate": 4.002781947866674e-06,
      "loss": 0.2477,
      "step": 3630
    },
    {
      "epoch": 0.5771393375851861,
      "grad_norm": 0.4923537075519562,
      "learning_rate": 4.000259566316077e-06,
      "loss": 0.1833,
      "step": 3631
    },
    {
      "epoch": 0.5772982853509765,
      "grad_norm": 0.4431675374507904,
      "learning_rate": 3.997737449763471e-06,
      "loss": 0.117,
      "step": 3632
    },
    {
      "epoch": 0.577457233116767,
      "grad_norm": 0.5511748790740967,
      "learning_rate": 3.9952155988773876e-06,
      "loss": 0.2855,
      "step": 3633
    },
    {
      "epoch": 0.5776161808825575,
      "grad_norm": 0.44367095828056335,
      "learning_rate": 3.992694014326289e-06,
      "loss": 0.166,
      "step": 3634
    },
    {
      "epoch": 0.5777751286483479,
      "grad_norm": 0.560847818851471,
      "learning_rate": 3.99017269677856e-06,
      "loss": 0.2627,
      "step": 3635
    },
    {
      "epoch": 0.5779340764141384,
      "grad_norm": 0.5233743190765381,
      "learning_rate": 3.987651646902518e-06,
      "loss": 0.2305,
      "step": 3636
    },
    {
      "epoch": 0.5780930241799289,
      "grad_norm": 0.5492939949035645,
      "learning_rate": 3.9851308653664136e-06,
      "loss": 0.2646,
      "step": 3637
    },
    {
      "epoch": 0.5782519719457193,
      "grad_norm": 0.5153036117553711,
      "learning_rate": 3.982610352838418e-06,
      "loss": 0.1613,
      "step": 3638
    },
    {
      "epoch": 0.5784109197115098,
      "grad_norm": 0.5944907665252686,
      "learning_rate": 3.980090109986634e-06,
      "loss": 0.2957,
      "step": 3639
    },
    {
      "epoch": 0.5785698674773003,
      "grad_norm": 0.5334997773170471,
      "learning_rate": 3.9775701374791e-06,
      "loss": 0.1987,
      "step": 3640
    },
    {
      "epoch": 0.5787288152430907,
      "grad_norm": 0.7862512469291687,
      "learning_rate": 3.9750504359837756e-06,
      "loss": 0.1984,
      "step": 3641
    },
    {
      "epoch": 0.5788877630088812,
      "grad_norm": 0.6951548457145691,
      "learning_rate": 3.972531006168545e-06,
      "loss": 0.2998,
      "step": 3642
    },
    {
      "epoch": 0.5790467107746716,
      "grad_norm": 0.640249490737915,
      "learning_rate": 3.9700118487012305e-06,
      "loss": 0.3894,
      "step": 3643
    },
    {
      "epoch": 0.5792056585404621,
      "grad_norm": 0.5508610010147095,
      "learning_rate": 3.9674929642495774e-06,
      "loss": 0.1883,
      "step": 3644
    },
    {
      "epoch": 0.5793646063062526,
      "grad_norm": 0.633601725101471,
      "learning_rate": 3.964974353481254e-06,
      "loss": 0.3231,
      "step": 3645
    },
    {
      "epoch": 0.579523554072043,
      "grad_norm": 0.5624282956123352,
      "learning_rate": 3.9624560170638635e-06,
      "loss": 0.1586,
      "step": 3646
    },
    {
      "epoch": 0.5796825018378335,
      "grad_norm": 0.7869174480438232,
      "learning_rate": 3.959937955664935e-06,
      "loss": 0.2372,
      "step": 3647
    },
    {
      "epoch": 0.579841449603624,
      "grad_norm": 0.4997694790363312,
      "learning_rate": 3.957420169951918e-06,
      "loss": 0.1946,
      "step": 3648
    },
    {
      "epoch": 0.5800003973694144,
      "grad_norm": 0.46662479639053345,
      "learning_rate": 3.954902660592196e-06,
      "loss": 0.1652,
      "step": 3649
    },
    {
      "epoch": 0.580159345135205,
      "grad_norm": 0.5789031386375427,
      "learning_rate": 3.952385428253078e-06,
      "loss": 0.1893,
      "step": 3650
    },
    {
      "epoch": 0.5803182929009955,
      "grad_norm": 0.4888748824596405,
      "learning_rate": 3.949868473601801e-06,
      "loss": 0.156,
      "step": 3651
    },
    {
      "epoch": 0.5804772406667859,
      "grad_norm": 0.48445600271224976,
      "learning_rate": 3.94735179730552e-06,
      "loss": 0.1258,
      "step": 3652
    },
    {
      "epoch": 0.5806361884325764,
      "grad_norm": 0.5344046950340271,
      "learning_rate": 3.944835400031327e-06,
      "loss": 0.2507,
      "step": 3653
    },
    {
      "epoch": 0.5807951361983668,
      "grad_norm": 0.6320852041244507,
      "learning_rate": 3.942319282446236e-06,
      "loss": 0.3446,
      "step": 3654
    },
    {
      "epoch": 0.5809540839641573,
      "grad_norm": 0.47997477650642395,
      "learning_rate": 3.9398034452171814e-06,
      "loss": 0.1582,
      "step": 3655
    },
    {
      "epoch": 0.5811130317299478,
      "grad_norm": 0.6306676864624023,
      "learning_rate": 3.937287889011033e-06,
      "loss": 0.2803,
      "step": 3656
    },
    {
      "epoch": 0.5812719794957382,
      "grad_norm": 0.5194656848907471,
      "learning_rate": 3.934772614494581e-06,
      "loss": 0.2478,
      "step": 3657
    },
    {
      "epoch": 0.5814309272615287,
      "grad_norm": 0.6990576386451721,
      "learning_rate": 3.932257622334537e-06,
      "loss": 0.2395,
      "step": 3658
    },
    {
      "epoch": 0.5815898750273192,
      "grad_norm": 0.8231648206710815,
      "learning_rate": 3.929742913197543e-06,
      "loss": 0.3824,
      "step": 3659
    },
    {
      "epoch": 0.5817488227931096,
      "grad_norm": 0.6553554534912109,
      "learning_rate": 3.927228487750168e-06,
      "loss": 0.3347,
      "step": 3660
    },
    {
      "epoch": 0.5819077705589001,
      "grad_norm": 0.6813991069793701,
      "learning_rate": 3.924714346658904e-06,
      "loss": 0.1234,
      "step": 3661
    },
    {
      "epoch": 0.5820667183246906,
      "grad_norm": 0.5317254662513733,
      "learning_rate": 3.922200490590158e-06,
      "loss": 0.2435,
      "step": 3662
    },
    {
      "epoch": 0.582225666090481,
      "grad_norm": 0.5737859010696411,
      "learning_rate": 3.9196869202102775e-06,
      "loss": 0.1667,
      "step": 3663
    },
    {
      "epoch": 0.5823846138562715,
      "grad_norm": 0.5409404039382935,
      "learning_rate": 3.917173636185526e-06,
      "loss": 0.2755,
      "step": 3664
    },
    {
      "epoch": 0.582543561622062,
      "grad_norm": 0.7162396311759949,
      "learning_rate": 3.914660639182087e-06,
      "loss": 0.4111,
      "step": 3665
    },
    {
      "epoch": 0.5827025093878524,
      "grad_norm": 0.5582729578018188,
      "learning_rate": 3.912147929866075e-06,
      "loss": 0.2519,
      "step": 3666
    },
    {
      "epoch": 0.5828614571536429,
      "grad_norm": 0.5268393158912659,
      "learning_rate": 3.909635508903528e-06,
      "loss": 0.2261,
      "step": 3667
    },
    {
      "epoch": 0.5830204049194333,
      "grad_norm": 0.45681238174438477,
      "learning_rate": 3.9071233769604036e-06,
      "loss": 0.1588,
      "step": 3668
    },
    {
      "epoch": 0.5831793526852238,
      "grad_norm": 0.5090959072113037,
      "learning_rate": 3.904611534702583e-06,
      "loss": 0.234,
      "step": 3669
    },
    {
      "epoch": 0.5833383004510143,
      "grad_norm": 0.5932827591896057,
      "learning_rate": 3.902099982795874e-06,
      "loss": 0.2838,
      "step": 3670
    },
    {
      "epoch": 0.5834972482168047,
      "grad_norm": 0.5206450819969177,
      "learning_rate": 3.899588721906007e-06,
      "loss": 0.2059,
      "step": 3671
    },
    {
      "epoch": 0.5836561959825952,
      "grad_norm": 0.5848025679588318,
      "learning_rate": 3.89707775269863e-06,
      "loss": 0.2,
      "step": 3672
    },
    {
      "epoch": 0.5838151437483857,
      "grad_norm": 0.6110434532165527,
      "learning_rate": 3.894567075839321e-06,
      "loss": 0.1829,
      "step": 3673
    },
    {
      "epoch": 0.5839740915141761,
      "grad_norm": 0.5627709031105042,
      "learning_rate": 3.892056691993577e-06,
      "loss": 0.2114,
      "step": 3674
    },
    {
      "epoch": 0.5841330392799666,
      "grad_norm": 0.39064323902130127,
      "learning_rate": 3.889546601826813e-06,
      "loss": 0.1391,
      "step": 3675
    },
    {
      "epoch": 0.5842919870457571,
      "grad_norm": 0.5763853192329407,
      "learning_rate": 3.887036806004376e-06,
      "loss": 0.1931,
      "step": 3676
    },
    {
      "epoch": 0.5844509348115475,
      "grad_norm": 0.5013429522514343,
      "learning_rate": 3.884527305191527e-06,
      "loss": 0.1902,
      "step": 3677
    },
    {
      "epoch": 0.584609882577338,
      "grad_norm": 0.5071088075637817,
      "learning_rate": 3.8820181000534515e-06,
      "loss": 0.2334,
      "step": 3678
    },
    {
      "epoch": 0.5847688303431285,
      "grad_norm": 0.6175433993339539,
      "learning_rate": 3.879509191255257e-06,
      "loss": 0.191,
      "step": 3679
    },
    {
      "epoch": 0.5849277781089189,
      "grad_norm": 0.518595814704895,
      "learning_rate": 3.87700057946197e-06,
      "loss": 0.1562,
      "step": 3680
    },
    {
      "epoch": 0.5850867258747094,
      "grad_norm": 0.5574377179145813,
      "learning_rate": 3.874492265338544e-06,
      "loss": 0.2246,
      "step": 3681
    },
    {
      "epoch": 0.5852456736404998,
      "grad_norm": 0.4331527352333069,
      "learning_rate": 3.871984249549846e-06,
      "loss": 0.1559,
      "step": 3682
    },
    {
      "epoch": 0.5854046214062903,
      "grad_norm": 0.5844193696975708,
      "learning_rate": 3.8694765327606694e-06,
      "loss": 0.1896,
      "step": 3683
    },
    {
      "epoch": 0.5855635691720809,
      "grad_norm": 0.6025131344795227,
      "learning_rate": 3.866969115635727e-06,
      "loss": 0.2567,
      "step": 3684
    },
    {
      "epoch": 0.5857225169378713,
      "grad_norm": 0.5151053667068481,
      "learning_rate": 3.8644619988396515e-06,
      "loss": 0.2422,
      "step": 3685
    },
    {
      "epoch": 0.5858814647036618,
      "grad_norm": 0.5129056572914124,
      "learning_rate": 3.861955183036995e-06,
      "loss": 0.2202,
      "step": 3686
    },
    {
      "epoch": 0.5860404124694523,
      "grad_norm": 0.5512536764144897,
      "learning_rate": 3.859448668892233e-06,
      "loss": 0.2001,
      "step": 3687
    },
    {
      "epoch": 0.5861993602352427,
      "grad_norm": 0.5785412192344666,
      "learning_rate": 3.856942457069759e-06,
      "loss": 0.2862,
      "step": 3688
    },
    {
      "epoch": 0.5863583080010332,
      "grad_norm": 0.4522736072540283,
      "learning_rate": 3.854436548233885e-06,
      "loss": 0.1881,
      "step": 3689
    },
    {
      "epoch": 0.5865172557668237,
      "grad_norm": 0.5209283232688904,
      "learning_rate": 3.851930943048845e-06,
      "loss": 0.1708,
      "step": 3690
    },
    {
      "epoch": 0.5866762035326141,
      "grad_norm": 0.5492621660232544,
      "learning_rate": 3.849425642178794e-06,
      "loss": 0.1545,
      "step": 3691
    },
    {
      "epoch": 0.5868351512984046,
      "grad_norm": 0.6427398324012756,
      "learning_rate": 3.8469206462878e-06,
      "loss": 0.2832,
      "step": 3692
    },
    {
      "epoch": 0.586994099064195,
      "grad_norm": 0.5666546821594238,
      "learning_rate": 3.844415956039856e-06,
      "loss": 0.2862,
      "step": 3693
    },
    {
      "epoch": 0.5871530468299855,
      "grad_norm": 0.5834473967552185,
      "learning_rate": 3.841911572098875e-06,
      "loss": 0.2898,
      "step": 3694
    },
    {
      "epoch": 0.587311994595776,
      "grad_norm": 0.5780474543571472,
      "learning_rate": 3.83940749512868e-06,
      "loss": 0.244,
      "step": 3695
    },
    {
      "epoch": 0.5874709423615664,
      "grad_norm": 0.5548325181007385,
      "learning_rate": 3.836903725793024e-06,
      "loss": 0.2124,
      "step": 3696
    },
    {
      "epoch": 0.5876298901273569,
      "grad_norm": 0.7096620202064514,
      "learning_rate": 3.8344002647555705e-06,
      "loss": 0.3692,
      "step": 3697
    },
    {
      "epoch": 0.5877888378931474,
      "grad_norm": 0.58381187915802,
      "learning_rate": 3.831897112679907e-06,
      "loss": 0.3259,
      "step": 3698
    },
    {
      "epoch": 0.5879477856589378,
      "grad_norm": 0.5891715884208679,
      "learning_rate": 3.829394270229531e-06,
      "loss": 0.3316,
      "step": 3699
    },
    {
      "epoch": 0.5881067334247283,
      "grad_norm": 0.4154750406742096,
      "learning_rate": 3.826891738067866e-06,
      "loss": 0.1624,
      "step": 3700
    },
    {
      "epoch": 0.5882656811905188,
      "grad_norm": 0.6452311277389526,
      "learning_rate": 3.824389516858251e-06,
      "loss": 0.3895,
      "step": 3701
    },
    {
      "epoch": 0.5884246289563092,
      "grad_norm": 0.45605722069740295,
      "learning_rate": 3.82188760726394e-06,
      "loss": 0.1703,
      "step": 3702
    },
    {
      "epoch": 0.5885835767220997,
      "grad_norm": 0.6690430641174316,
      "learning_rate": 3.819386009948106e-06,
      "loss": 0.2548,
      "step": 3703
    },
    {
      "epoch": 0.5887425244878902,
      "grad_norm": 0.5903059840202332,
      "learning_rate": 3.816884725573841e-06,
      "loss": 0.2971,
      "step": 3704
    },
    {
      "epoch": 0.5889014722536806,
      "grad_norm": 0.4905450940132141,
      "learning_rate": 3.814383754804152e-06,
      "loss": 0.1936,
      "step": 3705
    },
    {
      "epoch": 0.5890604200194711,
      "grad_norm": 0.7697815895080566,
      "learning_rate": 3.8118830983019615e-06,
      "loss": 0.285,
      "step": 3706
    },
    {
      "epoch": 0.5892193677852615,
      "grad_norm": 0.5028423070907593,
      "learning_rate": 3.8093827567301124e-06,
      "loss": 0.1895,
      "step": 3707
    },
    {
      "epoch": 0.589378315551052,
      "grad_norm": 0.4852893054485321,
      "learning_rate": 3.8068827307513624e-06,
      "loss": 0.1648,
      "step": 3708
    },
    {
      "epoch": 0.5895372633168425,
      "grad_norm": 0.4821375012397766,
      "learning_rate": 3.8043830210283837e-06,
      "loss": 0.1437,
      "step": 3709
    },
    {
      "epoch": 0.5896962110826329,
      "grad_norm": 0.43442147970199585,
      "learning_rate": 3.801883628223767e-06,
      "loss": 0.1298,
      "step": 3710
    },
    {
      "epoch": 0.5898551588484234,
      "grad_norm": 0.45148545503616333,
      "learning_rate": 3.79938455300002e-06,
      "loss": 0.1808,
      "step": 3711
    },
    {
      "epoch": 0.5900141066142139,
      "grad_norm": 0.541950523853302,
      "learning_rate": 3.796885796019562e-06,
      "loss": 0.2392,
      "step": 3712
    },
    {
      "epoch": 0.5901730543800043,
      "grad_norm": 0.4952412545681,
      "learning_rate": 3.794387357944732e-06,
      "loss": 0.174,
      "step": 3713
    },
    {
      "epoch": 0.5903320021457948,
      "grad_norm": 0.48910993337631226,
      "learning_rate": 3.7918892394377836e-06,
      "loss": 0.218,
      "step": 3714
    },
    {
      "epoch": 0.5904909499115853,
      "grad_norm": 0.49064522981643677,
      "learning_rate": 3.7893914411608836e-06,
      "loss": 0.2048,
      "step": 3715
    },
    {
      "epoch": 0.5906498976773757,
      "grad_norm": 0.6607600450515747,
      "learning_rate": 3.786893963776115e-06,
      "loss": 0.3286,
      "step": 3716
    },
    {
      "epoch": 0.5908088454431663,
      "grad_norm": 0.402975469827652,
      "learning_rate": 3.7843968079454773e-06,
      "loss": 0.1133,
      "step": 3717
    },
    {
      "epoch": 0.5909677932089568,
      "grad_norm": 0.46650564670562744,
      "learning_rate": 3.781899974330885e-06,
      "loss": 0.1795,
      "step": 3718
    },
    {
      "epoch": 0.5911267409747472,
      "grad_norm": 0.5569901466369629,
      "learning_rate": 3.779403463594163e-06,
      "loss": 0.1973,
      "step": 3719
    },
    {
      "epoch": 0.5912856887405377,
      "grad_norm": 0.6311907172203064,
      "learning_rate": 3.776907276397054e-06,
      "loss": 0.3096,
      "step": 3720
    },
    {
      "epoch": 0.5914446365063281,
      "grad_norm": 0.5234495997428894,
      "learning_rate": 3.7744114134012167e-06,
      "loss": 0.1509,
      "step": 3721
    },
    {
      "epoch": 0.5916035842721186,
      "grad_norm": 0.5377376675605774,
      "learning_rate": 3.7719158752682184e-06,
      "loss": 0.2111,
      "step": 3722
    },
    {
      "epoch": 0.5917625320379091,
      "grad_norm": 0.46933311223983765,
      "learning_rate": 3.7694206626595444e-06,
      "loss": 0.1472,
      "step": 3723
    },
    {
      "epoch": 0.5919214798036995,
      "grad_norm": 0.8650397658348083,
      "learning_rate": 3.766925776236594e-06,
      "loss": 0.3135,
      "step": 3724
    },
    {
      "epoch": 0.59208042756949,
      "grad_norm": 0.6746382117271423,
      "learning_rate": 3.7644312166606773e-06,
      "loss": 0.2624,
      "step": 3725
    },
    {
      "epoch": 0.5922393753352805,
      "grad_norm": 0.5071354508399963,
      "learning_rate": 3.7619369845930195e-06,
      "loss": 0.2365,
      "step": 3726
    },
    {
      "epoch": 0.5923983231010709,
      "grad_norm": 0.5403846502304077,
      "learning_rate": 3.7594430806947584e-06,
      "loss": 0.2733,
      "step": 3727
    },
    {
      "epoch": 0.5925572708668614,
      "grad_norm": 0.4616435468196869,
      "learning_rate": 3.7569495056269474e-06,
      "loss": 0.1559,
      "step": 3728
    },
    {
      "epoch": 0.5927162186326519,
      "grad_norm": 0.4759802222251892,
      "learning_rate": 3.7544562600505475e-06,
      "loss": 0.1704,
      "step": 3729
    },
    {
      "epoch": 0.5928751663984423,
      "grad_norm": 0.5015333294868469,
      "learning_rate": 3.7519633446264358e-06,
      "loss": 0.2218,
      "step": 3730
    },
    {
      "epoch": 0.5930341141642328,
      "grad_norm": 0.4691290557384491,
      "learning_rate": 3.7494707600154034e-06,
      "loss": 0.1468,
      "step": 3731
    },
    {
      "epoch": 0.5931930619300232,
      "grad_norm": 0.5009142756462097,
      "learning_rate": 3.74697850687815e-06,
      "loss": 0.2314,
      "step": 3732
    },
    {
      "epoch": 0.5933520096958137,
      "grad_norm": 0.5084394216537476,
      "learning_rate": 3.744486585875289e-06,
      "loss": 0.2024,
      "step": 3733
    },
    {
      "epoch": 0.5935109574616042,
      "grad_norm": 0.6558132767677307,
      "learning_rate": 3.7419949976673475e-06,
      "loss": 0.319,
      "step": 3734
    },
    {
      "epoch": 0.5936699052273946,
      "grad_norm": 0.38880082964897156,
      "learning_rate": 3.7395037429147615e-06,
      "loss": 0.1011,
      "step": 3735
    },
    {
      "epoch": 0.5938288529931851,
      "grad_norm": 0.5374141931533813,
      "learning_rate": 3.737012822277879e-06,
      "loss": 0.2182,
      "step": 3736
    },
    {
      "epoch": 0.5939878007589756,
      "grad_norm": 0.534810483455658,
      "learning_rate": 3.7345222364169627e-06,
      "loss": 0.2135,
      "step": 3737
    },
    {
      "epoch": 0.594146748524766,
      "grad_norm": 0.5084009766578674,
      "learning_rate": 3.7320319859921834e-06,
      "loss": 0.215,
      "step": 3738
    },
    {
      "epoch": 0.5943056962905565,
      "grad_norm": 0.4987250566482544,
      "learning_rate": 3.7295420716636227e-06,
      "loss": 0.1954,
      "step": 3739
    },
    {
      "epoch": 0.594464644056347,
      "grad_norm": 0.49173131585121155,
      "learning_rate": 3.7270524940912743e-06,
      "loss": 0.2025,
      "step": 3740
    },
    {
      "epoch": 0.5946235918221374,
      "grad_norm": 0.5087961554527283,
      "learning_rate": 3.724563253935045e-06,
      "loss": 0.2094,
      "step": 3741
    },
    {
      "epoch": 0.5947825395879279,
      "grad_norm": 0.45081400871276855,
      "learning_rate": 3.7220743518547474e-06,
      "loss": 0.1439,
      "step": 3742
    },
    {
      "epoch": 0.5949414873537184,
      "grad_norm": 0.5680370926856995,
      "learning_rate": 3.7195857885101066e-06,
      "loss": 0.2779,
      "step": 3743
    },
    {
      "epoch": 0.5951004351195088,
      "grad_norm": 0.5520505309104919,
      "learning_rate": 3.7170975645607587e-06,
      "loss": 0.2397,
      "step": 3744
    },
    {
      "epoch": 0.5952593828852993,
      "grad_norm": 0.6168899536132812,
      "learning_rate": 3.714609680666251e-06,
      "loss": 0.3287,
      "step": 3745
    },
    {
      "epoch": 0.5954183306510897,
      "grad_norm": 0.47129151225090027,
      "learning_rate": 3.712122137486036e-06,
      "loss": 0.148,
      "step": 3746
    },
    {
      "epoch": 0.5955772784168802,
      "grad_norm": 0.5962514281272888,
      "learning_rate": 3.7096349356794803e-06,
      "loss": 0.3066,
      "step": 3747
    },
    {
      "epoch": 0.5957362261826707,
      "grad_norm": 0.508669376373291,
      "learning_rate": 3.70714807590586e-06,
      "loss": 0.1767,
      "step": 3748
    },
    {
      "epoch": 0.5958951739484611,
      "grad_norm": 0.559428334236145,
      "learning_rate": 3.704661558824355e-06,
      "loss": 0.2235,
      "step": 3749
    },
    {
      "epoch": 0.5960541217142517,
      "grad_norm": 0.5739955306053162,
      "learning_rate": 3.7021753850940616e-06,
      "loss": 0.2425,
      "step": 3750
    },
    {
      "epoch": 0.5962130694800422,
      "grad_norm": 0.4782431423664093,
      "learning_rate": 3.699689555373982e-06,
      "loss": 0.2054,
      "step": 3751
    },
    {
      "epoch": 0.5963720172458326,
      "grad_norm": 0.5514639616012573,
      "learning_rate": 3.6972040703230254e-06,
      "loss": 0.2288,
      "step": 3752
    },
    {
      "epoch": 0.5965309650116231,
      "grad_norm": 0.5942153334617615,
      "learning_rate": 3.694718930600012e-06,
      "loss": 0.3178,
      "step": 3753
    },
    {
      "epoch": 0.5966899127774136,
      "grad_norm": 0.5829922556877136,
      "learning_rate": 3.6922341368636705e-06,
      "loss": 0.2851,
      "step": 3754
    },
    {
      "epoch": 0.596848860543204,
      "grad_norm": 0.56488037109375,
      "learning_rate": 3.689749689772637e-06,
      "loss": 0.3136,
      "step": 3755
    },
    {
      "epoch": 0.5970078083089945,
      "grad_norm": 0.4845668375492096,
      "learning_rate": 3.687265589985455e-06,
      "loss": 0.1864,
      "step": 3756
    },
    {
      "epoch": 0.597166756074785,
      "grad_norm": 0.5100685954093933,
      "learning_rate": 3.684781838160578e-06,
      "loss": 0.2055,
      "step": 3757
    },
    {
      "epoch": 0.5973257038405754,
      "grad_norm": 0.6215897798538208,
      "learning_rate": 3.682298434956366e-06,
      "loss": 0.2565,
      "step": 3758
    },
    {
      "epoch": 0.5974846516063659,
      "grad_norm": 0.5318080186843872,
      "learning_rate": 3.6798153810310854e-06,
      "loss": 0.2159,
      "step": 3759
    },
    {
      "epoch": 0.5976435993721563,
      "grad_norm": 0.528094470500946,
      "learning_rate": 3.677332677042913e-06,
      "loss": 0.1934,
      "step": 3760
    },
    {
      "epoch": 0.5978025471379468,
      "grad_norm": 0.6339430212974548,
      "learning_rate": 3.674850323649931e-06,
      "loss": 0.1949,
      "step": 3761
    },
    {
      "epoch": 0.5979614949037373,
      "grad_norm": 0.4298740029335022,
      "learning_rate": 3.672368321510128e-06,
      "loss": 0.1003,
      "step": 3762
    },
    {
      "epoch": 0.5981204426695277,
      "grad_norm": 0.6101162433624268,
      "learning_rate": 3.6698866712814003e-06,
      "loss": 0.2654,
      "step": 3763
    },
    {
      "epoch": 0.5982793904353182,
      "grad_norm": 0.670901894569397,
      "learning_rate": 3.6674053736215504e-06,
      "loss": 0.2111,
      "step": 3764
    },
    {
      "epoch": 0.5984383382011087,
      "grad_norm": 0.5659005641937256,
      "learning_rate": 3.6649244291882923e-06,
      "loss": 0.2877,
      "step": 3765
    },
    {
      "epoch": 0.5985972859668991,
      "grad_norm": 0.48598963022232056,
      "learning_rate": 3.662443838639237e-06,
      "loss": 0.1895,
      "step": 3766
    },
    {
      "epoch": 0.5987562337326896,
      "grad_norm": 0.5356449484825134,
      "learning_rate": 3.6599636026319073e-06,
      "loss": 0.1957,
      "step": 3767
    },
    {
      "epoch": 0.5989151814984801,
      "grad_norm": 0.5469594597816467,
      "learning_rate": 3.6574837218237343e-06,
      "loss": 0.2465,
      "step": 3768
    },
    {
      "epoch": 0.5990741292642705,
      "grad_norm": 0.5734338164329529,
      "learning_rate": 3.655004196872049e-06,
      "loss": 0.268,
      "step": 3769
    },
    {
      "epoch": 0.599233077030061,
      "grad_norm": 0.5512039661407471,
      "learning_rate": 3.652525028434092e-06,
      "loss": 0.253,
      "step": 3770
    },
    {
      "epoch": 0.5993920247958514,
      "grad_norm": 0.5478861331939697,
      "learning_rate": 3.6500462171670104e-06,
      "loss": 0.1653,
      "step": 3771
    },
    {
      "epoch": 0.5995509725616419,
      "grad_norm": 0.5588041543960571,
      "learning_rate": 3.647567763727852e-06,
      "loss": 0.2863,
      "step": 3772
    },
    {
      "epoch": 0.5997099203274324,
      "grad_norm": 0.5555254817008972,
      "learning_rate": 3.645089668773574e-06,
      "loss": 0.2445,
      "step": 3773
    },
    {
      "epoch": 0.5998688680932228,
      "grad_norm": 0.5751793384552002,
      "learning_rate": 3.6426119329610353e-06,
      "loss": 0.2982,
      "step": 3774
    },
    {
      "epoch": 0.6000278158590133,
      "grad_norm": 0.605590283870697,
      "learning_rate": 3.640134556947007e-06,
      "loss": 0.2315,
      "step": 3775
    },
    {
      "epoch": 0.6001867636248038,
      "grad_norm": 0.4751635491847992,
      "learning_rate": 3.637657541388153e-06,
      "loss": 0.1886,
      "step": 3776
    },
    {
      "epoch": 0.6003457113905942,
      "grad_norm": 0.642383873462677,
      "learning_rate": 3.6351808869410484e-06,
      "loss": 0.2377,
      "step": 3777
    },
    {
      "epoch": 0.6005046591563847,
      "grad_norm": 0.45723670721054077,
      "learning_rate": 3.632704594262177e-06,
      "loss": 0.1391,
      "step": 3778
    },
    {
      "epoch": 0.6006636069221752,
      "grad_norm": 0.671410858631134,
      "learning_rate": 3.6302286640079166e-06,
      "loss": 0.3252,
      "step": 3779
    },
    {
      "epoch": 0.6008225546879656,
      "grad_norm": 0.5906723737716675,
      "learning_rate": 3.6277530968345552e-06,
      "loss": 0.2867,
      "step": 3780
    },
    {
      "epoch": 0.6009815024537561,
      "grad_norm": 0.7225806713104248,
      "learning_rate": 3.6252778933982868e-06,
      "loss": 0.2105,
      "step": 3781
    },
    {
      "epoch": 0.6011404502195467,
      "grad_norm": 0.45331066846847534,
      "learning_rate": 3.6228030543552004e-06,
      "loss": 0.126,
      "step": 3782
    },
    {
      "epoch": 0.601299397985337,
      "grad_norm": 0.611504852771759,
      "learning_rate": 3.6203285803612975e-06,
      "loss": 0.2646,
      "step": 3783
    },
    {
      "epoch": 0.6014583457511276,
      "grad_norm": 0.5778433680534363,
      "learning_rate": 3.617854472072477e-06,
      "loss": 0.2535,
      "step": 3784
    },
    {
      "epoch": 0.601617293516918,
      "grad_norm": 0.5420029759407043,
      "learning_rate": 3.6153807301445465e-06,
      "loss": 0.2222,
      "step": 3785
    },
    {
      "epoch": 0.6017762412827085,
      "grad_norm": 0.5633811354637146,
      "learning_rate": 3.612907355233207e-06,
      "loss": 0.22,
      "step": 3786
    },
    {
      "epoch": 0.601935189048499,
      "grad_norm": 0.4702411890029907,
      "learning_rate": 3.610434347994071e-06,
      "loss": 0.1292,
      "step": 3787
    },
    {
      "epoch": 0.6020941368142894,
      "grad_norm": 0.5195151567459106,
      "learning_rate": 3.6079617090826542e-06,
      "loss": 0.2141,
      "step": 3788
    },
    {
      "epoch": 0.6022530845800799,
      "grad_norm": 0.5169677734375,
      "learning_rate": 3.605489439154365e-06,
      "loss": 0.1241,
      "step": 3789
    },
    {
      "epoch": 0.6024120323458704,
      "grad_norm": 0.5529968738555908,
      "learning_rate": 3.6030175388645216e-06,
      "loss": 0.2278,
      "step": 3790
    },
    {
      "epoch": 0.6025709801116608,
      "grad_norm": 0.5382649302482605,
      "learning_rate": 3.600546008868347e-06,
      "loss": 0.2851,
      "step": 3791
    },
    {
      "epoch": 0.6027299278774513,
      "grad_norm": 0.6571096777915955,
      "learning_rate": 3.5980748498209562e-06,
      "loss": 0.29,
      "step": 3792
    },
    {
      "epoch": 0.6028888756432418,
      "grad_norm": 0.49035558104515076,
      "learning_rate": 3.5956040623773723e-06,
      "loss": 0.1833,
      "step": 3793
    },
    {
      "epoch": 0.6030478234090322,
      "grad_norm": 0.49460336565971375,
      "learning_rate": 3.5931336471925227e-06,
      "loss": 0.1879,
      "step": 3794
    },
    {
      "epoch": 0.6032067711748227,
      "grad_norm": 0.4671454131603241,
      "learning_rate": 3.5906636049212316e-06,
      "loss": 0.0856,
      "step": 3795
    },
    {
      "epoch": 0.6033657189406132,
      "grad_norm": 0.5103927254676819,
      "learning_rate": 3.5881939362182218e-06,
      "loss": 0.1959,
      "step": 3796
    },
    {
      "epoch": 0.6035246667064036,
      "grad_norm": 0.5952330827713013,
      "learning_rate": 3.5857246417381208e-06,
      "loss": 0.3006,
      "step": 3797
    },
    {
      "epoch": 0.6036836144721941,
      "grad_norm": 0.4540480971336365,
      "learning_rate": 3.583255722135462e-06,
      "loss": 0.1135,
      "step": 3798
    },
    {
      "epoch": 0.6038425622379845,
      "grad_norm": 0.530174732208252,
      "learning_rate": 3.5807871780646675e-06,
      "loss": 0.2226,
      "step": 3799
    },
    {
      "epoch": 0.604001510003775,
      "grad_norm": 0.5875234603881836,
      "learning_rate": 3.5783190101800684e-06,
      "loss": 0.2808,
      "step": 3800
    },
    {
      "epoch": 0.6041604577695655,
      "grad_norm": 0.5640597343444824,
      "learning_rate": 3.575851219135898e-06,
      "loss": 0.2839,
      "step": 3801
    },
    {
      "epoch": 0.6043194055353559,
      "grad_norm": 0.5683982372283936,
      "learning_rate": 3.57338380558628e-06,
      "loss": 0.2393,
      "step": 3802
    },
    {
      "epoch": 0.6044783533011464,
      "grad_norm": 0.4952806532382965,
      "learning_rate": 3.5709167701852453e-06,
      "loss": 0.1735,
      "step": 3803
    },
    {
      "epoch": 0.6046373010669369,
      "grad_norm": 1.212184190750122,
      "learning_rate": 3.5684501135867257e-06,
      "loss": 0.2371,
      "step": 3804
    },
    {
      "epoch": 0.6047962488327273,
      "grad_norm": 0.6384809017181396,
      "learning_rate": 3.5659838364445505e-06,
      "loss": 0.2268,
      "step": 3805
    },
    {
      "epoch": 0.6049551965985178,
      "grad_norm": 0.5176821947097778,
      "learning_rate": 3.5635179394124417e-06,
      "loss": 0.2344,
      "step": 3806
    },
    {
      "epoch": 0.6051141443643083,
      "grad_norm": 0.5174615979194641,
      "learning_rate": 3.5610524231440324e-06,
      "loss": 0.2003,
      "step": 3807
    },
    {
      "epoch": 0.6052730921300987,
      "grad_norm": 0.43407362699508667,
      "learning_rate": 3.5585872882928495e-06,
      "loss": 0.11,
      "step": 3808
    },
    {
      "epoch": 0.6054320398958892,
      "grad_norm": 0.47498103976249695,
      "learning_rate": 3.556122535512314e-06,
      "loss": 0.1684,
      "step": 3809
    },
    {
      "epoch": 0.6055909876616796,
      "grad_norm": 0.5222708582878113,
      "learning_rate": 3.5536581654557513e-06,
      "loss": 0.1813,
      "step": 3810
    },
    {
      "epoch": 0.6057499354274701,
      "grad_norm": 0.5585159659385681,
      "learning_rate": 3.5511941787763864e-06,
      "loss": 0.2651,
      "step": 3811
    },
    {
      "epoch": 0.6059088831932606,
      "grad_norm": 0.5502270460128784,
      "learning_rate": 3.5487305761273416e-06,
      "loss": 0.1655,
      "step": 3812
    },
    {
      "epoch": 0.606067830959051,
      "grad_norm": 0.5173018574714661,
      "learning_rate": 3.5462673581616298e-06,
      "loss": 0.2537,
      "step": 3813
    },
    {
      "epoch": 0.6062267787248415,
      "grad_norm": 0.4306131601333618,
      "learning_rate": 3.5438045255321735e-06,
      "loss": 0.0908,
      "step": 3814
    },
    {
      "epoch": 0.606385726490632,
      "grad_norm": 0.5485956072807312,
      "learning_rate": 3.5413420788917883e-06,
      "loss": 0.2146,
      "step": 3815
    },
    {
      "epoch": 0.6065446742564224,
      "grad_norm": 0.5036998391151428,
      "learning_rate": 3.5388800188931825e-06,
      "loss": 0.2133,
      "step": 3816
    },
    {
      "epoch": 0.606703622022213,
      "grad_norm": 0.562861979007721,
      "learning_rate": 3.53641834618897e-06,
      "loss": 0.3108,
      "step": 3817
    },
    {
      "epoch": 0.6068625697880035,
      "grad_norm": 0.42838814854621887,
      "learning_rate": 3.53395706143166e-06,
      "loss": 0.1459,
      "step": 3818
    },
    {
      "epoch": 0.6070215175537939,
      "grad_norm": 0.698029637336731,
      "learning_rate": 3.5314961652736517e-06,
      "loss": 0.1848,
      "step": 3819
    },
    {
      "epoch": 0.6071804653195844,
      "grad_norm": 0.5444474220275879,
      "learning_rate": 3.5290356583672514e-06,
      "loss": 0.2559,
      "step": 3820
    },
    {
      "epoch": 0.6073394130853749,
      "grad_norm": 0.5482245683670044,
      "learning_rate": 3.5265755413646574e-06,
      "loss": 0.2812,
      "step": 3821
    },
    {
      "epoch": 0.6074983608511653,
      "grad_norm": 0.5425117611885071,
      "learning_rate": 3.5241158149179654e-06,
      "loss": 0.0984,
      "step": 3822
    },
    {
      "epoch": 0.6076573086169558,
      "grad_norm": 0.5187798142433167,
      "learning_rate": 3.5216564796791636e-06,
      "loss": 0.0786,
      "step": 3823
    },
    {
      "epoch": 0.6078162563827462,
      "grad_norm": 0.6027572751045227,
      "learning_rate": 3.519197536300144e-06,
      "loss": 0.2196,
      "step": 3824
    },
    {
      "epoch": 0.6079752041485367,
      "grad_norm": 0.4668632745742798,
      "learning_rate": 3.5167389854326907e-06,
      "loss": 0.1664,
      "step": 3825
    },
    {
      "epoch": 0.6081341519143272,
      "grad_norm": 0.522043764591217,
      "learning_rate": 3.51428082772848e-06,
      "loss": 0.1988,
      "step": 3826
    },
    {
      "epoch": 0.6082930996801176,
      "grad_norm": 0.5750517249107361,
      "learning_rate": 3.5118230638390915e-06,
      "loss": 0.2745,
      "step": 3827
    },
    {
      "epoch": 0.6084520474459081,
      "grad_norm": 0.5071806907653809,
      "learning_rate": 3.5093656944159987e-06,
      "loss": 0.2048,
      "step": 3828
    },
    {
      "epoch": 0.6086109952116986,
      "grad_norm": 0.5175158381462097,
      "learning_rate": 3.506908720110562e-06,
      "loss": 0.1886,
      "step": 3829
    },
    {
      "epoch": 0.608769942977489,
      "grad_norm": 0.5345913767814636,
      "learning_rate": 3.504452141574049e-06,
      "loss": 0.2225,
      "step": 3830
    },
    {
      "epoch": 0.6089288907432795,
      "grad_norm": 0.5356401205062866,
      "learning_rate": 3.501995959457616e-06,
      "loss": 0.2318,
      "step": 3831
    },
    {
      "epoch": 0.60908783850907,
      "grad_norm": 0.567011833190918,
      "learning_rate": 3.499540174412315e-06,
      "loss": 0.233,
      "step": 3832
    },
    {
      "epoch": 0.6092467862748604,
      "grad_norm": 0.5559180974960327,
      "learning_rate": 3.497084787089092e-06,
      "loss": 0.2049,
      "step": 3833
    },
    {
      "epoch": 0.6094057340406509,
      "grad_norm": 0.603826105594635,
      "learning_rate": 3.4946297981387913e-06,
      "loss": 0.26,
      "step": 3834
    },
    {
      "epoch": 0.6095646818064414,
      "grad_norm": 0.5985497236251831,
      "learning_rate": 3.4921752082121467e-06,
      "loss": 0.2255,
      "step": 3835
    },
    {
      "epoch": 0.6097236295722318,
      "grad_norm": 0.6281833648681641,
      "learning_rate": 3.4897210179597884e-06,
      "loss": 0.3679,
      "step": 3836
    },
    {
      "epoch": 0.6098825773380223,
      "grad_norm": 0.5391944646835327,
      "learning_rate": 3.487267228032242e-06,
      "loss": 0.2468,
      "step": 3837
    },
    {
      "epoch": 0.6100415251038127,
      "grad_norm": 0.5557356476783752,
      "learning_rate": 3.4848138390799273e-06,
      "loss": 0.1995,
      "step": 3838
    },
    {
      "epoch": 0.6102004728696032,
      "grad_norm": 0.5423392057418823,
      "learning_rate": 3.482360851753151e-06,
      "loss": 0.1859,
      "step": 3839
    },
    {
      "epoch": 0.6103594206353937,
      "grad_norm": 0.564566969871521,
      "learning_rate": 3.479908266702122e-06,
      "loss": 0.2349,
      "step": 3840
    },
    {
      "epoch": 0.6105183684011841,
      "grad_norm": 0.5640186071395874,
      "learning_rate": 3.47745608457694e-06,
      "loss": 0.2941,
      "step": 3841
    },
    {
      "epoch": 0.6106773161669746,
      "grad_norm": 0.53472501039505,
      "learning_rate": 3.475004306027597e-06,
      "loss": 0.2302,
      "step": 3842
    },
    {
      "epoch": 0.6108362639327651,
      "grad_norm": 0.5985433459281921,
      "learning_rate": 3.472552931703975e-06,
      "loss": 0.1398,
      "step": 3843
    },
    {
      "epoch": 0.6109952116985555,
      "grad_norm": 0.5690467357635498,
      "learning_rate": 3.4701019622558554e-06,
      "loss": 0.2537,
      "step": 3844
    },
    {
      "epoch": 0.611154159464346,
      "grad_norm": 0.5946225523948669,
      "learning_rate": 3.4676513983329076e-06,
      "loss": 0.3199,
      "step": 3845
    },
    {
      "epoch": 0.6113131072301365,
      "grad_norm": 0.6037344932556152,
      "learning_rate": 3.4652012405846934e-06,
      "loss": 0.2776,
      "step": 3846
    },
    {
      "epoch": 0.6114720549959269,
      "grad_norm": 0.5392839908599854,
      "learning_rate": 3.4627514896606707e-06,
      "loss": 0.1954,
      "step": 3847
    },
    {
      "epoch": 0.6116310027617174,
      "grad_norm": 0.5671378970146179,
      "learning_rate": 3.4603021462101854e-06,
      "loss": 0.2352,
      "step": 3848
    },
    {
      "epoch": 0.611789950527508,
      "grad_norm": 0.509992241859436,
      "learning_rate": 3.457853210882477e-06,
      "loss": 0.2128,
      "step": 3849
    },
    {
      "epoch": 0.6119488982932983,
      "grad_norm": 0.5407853722572327,
      "learning_rate": 3.455404684326678e-06,
      "loss": 0.2297,
      "step": 3850
    },
    {
      "epoch": 0.6121078460590889,
      "grad_norm": 0.5072181224822998,
      "learning_rate": 3.452956567191811e-06,
      "loss": 0.1885,
      "step": 3851
    },
    {
      "epoch": 0.6122667938248793,
      "grad_norm": 0.5006399750709534,
      "learning_rate": 3.4505088601267913e-06,
      "loss": 0.1255,
      "step": 3852
    },
    {
      "epoch": 0.6124257415906698,
      "grad_norm": 0.6447387337684631,
      "learning_rate": 3.4480615637804228e-06,
      "loss": 0.2287,
      "step": 3853
    },
    {
      "epoch": 0.6125846893564603,
      "grad_norm": 0.48958152532577515,
      "learning_rate": 3.445614678801404e-06,
      "loss": 0.1847,
      "step": 3854
    },
    {
      "epoch": 0.6127436371222507,
      "grad_norm": 0.6194519996643066,
      "learning_rate": 3.443168205838323e-06,
      "loss": 0.3136,
      "step": 3855
    },
    {
      "epoch": 0.6129025848880412,
      "grad_norm": 0.6128250360488892,
      "learning_rate": 3.440722145539658e-06,
      "loss": 0.2313,
      "step": 3856
    },
    {
      "epoch": 0.6130615326538317,
      "grad_norm": 0.4620150625705719,
      "learning_rate": 3.4382764985537786e-06,
      "loss": 0.1823,
      "step": 3857
    },
    {
      "epoch": 0.6132204804196221,
      "grad_norm": 0.6293525695800781,
      "learning_rate": 3.435831265528945e-06,
      "loss": 0.1893,
      "step": 3858
    },
    {
      "epoch": 0.6133794281854126,
      "grad_norm": 0.47573062777519226,
      "learning_rate": 3.433386447113306e-06,
      "loss": 0.1561,
      "step": 3859
    },
    {
      "epoch": 0.6135383759512031,
      "grad_norm": 0.6342755556106567,
      "learning_rate": 3.4309420439549024e-06,
      "loss": 0.3194,
      "step": 3860
    },
    {
      "epoch": 0.6136973237169935,
      "grad_norm": 0.76969975233078,
      "learning_rate": 3.428498056701665e-06,
      "loss": 0.1887,
      "step": 3861
    },
    {
      "epoch": 0.613856271482784,
      "grad_norm": 0.6001958250999451,
      "learning_rate": 3.4260544860014145e-06,
      "loss": 0.2864,
      "step": 3862
    },
    {
      "epoch": 0.6140152192485744,
      "grad_norm": 0.5596015453338623,
      "learning_rate": 3.423611332501857e-06,
      "loss": 0.2276,
      "step": 3863
    },
    {
      "epoch": 0.6141741670143649,
      "grad_norm": 0.5278302431106567,
      "learning_rate": 3.4211685968505943e-06,
      "loss": 0.1981,
      "step": 3864
    },
    {
      "epoch": 0.6143331147801554,
      "grad_norm": 0.6202066540718079,
      "learning_rate": 3.4187262796951143e-06,
      "loss": 0.2826,
      "step": 3865
    },
    {
      "epoch": 0.6144920625459458,
      "grad_norm": 0.4473862946033478,
      "learning_rate": 3.416284381682793e-06,
      "loss": 0.1568,
      "step": 3866
    },
    {
      "epoch": 0.6146510103117363,
      "grad_norm": 0.6066824793815613,
      "learning_rate": 3.413842903460896e-06,
      "loss": 0.2489,
      "step": 3867
    },
    {
      "epoch": 0.6148099580775268,
      "grad_norm": 0.5377589464187622,
      "learning_rate": 3.4114018456765806e-06,
      "loss": 0.1859,
      "step": 3868
    },
    {
      "epoch": 0.6149689058433172,
      "grad_norm": 0.5252276062965393,
      "learning_rate": 3.408961208976888e-06,
      "loss": 0.2447,
      "step": 3869
    },
    {
      "epoch": 0.6151278536091077,
      "grad_norm": 0.8207385540008545,
      "learning_rate": 3.4065209940087507e-06,
      "loss": 0.1836,
      "step": 3870
    },
    {
      "epoch": 0.6152868013748982,
      "grad_norm": 0.5639455318450928,
      "learning_rate": 3.4040812014189883e-06,
      "loss": 0.282,
      "step": 3871
    },
    {
      "epoch": 0.6154457491406886,
      "grad_norm": 0.6818265914916992,
      "learning_rate": 3.40164183185431e-06,
      "loss": 0.3728,
      "step": 3872
    },
    {
      "epoch": 0.6156046969064791,
      "grad_norm": 0.43257591128349304,
      "learning_rate": 3.39920288596131e-06,
      "loss": 0.1141,
      "step": 3873
    },
    {
      "epoch": 0.6157636446722696,
      "grad_norm": 0.5382965207099915,
      "learning_rate": 3.3967643643864725e-06,
      "loss": 0.2854,
      "step": 3874
    },
    {
      "epoch": 0.61592259243806,
      "grad_norm": 0.5064506530761719,
      "learning_rate": 3.39432626777617e-06,
      "loss": 0.2044,
      "step": 3875
    },
    {
      "epoch": 0.6160815402038505,
      "grad_norm": 0.5584886074066162,
      "learning_rate": 3.3918885967766583e-06,
      "loss": 0.2805,
      "step": 3876
    },
    {
      "epoch": 0.6162404879696409,
      "grad_norm": 0.5695246458053589,
      "learning_rate": 3.389451352034085e-06,
      "loss": 0.3168,
      "step": 3877
    },
    {
      "epoch": 0.6163994357354314,
      "grad_norm": 0.4921927750110626,
      "learning_rate": 3.3870145341944825e-06,
      "loss": 0.1557,
      "step": 3878
    },
    {
      "epoch": 0.6165583835012219,
      "grad_norm": 0.5798964500427246,
      "learning_rate": 3.3845781439037695e-06,
      "loss": 0.2928,
      "step": 3879
    },
    {
      "epoch": 0.6167173312670123,
      "grad_norm": 0.6036869883537292,
      "learning_rate": 3.382142181807753e-06,
      "loss": 0.175,
      "step": 3880
    },
    {
      "epoch": 0.6168762790328028,
      "grad_norm": 0.6262246966362,
      "learning_rate": 3.3797066485521244e-06,
      "loss": 0.348,
      "step": 3881
    },
    {
      "epoch": 0.6170352267985934,
      "grad_norm": 0.5571284294128418,
      "learning_rate": 3.3772715447824657e-06,
      "loss": 0.2196,
      "step": 3882
    },
    {
      "epoch": 0.6171941745643837,
      "grad_norm": 0.5771488547325134,
      "learning_rate": 3.3748368711442386e-06,
      "loss": 0.2765,
      "step": 3883
    },
    {
      "epoch": 0.6173531223301743,
      "grad_norm": 0.5837367177009583,
      "learning_rate": 3.3724026282827954e-06,
      "loss": 0.3255,
      "step": 3884
    },
    {
      "epoch": 0.6175120700959648,
      "grad_norm": 0.5802327394485474,
      "learning_rate": 3.369968816843375e-06,
      "loss": 0.3177,
      "step": 3885
    },
    {
      "epoch": 0.6176710178617552,
      "grad_norm": 0.6766254305839539,
      "learning_rate": 3.3675354374710965e-06,
      "loss": 0.2596,
      "step": 3886
    },
    {
      "epoch": 0.6178299656275457,
      "grad_norm": 0.9004592895507812,
      "learning_rate": 3.3651024908109698e-06,
      "loss": 0.1068,
      "step": 3887
    },
    {
      "epoch": 0.6179889133933362,
      "grad_norm": 0.5119531750679016,
      "learning_rate": 3.3626699775078884e-06,
      "loss": 0.1831,
      "step": 3888
    },
    {
      "epoch": 0.6181478611591266,
      "grad_norm": 0.6178765892982483,
      "learning_rate": 3.360237898206632e-06,
      "loss": 0.3225,
      "step": 3889
    },
    {
      "epoch": 0.6183068089249171,
      "grad_norm": 2.0404419898986816,
      "learning_rate": 3.357806253551862e-06,
      "loss": 0.1946,
      "step": 3890
    },
    {
      "epoch": 0.6184657566907075,
      "grad_norm": 0.4666042625904083,
      "learning_rate": 3.3553750441881266e-06,
      "loss": 0.1659,
      "step": 3891
    },
    {
      "epoch": 0.618624704456498,
      "grad_norm": 0.5844752192497253,
      "learning_rate": 3.352944270759861e-06,
      "loss": 0.2634,
      "step": 3892
    },
    {
      "epoch": 0.6187836522222885,
      "grad_norm": 0.5687609910964966,
      "learning_rate": 3.3505139339113795e-06,
      "loss": 0.2353,
      "step": 3893
    },
    {
      "epoch": 0.6189425999880789,
      "grad_norm": 0.6984485983848572,
      "learning_rate": 3.348084034286886e-06,
      "loss": 0.3489,
      "step": 3894
    },
    {
      "epoch": 0.6191015477538694,
      "grad_norm": 0.6529414057731628,
      "learning_rate": 3.3456545725304658e-06,
      "loss": 0.3358,
      "step": 3895
    },
    {
      "epoch": 0.6192604955196599,
      "grad_norm": 0.7569276094436646,
      "learning_rate": 3.343225549286087e-06,
      "loss": 0.2336,
      "step": 3896
    },
    {
      "epoch": 0.6194194432854503,
      "grad_norm": 0.46540260314941406,
      "learning_rate": 3.3407969651976045e-06,
      "loss": 0.1577,
      "step": 3897
    },
    {
      "epoch": 0.6195783910512408,
      "grad_norm": 0.860538899898529,
      "learning_rate": 3.338368820908755e-06,
      "loss": 0.2997,
      "step": 3898
    },
    {
      "epoch": 0.6197373388170313,
      "grad_norm": 0.7107812166213989,
      "learning_rate": 3.3359411170631595e-06,
      "loss": 0.3032,
      "step": 3899
    },
    {
      "epoch": 0.6198962865828217,
      "grad_norm": 0.5067008137702942,
      "learning_rate": 3.3335138543043203e-06,
      "loss": 0.1893,
      "step": 3900
    },
    {
      "epoch": 0.6200552343486122,
      "grad_norm": 0.5894084572792053,
      "learning_rate": 3.331087033275625e-06,
      "loss": 0.2269,
      "step": 3901
    },
    {
      "epoch": 0.6202141821144026,
      "grad_norm": 0.4779911935329437,
      "learning_rate": 3.3286606546203443e-06,
      "loss": 0.1381,
      "step": 3902
    },
    {
      "epoch": 0.6203731298801931,
      "grad_norm": 0.9043981432914734,
      "learning_rate": 3.326234718981628e-06,
      "loss": 0.2111,
      "step": 3903
    },
    {
      "epoch": 0.6205320776459836,
      "grad_norm": 0.5061827898025513,
      "learning_rate": 3.3238092270025135e-06,
      "loss": 0.1763,
      "step": 3904
    },
    {
      "epoch": 0.620691025411774,
      "grad_norm": 0.6293509006500244,
      "learning_rate": 3.321384179325918e-06,
      "loss": 0.3049,
      "step": 3905
    },
    {
      "epoch": 0.6208499731775645,
      "grad_norm": 0.4791627526283264,
      "learning_rate": 3.3189595765946394e-06,
      "loss": 0.168,
      "step": 3906
    },
    {
      "epoch": 0.621008920943355,
      "grad_norm": 1.0009841918945312,
      "learning_rate": 3.31653541945136e-06,
      "loss": 0.2316,
      "step": 3907
    },
    {
      "epoch": 0.6211678687091454,
      "grad_norm": 0.6780681610107422,
      "learning_rate": 3.314111708538644e-06,
      "loss": 0.2685,
      "step": 3908
    },
    {
      "epoch": 0.6213268164749359,
      "grad_norm": 0.49108806252479553,
      "learning_rate": 3.311688444498937e-06,
      "loss": 0.1846,
      "step": 3909
    },
    {
      "epoch": 0.6214857642407264,
      "grad_norm": 0.6127731204032898,
      "learning_rate": 3.309265627974565e-06,
      "loss": 0.3234,
      "step": 3910
    },
    {
      "epoch": 0.6216447120065168,
      "grad_norm": 0.5576938986778259,
      "learning_rate": 3.3068432596077366e-06,
      "loss": 0.2165,
      "step": 3911
    },
    {
      "epoch": 0.6218036597723073,
      "grad_norm": 0.5525933504104614,
      "learning_rate": 3.3044213400405415e-06,
      "loss": 0.2728,
      "step": 3912
    },
    {
      "epoch": 0.6219626075380978,
      "grad_norm": 0.4943189024925232,
      "learning_rate": 3.301999869914949e-06,
      "loss": 0.1852,
      "step": 3913
    },
    {
      "epoch": 0.6221215553038882,
      "grad_norm": 0.5458701252937317,
      "learning_rate": 3.299578849872812e-06,
      "loss": 0.2256,
      "step": 3914
    },
    {
      "epoch": 0.6222805030696787,
      "grad_norm": 0.5429419875144958,
      "learning_rate": 3.2971582805558622e-06,
      "loss": 0.2379,
      "step": 3915
    },
    {
      "epoch": 0.6224394508354691,
      "grad_norm": 0.5550749897956848,
      "learning_rate": 3.29473816260571e-06,
      "loss": 0.2661,
      "step": 3916
    },
    {
      "epoch": 0.6225983986012597,
      "grad_norm": 0.5184328556060791,
      "learning_rate": 3.292318496663851e-06,
      "loss": 0.1277,
      "step": 3917
    },
    {
      "epoch": 0.6227573463670502,
      "grad_norm": 0.6037155985832214,
      "learning_rate": 3.289899283371657e-06,
      "loss": 0.3044,
      "step": 3918
    },
    {
      "epoch": 0.6229162941328406,
      "grad_norm": 0.41407227516174316,
      "learning_rate": 3.287480523370382e-06,
      "loss": 0.13,
      "step": 3919
    },
    {
      "epoch": 0.6230752418986311,
      "grad_norm": 0.5613107085227966,
      "learning_rate": 3.285062217301158e-06,
      "loss": 0.2504,
      "step": 3920
    },
    {
      "epoch": 0.6232341896644216,
      "grad_norm": 0.4882543683052063,
      "learning_rate": 3.2826443658049977e-06,
      "loss": 0.1553,
      "step": 3921
    },
    {
      "epoch": 0.623393137430212,
      "grad_norm": 0.6388324499130249,
      "learning_rate": 3.2802269695227945e-06,
      "loss": 0.313,
      "step": 3922
    },
    {
      "epoch": 0.6235520851960025,
      "grad_norm": 0.5040161609649658,
      "learning_rate": 3.2778100290953184e-06,
      "loss": 0.2143,
      "step": 3923
    },
    {
      "epoch": 0.623711032961793,
      "grad_norm": 0.5687873959541321,
      "learning_rate": 3.27539354516322e-06,
      "loss": 0.2132,
      "step": 3924
    },
    {
      "epoch": 0.6238699807275834,
      "grad_norm": 0.6765123605728149,
      "learning_rate": 3.272977518367031e-06,
      "loss": 0.3556,
      "step": 3925
    },
    {
      "epoch": 0.6240289284933739,
      "grad_norm": 0.6021995544433594,
      "learning_rate": 3.2705619493471573e-06,
      "loss": 0.2436,
      "step": 3926
    },
    {
      "epoch": 0.6241878762591644,
      "grad_norm": 0.5592111945152283,
      "learning_rate": 3.2681468387438876e-06,
      "loss": 0.2679,
      "step": 3927
    },
    {
      "epoch": 0.6243468240249548,
      "grad_norm": 0.6069043874740601,
      "learning_rate": 3.2657321871973857e-06,
      "loss": 0.3197,
      "step": 3928
    },
    {
      "epoch": 0.6245057717907453,
      "grad_norm": 0.6133748292922974,
      "learning_rate": 3.2633179953477e-06,
      "loss": 0.3276,
      "step": 3929
    },
    {
      "epoch": 0.6246647195565357,
      "grad_norm": 0.5223662853240967,
      "learning_rate": 3.2609042638347475e-06,
      "loss": 0.1647,
      "step": 3930
    },
    {
      "epoch": 0.6248236673223262,
      "grad_norm": 0.552376389503479,
      "learning_rate": 3.258490993298331e-06,
      "loss": 0.1388,
      "step": 3931
    },
    {
      "epoch": 0.6249826150881167,
      "grad_norm": 0.6835114359855652,
      "learning_rate": 3.2560781843781287e-06,
      "loss": 0.3169,
      "step": 3932
    },
    {
      "epoch": 0.6251415628539071,
      "grad_norm": 0.6873213648796082,
      "learning_rate": 3.253665837713694e-06,
      "loss": 0.3368,
      "step": 3933
    },
    {
      "epoch": 0.6253005106196976,
      "grad_norm": 0.5079847574234009,
      "learning_rate": 3.251253953944461e-06,
      "loss": 0.1817,
      "step": 3934
    },
    {
      "epoch": 0.6254594583854881,
      "grad_norm": 0.5198132991790771,
      "learning_rate": 3.2488425337097405e-06,
      "loss": 0.1605,
      "step": 3935
    },
    {
      "epoch": 0.6256184061512785,
      "grad_norm": 0.4610375463962555,
      "learning_rate": 3.2464315776487193e-06,
      "loss": 0.1317,
      "step": 3936
    },
    {
      "epoch": 0.625777353917069,
      "grad_norm": 0.47266221046447754,
      "learning_rate": 3.2440210864004617e-06,
      "loss": 0.1683,
      "step": 3937
    },
    {
      "epoch": 0.6259363016828595,
      "grad_norm": 0.5719338655471802,
      "learning_rate": 3.2416110606039086e-06,
      "loss": 0.2277,
      "step": 3938
    },
    {
      "epoch": 0.6260952494486499,
      "grad_norm": 0.5912227034568787,
      "learning_rate": 3.239201500897881e-06,
      "loss": 0.2514,
      "step": 3939
    },
    {
      "epoch": 0.6262541972144404,
      "grad_norm": 0.5196862816810608,
      "learning_rate": 3.236792407921069e-06,
      "loss": 0.207,
      "step": 3940
    },
    {
      "epoch": 0.6264131449802308,
      "grad_norm": 0.5718693137168884,
      "learning_rate": 3.2343837823120433e-06,
      "loss": 0.2234,
      "step": 3941
    },
    {
      "epoch": 0.6265720927460213,
      "grad_norm": 0.5475995540618896,
      "learning_rate": 3.2319756247092552e-06,
      "loss": 0.2089,
      "step": 3942
    },
    {
      "epoch": 0.6267310405118118,
      "grad_norm": 0.5726010203361511,
      "learning_rate": 3.2295679357510224e-06,
      "loss": 0.2344,
      "step": 3943
    },
    {
      "epoch": 0.6268899882776022,
      "grad_norm": 2.9718005657196045,
      "learning_rate": 3.2271607160755435e-06,
      "loss": 0.1539,
      "step": 3944
    },
    {
      "epoch": 0.6270489360433927,
      "grad_norm": 0.6004242897033691,
      "learning_rate": 3.224753966320898e-06,
      "loss": 0.2559,
      "step": 3945
    },
    {
      "epoch": 0.6272078838091832,
      "grad_norm": 1.2349926233291626,
      "learning_rate": 3.222347687125029e-06,
      "loss": 0.1447,
      "step": 3946
    },
    {
      "epoch": 0.6273668315749736,
      "grad_norm": 0.6495650410652161,
      "learning_rate": 3.2199418791257635e-06,
      "loss": 0.2084,
      "step": 3947
    },
    {
      "epoch": 0.6275257793407641,
      "grad_norm": 0.49524345993995667,
      "learning_rate": 3.217536542960801e-06,
      "loss": 0.1931,
      "step": 3948
    },
    {
      "epoch": 0.6276847271065547,
      "grad_norm": 0.49046728014945984,
      "learning_rate": 3.215131679267719e-06,
      "loss": 0.0928,
      "step": 3949
    },
    {
      "epoch": 0.627843674872345,
      "grad_norm": 0.5482075214385986,
      "learning_rate": 3.2127272886839626e-06,
      "loss": 0.2176,
      "step": 3950
    },
    {
      "epoch": 0.6280026226381356,
      "grad_norm": 0.5254293084144592,
      "learning_rate": 3.2103233718468574e-06,
      "loss": 0.1814,
      "step": 3951
    },
    {
      "epoch": 0.6281615704039261,
      "grad_norm": 0.5326969027519226,
      "learning_rate": 3.207919929393606e-06,
      "loss": 0.152,
      "step": 3952
    },
    {
      "epoch": 0.6283205181697165,
      "grad_norm": 0.6220924258232117,
      "learning_rate": 3.205516961961275e-06,
      "loss": 0.2645,
      "step": 3953
    },
    {
      "epoch": 0.628479465935507,
      "grad_norm": 0.45458850264549255,
      "learning_rate": 3.203114470186813e-06,
      "loss": 0.1312,
      "step": 3954
    },
    {
      "epoch": 0.6286384137012974,
      "grad_norm": 0.5089741945266724,
      "learning_rate": 3.2007124547070436e-06,
      "loss": 0.2212,
      "step": 3955
    },
    {
      "epoch": 0.6287973614670879,
      "grad_norm": 0.5046517252922058,
      "learning_rate": 3.1983109161586613e-06,
      "loss": 0.1893,
      "step": 3956
    },
    {
      "epoch": 0.6289563092328784,
      "grad_norm": 0.5148112773895264,
      "learning_rate": 3.1959098551782285e-06,
      "loss": 0.1952,
      "step": 3957
    },
    {
      "epoch": 0.6291152569986688,
      "grad_norm": 0.6706193685531616,
      "learning_rate": 3.193509272402193e-06,
      "loss": 0.3147,
      "step": 3958
    },
    {
      "epoch": 0.6292742047644593,
      "grad_norm": 0.5790964365005493,
      "learning_rate": 3.1911091684668694e-06,
      "loss": 0.2071,
      "step": 3959
    },
    {
      "epoch": 0.6294331525302498,
      "grad_norm": 0.6057375073432922,
      "learning_rate": 3.1887095440084402e-06,
      "loss": 0.3275,
      "step": 3960
    },
    {
      "epoch": 0.6295921002960402,
      "grad_norm": 0.4937993288040161,
      "learning_rate": 3.1863103996629697e-06,
      "loss": 0.2323,
      "step": 3961
    },
    {
      "epoch": 0.6297510480618307,
      "grad_norm": 0.6214837431907654,
      "learning_rate": 3.183911736066394e-06,
      "loss": 0.2783,
      "step": 3962
    },
    {
      "epoch": 0.6299099958276212,
      "grad_norm": 0.540605366230011,
      "learning_rate": 3.181513553854514e-06,
      "loss": 0.2388,
      "step": 3963
    },
    {
      "epoch": 0.6300689435934116,
      "grad_norm": 0.6152628064155579,
      "learning_rate": 3.1791158536630095e-06,
      "loss": 0.2309,
      "step": 3964
    },
    {
      "epoch": 0.6302278913592021,
      "grad_norm": 0.5476465821266174,
      "learning_rate": 3.176718636127434e-06,
      "loss": 0.1922,
      "step": 3965
    },
    {
      "epoch": 0.6303868391249926,
      "grad_norm": 0.6532779335975647,
      "learning_rate": 3.1743219018832093e-06,
      "loss": 0.2173,
      "step": 3966
    },
    {
      "epoch": 0.630545786890783,
      "grad_norm": 0.4963129162788391,
      "learning_rate": 3.171925651565627e-06,
      "loss": 0.194,
      "step": 3967
    },
    {
      "epoch": 0.6307047346565735,
      "grad_norm": 0.5309113264083862,
      "learning_rate": 3.1695298858098564e-06,
      "loss": 0.2383,
      "step": 3968
    },
    {
      "epoch": 0.6308636824223639,
      "grad_norm": 0.5127373337745667,
      "learning_rate": 3.167134605250938e-06,
      "loss": 0.1863,
      "step": 3969
    },
    {
      "epoch": 0.6310226301881544,
      "grad_norm": 0.5769792199134827,
      "learning_rate": 3.1647398105237736e-06,
      "loss": 0.2118,
      "step": 3970
    },
    {
      "epoch": 0.6311815779539449,
      "grad_norm": 0.5011568069458008,
      "learning_rate": 3.1623455022631493e-06,
      "loss": 0.1631,
      "step": 3971
    },
    {
      "epoch": 0.6313405257197353,
      "grad_norm": 0.6219683885574341,
      "learning_rate": 3.1599516811037177e-06,
      "loss": 0.3057,
      "step": 3972
    },
    {
      "epoch": 0.6314994734855258,
      "grad_norm": 0.7661803364753723,
      "learning_rate": 3.1575583476799975e-06,
      "loss": 0.2667,
      "step": 3973
    },
    {
      "epoch": 0.6316584212513163,
      "grad_norm": 0.5790497064590454,
      "learning_rate": 3.155165502626382e-06,
      "loss": 0.2956,
      "step": 3974
    },
    {
      "epoch": 0.6318173690171067,
      "grad_norm": 0.5314220190048218,
      "learning_rate": 3.152773146577138e-06,
      "loss": 0.1978,
      "step": 3975
    },
    {
      "epoch": 0.6319763167828972,
      "grad_norm": 0.5574676990509033,
      "learning_rate": 3.1503812801664003e-06,
      "loss": 0.2558,
      "step": 3976
    },
    {
      "epoch": 0.6321352645486877,
      "grad_norm": 0.5755628943443298,
      "learning_rate": 3.147989904028168e-06,
      "loss": 0.1645,
      "step": 3977
    },
    {
      "epoch": 0.6322942123144781,
      "grad_norm": 0.6570416688919067,
      "learning_rate": 3.14559901879632e-06,
      "loss": 0.2693,
      "step": 3978
    },
    {
      "epoch": 0.6324531600802686,
      "grad_norm": 0.5039469003677368,
      "learning_rate": 3.1432086251046006e-06,
      "loss": 0.1408,
      "step": 3979
    },
    {
      "epoch": 0.632612107846059,
      "grad_norm": 0.6669409275054932,
      "learning_rate": 3.14081872358662e-06,
      "loss": 0.3273,
      "step": 3980
    },
    {
      "epoch": 0.6327710556118495,
      "grad_norm": 0.9877428412437439,
      "learning_rate": 3.138429314875865e-06,
      "loss": 0.2848,
      "step": 3981
    },
    {
      "epoch": 0.63293000337764,
      "grad_norm": 0.47325748205184937,
      "learning_rate": 3.13604039960569e-06,
      "loss": 0.1386,
      "step": 3982
    },
    {
      "epoch": 0.6330889511434304,
      "grad_norm": 0.7204598784446716,
      "learning_rate": 3.133651978409311e-06,
      "loss": 0.1452,
      "step": 3983
    },
    {
      "epoch": 0.633247898909221,
      "grad_norm": 0.6398553252220154,
      "learning_rate": 3.131264051919825e-06,
      "loss": 0.1882,
      "step": 3984
    },
    {
      "epoch": 0.6334068466750115,
      "grad_norm": 0.5359397530555725,
      "learning_rate": 3.1288766207701894e-06,
      "loss": 0.1977,
      "step": 3985
    },
    {
      "epoch": 0.6335657944408019,
      "grad_norm": 0.6088843941688538,
      "learning_rate": 3.1264896855932346e-06,
      "loss": 0.2451,
      "step": 3986
    },
    {
      "epoch": 0.6337247422065924,
      "grad_norm": 0.5223645567893982,
      "learning_rate": 3.1241032470216564e-06,
      "loss": 0.1617,
      "step": 3987
    },
    {
      "epoch": 0.6338836899723829,
      "grad_norm": 0.7455655932426453,
      "learning_rate": 3.12171730568802e-06,
      "loss": 0.2597,
      "step": 3988
    },
    {
      "epoch": 0.6340426377381733,
      "grad_norm": 0.6693089008331299,
      "learning_rate": 3.1193318622247624e-06,
      "loss": 0.2964,
      "step": 3989
    },
    {
      "epoch": 0.6342015855039638,
      "grad_norm": 0.6657364368438721,
      "learning_rate": 3.1169469172641807e-06,
      "loss": 0.2884,
      "step": 3990
    },
    {
      "epoch": 0.6343605332697543,
      "grad_norm": 0.515089750289917,
      "learning_rate": 3.1145624714384477e-06,
      "loss": 0.1981,
      "step": 3991
    },
    {
      "epoch": 0.6345194810355447,
      "grad_norm": 0.5760700702667236,
      "learning_rate": 3.112178525379602e-06,
      "loss": 0.22,
      "step": 3992
    },
    {
      "epoch": 0.6346784288013352,
      "grad_norm": 0.457807332277298,
      "learning_rate": 3.109795079719544e-06,
      "loss": 0.1544,
      "step": 3993
    },
    {
      "epoch": 0.6348373765671256,
      "grad_norm": 0.5596691966056824,
      "learning_rate": 3.1074121350900487e-06,
      "loss": 0.2281,
      "step": 3994
    },
    {
      "epoch": 0.6349963243329161,
      "grad_norm": 0.445812851190567,
      "learning_rate": 3.1050296921227563e-06,
      "loss": 0.1193,
      "step": 3995
    },
    {
      "epoch": 0.6351552720987066,
      "grad_norm": 0.7179731130599976,
      "learning_rate": 3.102647751449174e-06,
      "loss": 0.4784,
      "step": 3996
    },
    {
      "epoch": 0.635314219864497,
      "grad_norm": 0.5052682161331177,
      "learning_rate": 3.1002663137006723e-06,
      "loss": 0.1912,
      "step": 3997
    },
    {
      "epoch": 0.6354731676302875,
      "grad_norm": 0.48156654834747314,
      "learning_rate": 3.097885379508493e-06,
      "loss": 0.1872,
      "step": 3998
    },
    {
      "epoch": 0.635632115396078,
      "grad_norm": 0.6038041114807129,
      "learning_rate": 3.0955049495037435e-06,
      "loss": 0.3089,
      "step": 3999
    },
    {
      "epoch": 0.6357910631618684,
      "grad_norm": 0.5769513249397278,
      "learning_rate": 3.093125024317395e-06,
      "loss": 0.3064,
      "step": 4000
    },
    {
      "epoch": 0.6359500109276589,
      "grad_norm": 0.9568398594856262,
      "learning_rate": 3.0907456045802863e-06,
      "loss": 0.1691,
      "step": 4001
    },
    {
      "epoch": 0.6361089586934494,
      "grad_norm": 0.6696579456329346,
      "learning_rate": 3.088366690923127e-06,
      "loss": 0.3242,
      "step": 4002
    },
    {
      "epoch": 0.6362679064592398,
      "grad_norm": 0.5589609742164612,
      "learning_rate": 3.085988283976481e-06,
      "loss": 0.1328,
      "step": 4003
    },
    {
      "epoch": 0.6364268542250303,
      "grad_norm": 0.7070645689964294,
      "learning_rate": 3.08361038437079e-06,
      "loss": 0.3513,
      "step": 4004
    },
    {
      "epoch": 0.6365858019908208,
      "grad_norm": 0.5858213305473328,
      "learning_rate": 3.081232992736355e-06,
      "loss": 0.2622,
      "step": 4005
    },
    {
      "epoch": 0.6367447497566112,
      "grad_norm": 0.586919367313385,
      "learning_rate": 3.078856109703344e-06,
      "loss": 0.2501,
      "step": 4006
    },
    {
      "epoch": 0.6369036975224017,
      "grad_norm": 0.5548281073570251,
      "learning_rate": 3.0764797359017894e-06,
      "loss": 0.1963,
      "step": 4007
    },
    {
      "epoch": 0.6370626452881921,
      "grad_norm": 0.4610653519630432,
      "learning_rate": 3.0741038719615883e-06,
      "loss": 0.147,
      "step": 4008
    },
    {
      "epoch": 0.6372215930539826,
      "grad_norm": 0.5990642309188843,
      "learning_rate": 3.071728518512505e-06,
      "loss": 0.2884,
      "step": 4009
    },
    {
      "epoch": 0.6373805408197731,
      "grad_norm": 0.5986189246177673,
      "learning_rate": 3.069353676184165e-06,
      "loss": 0.2711,
      "step": 4010
    },
    {
      "epoch": 0.6375394885855635,
      "grad_norm": 0.5119013786315918,
      "learning_rate": 3.0669793456060613e-06,
      "loss": 0.2031,
      "step": 4011
    },
    {
      "epoch": 0.637698436351354,
      "grad_norm": 0.5747219324111938,
      "learning_rate": 3.0646055274075504e-06,
      "loss": 0.2344,
      "step": 4012
    },
    {
      "epoch": 0.6378573841171445,
      "grad_norm": 0.572881281375885,
      "learning_rate": 3.0622322222178512e-06,
      "loss": 0.2762,
      "step": 4013
    },
    {
      "epoch": 0.6380163318829349,
      "grad_norm": 0.4765254259109497,
      "learning_rate": 3.059859430666049e-06,
      "loss": 0.1509,
      "step": 4014
    },
    {
      "epoch": 0.6381752796487254,
      "grad_norm": 0.9861600399017334,
      "learning_rate": 3.057487153381092e-06,
      "loss": 0.2664,
      "step": 4015
    },
    {
      "epoch": 0.638334227414516,
      "grad_norm": 0.49147364497184753,
      "learning_rate": 3.055115390991793e-06,
      "loss": 0.1654,
      "step": 4016
    },
    {
      "epoch": 0.6384931751803063,
      "grad_norm": 0.6179282069206238,
      "learning_rate": 3.052744144126826e-06,
      "loss": 0.2009,
      "step": 4017
    },
    {
      "epoch": 0.6386521229460969,
      "grad_norm": 0.6823087930679321,
      "learning_rate": 3.05037341341473e-06,
      "loss": 0.2471,
      "step": 4018
    },
    {
      "epoch": 0.6388110707118873,
      "grad_norm": 0.5613659620285034,
      "learning_rate": 3.048003199483909e-06,
      "loss": 0.1687,
      "step": 4019
    },
    {
      "epoch": 0.6389700184776778,
      "grad_norm": 0.5294617414474487,
      "learning_rate": 3.0456335029626245e-06,
      "loss": 0.2506,
      "step": 4020
    },
    {
      "epoch": 0.6391289662434683,
      "grad_norm": 0.5674716234207153,
      "learning_rate": 3.043264324479007e-06,
      "loss": 0.2361,
      "step": 4021
    },
    {
      "epoch": 0.6392879140092587,
      "grad_norm": 0.6446879506111145,
      "learning_rate": 3.040895664661046e-06,
      "loss": 0.2213,
      "step": 4022
    },
    {
      "epoch": 0.6394468617750492,
      "grad_norm": 0.6387301683425903,
      "learning_rate": 3.0385275241365965e-06,
      "loss": 0.2928,
      "step": 4023
    },
    {
      "epoch": 0.6396058095408397,
      "grad_norm": 0.6491265892982483,
      "learning_rate": 3.0361599035333705e-06,
      "loss": 0.2177,
      "step": 4024
    },
    {
      "epoch": 0.6397647573066301,
      "grad_norm": 0.5928146839141846,
      "learning_rate": 3.0337928034789475e-06,
      "loss": 0.2396,
      "step": 4025
    },
    {
      "epoch": 0.6399237050724206,
      "grad_norm": 0.6156557202339172,
      "learning_rate": 3.0314262246007684e-06,
      "loss": 0.2134,
      "step": 4026
    },
    {
      "epoch": 0.6400826528382111,
      "grad_norm": 1.1610182523727417,
      "learning_rate": 3.029060167526133e-06,
      "loss": 0.1381,
      "step": 4027
    },
    {
      "epoch": 0.6402416006040015,
      "grad_norm": 0.6597337126731873,
      "learning_rate": 3.0266946328822045e-06,
      "loss": 0.2584,
      "step": 4028
    },
    {
      "epoch": 0.640400548369792,
      "grad_norm": 0.5221891403198242,
      "learning_rate": 3.024329621296008e-06,
      "loss": 0.1615,
      "step": 4029
    },
    {
      "epoch": 0.6405594961355825,
      "grad_norm": 0.613548219203949,
      "learning_rate": 3.02196513339443e-06,
      "loss": 0.2876,
      "step": 4030
    },
    {
      "epoch": 0.6407184439013729,
      "grad_norm": 0.5740320682525635,
      "learning_rate": 3.019601169804216e-06,
      "loss": 0.2904,
      "step": 4031
    },
    {
      "epoch": 0.6408773916671634,
      "grad_norm": 0.47611743211746216,
      "learning_rate": 3.017237731151976e-06,
      "loss": 0.1699,
      "step": 4032
    },
    {
      "epoch": 0.6410363394329538,
      "grad_norm": 0.7223385572433472,
      "learning_rate": 3.0148748180641797e-06,
      "loss": 0.1484,
      "step": 4033
    },
    {
      "epoch": 0.6411952871987443,
      "grad_norm": 0.4719396233558655,
      "learning_rate": 3.0125124311671546e-06,
      "loss": 0.1203,
      "step": 4034
    },
    {
      "epoch": 0.6413542349645348,
      "grad_norm": 0.5988761782646179,
      "learning_rate": 3.0101505710870914e-06,
      "loss": 0.2468,
      "step": 4035
    },
    {
      "epoch": 0.6415131827303252,
      "grad_norm": 0.4725465178489685,
      "learning_rate": 3.007789238450044e-06,
      "loss": 0.169,
      "step": 4036
    },
    {
      "epoch": 0.6416721304961157,
      "grad_norm": 0.44939833879470825,
      "learning_rate": 3.005428433881919e-06,
      "loss": 0.0771,
      "step": 4037
    },
    {
      "epoch": 0.6418310782619062,
      "grad_norm": 0.591638445854187,
      "learning_rate": 3.003068158008489e-06,
      "loss": 0.2207,
      "step": 4038
    },
    {
      "epoch": 0.6419900260276966,
      "grad_norm": 0.5489819645881653,
      "learning_rate": 3.0007084114553866e-06,
      "loss": 0.2066,
      "step": 4039
    },
    {
      "epoch": 0.6421489737934871,
      "grad_norm": 0.4549437165260315,
      "learning_rate": 2.998349194848099e-06,
      "loss": 0.1241,
      "step": 4040
    },
    {
      "epoch": 0.6423079215592776,
      "grad_norm": 0.536156952381134,
      "learning_rate": 2.9959905088119777e-06,
      "loss": 0.2161,
      "step": 4041
    },
    {
      "epoch": 0.642466869325068,
      "grad_norm": 0.5513420701026917,
      "learning_rate": 2.993632353972233e-06,
      "loss": 0.2258,
      "step": 4042
    },
    {
      "epoch": 0.6426258170908585,
      "grad_norm": 0.5841662287712097,
      "learning_rate": 2.9912747309539324e-06,
      "loss": 0.1735,
      "step": 4043
    },
    {
      "epoch": 0.642784764856649,
      "grad_norm": 0.6580124497413635,
      "learning_rate": 2.9889176403820037e-06,
      "loss": 0.2857,
      "step": 4044
    },
    {
      "epoch": 0.6429437126224394,
      "grad_norm": 0.5220490097999573,
      "learning_rate": 2.986561082881233e-06,
      "loss": 0.2086,
      "step": 4045
    },
    {
      "epoch": 0.6431026603882299,
      "grad_norm": 0.5635796785354614,
      "learning_rate": 2.984205059076266e-06,
      "loss": 0.1956,
      "step": 4046
    },
    {
      "epoch": 0.6432616081540203,
      "grad_norm": 0.6055952310562134,
      "learning_rate": 2.981849569591606e-06,
      "loss": 0.3216,
      "step": 4047
    },
    {
      "epoch": 0.6434205559198108,
      "grad_norm": 0.5282149314880371,
      "learning_rate": 2.9794946150516153e-06,
      "loss": 0.1304,
      "step": 4048
    },
    {
      "epoch": 0.6435795036856014,
      "grad_norm": 0.5879958868026733,
      "learning_rate": 2.9771401960805147e-06,
      "loss": 0.2877,
      "step": 4049
    },
    {
      "epoch": 0.6437384514513917,
      "grad_norm": 0.5772281289100647,
      "learning_rate": 2.9747863133023803e-06,
      "loss": 0.2599,
      "step": 4050
    },
    {
      "epoch": 0.6438973992171823,
      "grad_norm": 0.5537718534469604,
      "learning_rate": 2.9724329673411505e-06,
      "loss": 0.2786,
      "step": 4051
    },
    {
      "epoch": 0.6440563469829728,
      "grad_norm": 0.4565299451351166,
      "learning_rate": 2.9700801588206186e-06,
      "loss": 0.1198,
      "step": 4052
    },
    {
      "epoch": 0.6442152947487632,
      "grad_norm": 0.5322233438491821,
      "learning_rate": 2.9677278883644367e-06,
      "loss": 0.2775,
      "step": 4053
    },
    {
      "epoch": 0.6443742425145537,
      "grad_norm": 0.5660643577575684,
      "learning_rate": 2.9653761565961116e-06,
      "loss": 0.2065,
      "step": 4054
    },
    {
      "epoch": 0.6445331902803442,
      "grad_norm": 0.5652996301651001,
      "learning_rate": 2.96302496413901e-06,
      "loss": 0.2241,
      "step": 4055
    },
    {
      "epoch": 0.6446921380461346,
      "grad_norm": 0.5118306279182434,
      "learning_rate": 2.960674311616357e-06,
      "loss": 0.184,
      "step": 4056
    },
    {
      "epoch": 0.6448510858119251,
      "grad_norm": 0.6149147748947144,
      "learning_rate": 2.95832419965123e-06,
      "loss": 0.2031,
      "step": 4057
    },
    {
      "epoch": 0.6450100335777155,
      "grad_norm": 0.5932053327560425,
      "learning_rate": 2.955974628866567e-06,
      "loss": 0.2282,
      "step": 4058
    },
    {
      "epoch": 0.645168981343506,
      "grad_norm": 0.5844704508781433,
      "learning_rate": 2.9536255998851615e-06,
      "loss": 0.2812,
      "step": 4059
    },
    {
      "epoch": 0.6453279291092965,
      "grad_norm": 0.5533096790313721,
      "learning_rate": 2.9512771133296613e-06,
      "loss": 0.1959,
      "step": 4060
    },
    {
      "epoch": 0.6454868768750869,
      "grad_norm": 0.6351448893547058,
      "learning_rate": 2.948929169822573e-06,
      "loss": 0.1551,
      "step": 4061
    },
    {
      "epoch": 0.6456458246408774,
      "grad_norm": 0.5145891904830933,
      "learning_rate": 2.946581769986259e-06,
      "loss": 0.2071,
      "step": 4062
    },
    {
      "epoch": 0.6458047724066679,
      "grad_norm": 0.5425848960876465,
      "learning_rate": 2.9442349144429384e-06,
      "loss": 0.2564,
      "step": 4063
    },
    {
      "epoch": 0.6459637201724583,
      "grad_norm": 0.5760414600372314,
      "learning_rate": 2.9418886038146814e-06,
      "loss": 0.282,
      "step": 4064
    },
    {
      "epoch": 0.6461226679382488,
      "grad_norm": 0.5294649600982666,
      "learning_rate": 2.9395428387234192e-06,
      "loss": 0.2355,
      "step": 4065
    },
    {
      "epoch": 0.6462816157040393,
      "grad_norm": 0.42969802021980286,
      "learning_rate": 2.937197619790937e-06,
      "loss": 0.1062,
      "step": 4066
    },
    {
      "epoch": 0.6464405634698297,
      "grad_norm": 0.5730480551719666,
      "learning_rate": 2.9348529476388722e-06,
      "loss": 0.2583,
      "step": 4067
    },
    {
      "epoch": 0.6465995112356202,
      "grad_norm": 0.48697957396507263,
      "learning_rate": 2.93250882288872e-06,
      "loss": 0.1727,
      "step": 4068
    },
    {
      "epoch": 0.6467584590014107,
      "grad_norm": 0.5241697430610657,
      "learning_rate": 2.930165246161832e-06,
      "loss": 0.2043,
      "step": 4069
    },
    {
      "epoch": 0.6469174067672011,
      "grad_norm": 0.8010890483856201,
      "learning_rate": 2.9278222180794103e-06,
      "loss": 0.1921,
      "step": 4070
    },
    {
      "epoch": 0.6470763545329916,
      "grad_norm": 0.532006025314331,
      "learning_rate": 2.9254797392625146e-06,
      "loss": 0.2282,
      "step": 4071
    },
    {
      "epoch": 0.647235302298782,
      "grad_norm": 0.5680414438247681,
      "learning_rate": 2.9231378103320583e-06,
      "loss": 0.3067,
      "step": 4072
    },
    {
      "epoch": 0.6473942500645725,
      "grad_norm": 0.5584293007850647,
      "learning_rate": 2.92079643190881e-06,
      "loss": 0.169,
      "step": 4073
    },
    {
      "epoch": 0.647553197830363,
      "grad_norm": 0.4184533357620239,
      "learning_rate": 2.9184556046133903e-06,
      "loss": 0.0963,
      "step": 4074
    },
    {
      "epoch": 0.6477121455961534,
      "grad_norm": 0.509896457195282,
      "learning_rate": 2.9161153290662748e-06,
      "loss": 0.2287,
      "step": 4075
    },
    {
      "epoch": 0.6478710933619439,
      "grad_norm": 0.5326715111732483,
      "learning_rate": 2.913775605887794e-06,
      "loss": 0.2135,
      "step": 4076
    },
    {
      "epoch": 0.6480300411277344,
      "grad_norm": 0.7572981119155884,
      "learning_rate": 2.9114364356981274e-06,
      "loss": 0.3166,
      "step": 4077
    },
    {
      "epoch": 0.6481889888935248,
      "grad_norm": 0.5880705714225769,
      "learning_rate": 2.9090978191173145e-06,
      "loss": 0.2008,
      "step": 4078
    },
    {
      "epoch": 0.6483479366593153,
      "grad_norm": 1.3299304246902466,
      "learning_rate": 2.906759756765247e-06,
      "loss": 0.2498,
      "step": 4079
    },
    {
      "epoch": 0.6485068844251058,
      "grad_norm": 0.48753565549850464,
      "learning_rate": 2.9044222492616627e-06,
      "loss": 0.176,
      "step": 4080
    },
    {
      "epoch": 0.6486658321908962,
      "grad_norm": 0.5596939921379089,
      "learning_rate": 2.9020852972261587e-06,
      "loss": 0.2897,
      "step": 4081
    },
    {
      "epoch": 0.6488247799566867,
      "grad_norm": 0.4789898991584778,
      "learning_rate": 2.8997489012781845e-06,
      "loss": 0.1715,
      "step": 4082
    },
    {
      "epoch": 0.6489837277224773,
      "grad_norm": 0.4976705312728882,
      "learning_rate": 2.8974130620370405e-06,
      "loss": 0.2134,
      "step": 4083
    },
    {
      "epoch": 0.6491426754882677,
      "grad_norm": 0.5663854479789734,
      "learning_rate": 2.8950777801218803e-06,
      "loss": 0.2329,
      "step": 4084
    },
    {
      "epoch": 0.6493016232540582,
      "grad_norm": 0.6205146312713623,
      "learning_rate": 2.89274305615171e-06,
      "loss": 0.2215,
      "step": 4085
    },
    {
      "epoch": 0.6494605710198486,
      "grad_norm": 0.6383829712867737,
      "learning_rate": 2.8904088907453887e-06,
      "loss": 0.1708,
      "step": 4086
    },
    {
      "epoch": 0.6496195187856391,
      "grad_norm": 0.5554028749465942,
      "learning_rate": 2.888075284521622e-06,
      "loss": 0.2373,
      "step": 4087
    },
    {
      "epoch": 0.6497784665514296,
      "grad_norm": 1.229232668876648,
      "learning_rate": 2.885742238098974e-06,
      "loss": 0.2334,
      "step": 4088
    },
    {
      "epoch": 0.64993741431722,
      "grad_norm": 0.5453943014144897,
      "learning_rate": 2.883409752095857e-06,
      "loss": 0.2204,
      "step": 4089
    },
    {
      "epoch": 0.6500963620830105,
      "grad_norm": 0.5031276941299438,
      "learning_rate": 2.8810778271305375e-06,
      "loss": 0.1998,
      "step": 4090
    },
    {
      "epoch": 0.650255309848801,
      "grad_norm": 0.6511160731315613,
      "learning_rate": 2.878746463821129e-06,
      "loss": 0.2932,
      "step": 4091
    },
    {
      "epoch": 0.6504142576145914,
      "grad_norm": 0.45964375138282776,
      "learning_rate": 2.8764156627856006e-06,
      "loss": 0.171,
      "step": 4092
    },
    {
      "epoch": 0.6505732053803819,
      "grad_norm": 2.5792806148529053,
      "learning_rate": 2.8740854246417704e-06,
      "loss": 0.105,
      "step": 4093
    },
    {
      "epoch": 0.6507321531461724,
      "grad_norm": 0.5575007796287537,
      "learning_rate": 2.8717557500073044e-06,
      "loss": 0.1347,
      "step": 4094
    },
    {
      "epoch": 0.6508911009119628,
      "grad_norm": 0.5253024697303772,
      "learning_rate": 2.8694266394997238e-06,
      "loss": 0.1355,
      "step": 4095
    },
    {
      "epoch": 0.6510500486777533,
      "grad_norm": 0.5280882120132446,
      "learning_rate": 2.8670980937363984e-06,
      "loss": 0.1933,
      "step": 4096
    },
    {
      "epoch": 0.6512089964435437,
      "grad_norm": 0.6765844821929932,
      "learning_rate": 2.8647701133345484e-06,
      "loss": 0.3045,
      "step": 4097
    },
    {
      "epoch": 0.6513679442093342,
      "grad_norm": 0.32603752613067627,
      "learning_rate": 2.8624426989112435e-06,
      "loss": 0.0555,
      "step": 4098
    },
    {
      "epoch": 0.6515268919751247,
      "grad_norm": 0.5927666425704956,
      "learning_rate": 2.8601158510834047e-06,
      "loss": 0.2487,
      "step": 4099
    },
    {
      "epoch": 0.6516858397409151,
      "grad_norm": 0.5612424612045288,
      "learning_rate": 2.8577895704678036e-06,
      "loss": 0.1923,
      "step": 4100
    },
    {
      "epoch": 0.6518447875067056,
      "grad_norm": 0.5658617615699768,
      "learning_rate": 2.8554638576810565e-06,
      "loss": 0.2852,
      "step": 4101
    },
    {
      "epoch": 0.6520037352724961,
      "grad_norm": 0.6081926226615906,
      "learning_rate": 2.8531387133396344e-06,
      "loss": 0.2349,
      "step": 4102
    },
    {
      "epoch": 0.6521626830382865,
      "grad_norm": 0.5950771570205688,
      "learning_rate": 2.8508141380598553e-06,
      "loss": 0.2907,
      "step": 4103
    },
    {
      "epoch": 0.652321630804077,
      "grad_norm": 0.6114478707313538,
      "learning_rate": 2.8484901324578883e-06,
      "loss": 0.28,
      "step": 4104
    },
    {
      "epoch": 0.6524805785698675,
      "grad_norm": 0.5747087001800537,
      "learning_rate": 2.846166697149748e-06,
      "loss": 0.1612,
      "step": 4105
    },
    {
      "epoch": 0.6526395263356579,
      "grad_norm": 0.619561493396759,
      "learning_rate": 2.8438438327513046e-06,
      "loss": 0.2513,
      "step": 4106
    },
    {
      "epoch": 0.6527984741014484,
      "grad_norm": 0.5227118730545044,
      "learning_rate": 2.8415215398782657e-06,
      "loss": 0.1795,
      "step": 4107
    },
    {
      "epoch": 0.6529574218672389,
      "grad_norm": 0.5857772827148438,
      "learning_rate": 2.8391998191461985e-06,
      "loss": 0.288,
      "step": 4108
    },
    {
      "epoch": 0.6531163696330293,
      "grad_norm": 0.6226968765258789,
      "learning_rate": 2.836878671170512e-06,
      "loss": 0.3487,
      "step": 4109
    },
    {
      "epoch": 0.6532753173988198,
      "grad_norm": 0.5538944005966187,
      "learning_rate": 2.8345580965664664e-06,
      "loss": 0.1842,
      "step": 4110
    },
    {
      "epoch": 0.6534342651646102,
      "grad_norm": 0.653691291809082,
      "learning_rate": 2.832238095949169e-06,
      "loss": 0.3042,
      "step": 4111
    },
    {
      "epoch": 0.6535932129304007,
      "grad_norm": 0.46942615509033203,
      "learning_rate": 2.8299186699335744e-06,
      "loss": 0.1421,
      "step": 4112
    },
    {
      "epoch": 0.6537521606961912,
      "grad_norm": 0.6070226430892944,
      "learning_rate": 2.827599819134489e-06,
      "loss": 0.1738,
      "step": 4113
    },
    {
      "epoch": 0.6539111084619816,
      "grad_norm": 0.5251858830451965,
      "learning_rate": 2.825281544166557e-06,
      "loss": 0.1651,
      "step": 4114
    },
    {
      "epoch": 0.6540700562277721,
      "grad_norm": 0.46270689368247986,
      "learning_rate": 2.8229638456442786e-06,
      "loss": 0.1749,
      "step": 4115
    },
    {
      "epoch": 0.6542290039935627,
      "grad_norm": 0.5058267712593079,
      "learning_rate": 2.820646724182e-06,
      "loss": 0.1743,
      "step": 4116
    },
    {
      "epoch": 0.654387951759353,
      "grad_norm": 0.5901390910148621,
      "learning_rate": 2.8183301803939122e-06,
      "loss": 0.2919,
      "step": 4117
    },
    {
      "epoch": 0.6545468995251436,
      "grad_norm": 0.5407037734985352,
      "learning_rate": 2.8160142148940546e-06,
      "loss": 0.2519,
      "step": 4118
    },
    {
      "epoch": 0.6547058472909341,
      "grad_norm": 0.5535001754760742,
      "learning_rate": 2.813698828296312e-06,
      "loss": 0.2411,
      "step": 4119
    },
    {
      "epoch": 0.6548647950567245,
      "grad_norm": 0.5008181929588318,
      "learning_rate": 2.811384021214419e-06,
      "loss": 0.1649,
      "step": 4120
    },
    {
      "epoch": 0.655023742822515,
      "grad_norm": 0.5608908534049988,
      "learning_rate": 2.80906979426195e-06,
      "loss": 0.2201,
      "step": 4121
    },
    {
      "epoch": 0.6551826905883055,
      "grad_norm": 0.5240474939346313,
      "learning_rate": 2.8067561480523315e-06,
      "loss": 0.1579,
      "step": 4122
    },
    {
      "epoch": 0.6553416383540959,
      "grad_norm": 0.569015383720398,
      "learning_rate": 2.8044430831988345e-06,
      "loss": 0.187,
      "step": 4123
    },
    {
      "epoch": 0.6555005861198864,
      "grad_norm": 0.622272253036499,
      "learning_rate": 2.802130600314576e-06,
      "loss": 0.3442,
      "step": 4124
    },
    {
      "epoch": 0.6556595338856768,
      "grad_norm": 0.5777409672737122,
      "learning_rate": 2.799818700012518e-06,
      "loss": 0.3166,
      "step": 4125
    },
    {
      "epoch": 0.6558184816514673,
      "grad_norm": 0.6173734664916992,
      "learning_rate": 2.7975073829054704e-06,
      "loss": 0.3201,
      "step": 4126
    },
    {
      "epoch": 0.6559774294172578,
      "grad_norm": 0.5198959112167358,
      "learning_rate": 2.7951966496060834e-06,
      "loss": 0.1962,
      "step": 4127
    },
    {
      "epoch": 0.6561363771830482,
      "grad_norm": 0.4808778464794159,
      "learning_rate": 2.7928865007268565e-06,
      "loss": 0.1708,
      "step": 4128
    },
    {
      "epoch": 0.6562953249488387,
      "grad_norm": 0.6057060956954956,
      "learning_rate": 2.790576936880134e-06,
      "loss": 0.2843,
      "step": 4129
    },
    {
      "epoch": 0.6564542727146292,
      "grad_norm": 0.5299909114837646,
      "learning_rate": 2.7882679586781046e-06,
      "loss": 0.18,
      "step": 4130
    },
    {
      "epoch": 0.6566132204804196,
      "grad_norm": 0.47095444798469543,
      "learning_rate": 2.7859595667328027e-06,
      "loss": 0.1809,
      "step": 4131
    },
    {
      "epoch": 0.6567721682462101,
      "grad_norm": 0.5352177619934082,
      "learning_rate": 2.7836517616561053e-06,
      "loss": 0.1993,
      "step": 4132
    },
    {
      "epoch": 0.6569311160120006,
      "grad_norm": 0.6423991322517395,
      "learning_rate": 2.7813445440597363e-06,
      "loss": 0.3031,
      "step": 4133
    },
    {
      "epoch": 0.657090063777791,
      "grad_norm": 0.559294581413269,
      "learning_rate": 2.77903791455526e-06,
      "loss": 0.2028,
      "step": 4134
    },
    {
      "epoch": 0.6572490115435815,
      "grad_norm": 0.6319764256477356,
      "learning_rate": 2.7767318737540884e-06,
      "loss": 0.2871,
      "step": 4135
    },
    {
      "epoch": 0.6574079593093719,
      "grad_norm": 0.49729982018470764,
      "learning_rate": 2.774426422267476e-06,
      "loss": 0.1983,
      "step": 4136
    },
    {
      "epoch": 0.6575669070751624,
      "grad_norm": 0.5780603885650635,
      "learning_rate": 2.772121560706522e-06,
      "loss": 0.2663,
      "step": 4137
    },
    {
      "epoch": 0.6577258548409529,
      "grad_norm": 0.49630823731422424,
      "learning_rate": 2.7698172896821695e-06,
      "loss": 0.2062,
      "step": 4138
    },
    {
      "epoch": 0.6578848026067433,
      "grad_norm": 0.5340611934661865,
      "learning_rate": 2.7675136098052025e-06,
      "loss": 0.25,
      "step": 4139
    },
    {
      "epoch": 0.6580437503725338,
      "grad_norm": 0.5865193009376526,
      "learning_rate": 2.7652105216862536e-06,
      "loss": 0.2781,
      "step": 4140
    },
    {
      "epoch": 0.6582026981383243,
      "grad_norm": 0.5237875580787659,
      "learning_rate": 2.7629080259357898e-06,
      "loss": 0.2246,
      "step": 4141
    },
    {
      "epoch": 0.6583616459041147,
      "grad_norm": 0.5574514865875244,
      "learning_rate": 2.7606061231641285e-06,
      "loss": 0.2422,
      "step": 4142
    },
    {
      "epoch": 0.6585205936699052,
      "grad_norm": 0.5235680937767029,
      "learning_rate": 2.758304813981428e-06,
      "loss": 0.2015,
      "step": 4143
    },
    {
      "epoch": 0.6586795414356957,
      "grad_norm": 0.5741233229637146,
      "learning_rate": 2.7560040989976894e-06,
      "loss": 0.2675,
      "step": 4144
    },
    {
      "epoch": 0.6588384892014861,
      "grad_norm": 0.5455973148345947,
      "learning_rate": 2.7537039788227547e-06,
      "loss": 0.2009,
      "step": 4145
    },
    {
      "epoch": 0.6589974369672766,
      "grad_norm": 0.5818950533866882,
      "learning_rate": 2.7514044540663132e-06,
      "loss": 0.2466,
      "step": 4146
    },
    {
      "epoch": 0.6591563847330671,
      "grad_norm": 0.6249278783798218,
      "learning_rate": 2.749105525337886e-06,
      "loss": 0.2683,
      "step": 4147
    },
    {
      "epoch": 0.6593153324988575,
      "grad_norm": 0.5048378109931946,
      "learning_rate": 2.7468071932468473e-06,
      "loss": 0.1979,
      "step": 4148
    },
    {
      "epoch": 0.659474280264648,
      "grad_norm": 0.5472596287727356,
      "learning_rate": 2.7445094584024067e-06,
      "loss": 0.224,
      "step": 4149
    },
    {
      "epoch": 0.6596332280304384,
      "grad_norm": 0.48682793974876404,
      "learning_rate": 2.7422123214136188e-06,
      "loss": 0.1888,
      "step": 4150
    },
    {
      "epoch": 0.659792175796229,
      "grad_norm": 0.7168745994567871,
      "learning_rate": 2.7399157828893775e-06,
      "loss": 0.3286,
      "step": 4151
    },
    {
      "epoch": 0.6599511235620195,
      "grad_norm": 0.45040279626846313,
      "learning_rate": 2.7376198434384187e-06,
      "loss": 0.1314,
      "step": 4152
    },
    {
      "epoch": 0.6601100713278099,
      "grad_norm": 0.5042120814323425,
      "learning_rate": 2.735324503669323e-06,
      "loss": 0.1985,
      "step": 4153
    },
    {
      "epoch": 0.6602690190936004,
      "grad_norm": 0.5358031392097473,
      "learning_rate": 2.7330297641905035e-06,
      "loss": 0.2135,
      "step": 4154
    },
    {
      "epoch": 0.6604279668593909,
      "grad_norm": 0.558658242225647,
      "learning_rate": 2.7307356256102215e-06,
      "loss": 0.2511,
      "step": 4155
    },
    {
      "epoch": 0.6605869146251813,
      "grad_norm": 0.6017303466796875,
      "learning_rate": 2.7284420885365782e-06,
      "loss": 0.2628,
      "step": 4156
    },
    {
      "epoch": 0.6607458623909718,
      "grad_norm": 0.5381983518600464,
      "learning_rate": 2.726149153577512e-06,
      "loss": 0.2266,
      "step": 4157
    },
    {
      "epoch": 0.6609048101567623,
      "grad_norm": 0.5231665968894958,
      "learning_rate": 2.723856821340806e-06,
      "loss": 0.202,
      "step": 4158
    },
    {
      "epoch": 0.6610637579225527,
      "grad_norm": 0.5650283098220825,
      "learning_rate": 2.721565092434081e-06,
      "loss": 0.2767,
      "step": 4159
    },
    {
      "epoch": 0.6612227056883432,
      "grad_norm": 0.5365368723869324,
      "learning_rate": 2.7192739674647984e-06,
      "loss": 0.1958,
      "step": 4160
    },
    {
      "epoch": 0.6613816534541337,
      "grad_norm": 0.6185715198516846,
      "learning_rate": 2.716983447040257e-06,
      "loss": 0.3535,
      "step": 4161
    },
    {
      "epoch": 0.6615406012199241,
      "grad_norm": 0.559769332408905,
      "learning_rate": 2.7146935317676e-06,
      "loss": 0.2308,
      "step": 4162
    },
    {
      "epoch": 0.6616995489857146,
      "grad_norm": 0.516913890838623,
      "learning_rate": 2.712404222253807e-06,
      "loss": 0.196,
      "step": 4163
    },
    {
      "epoch": 0.661858496751505,
      "grad_norm": 0.5770569443702698,
      "learning_rate": 2.7101155191056985e-06,
      "loss": 0.2262,
      "step": 4164
    },
    {
      "epoch": 0.6620174445172955,
      "grad_norm": 0.540181040763855,
      "learning_rate": 2.707827422929933e-06,
      "loss": 0.2248,
      "step": 4165
    },
    {
      "epoch": 0.662176392283086,
      "grad_norm": 0.5356729626655579,
      "learning_rate": 2.7055399343330085e-06,
      "loss": 0.2172,
      "step": 4166
    },
    {
      "epoch": 0.6623353400488764,
      "grad_norm": 0.5466698408126831,
      "learning_rate": 2.703253053921266e-06,
      "loss": 0.2091,
      "step": 4167
    },
    {
      "epoch": 0.6624942878146669,
      "grad_norm": 0.5082042217254639,
      "learning_rate": 2.7009667823008763e-06,
      "loss": 0.2009,
      "step": 4168
    },
    {
      "epoch": 0.6626532355804574,
      "grad_norm": 0.5733219981193542,
      "learning_rate": 2.698681120077854e-06,
      "loss": 0.2617,
      "step": 4169
    },
    {
      "epoch": 0.6628121833462478,
      "grad_norm": 0.5578124523162842,
      "learning_rate": 2.696396067858059e-06,
      "loss": 0.2191,
      "step": 4170
    },
    {
      "epoch": 0.6629711311120383,
      "grad_norm": 0.43512535095214844,
      "learning_rate": 2.6941116262471767e-06,
      "loss": 0.1642,
      "step": 4171
    },
    {
      "epoch": 0.6631300788778288,
      "grad_norm": 0.5681657195091248,
      "learning_rate": 2.691827795850738e-06,
      "loss": 0.1872,
      "step": 4172
    },
    {
      "epoch": 0.6632890266436192,
      "grad_norm": 0.7303896546363831,
      "learning_rate": 2.689544577274113e-06,
      "loss": 0.1728,
      "step": 4173
    },
    {
      "epoch": 0.6634479744094097,
      "grad_norm": 0.5202891230583191,
      "learning_rate": 2.6872619711225033e-06,
      "loss": 0.1982,
      "step": 4174
    },
    {
      "epoch": 0.6636069221752001,
      "grad_norm": 0.5238774418830872,
      "learning_rate": 2.6849799780009535e-06,
      "loss": 0.2065,
      "step": 4175
    },
    {
      "epoch": 0.6637658699409906,
      "grad_norm": 0.4727991819381714,
      "learning_rate": 2.682698598514343e-06,
      "loss": 0.1607,
      "step": 4176
    },
    {
      "epoch": 0.6639248177067811,
      "grad_norm": 0.5710490345954895,
      "learning_rate": 2.6804178332673947e-06,
      "loss": 0.1438,
      "step": 4177
    },
    {
      "epoch": 0.6640837654725715,
      "grad_norm": 0.5644683241844177,
      "learning_rate": 2.6781376828646575e-06,
      "loss": 0.2284,
      "step": 4178
    },
    {
      "epoch": 0.664242713238362,
      "grad_norm": 0.5815243124961853,
      "learning_rate": 2.6758581479105274e-06,
      "loss": 0.2377,
      "step": 4179
    },
    {
      "epoch": 0.6644016610041525,
      "grad_norm": 0.4890017807483673,
      "learning_rate": 2.6735792290092344e-06,
      "loss": 0.1838,
      "step": 4180
    },
    {
      "epoch": 0.6645606087699429,
      "grad_norm": 0.497361958026886,
      "learning_rate": 2.6713009267648393e-06,
      "loss": 0.1178,
      "step": 4181
    },
    {
      "epoch": 0.6647195565357334,
      "grad_norm": 0.6066496968269348,
      "learning_rate": 2.669023241781246e-06,
      "loss": 0.3125,
      "step": 4182
    },
    {
      "epoch": 0.664878504301524,
      "grad_norm": 0.5948188304901123,
      "learning_rate": 2.6667461746621983e-06,
      "loss": 0.2653,
      "step": 4183
    },
    {
      "epoch": 0.6650374520673143,
      "grad_norm": 0.590793788433075,
      "learning_rate": 2.6644697260112653e-06,
      "loss": 0.2671,
      "step": 4184
    },
    {
      "epoch": 0.6651963998331049,
      "grad_norm": 0.5053858160972595,
      "learning_rate": 2.6621938964318593e-06,
      "loss": 0.1545,
      "step": 4185
    },
    {
      "epoch": 0.6653553475988954,
      "grad_norm": 0.5722150802612305,
      "learning_rate": 2.6599186865272284e-06,
      "loss": 0.2282,
      "step": 4186
    },
    {
      "epoch": 0.6655142953646858,
      "grad_norm": 0.6012914776802063,
      "learning_rate": 2.6576440969004562e-06,
      "loss": 0.3297,
      "step": 4187
    },
    {
      "epoch": 0.6656732431304763,
      "grad_norm": 0.5363425016403198,
      "learning_rate": 2.6553701281544574e-06,
      "loss": 0.2549,
      "step": 4188
    },
    {
      "epoch": 0.6658321908962667,
      "grad_norm": 0.5733873248100281,
      "learning_rate": 2.653096780891985e-06,
      "loss": 0.2982,
      "step": 4189
    },
    {
      "epoch": 0.6659911386620572,
      "grad_norm": 0.5210521221160889,
      "learning_rate": 2.6508240557156346e-06,
      "loss": 0.177,
      "step": 4190
    },
    {
      "epoch": 0.6661500864278477,
      "grad_norm": 0.5875582098960876,
      "learning_rate": 2.6485519532278235e-06,
      "loss": 0.2704,
      "step": 4191
    },
    {
      "epoch": 0.6663090341936381,
      "grad_norm": 0.5533907413482666,
      "learning_rate": 2.6462804740308134e-06,
      "loss": 0.218,
      "step": 4192
    },
    {
      "epoch": 0.6664679819594286,
      "grad_norm": 0.5761290192604065,
      "learning_rate": 2.6440096187266996e-06,
      "loss": 0.1595,
      "step": 4193
    },
    {
      "epoch": 0.6666269297252191,
      "grad_norm": 0.5414677262306213,
      "learning_rate": 2.6417393879174056e-06,
      "loss": 0.2144,
      "step": 4194
    },
    {
      "epoch": 0.6667858774910095,
      "grad_norm": 0.5184635519981384,
      "learning_rate": 2.6394697822046967e-06,
      "loss": 0.1668,
      "step": 4195
    },
    {
      "epoch": 0.6669448252568,
      "grad_norm": 0.4749106168746948,
      "learning_rate": 2.637200802190171e-06,
      "loss": 0.1559,
      "step": 4196
    },
    {
      "epoch": 0.6671037730225905,
      "grad_norm": 0.46430397033691406,
      "learning_rate": 2.6349324484752612e-06,
      "loss": 0.1419,
      "step": 4197
    },
    {
      "epoch": 0.6672627207883809,
      "grad_norm": 0.6280022263526917,
      "learning_rate": 2.6326647216612287e-06,
      "loss": 0.3068,
      "step": 4198
    },
    {
      "epoch": 0.6674216685541714,
      "grad_norm": 0.5297581553459167,
      "learning_rate": 2.6303976223491752e-06,
      "loss": 0.2064,
      "step": 4199
    },
    {
      "epoch": 0.6675806163199619,
      "grad_norm": 0.5358562469482422,
      "learning_rate": 2.6281311511400335e-06,
      "loss": 0.202,
      "step": 4200
    },
    {
      "epoch": 0.6677395640857523,
      "grad_norm": 1.4923776388168335,
      "learning_rate": 2.6258653086345675e-06,
      "loss": 0.2428,
      "step": 4201
    },
    {
      "epoch": 0.6678985118515428,
      "grad_norm": 0.47017648816108704,
      "learning_rate": 2.623600095433376e-06,
      "loss": 0.1478,
      "step": 4202
    },
    {
      "epoch": 0.6680574596173332,
      "grad_norm": 0.5274255275726318,
      "learning_rate": 2.621335512136899e-06,
      "loss": 0.2207,
      "step": 4203
    },
    {
      "epoch": 0.6682164073831237,
      "grad_norm": 0.5656169652938843,
      "learning_rate": 2.619071559345394e-06,
      "loss": 0.2552,
      "step": 4204
    },
    {
      "epoch": 0.6683753551489142,
      "grad_norm": 0.5719088912010193,
      "learning_rate": 2.6168082376589643e-06,
      "loss": 0.2465,
      "step": 4205
    },
    {
      "epoch": 0.6685343029147046,
      "grad_norm": 0.6075772047042847,
      "learning_rate": 2.61454554767754e-06,
      "loss": 0.2037,
      "step": 4206
    },
    {
      "epoch": 0.6686932506804951,
      "grad_norm": 0.5988118648529053,
      "learning_rate": 2.612283490000887e-06,
      "loss": 0.2424,
      "step": 4207
    },
    {
      "epoch": 0.6688521984462856,
      "grad_norm": 0.5888796448707581,
      "learning_rate": 2.610022065228596e-06,
      "loss": 0.2011,
      "step": 4208
    },
    {
      "epoch": 0.669011146212076,
      "grad_norm": 0.4843522310256958,
      "learning_rate": 2.6077612739601015e-06,
      "loss": 0.1559,
      "step": 4209
    },
    {
      "epoch": 0.6691700939778665,
      "grad_norm": 0.5015090703964233,
      "learning_rate": 2.6055011167946644e-06,
      "loss": 0.1564,
      "step": 4210
    },
    {
      "epoch": 0.669329041743657,
      "grad_norm": 0.5637962222099304,
      "learning_rate": 2.6032415943313727e-06,
      "loss": 0.2536,
      "step": 4211
    },
    {
      "epoch": 0.6694879895094474,
      "grad_norm": 0.5474973320960999,
      "learning_rate": 2.600982707169154e-06,
      "loss": 0.2404,
      "step": 4212
    },
    {
      "epoch": 0.6696469372752379,
      "grad_norm": 0.5290676951408386,
      "learning_rate": 2.598724455906765e-06,
      "loss": 0.1387,
      "step": 4213
    },
    {
      "epoch": 0.6698058850410283,
      "grad_norm": 0.67929607629776,
      "learning_rate": 2.59646684114279e-06,
      "loss": 0.3213,
      "step": 4214
    },
    {
      "epoch": 0.6699648328068188,
      "grad_norm": 0.8218638896942139,
      "learning_rate": 2.5942098634756475e-06,
      "loss": 0.2326,
      "step": 4215
    },
    {
      "epoch": 0.6701237805726094,
      "grad_norm": 0.5832724571228027,
      "learning_rate": 2.5919535235035907e-06,
      "loss": 0.2835,
      "step": 4216
    },
    {
      "epoch": 0.6702827283383997,
      "grad_norm": 0.5054391026496887,
      "learning_rate": 2.5896978218247013e-06,
      "loss": 0.1417,
      "step": 4217
    },
    {
      "epoch": 0.6704416761041903,
      "grad_norm": 0.5014663934707642,
      "learning_rate": 2.587442759036887e-06,
      "loss": 0.1838,
      "step": 4218
    },
    {
      "epoch": 0.6706006238699808,
      "grad_norm": 0.47669628262519836,
      "learning_rate": 2.585188335737891e-06,
      "loss": 0.1685,
      "step": 4219
    },
    {
      "epoch": 0.6707595716357712,
      "grad_norm": 0.5367156863212585,
      "learning_rate": 2.582934552525289e-06,
      "loss": 0.1725,
      "step": 4220
    },
    {
      "epoch": 0.6709185194015617,
      "grad_norm": 0.4073334038257599,
      "learning_rate": 2.580681409996477e-06,
      "loss": 0.1096,
      "step": 4221
    },
    {
      "epoch": 0.6710774671673522,
      "grad_norm": 0.5306112170219421,
      "learning_rate": 2.578428908748696e-06,
      "loss": 0.2035,
      "step": 4222
    },
    {
      "epoch": 0.6712364149331426,
      "grad_norm": 0.4693009853363037,
      "learning_rate": 2.5761770493790084e-06,
      "loss": 0.1507,
      "step": 4223
    },
    {
      "epoch": 0.6713953626989331,
      "grad_norm": 0.7096239924430847,
      "learning_rate": 2.5739258324843027e-06,
      "loss": 0.0992,
      "step": 4224
    },
    {
      "epoch": 0.6715543104647236,
      "grad_norm": 0.5769004821777344,
      "learning_rate": 2.5716752586613046e-06,
      "loss": 0.217,
      "step": 4225
    },
    {
      "epoch": 0.671713258230514,
      "grad_norm": 0.6714112758636475,
      "learning_rate": 2.5694253285065662e-06,
      "loss": 0.3672,
      "step": 4226
    },
    {
      "epoch": 0.6718722059963045,
      "grad_norm": 0.8467180132865906,
      "learning_rate": 2.567176042616471e-06,
      "loss": 0.2152,
      "step": 4227
    },
    {
      "epoch": 0.6720311537620949,
      "grad_norm": 0.46347805857658386,
      "learning_rate": 2.564927401587225e-06,
      "loss": 0.2024,
      "step": 4228
    },
    {
      "epoch": 0.6721901015278854,
      "grad_norm": 0.49580395221710205,
      "learning_rate": 2.562679406014873e-06,
      "loss": 0.1686,
      "step": 4229
    },
    {
      "epoch": 0.6723490492936759,
      "grad_norm": 0.5469022393226624,
      "learning_rate": 2.5604320564952846e-06,
      "loss": 0.2065,
      "step": 4230
    },
    {
      "epoch": 0.6725079970594663,
      "grad_norm": 0.4522978663444519,
      "learning_rate": 2.558185353624154e-06,
      "loss": 0.1142,
      "step": 4231
    },
    {
      "epoch": 0.6726669448252568,
      "grad_norm": 0.49629876017570496,
      "learning_rate": 2.5559392979970087e-06,
      "loss": 0.1473,
      "step": 4232
    },
    {
      "epoch": 0.6728258925910473,
      "grad_norm": 0.4499540328979492,
      "learning_rate": 2.5536938902092056e-06,
      "loss": 0.101,
      "step": 4233
    },
    {
      "epoch": 0.6729848403568377,
      "grad_norm": 0.4710301160812378,
      "learning_rate": 2.5514491308559225e-06,
      "loss": 0.1133,
      "step": 4234
    },
    {
      "epoch": 0.6731437881226282,
      "grad_norm": 0.501005232334137,
      "learning_rate": 2.549205020532176e-06,
      "loss": 0.2082,
      "step": 4235
    },
    {
      "epoch": 0.6733027358884187,
      "grad_norm": 0.5264378786087036,
      "learning_rate": 2.5469615598328027e-06,
      "loss": 0.2043,
      "step": 4236
    },
    {
      "epoch": 0.6734616836542091,
      "grad_norm": 0.711484432220459,
      "learning_rate": 2.544718749352473e-06,
      "loss": 0.2697,
      "step": 4237
    },
    {
      "epoch": 0.6736206314199996,
      "grad_norm": 0.5654981732368469,
      "learning_rate": 2.5424765896856756e-06,
      "loss": 0.2173,
      "step": 4238
    },
    {
      "epoch": 0.6737795791857901,
      "grad_norm": 0.4628738462924957,
      "learning_rate": 2.5402350814267364e-06,
      "loss": 0.0934,
      "step": 4239
    },
    {
      "epoch": 0.6739385269515805,
      "grad_norm": 0.5356011390686035,
      "learning_rate": 2.5379942251698053e-06,
      "loss": 0.237,
      "step": 4240
    },
    {
      "epoch": 0.674097474717371,
      "grad_norm": 0.6875442266464233,
      "learning_rate": 2.5357540215088537e-06,
      "loss": 0.2885,
      "step": 4241
    },
    {
      "epoch": 0.6742564224831614,
      "grad_norm": 0.6051203608512878,
      "learning_rate": 2.5335144710376913e-06,
      "loss": 0.2109,
      "step": 4242
    },
    {
      "epoch": 0.6744153702489519,
      "grad_norm": 0.5128576755523682,
      "learning_rate": 2.531275574349947e-06,
      "loss": 0.203,
      "step": 4243
    },
    {
      "epoch": 0.6745743180147424,
      "grad_norm": 0.4402129054069519,
      "learning_rate": 2.529037332039078e-06,
      "loss": 0.1368,
      "step": 4244
    },
    {
      "epoch": 0.6747332657805328,
      "grad_norm": 0.5198051333427429,
      "learning_rate": 2.526799744698366e-06,
      "loss": 0.2414,
      "step": 4245
    },
    {
      "epoch": 0.6748922135463233,
      "grad_norm": 0.5737464427947998,
      "learning_rate": 2.524562812920923e-06,
      "loss": 0.2897,
      "step": 4246
    },
    {
      "epoch": 0.6750511613121138,
      "grad_norm": 1.0623618364334106,
      "learning_rate": 2.522326537299684e-06,
      "loss": 0.2258,
      "step": 4247
    },
    {
      "epoch": 0.6752101090779042,
      "grad_norm": 0.5957176089286804,
      "learning_rate": 2.5200909184274125e-06,
      "loss": 0.2532,
      "step": 4248
    },
    {
      "epoch": 0.6753690568436947,
      "grad_norm": 0.5663220882415771,
      "learning_rate": 2.5178559568966966e-06,
      "loss": 0.2457,
      "step": 4249
    },
    {
      "epoch": 0.6755280046094853,
      "grad_norm": 0.5344353914260864,
      "learning_rate": 2.5156216532999523e-06,
      "loss": 0.2241,
      "step": 4250
    },
    {
      "epoch": 0.6756869523752757,
      "grad_norm": 0.5589856505393982,
      "learning_rate": 2.5133880082294155e-06,
      "loss": 0.1727,
      "step": 4251
    },
    {
      "epoch": 0.6758459001410662,
      "grad_norm": 0.5462359189987183,
      "learning_rate": 2.511155022277153e-06,
      "loss": 0.2353,
      "step": 4252
    },
    {
      "epoch": 0.6760048479068566,
      "grad_norm": 0.6372504234313965,
      "learning_rate": 2.5089226960350553e-06,
      "loss": 0.3244,
      "step": 4253
    },
    {
      "epoch": 0.6761637956726471,
      "grad_norm": 0.5861800909042358,
      "learning_rate": 2.5066910300948384e-06,
      "loss": 0.3272,
      "step": 4254
    },
    {
      "epoch": 0.6763227434384376,
      "grad_norm": 0.5780372023582458,
      "learning_rate": 2.504460025048042e-06,
      "loss": 0.2224,
      "step": 4255
    },
    {
      "epoch": 0.676481691204228,
      "grad_norm": 0.9928068518638611,
      "learning_rate": 2.5022296814860325e-06,
      "loss": 0.2684,
      "step": 4256
    },
    {
      "epoch": 0.6766406389700185,
      "grad_norm": 0.7442824840545654,
      "learning_rate": 2.5000000000000015e-06,
      "loss": 0.2249,
      "step": 4257
    },
    {
      "epoch": 0.676799586735809,
      "grad_norm": 0.5460633635520935,
      "learning_rate": 2.4977709811809585e-06,
      "loss": 0.2564,
      "step": 4258
    },
    {
      "epoch": 0.6769585345015994,
      "grad_norm": 0.6015155911445618,
      "learning_rate": 2.495542625619746e-06,
      "loss": 0.2593,
      "step": 4259
    },
    {
      "epoch": 0.6771174822673899,
      "grad_norm": 0.5540652871131897,
      "learning_rate": 2.4933149339070268e-06,
      "loss": 0.2418,
      "step": 4260
    },
    {
      "epoch": 0.6772764300331804,
      "grad_norm": 0.5614826679229736,
      "learning_rate": 2.4910879066332873e-06,
      "loss": 0.2705,
      "step": 4261
    },
    {
      "epoch": 0.6774353777989708,
      "grad_norm": 0.5291662216186523,
      "learning_rate": 2.488861544388838e-06,
      "loss": 0.1891,
      "step": 4262
    },
    {
      "epoch": 0.6775943255647613,
      "grad_norm": 0.425178200006485,
      "learning_rate": 2.486635847763815e-06,
      "loss": 0.1306,
      "step": 4263
    },
    {
      "epoch": 0.6777532733305518,
      "grad_norm": 0.8680059313774109,
      "learning_rate": 2.484410817348178e-06,
      "loss": 0.1403,
      "step": 4264
    },
    {
      "epoch": 0.6779122210963422,
      "grad_norm": 0.6585168838500977,
      "learning_rate": 2.4821864537317043e-06,
      "loss": 0.2022,
      "step": 4265
    },
    {
      "epoch": 0.6780711688621327,
      "grad_norm": 0.5756145119667053,
      "learning_rate": 2.4799627575040014e-06,
      "loss": 0.2398,
      "step": 4266
    },
    {
      "epoch": 0.6782301166279231,
      "grad_norm": 0.5386219620704651,
      "learning_rate": 2.477739729254497e-06,
      "loss": 0.1727,
      "step": 4267
    },
    {
      "epoch": 0.6783890643937136,
      "grad_norm": 0.5400603413581848,
      "learning_rate": 2.4755173695724427e-06,
      "loss": 0.1992,
      "step": 4268
    },
    {
      "epoch": 0.6785480121595041,
      "grad_norm": 0.7096137404441833,
      "learning_rate": 2.473295679046911e-06,
      "loss": 0.067,
      "step": 4269
    },
    {
      "epoch": 0.6787069599252945,
      "grad_norm": 0.5266890525817871,
      "learning_rate": 2.471074658266801e-06,
      "loss": 0.2369,
      "step": 4270
    },
    {
      "epoch": 0.678865907691085,
      "grad_norm": 0.416133850812912,
      "learning_rate": 2.4688543078208284e-06,
      "loss": 0.1107,
      "step": 4271
    },
    {
      "epoch": 0.6790248554568755,
      "grad_norm": 0.6117424964904785,
      "learning_rate": 2.466634628297535e-06,
      "loss": 0.3367,
      "step": 4272
    },
    {
      "epoch": 0.6791838032226659,
      "grad_norm": 0.4746673107147217,
      "learning_rate": 2.464415620285285e-06,
      "loss": 0.1499,
      "step": 4273
    },
    {
      "epoch": 0.6793427509884564,
      "grad_norm": 0.7663189172744751,
      "learning_rate": 2.462197284372263e-06,
      "loss": 0.112,
      "step": 4274
    },
    {
      "epoch": 0.6795016987542469,
      "grad_norm": 0.6465777158737183,
      "learning_rate": 2.4599796211464772e-06,
      "loss": 0.2939,
      "step": 4275
    },
    {
      "epoch": 0.6796606465200373,
      "grad_norm": 0.5781603455543518,
      "learning_rate": 2.4577626311957553e-06,
      "loss": 0.2698,
      "step": 4276
    },
    {
      "epoch": 0.6798195942858278,
      "grad_norm": 0.4868364930152893,
      "learning_rate": 2.4555463151077507e-06,
      "loss": 0.1811,
      "step": 4277
    },
    {
      "epoch": 0.6799785420516183,
      "grad_norm": 0.538498044013977,
      "learning_rate": 2.4533306734699314e-06,
      "loss": 0.213,
      "step": 4278
    },
    {
      "epoch": 0.6801374898174087,
      "grad_norm": 0.6540230512619019,
      "learning_rate": 2.4511157068695913e-06,
      "loss": 0.2111,
      "step": 4279
    },
    {
      "epoch": 0.6802964375831992,
      "grad_norm": 0.5608181953430176,
      "learning_rate": 2.448901415893845e-06,
      "loss": 0.224,
      "step": 4280
    },
    {
      "epoch": 0.6804553853489896,
      "grad_norm": 0.5554811358451843,
      "learning_rate": 2.446687801129628e-06,
      "loss": 0.1989,
      "step": 4281
    },
    {
      "epoch": 0.6806143331147801,
      "grad_norm": 0.5839480757713318,
      "learning_rate": 2.4444748631636955e-06,
      "loss": 0.2255,
      "step": 4282
    },
    {
      "epoch": 0.6807732808805707,
      "grad_norm": 0.5591074824333191,
      "learning_rate": 2.442262602582624e-06,
      "loss": 0.1949,
      "step": 4283
    },
    {
      "epoch": 0.680932228646361,
      "grad_norm": 0.6009390354156494,
      "learning_rate": 2.4400510199728123e-06,
      "loss": 0.304,
      "step": 4284
    },
    {
      "epoch": 0.6810911764121516,
      "grad_norm": 0.5658441781997681,
      "learning_rate": 2.437840115920474e-06,
      "loss": 0.2186,
      "step": 4285
    },
    {
      "epoch": 0.6812501241779421,
      "grad_norm": 0.6645838022232056,
      "learning_rate": 2.4356298910116477e-06,
      "loss": 0.2551,
      "step": 4286
    },
    {
      "epoch": 0.6814090719437325,
      "grad_norm": 0.5843661427497864,
      "learning_rate": 2.433420345832191e-06,
      "loss": 0.1622,
      "step": 4287
    },
    {
      "epoch": 0.681568019709523,
      "grad_norm": 0.5488671660423279,
      "learning_rate": 2.431211480967781e-06,
      "loss": 0.1693,
      "step": 4288
    },
    {
      "epoch": 0.6817269674753135,
      "grad_norm": 0.505793035030365,
      "learning_rate": 2.429003297003914e-06,
      "loss": 0.1163,
      "step": 4289
    },
    {
      "epoch": 0.6818859152411039,
      "grad_norm": 0.5511645078659058,
      "learning_rate": 2.4267957945259083e-06,
      "loss": 0.1863,
      "step": 4290
    },
    {
      "epoch": 0.6820448630068944,
      "grad_norm": 0.5315791964530945,
      "learning_rate": 2.4245889741188964e-06,
      "loss": 0.2108,
      "step": 4291
    },
    {
      "epoch": 0.6822038107726848,
      "grad_norm": 0.567646324634552,
      "learning_rate": 2.422382836367834e-06,
      "loss": 0.2102,
      "step": 4292
    },
    {
      "epoch": 0.6823627585384753,
      "grad_norm": 0.584669291973114,
      "learning_rate": 2.4201773818574956e-06,
      "loss": 0.265,
      "step": 4293
    },
    {
      "epoch": 0.6825217063042658,
      "grad_norm": 0.6362424492835999,
      "learning_rate": 2.417972611172474e-06,
      "loss": 0.1381,
      "step": 4294
    },
    {
      "epoch": 0.6826806540700562,
      "grad_norm": 0.5738860964775085,
      "learning_rate": 2.4157685248971802e-06,
      "loss": 0.2041,
      "step": 4295
    },
    {
      "epoch": 0.6828396018358467,
      "grad_norm": 0.5039923191070557,
      "learning_rate": 2.413565123615845e-06,
      "loss": 0.1513,
      "step": 4296
    },
    {
      "epoch": 0.6829985496016372,
      "grad_norm": 0.5573960542678833,
      "learning_rate": 2.411362407912518e-06,
      "loss": 0.2453,
      "step": 4297
    },
    {
      "epoch": 0.6831574973674276,
      "grad_norm": 0.5250556468963623,
      "learning_rate": 2.4091603783710625e-06,
      "loss": 0.1662,
      "step": 4298
    },
    {
      "epoch": 0.6833164451332181,
      "grad_norm": 0.6027401089668274,
      "learning_rate": 2.406959035575166e-06,
      "loss": 0.2248,
      "step": 4299
    },
    {
      "epoch": 0.6834753928990086,
      "grad_norm": 0.46378034353256226,
      "learning_rate": 2.40475838010833e-06,
      "loss": 0.176,
      "step": 4300
    },
    {
      "epoch": 0.683634340664799,
      "grad_norm": 0.6135565042495728,
      "learning_rate": 2.402558412553877e-06,
      "loss": 0.1924,
      "step": 4301
    },
    {
      "epoch": 0.6837932884305895,
      "grad_norm": 0.5246086120605469,
      "learning_rate": 2.400359133494944e-06,
      "loss": 0.195,
      "step": 4302
    },
    {
      "epoch": 0.68395223619638,
      "grad_norm": 0.576998233795166,
      "learning_rate": 2.398160543514487e-06,
      "loss": 0.2328,
      "step": 4303
    },
    {
      "epoch": 0.6841111839621704,
      "grad_norm": 0.5943166017532349,
      "learning_rate": 2.395962643195281e-06,
      "loss": 0.281,
      "step": 4304
    },
    {
      "epoch": 0.6842701317279609,
      "grad_norm": 0.6681926846504211,
      "learning_rate": 2.393765433119913e-06,
      "loss": 0.1842,
      "step": 4305
    },
    {
      "epoch": 0.6844290794937513,
      "grad_norm": 0.489478200674057,
      "learning_rate": 2.3915689138707925e-06,
      "loss": 0.1765,
      "step": 4306
    },
    {
      "epoch": 0.6845880272595418,
      "grad_norm": 0.4927923083305359,
      "learning_rate": 2.3893730860301433e-06,
      "loss": 0.1749,
      "step": 4307
    },
    {
      "epoch": 0.6847469750253323,
      "grad_norm": 0.4934627115726471,
      "learning_rate": 2.387177950180007e-06,
      "loss": 0.221,
      "step": 4308
    },
    {
      "epoch": 0.6849059227911227,
      "grad_norm": 0.6294262409210205,
      "learning_rate": 2.384983506902241e-06,
      "loss": 0.2839,
      "step": 4309
    },
    {
      "epoch": 0.6850648705569132,
      "grad_norm": 2.124830484390259,
      "learning_rate": 2.382789756778519e-06,
      "loss": 0.1756,
      "step": 4310
    },
    {
      "epoch": 0.6852238183227037,
      "grad_norm": 0.48982951045036316,
      "learning_rate": 2.3805967003903336e-06,
      "loss": 0.172,
      "step": 4311
    },
    {
      "epoch": 0.6853827660884941,
      "grad_norm": 0.6530374884605408,
      "learning_rate": 2.3784043383189873e-06,
      "loss": 0.1546,
      "step": 4312
    },
    {
      "epoch": 0.6855417138542846,
      "grad_norm": 0.6038556098937988,
      "learning_rate": 2.3762126711456047e-06,
      "loss": 0.2669,
      "step": 4313
    },
    {
      "epoch": 0.6857006616200751,
      "grad_norm": 0.4448460340499878,
      "learning_rate": 2.3740216994511235e-06,
      "loss": 0.1332,
      "step": 4314
    },
    {
      "epoch": 0.6858596093858655,
      "grad_norm": 0.4624577462673187,
      "learning_rate": 2.3718314238162976e-06,
      "loss": 0.1833,
      "step": 4315
    },
    {
      "epoch": 0.686018557151656,
      "grad_norm": 0.5832996964454651,
      "learning_rate": 2.369641844821697e-06,
      "loss": 0.2503,
      "step": 4316
    },
    {
      "epoch": 0.6861775049174466,
      "grad_norm": 0.4782527983188629,
      "learning_rate": 2.3674529630477074e-06,
      "loss": 0.1195,
      "step": 4317
    },
    {
      "epoch": 0.686336452683237,
      "grad_norm": 0.5757583379745483,
      "learning_rate": 2.365264779074525e-06,
      "loss": 0.2442,
      "step": 4318
    },
    {
      "epoch": 0.6864954004490275,
      "grad_norm": 0.6009016036987305,
      "learning_rate": 2.363077293482167e-06,
      "loss": 0.2667,
      "step": 4319
    },
    {
      "epoch": 0.6866543482148179,
      "grad_norm": 0.5821034908294678,
      "learning_rate": 2.360890506850464e-06,
      "loss": 0.2344,
      "step": 4320
    },
    {
      "epoch": 0.6868132959806084,
      "grad_norm": 0.4396170973777771,
      "learning_rate": 2.3587044197590584e-06,
      "loss": 0.1444,
      "step": 4321
    },
    {
      "epoch": 0.6869722437463989,
      "grad_norm": 0.5851983428001404,
      "learning_rate": 2.3565190327874114e-06,
      "loss": 0.1459,
      "step": 4322
    },
    {
      "epoch": 0.6871311915121893,
      "grad_norm": 0.5192058682441711,
      "learning_rate": 2.3543343465147956e-06,
      "loss": 0.1849,
      "step": 4323
    },
    {
      "epoch": 0.6872901392779798,
      "grad_norm": 0.6458311080932617,
      "learning_rate": 2.3521503615203e-06,
      "loss": 0.234,
      "step": 4324
    },
    {
      "epoch": 0.6874490870437703,
      "grad_norm": 2.2448179721832275,
      "learning_rate": 2.3499670783828243e-06,
      "loss": 0.2352,
      "step": 4325
    },
    {
      "epoch": 0.6876080348095607,
      "grad_norm": 0.58514404296875,
      "learning_rate": 2.347784497681085e-06,
      "loss": 0.2397,
      "step": 4326
    },
    {
      "epoch": 0.6877669825753512,
      "grad_norm": 0.5196040272712708,
      "learning_rate": 2.3456026199936123e-06,
      "loss": 0.1999,
      "step": 4327
    },
    {
      "epoch": 0.6879259303411417,
      "grad_norm": 0.43405893445014954,
      "learning_rate": 2.343421445898749e-06,
      "loss": 0.1384,
      "step": 4328
    },
    {
      "epoch": 0.6880848781069321,
      "grad_norm": 0.5826170444488525,
      "learning_rate": 2.341240975974653e-06,
      "loss": 0.2408,
      "step": 4329
    },
    {
      "epoch": 0.6882438258727226,
      "grad_norm": 0.5079994201660156,
      "learning_rate": 2.339061210799293e-06,
      "loss": 0.1613,
      "step": 4330
    },
    {
      "epoch": 0.6884027736385131,
      "grad_norm": 0.526684045791626,
      "learning_rate": 2.336882150950456e-06,
      "loss": 0.1934,
      "step": 4331
    },
    {
      "epoch": 0.6885617214043035,
      "grad_norm": 0.6196853518486023,
      "learning_rate": 2.334703797005733e-06,
      "loss": 0.2983,
      "step": 4332
    },
    {
      "epoch": 0.688720669170094,
      "grad_norm": 0.518538236618042,
      "learning_rate": 2.3325261495425343e-06,
      "loss": 0.1833,
      "step": 4333
    },
    {
      "epoch": 0.6888796169358844,
      "grad_norm": 0.5830349326133728,
      "learning_rate": 2.3303492091380876e-06,
      "loss": 0.2127,
      "step": 4334
    },
    {
      "epoch": 0.6890385647016749,
      "grad_norm": 0.5266851186752319,
      "learning_rate": 2.328172976369421e-06,
      "loss": 0.1914,
      "step": 4335
    },
    {
      "epoch": 0.6891975124674654,
      "grad_norm": 0.576433002948761,
      "learning_rate": 2.325997451813385e-06,
      "loss": 0.2233,
      "step": 4336
    },
    {
      "epoch": 0.6893564602332558,
      "grad_norm": 0.4916541278362274,
      "learning_rate": 2.3238226360466385e-06,
      "loss": 0.1593,
      "step": 4337
    },
    {
      "epoch": 0.6895154079990463,
      "grad_norm": 0.6068398952484131,
      "learning_rate": 2.3216485296456514e-06,
      "loss": 0.3048,
      "step": 4338
    },
    {
      "epoch": 0.6896743557648368,
      "grad_norm": 0.501585066318512,
      "learning_rate": 2.3194751331867075e-06,
      "loss": 0.2333,
      "step": 4339
    },
    {
      "epoch": 0.6898333035306272,
      "grad_norm": 0.47286972403526306,
      "learning_rate": 2.3173024472459016e-06,
      "loss": 0.1675,
      "step": 4340
    },
    {
      "epoch": 0.6899922512964177,
      "grad_norm": 0.5924230217933655,
      "learning_rate": 2.315130472399145e-06,
      "loss": 0.282,
      "step": 4341
    },
    {
      "epoch": 0.6901511990622082,
      "grad_norm": 0.6386135220527649,
      "learning_rate": 2.3129592092221508e-06,
      "loss": 0.3039,
      "step": 4342
    },
    {
      "epoch": 0.6903101468279986,
      "grad_norm": 0.5441910028457642,
      "learning_rate": 2.3107886582904503e-06,
      "loss": 0.1994,
      "step": 4343
    },
    {
      "epoch": 0.6904690945937891,
      "grad_norm": 0.6175159215927124,
      "learning_rate": 2.3086188201793875e-06,
      "loss": 0.2923,
      "step": 4344
    },
    {
      "epoch": 0.6906280423595795,
      "grad_norm": 0.5675325393676758,
      "learning_rate": 2.3064496954641097e-06,
      "loss": 0.201,
      "step": 4345
    },
    {
      "epoch": 0.69078699012537,
      "grad_norm": 0.7298709750175476,
      "learning_rate": 2.30428128471958e-06,
      "loss": 0.3224,
      "step": 4346
    },
    {
      "epoch": 0.6909459378911605,
      "grad_norm": 0.5868433713912964,
      "learning_rate": 2.302113588520578e-06,
      "loss": 0.2508,
      "step": 4347
    },
    {
      "epoch": 0.6911048856569509,
      "grad_norm": 0.6007326245307922,
      "learning_rate": 2.299946607441682e-06,
      "loss": 0.3087,
      "step": 4348
    },
    {
      "epoch": 0.6912638334227414,
      "grad_norm": 0.49299943447113037,
      "learning_rate": 2.297780342057289e-06,
      "loss": 0.1566,
      "step": 4349
    },
    {
      "epoch": 0.691422781188532,
      "grad_norm": 0.5093328356742859,
      "learning_rate": 2.295614792941604e-06,
      "loss": 0.1862,
      "step": 4350
    },
    {
      "epoch": 0.6915817289543224,
      "grad_norm": 0.6528547406196594,
      "learning_rate": 2.2934499606686435e-06,
      "loss": 0.2809,
      "step": 4351
    },
    {
      "epoch": 0.6917406767201129,
      "grad_norm": 0.5150148868560791,
      "learning_rate": 2.2912858458122294e-06,
      "loss": 0.2165,
      "step": 4352
    },
    {
      "epoch": 0.6918996244859034,
      "grad_norm": 0.42925646901130676,
      "learning_rate": 2.289122448945997e-06,
      "loss": 0.1263,
      "step": 4353
    },
    {
      "epoch": 0.6920585722516938,
      "grad_norm": 0.5061959624290466,
      "learning_rate": 2.2869597706433955e-06,
      "loss": 0.1643,
      "step": 4354
    },
    {
      "epoch": 0.6922175200174843,
      "grad_norm": 0.5978067517280579,
      "learning_rate": 2.2847978114776744e-06,
      "loss": 0.3031,
      "step": 4355
    },
    {
      "epoch": 0.6923764677832748,
      "grad_norm": 0.583825945854187,
      "learning_rate": 2.2826365720218984e-06,
      "loss": 0.2216,
      "step": 4356
    },
    {
      "epoch": 0.6925354155490652,
      "grad_norm": 0.5562809109687805,
      "learning_rate": 2.2804760528489434e-06,
      "loss": 0.1866,
      "step": 4357
    },
    {
      "epoch": 0.6926943633148557,
      "grad_norm": 0.6843230128288269,
      "learning_rate": 2.2783162545314862e-06,
      "loss": 0.2896,
      "step": 4358
    },
    {
      "epoch": 0.6928533110806461,
      "grad_norm": 0.5046536922454834,
      "learning_rate": 2.2761571776420187e-06,
      "loss": 0.1707,
      "step": 4359
    },
    {
      "epoch": 0.6930122588464366,
      "grad_norm": 0.5613179802894592,
      "learning_rate": 2.273998822752844e-06,
      "loss": 0.2371,
      "step": 4360
    },
    {
      "epoch": 0.6931712066122271,
      "grad_norm": 0.607180118560791,
      "learning_rate": 2.27184119043607e-06,
      "loss": 0.2994,
      "step": 4361
    },
    {
      "epoch": 0.6933301543780175,
      "grad_norm": 0.48290663957595825,
      "learning_rate": 2.26968428126361e-06,
      "loss": 0.1805,
      "step": 4362
    },
    {
      "epoch": 0.693489102143808,
      "grad_norm": 0.671336829662323,
      "learning_rate": 2.26752809580719e-06,
      "loss": 0.3439,
      "step": 4363
    },
    {
      "epoch": 0.6936480499095985,
      "grad_norm": 0.5006006360054016,
      "learning_rate": 2.2653726346383465e-06,
      "loss": 0.1818,
      "step": 4364
    },
    {
      "epoch": 0.6938069976753889,
      "grad_norm": 0.8099275231361389,
      "learning_rate": 2.263217898328415e-06,
      "loss": 0.2657,
      "step": 4365
    },
    {
      "epoch": 0.6939659454411794,
      "grad_norm": 1.2582414150238037,
      "learning_rate": 2.261063887448547e-06,
      "loss": 0.2315,
      "step": 4366
    },
    {
      "epoch": 0.6941248932069699,
      "grad_norm": 0.42287492752075195,
      "learning_rate": 2.2589106025697027e-06,
      "loss": 0.1414,
      "step": 4367
    },
    {
      "epoch": 0.6942838409727603,
      "grad_norm": 0.5928240418434143,
      "learning_rate": 2.256758044262642e-06,
      "loss": 0.2609,
      "step": 4368
    },
    {
      "epoch": 0.6944427887385508,
      "grad_norm": 0.5004671812057495,
      "learning_rate": 2.2546062130979377e-06,
      "loss": 0.1454,
      "step": 4369
    },
    {
      "epoch": 0.6946017365043413,
      "grad_norm": 0.5511868596076965,
      "learning_rate": 2.2524551096459703e-06,
      "loss": 0.2589,
      "step": 4370
    },
    {
      "epoch": 0.6947606842701317,
      "grad_norm": 0.5212135314941406,
      "learning_rate": 2.2503047344769256e-06,
      "loss": 0.1559,
      "step": 4371
    },
    {
      "epoch": 0.6949196320359222,
      "grad_norm": 0.4146222770214081,
      "learning_rate": 2.2481550881607927e-06,
      "loss": 0.0949,
      "step": 4372
    },
    {
      "epoch": 0.6950785798017126,
      "grad_norm": 0.5357129573822021,
      "learning_rate": 2.2460061712673768e-06,
      "loss": 0.2104,
      "step": 4373
    },
    {
      "epoch": 0.6952375275675031,
      "grad_norm": 0.5805232524871826,
      "learning_rate": 2.243857984366284e-06,
      "loss": 0.2669,
      "step": 4374
    },
    {
      "epoch": 0.6953964753332936,
      "grad_norm": 0.4918021261692047,
      "learning_rate": 2.2417105280269235e-06,
      "loss": 0.1347,
      "step": 4375
    },
    {
      "epoch": 0.695555423099084,
      "grad_norm": 2.4116129875183105,
      "learning_rate": 2.2395638028185175e-06,
      "loss": 0.2648,
      "step": 4376
    },
    {
      "epoch": 0.6957143708648745,
      "grad_norm": 0.5510293841362,
      "learning_rate": 2.23741780931009e-06,
      "loss": 0.229,
      "step": 4377
    },
    {
      "epoch": 0.695873318630665,
      "grad_norm": 0.6128736734390259,
      "learning_rate": 2.2352725480704756e-06,
      "loss": 0.289,
      "step": 4378
    },
    {
      "epoch": 0.6960322663964554,
      "grad_norm": 0.7288392782211304,
      "learning_rate": 2.2331280196683064e-06,
      "loss": 0.3082,
      "step": 4379
    },
    {
      "epoch": 0.6961912141622459,
      "grad_norm": 0.5121594071388245,
      "learning_rate": 2.2309842246720303e-06,
      "loss": 0.209,
      "step": 4380
    },
    {
      "epoch": 0.6963501619280364,
      "grad_norm": 0.5694230198860168,
      "learning_rate": 2.2288411636498967e-06,
      "loss": 0.199,
      "step": 4381
    },
    {
      "epoch": 0.6965091096938268,
      "grad_norm": 0.5274388790130615,
      "learning_rate": 2.2266988371699573e-06,
      "loss": 0.1906,
      "step": 4382
    },
    {
      "epoch": 0.6966680574596174,
      "grad_norm": 0.5166686773300171,
      "learning_rate": 2.2245572458000714e-06,
      "loss": 0.1569,
      "step": 4383
    },
    {
      "epoch": 0.6968270052254077,
      "grad_norm": 0.5408204793930054,
      "learning_rate": 2.222416390107907e-06,
      "loss": 0.2122,
      "step": 4384
    },
    {
      "epoch": 0.6969859529911983,
      "grad_norm": 0.6034508347511292,
      "learning_rate": 2.220276270660928e-06,
      "loss": 0.2862,
      "step": 4385
    },
    {
      "epoch": 0.6971449007569888,
      "grad_norm": 0.5254374146461487,
      "learning_rate": 2.2181368880264147e-06,
      "loss": 0.1735,
      "step": 4386
    },
    {
      "epoch": 0.6973038485227792,
      "grad_norm": 0.524292528629303,
      "learning_rate": 2.215998242771445e-06,
      "loss": 0.1545,
      "step": 4387
    },
    {
      "epoch": 0.6974627962885697,
      "grad_norm": 0.6494830250740051,
      "learning_rate": 2.213860335462903e-06,
      "loss": 0.2992,
      "step": 4388
    },
    {
      "epoch": 0.6976217440543602,
      "grad_norm": 0.5822036862373352,
      "learning_rate": 2.211723166667475e-06,
      "loss": 0.2722,
      "step": 4389
    },
    {
      "epoch": 0.6977806918201506,
      "grad_norm": 0.5124265551567078,
      "learning_rate": 2.2095867369516544e-06,
      "loss": 0.1961,
      "step": 4390
    },
    {
      "epoch": 0.6979396395859411,
      "grad_norm": 0.5866488814353943,
      "learning_rate": 2.2074510468817394e-06,
      "loss": 0.2169,
      "step": 4391
    },
    {
      "epoch": 0.6980985873517316,
      "grad_norm": 0.48490259051322937,
      "learning_rate": 2.205316097023826e-06,
      "loss": 0.1658,
      "step": 4392
    },
    {
      "epoch": 0.698257535117522,
      "grad_norm": 0.5930293202400208,
      "learning_rate": 2.2031818879438234e-06,
      "loss": 0.26,
      "step": 4393
    },
    {
      "epoch": 0.6984164828833125,
      "grad_norm": 0.5552828311920166,
      "learning_rate": 2.2010484202074393e-06,
      "loss": 0.1533,
      "step": 4394
    },
    {
      "epoch": 0.698575430649103,
      "grad_norm": 0.5933102965354919,
      "learning_rate": 2.198915694380182e-06,
      "loss": 0.2699,
      "step": 4395
    },
    {
      "epoch": 0.6987343784148934,
      "grad_norm": 0.6178085207939148,
      "learning_rate": 2.1967837110273682e-06,
      "loss": 0.2521,
      "step": 4396
    },
    {
      "epoch": 0.6988933261806839,
      "grad_norm": 0.6145750284194946,
      "learning_rate": 2.1946524707141154e-06,
      "loss": 0.3065,
      "step": 4397
    },
    {
      "epoch": 0.6990522739464743,
      "grad_norm": 0.5147088766098022,
      "learning_rate": 2.192521974005345e-06,
      "loss": 0.2133,
      "step": 4398
    },
    {
      "epoch": 0.6992112217122648,
      "grad_norm": 0.5997684001922607,
      "learning_rate": 2.1903922214657803e-06,
      "loss": 0.1993,
      "step": 4399
    },
    {
      "epoch": 0.6993701694780553,
      "grad_norm": 0.5515148639678955,
      "learning_rate": 2.188263213659949e-06,
      "loss": 0.2103,
      "step": 4400
    },
    {
      "epoch": 0.6995291172438457,
      "grad_norm": 0.5499638319015503,
      "learning_rate": 2.1861349511521817e-06,
      "loss": 0.2074,
      "step": 4401
    },
    {
      "epoch": 0.6996880650096362,
      "grad_norm": 0.6021727919578552,
      "learning_rate": 2.1840074345066064e-06,
      "loss": 0.3317,
      "step": 4402
    },
    {
      "epoch": 0.6998470127754267,
      "grad_norm": 0.498124361038208,
      "learning_rate": 2.1818806642871594e-06,
      "loss": 0.2225,
      "step": 4403
    },
    {
      "epoch": 0.7000059605412171,
      "grad_norm": 0.48504677414894104,
      "learning_rate": 2.1797546410575783e-06,
      "loss": 0.1526,
      "step": 4404
    },
    {
      "epoch": 0.7001649083070076,
      "grad_norm": 0.6194789409637451,
      "learning_rate": 2.177629365381395e-06,
      "loss": 0.2178,
      "step": 4405
    },
    {
      "epoch": 0.7003238560727981,
      "grad_norm": 0.6003651022911072,
      "learning_rate": 2.175504837821957e-06,
      "loss": 0.2247,
      "step": 4406
    },
    {
      "epoch": 0.7004828038385885,
      "grad_norm": 0.6433189511299133,
      "learning_rate": 2.173381058942402e-06,
      "loss": 0.3325,
      "step": 4407
    },
    {
      "epoch": 0.700641751604379,
      "grad_norm": 0.6029658317565918,
      "learning_rate": 2.171258029305677e-06,
      "loss": 0.3323,
      "step": 4408
    },
    {
      "epoch": 0.7008006993701695,
      "grad_norm": 0.522352933883667,
      "learning_rate": 2.1691357494745215e-06,
      "loss": 0.2107,
      "step": 4409
    },
    {
      "epoch": 0.7009596471359599,
      "grad_norm": 0.5585768818855286,
      "learning_rate": 2.1670142200114837e-06,
      "loss": 0.2433,
      "step": 4410
    },
    {
      "epoch": 0.7011185949017504,
      "grad_norm": 0.5391258597373962,
      "learning_rate": 2.164893441478911e-06,
      "loss": 0.2117,
      "step": 4411
    },
    {
      "epoch": 0.7012775426675408,
      "grad_norm": 0.5198757648468018,
      "learning_rate": 2.1627734144389513e-06,
      "loss": 0.1886,
      "step": 4412
    },
    {
      "epoch": 0.7014364904333313,
      "grad_norm": 0.5285594463348389,
      "learning_rate": 2.1606541394535528e-06,
      "loss": 0.248,
      "step": 4413
    },
    {
      "epoch": 0.7015954381991218,
      "grad_norm": 0.5227158665657043,
      "learning_rate": 2.158535617084468e-06,
      "loss": 0.1232,
      "step": 4414
    },
    {
      "epoch": 0.7017543859649122,
      "grad_norm": 0.5612882971763611,
      "learning_rate": 2.156417847893242e-06,
      "loss": 0.2576,
      "step": 4415
    },
    {
      "epoch": 0.7019133337307027,
      "grad_norm": 0.4820683002471924,
      "learning_rate": 2.154300832441227e-06,
      "loss": 0.1662,
      "step": 4416
    },
    {
      "epoch": 0.7020722814964933,
      "grad_norm": 0.4612361490726471,
      "learning_rate": 2.1521845712895734e-06,
      "loss": 0.1262,
      "step": 4417
    },
    {
      "epoch": 0.7022312292622837,
      "grad_norm": 0.5873110294342041,
      "learning_rate": 2.150069064999233e-06,
      "loss": 0.2855,
      "step": 4418
    },
    {
      "epoch": 0.7023901770280742,
      "grad_norm": 0.4559609293937683,
      "learning_rate": 2.147954314130955e-06,
      "loss": 0.1274,
      "step": 4419
    },
    {
      "epoch": 0.7025491247938647,
      "grad_norm": 0.6091238260269165,
      "learning_rate": 2.14584031924529e-06,
      "loss": 0.2921,
      "step": 4420
    },
    {
      "epoch": 0.7027080725596551,
      "grad_norm": 0.47246837615966797,
      "learning_rate": 2.1437270809025897e-06,
      "loss": 0.1523,
      "step": 4421
    },
    {
      "epoch": 0.7028670203254456,
      "grad_norm": 0.5604346394538879,
      "learning_rate": 2.141614599663e-06,
      "loss": 0.2201,
      "step": 4422
    },
    {
      "epoch": 0.703025968091236,
      "grad_norm": 0.5064395070075989,
      "learning_rate": 2.139502876086471e-06,
      "loss": 0.184,
      "step": 4423
    },
    {
      "epoch": 0.7031849158570265,
      "grad_norm": 0.4450359046459198,
      "learning_rate": 2.1373919107327506e-06,
      "loss": 0.1115,
      "step": 4424
    },
    {
      "epoch": 0.703343863622817,
      "grad_norm": 0.5753934979438782,
      "learning_rate": 2.135281704161386e-06,
      "loss": 0.2871,
      "step": 4425
    },
    {
      "epoch": 0.7035028113886074,
      "grad_norm": 0.5397241115570068,
      "learning_rate": 2.1331722569317226e-06,
      "loss": 0.2508,
      "step": 4426
    },
    {
      "epoch": 0.7036617591543979,
      "grad_norm": 0.5971965193748474,
      "learning_rate": 2.1310635696029046e-06,
      "loss": 0.2746,
      "step": 4427
    },
    {
      "epoch": 0.7038207069201884,
      "grad_norm": 0.5413930416107178,
      "learning_rate": 2.128955642733877e-06,
      "loss": 0.1597,
      "step": 4428
    },
    {
      "epoch": 0.7039796546859788,
      "grad_norm": 0.6362301707267761,
      "learning_rate": 2.1268484768833776e-06,
      "loss": 0.3346,
      "step": 4429
    },
    {
      "epoch": 0.7041386024517693,
      "grad_norm": 0.5442999005317688,
      "learning_rate": 2.1247420726099483e-06,
      "loss": 0.2035,
      "step": 4430
    },
    {
      "epoch": 0.7042975502175598,
      "grad_norm": 0.5860608816146851,
      "learning_rate": 2.122636430471926e-06,
      "loss": 0.3003,
      "step": 4431
    },
    {
      "epoch": 0.7044564979833502,
      "grad_norm": 0.5533650517463684,
      "learning_rate": 2.1205315510274473e-06,
      "loss": 0.2276,
      "step": 4432
    },
    {
      "epoch": 0.7046154457491407,
      "grad_norm": 0.6134543418884277,
      "learning_rate": 2.1184274348344457e-06,
      "loss": 0.2963,
      "step": 4433
    },
    {
      "epoch": 0.7047743935149312,
      "grad_norm": 0.5027704238891602,
      "learning_rate": 2.1163240824506544e-06,
      "loss": 0.1874,
      "step": 4434
    },
    {
      "epoch": 0.7049333412807216,
      "grad_norm": 0.7629569172859192,
      "learning_rate": 2.114221494433598e-06,
      "loss": 0.2136,
      "step": 4435
    },
    {
      "epoch": 0.7050922890465121,
      "grad_norm": 0.6809821128845215,
      "learning_rate": 2.1121196713406055e-06,
      "loss": 0.3568,
      "step": 4436
    },
    {
      "epoch": 0.7052512368123025,
      "grad_norm": 0.5459966063499451,
      "learning_rate": 2.1100186137288005e-06,
      "loss": 0.2012,
      "step": 4437
    },
    {
      "epoch": 0.705410184578093,
      "grad_norm": 0.6661441326141357,
      "learning_rate": 2.107918322155102e-06,
      "loss": 0.2001,
      "step": 4438
    },
    {
      "epoch": 0.7055691323438835,
      "grad_norm": 0.661453127861023,
      "learning_rate": 2.1058187971762296e-06,
      "loss": 0.3301,
      "step": 4439
    },
    {
      "epoch": 0.7057280801096739,
      "grad_norm": 0.5182021856307983,
      "learning_rate": 2.103720039348696e-06,
      "loss": 0.1862,
      "step": 4440
    },
    {
      "epoch": 0.7058870278754644,
      "grad_norm": 0.5978359580039978,
      "learning_rate": 2.101622049228815e-06,
      "loss": 0.3017,
      "step": 4441
    },
    {
      "epoch": 0.7060459756412549,
      "grad_norm": 0.4812301993370056,
      "learning_rate": 2.099524827372691e-06,
      "loss": 0.1702,
      "step": 4442
    },
    {
      "epoch": 0.7062049234070453,
      "grad_norm": 0.598118007183075,
      "learning_rate": 2.0974283743362283e-06,
      "loss": 0.2801,
      "step": 4443
    },
    {
      "epoch": 0.7063638711728358,
      "grad_norm": 0.5730642080307007,
      "learning_rate": 2.0953326906751283e-06,
      "loss": 0.2096,
      "step": 4444
    },
    {
      "epoch": 0.7065228189386263,
      "grad_norm": 0.6737815737724304,
      "learning_rate": 2.093237776944886e-06,
      "loss": 0.3038,
      "step": 4445
    },
    {
      "epoch": 0.7066817667044167,
      "grad_norm": 0.5590664148330688,
      "learning_rate": 2.0911436337007935e-06,
      "loss": 0.2036,
      "step": 4446
    },
    {
      "epoch": 0.7068407144702072,
      "grad_norm": 0.5878391861915588,
      "learning_rate": 2.0890502614979397e-06,
      "loss": 0.3234,
      "step": 4447
    },
    {
      "epoch": 0.7069996622359978,
      "grad_norm": 0.4225369989871979,
      "learning_rate": 2.0869576608912093e-06,
      "loss": 0.1126,
      "step": 4448
    },
    {
      "epoch": 0.7071586100017881,
      "grad_norm": 0.5221978425979614,
      "learning_rate": 2.084865832435278e-06,
      "loss": 0.2074,
      "step": 4449
    },
    {
      "epoch": 0.7073175577675787,
      "grad_norm": 0.633033275604248,
      "learning_rate": 2.0827747766846205e-06,
      "loss": 0.32,
      "step": 4450
    },
    {
      "epoch": 0.707476505533369,
      "grad_norm": 0.5500040054321289,
      "learning_rate": 2.0806844941935078e-06,
      "loss": 0.2498,
      "step": 4451
    },
    {
      "epoch": 0.7076354532991596,
      "grad_norm": 0.6197794675827026,
      "learning_rate": 2.078594985516004e-06,
      "loss": 0.3496,
      "step": 4452
    },
    {
      "epoch": 0.7077944010649501,
      "grad_norm": 0.5284186601638794,
      "learning_rate": 2.076506251205968e-06,
      "loss": 0.1877,
      "step": 4453
    },
    {
      "epoch": 0.7079533488307405,
      "grad_norm": 0.5576983094215393,
      "learning_rate": 2.0744182918170543e-06,
      "loss": 0.2534,
      "step": 4454
    },
    {
      "epoch": 0.708112296596531,
      "grad_norm": 0.4786704182624817,
      "learning_rate": 2.072331107902713e-06,
      "loss": 0.1282,
      "step": 4455
    },
    {
      "epoch": 0.7082712443623215,
      "grad_norm": 0.49295029044151306,
      "learning_rate": 2.070244700016184e-06,
      "loss": 0.1768,
      "step": 4456
    },
    {
      "epoch": 0.7084301921281119,
      "grad_norm": 0.9490803480148315,
      "learning_rate": 2.068159068710507e-06,
      "loss": 0.2325,
      "step": 4457
    },
    {
      "epoch": 0.7085891398939024,
      "grad_norm": 0.583041787147522,
      "learning_rate": 2.0660742145385133e-06,
      "loss": 0.149,
      "step": 4458
    },
    {
      "epoch": 0.7087480876596929,
      "grad_norm": 0.4835878908634186,
      "learning_rate": 2.063990138052828e-06,
      "loss": 0.1692,
      "step": 4459
    },
    {
      "epoch": 0.7089070354254833,
      "grad_norm": 0.576458215713501,
      "learning_rate": 2.0619068398058706e-06,
      "loss": 0.2442,
      "step": 4460
    },
    {
      "epoch": 0.7090659831912738,
      "grad_norm": 0.5485645532608032,
      "learning_rate": 2.0598243203498562e-06,
      "loss": 0.2155,
      "step": 4461
    },
    {
      "epoch": 0.7092249309570642,
      "grad_norm": 0.6377038359642029,
      "learning_rate": 2.057742580236789e-06,
      "loss": 0.3209,
      "step": 4462
    },
    {
      "epoch": 0.7093838787228547,
      "grad_norm": 0.5357521772384644,
      "learning_rate": 2.0556616200184697e-06,
      "loss": 0.1757,
      "step": 4463
    },
    {
      "epoch": 0.7095428264886452,
      "grad_norm": 0.5491089224815369,
      "learning_rate": 2.0535814402464922e-06,
      "loss": 0.1522,
      "step": 4464
    },
    {
      "epoch": 0.7097017742544356,
      "grad_norm": 0.5104311108589172,
      "learning_rate": 2.051502041472243e-06,
      "loss": 0.1407,
      "step": 4465
    },
    {
      "epoch": 0.7098607220202261,
      "grad_norm": 0.5791493654251099,
      "learning_rate": 2.0494234242469026e-06,
      "loss": 0.3062,
      "step": 4466
    },
    {
      "epoch": 0.7100196697860166,
      "grad_norm": 0.6635854244232178,
      "learning_rate": 2.0473455891214416e-06,
      "loss": 0.2339,
      "step": 4467
    },
    {
      "epoch": 0.710178617551807,
      "grad_norm": 0.5941806435585022,
      "learning_rate": 2.0452685366466287e-06,
      "loss": 0.1748,
      "step": 4468
    },
    {
      "epoch": 0.7103375653175975,
      "grad_norm": 0.5365616083145142,
      "learning_rate": 2.0431922673730166e-06,
      "loss": 0.2504,
      "step": 4469
    },
    {
      "epoch": 0.710496513083388,
      "grad_norm": 0.6190725564956665,
      "learning_rate": 2.0411167818509577e-06,
      "loss": 0.1962,
      "step": 4470
    },
    {
      "epoch": 0.7106554608491784,
      "grad_norm": 0.4243365526199341,
      "learning_rate": 2.0390420806305945e-06,
      "loss": 0.1301,
      "step": 4471
    },
    {
      "epoch": 0.7108144086149689,
      "grad_norm": 0.6125600934028625,
      "learning_rate": 2.0369681642618605e-06,
      "loss": 0.2355,
      "step": 4472
    },
    {
      "epoch": 0.7109733563807594,
      "grad_norm": 0.6009012460708618,
      "learning_rate": 2.034895033294483e-06,
      "loss": 0.2805,
      "step": 4473
    },
    {
      "epoch": 0.7111323041465498,
      "grad_norm": 0.5139660835266113,
      "learning_rate": 2.0328226882779805e-06,
      "loss": 0.1753,
      "step": 4474
    },
    {
      "epoch": 0.7112912519123403,
      "grad_norm": 0.6434154510498047,
      "learning_rate": 2.030751129761664e-06,
      "loss": 0.3075,
      "step": 4475
    },
    {
      "epoch": 0.7114501996781307,
      "grad_norm": 0.4811020791530609,
      "learning_rate": 2.0286803582946314e-06,
      "loss": 0.1413,
      "step": 4476
    },
    {
      "epoch": 0.7116091474439212,
      "grad_norm": 0.6515394449234009,
      "learning_rate": 2.0266103744257763e-06,
      "loss": 0.284,
      "step": 4477
    },
    {
      "epoch": 0.7117680952097117,
      "grad_norm": 0.4563288986682892,
      "learning_rate": 2.0245411787037844e-06,
      "loss": 0.1236,
      "step": 4478
    },
    {
      "epoch": 0.7119270429755021,
      "grad_norm": 0.6626183986663818,
      "learning_rate": 2.0224727716771297e-06,
      "loss": 0.2267,
      "step": 4479
    },
    {
      "epoch": 0.7120859907412926,
      "grad_norm": 0.581011176109314,
      "learning_rate": 2.020405153894079e-06,
      "loss": 0.191,
      "step": 4480
    },
    {
      "epoch": 0.7122449385070831,
      "grad_norm": 0.5991584658622742,
      "learning_rate": 2.01833832590269e-06,
      "loss": 0.3374,
      "step": 4481
    },
    {
      "epoch": 0.7124038862728735,
      "grad_norm": 0.653606653213501,
      "learning_rate": 2.0162722882508072e-06,
      "loss": 0.2701,
      "step": 4482
    },
    {
      "epoch": 0.712562834038664,
      "grad_norm": 0.7200878858566284,
      "learning_rate": 2.0142070414860704e-06,
      "loss": 0.4265,
      "step": 4483
    },
    {
      "epoch": 0.7127217818044546,
      "grad_norm": 0.6919123530387878,
      "learning_rate": 2.0121425861559056e-06,
      "loss": 0.2543,
      "step": 4484
    },
    {
      "epoch": 0.712880729570245,
      "grad_norm": 0.5662816166877747,
      "learning_rate": 2.0100789228075375e-06,
      "loss": 0.2635,
      "step": 4485
    },
    {
      "epoch": 0.7130396773360355,
      "grad_norm": 0.6359437704086304,
      "learning_rate": 2.008016051987968e-06,
      "loss": 0.29,
      "step": 4486
    },
    {
      "epoch": 0.713198625101826,
      "grad_norm": 0.6000770330429077,
      "learning_rate": 2.0059539742439993e-06,
      "loss": 0.2492,
      "step": 4487
    },
    {
      "epoch": 0.7133575728676164,
      "grad_norm": 0.49207761883735657,
      "learning_rate": 2.0038926901222204e-06,
      "loss": 0.1396,
      "step": 4488
    },
    {
      "epoch": 0.7135165206334069,
      "grad_norm": 0.5230535268783569,
      "learning_rate": 2.0018322001690055e-06,
      "loss": 0.1868,
      "step": 4489
    },
    {
      "epoch": 0.7136754683991973,
      "grad_norm": 0.6749109625816345,
      "learning_rate": 1.999772504930525e-06,
      "loss": 0.3365,
      "step": 4490
    },
    {
      "epoch": 0.7138344161649878,
      "grad_norm": 0.49733462929725647,
      "learning_rate": 1.9977136049527348e-06,
      "loss": 0.1921,
      "step": 4491
    },
    {
      "epoch": 0.7139933639307783,
      "grad_norm": 0.5829271674156189,
      "learning_rate": 1.9956555007813804e-06,
      "loss": 0.2381,
      "step": 4492
    },
    {
      "epoch": 0.7141523116965687,
      "grad_norm": 0.5755957365036011,
      "learning_rate": 1.9935981929619987e-06,
      "loss": 0.209,
      "step": 4493
    },
    {
      "epoch": 0.7143112594623592,
      "grad_norm": 0.4687788188457489,
      "learning_rate": 1.991541682039912e-06,
      "loss": 0.1404,
      "step": 4494
    },
    {
      "epoch": 0.7144702072281497,
      "grad_norm": 0.6875451803207397,
      "learning_rate": 1.9894859685602353e-06,
      "loss": 0.3089,
      "step": 4495
    },
    {
      "epoch": 0.7146291549939401,
      "grad_norm": 0.5127573013305664,
      "learning_rate": 1.987431053067867e-06,
      "loss": 0.1467,
      "step": 4496
    },
    {
      "epoch": 0.7147881027597306,
      "grad_norm": 0.5762723088264465,
      "learning_rate": 1.9853769361074964e-06,
      "loss": 0.2447,
      "step": 4497
    },
    {
      "epoch": 0.7149470505255211,
      "grad_norm": 0.5703055262565613,
      "learning_rate": 1.983323618223607e-06,
      "loss": 0.132,
      "step": 4498
    },
    {
      "epoch": 0.7151059982913115,
      "grad_norm": 0.6528694033622742,
      "learning_rate": 1.9812710999604603e-06,
      "loss": 0.3256,
      "step": 4499
    },
    {
      "epoch": 0.715264946057102,
      "grad_norm": 1.0905405282974243,
      "learning_rate": 1.9792193818621118e-06,
      "loss": 0.1198,
      "step": 4500
    },
    {
      "epoch": 0.7154238938228924,
      "grad_norm": 0.8370436429977417,
      "learning_rate": 1.9771684644724066e-06,
      "loss": 0.361,
      "step": 4501
    },
    {
      "epoch": 0.7155828415886829,
      "grad_norm": 0.5914266109466553,
      "learning_rate": 1.97511834833497e-06,
      "loss": 0.295,
      "step": 4502
    },
    {
      "epoch": 0.7157417893544734,
      "grad_norm": 0.5525909066200256,
      "learning_rate": 1.973069033993223e-06,
      "loss": 0.2064,
      "step": 4503
    },
    {
      "epoch": 0.7159007371202638,
      "grad_norm": 0.609703004360199,
      "learning_rate": 1.971020521990368e-06,
      "loss": 0.2486,
      "step": 4504
    },
    {
      "epoch": 0.7160596848860543,
      "grad_norm": 0.5157434344291687,
      "learning_rate": 1.968972812869403e-06,
      "loss": 0.2074,
      "step": 4505
    },
    {
      "epoch": 0.7162186326518448,
      "grad_norm": 0.5418475270271301,
      "learning_rate": 1.9669259071731024e-06,
      "loss": 0.1714,
      "step": 4506
    },
    {
      "epoch": 0.7163775804176352,
      "grad_norm": 0.7552390098571777,
      "learning_rate": 1.9648798054440345e-06,
      "loss": 0.2498,
      "step": 4507
    },
    {
      "epoch": 0.7165365281834257,
      "grad_norm": 0.6796334981918335,
      "learning_rate": 1.9628345082245555e-06,
      "loss": 0.1895,
      "step": 4508
    },
    {
      "epoch": 0.7166954759492162,
      "grad_norm": 0.49011877179145813,
      "learning_rate": 1.960790016056801e-06,
      "loss": 0.1416,
      "step": 4509
    },
    {
      "epoch": 0.7168544237150066,
      "grad_norm": 0.5838510990142822,
      "learning_rate": 1.9587463294826993e-06,
      "loss": 0.242,
      "step": 4510
    },
    {
      "epoch": 0.7170133714807971,
      "grad_norm": 0.538833737373352,
      "learning_rate": 1.9567034490439677e-06,
      "loss": 0.2288,
      "step": 4511
    },
    {
      "epoch": 0.7171723192465876,
      "grad_norm": 0.44178786873817444,
      "learning_rate": 1.9546613752821025e-06,
      "loss": 0.129,
      "step": 4512
    },
    {
      "epoch": 0.717331267012378,
      "grad_norm": 0.5706019997596741,
      "learning_rate": 1.9526201087383902e-06,
      "loss": 0.2291,
      "step": 4513
    },
    {
      "epoch": 0.7174902147781685,
      "grad_norm": 0.7706211805343628,
      "learning_rate": 1.9505796499539024e-06,
      "loss": 0.1962,
      "step": 4514
    },
    {
      "epoch": 0.7176491625439589,
      "grad_norm": 0.5649141073226929,
      "learning_rate": 1.9485399994694998e-06,
      "loss": 0.1985,
      "step": 4515
    },
    {
      "epoch": 0.7178081103097494,
      "grad_norm": 0.9781752824783325,
      "learning_rate": 1.9465011578258217e-06,
      "loss": 0.1387,
      "step": 4516
    },
    {
      "epoch": 0.71796705807554,
      "grad_norm": 0.589708149433136,
      "learning_rate": 1.944463125563298e-06,
      "loss": 0.286,
      "step": 4517
    },
    {
      "epoch": 0.7181260058413304,
      "grad_norm": 0.6461740732192993,
      "learning_rate": 1.9424259032221482e-06,
      "loss": 0.1844,
      "step": 4518
    },
    {
      "epoch": 0.7182849536071209,
      "grad_norm": 0.53656405210495,
      "learning_rate": 1.940389491342367e-06,
      "loss": 0.1846,
      "step": 4519
    },
    {
      "epoch": 0.7184439013729114,
      "grad_norm": 0.45798125863075256,
      "learning_rate": 1.9383538904637422e-06,
      "loss": 0.1463,
      "step": 4520
    },
    {
      "epoch": 0.7186028491387018,
      "grad_norm": 0.6423057913780212,
      "learning_rate": 1.9363191011258426e-06,
      "loss": 0.3057,
      "step": 4521
    },
    {
      "epoch": 0.7187617969044923,
      "grad_norm": 0.693695604801178,
      "learning_rate": 1.934285123868026e-06,
      "loss": 0.3197,
      "step": 4522
    },
    {
      "epoch": 0.7189207446702828,
      "grad_norm": 0.6007724404335022,
      "learning_rate": 1.9322519592294265e-06,
      "loss": 0.241,
      "step": 4523
    },
    {
      "epoch": 0.7190796924360732,
      "grad_norm": 0.5573216080665588,
      "learning_rate": 1.930219607748974e-06,
      "loss": 0.2414,
      "step": 4524
    },
    {
      "epoch": 0.7192386402018637,
      "grad_norm": 0.5801519155502319,
      "learning_rate": 1.9281880699653773e-06,
      "loss": 0.2454,
      "step": 4525
    },
    {
      "epoch": 0.7193975879676542,
      "grad_norm": 0.6248806715011597,
      "learning_rate": 1.9261573464171264e-06,
      "loss": 0.3315,
      "step": 4526
    },
    {
      "epoch": 0.7195565357334446,
      "grad_norm": 0.5141265392303467,
      "learning_rate": 1.9241274376425e-06,
      "loss": 0.2139,
      "step": 4527
    },
    {
      "epoch": 0.7197154834992351,
      "grad_norm": 0.6272164583206177,
      "learning_rate": 1.9220983441795614e-06,
      "loss": 0.2382,
      "step": 4528
    },
    {
      "epoch": 0.7198744312650255,
      "grad_norm": 0.5203463435173035,
      "learning_rate": 1.920070066566153e-06,
      "loss": 0.1904,
      "step": 4529
    },
    {
      "epoch": 0.720033379030816,
      "grad_norm": 0.6540848612785339,
      "learning_rate": 1.9180426053399033e-06,
      "loss": 0.2242,
      "step": 4530
    },
    {
      "epoch": 0.7201923267966065,
      "grad_norm": 0.5036574602127075,
      "learning_rate": 1.9160159610382284e-06,
      "loss": 0.1793,
      "step": 4531
    },
    {
      "epoch": 0.7203512745623969,
      "grad_norm": 0.5765871405601501,
      "learning_rate": 1.913990134198324e-06,
      "loss": 0.2629,
      "step": 4532
    },
    {
      "epoch": 0.7205102223281874,
      "grad_norm": 0.516997754573822,
      "learning_rate": 1.9119651253571676e-06,
      "loss": 0.1653,
      "step": 4533
    },
    {
      "epoch": 0.7206691700939779,
      "grad_norm": 0.5615277290344238,
      "learning_rate": 1.9099409350515217e-06,
      "loss": 0.2182,
      "step": 4534
    },
    {
      "epoch": 0.7208281178597683,
      "grad_norm": 0.46783530712127686,
      "learning_rate": 1.9079175638179347e-06,
      "loss": 0.1426,
      "step": 4535
    },
    {
      "epoch": 0.7209870656255588,
      "grad_norm": 0.5069355368614197,
      "learning_rate": 1.90589501219273e-06,
      "loss": 0.1965,
      "step": 4536
    },
    {
      "epoch": 0.7211460133913493,
      "grad_norm": 0.4919734299182892,
      "learning_rate": 1.903873280712023e-06,
      "loss": 0.1673,
      "step": 4537
    },
    {
      "epoch": 0.7213049611571397,
      "grad_norm": 0.5854424834251404,
      "learning_rate": 1.9018523699117093e-06,
      "loss": 0.2585,
      "step": 4538
    },
    {
      "epoch": 0.7214639089229302,
      "grad_norm": 0.5068544745445251,
      "learning_rate": 1.89983228032746e-06,
      "loss": 0.1816,
      "step": 4539
    },
    {
      "epoch": 0.7216228566887206,
      "grad_norm": 0.5994275808334351,
      "learning_rate": 1.897813012494737e-06,
      "loss": 0.2312,
      "step": 4540
    },
    {
      "epoch": 0.7217818044545111,
      "grad_norm": 0.5725495219230652,
      "learning_rate": 1.8957945669487803e-06,
      "loss": 0.1856,
      "step": 4541
    },
    {
      "epoch": 0.7219407522203016,
      "grad_norm": 0.6027479767799377,
      "learning_rate": 1.8937769442246145e-06,
      "loss": 0.2864,
      "step": 4542
    },
    {
      "epoch": 0.722099699986092,
      "grad_norm": 0.6738179922103882,
      "learning_rate": 1.8917601448570399e-06,
      "loss": 0.3415,
      "step": 4543
    },
    {
      "epoch": 0.7222586477518825,
      "grad_norm": 0.4869612455368042,
      "learning_rate": 1.8897441693806478e-06,
      "loss": 0.1664,
      "step": 4544
    },
    {
      "epoch": 0.722417595517673,
      "grad_norm": 0.8811489939689636,
      "learning_rate": 1.8877290183298058e-06,
      "loss": 0.3254,
      "step": 4545
    },
    {
      "epoch": 0.7225765432834634,
      "grad_norm": 0.5573135614395142,
      "learning_rate": 1.885714692238661e-06,
      "loss": 0.209,
      "step": 4546
    },
    {
      "epoch": 0.7227354910492539,
      "grad_norm": 0.6489150524139404,
      "learning_rate": 1.8837011916411458e-06,
      "loss": 0.1874,
      "step": 4547
    },
    {
      "epoch": 0.7228944388150444,
      "grad_norm": 0.6162731647491455,
      "learning_rate": 1.8816885170709742e-06,
      "loss": 0.2847,
      "step": 4548
    },
    {
      "epoch": 0.7230533865808348,
      "grad_norm": 0.5463405847549438,
      "learning_rate": 1.8796766690616337e-06,
      "loss": 0.1981,
      "step": 4549
    },
    {
      "epoch": 0.7232123343466254,
      "grad_norm": 0.5233010053634644,
      "learning_rate": 1.8776656481464034e-06,
      "loss": 0.1949,
      "step": 4550
    },
    {
      "epoch": 0.7233712821124159,
      "grad_norm": 0.5087677836418152,
      "learning_rate": 1.8756554548583377e-06,
      "loss": 0.2007,
      "step": 4551
    },
    {
      "epoch": 0.7235302298782063,
      "grad_norm": 0.6195115447044373,
      "learning_rate": 1.8736460897302728e-06,
      "loss": 0.2081,
      "step": 4552
    },
    {
      "epoch": 0.7236891776439968,
      "grad_norm": 0.5122350454330444,
      "learning_rate": 1.8716375532948216e-06,
      "loss": 0.1762,
      "step": 4553
    },
    {
      "epoch": 0.7238481254097872,
      "grad_norm": 0.9884020686149597,
      "learning_rate": 1.869629846084382e-06,
      "loss": 0.2207,
      "step": 4554
    },
    {
      "epoch": 0.7240070731755777,
      "grad_norm": 0.6916525363922119,
      "learning_rate": 1.867622968631132e-06,
      "loss": 0.3808,
      "step": 4555
    },
    {
      "epoch": 0.7241660209413682,
      "grad_norm": 0.6440565586090088,
      "learning_rate": 1.8656169214670233e-06,
      "loss": 0.3111,
      "step": 4556
    },
    {
      "epoch": 0.7243249687071586,
      "grad_norm": 0.5076801776885986,
      "learning_rate": 1.863611705123798e-06,
      "loss": 0.1752,
      "step": 4557
    },
    {
      "epoch": 0.7244839164729491,
      "grad_norm": 0.6423662900924683,
      "learning_rate": 1.8616073201329714e-06,
      "loss": 0.3409,
      "step": 4558
    },
    {
      "epoch": 0.7246428642387396,
      "grad_norm": 0.594069242477417,
      "learning_rate": 1.8596037670258372e-06,
      "loss": 0.1877,
      "step": 4559
    },
    {
      "epoch": 0.72480181200453,
      "grad_norm": 0.522026002407074,
      "learning_rate": 1.8576010463334716e-06,
      "loss": 0.2079,
      "step": 4560
    },
    {
      "epoch": 0.7249607597703205,
      "grad_norm": 0.5051867365837097,
      "learning_rate": 1.855599158586729e-06,
      "loss": 0.168,
      "step": 4561
    },
    {
      "epoch": 0.725119707536111,
      "grad_norm": 0.64227294921875,
      "learning_rate": 1.8535981043162442e-06,
      "loss": 0.1638,
      "step": 4562
    },
    {
      "epoch": 0.7252786553019014,
      "grad_norm": 0.46473199129104614,
      "learning_rate": 1.8515978840524302e-06,
      "loss": 0.1505,
      "step": 4563
    },
    {
      "epoch": 0.7254376030676919,
      "grad_norm": 0.4980698227882385,
      "learning_rate": 1.8495984983254782e-06,
      "loss": 0.1523,
      "step": 4564
    },
    {
      "epoch": 0.7255965508334824,
      "grad_norm": 0.5571750998497009,
      "learning_rate": 1.8475999476653622e-06,
      "loss": 0.1702,
      "step": 4565
    },
    {
      "epoch": 0.7257554985992728,
      "grad_norm": 0.5818113684654236,
      "learning_rate": 1.8456022326018264e-06,
      "loss": 0.2144,
      "step": 4566
    },
    {
      "epoch": 0.7259144463650633,
      "grad_norm": 0.6431606411933899,
      "learning_rate": 1.8436053536644017e-06,
      "loss": 0.2269,
      "step": 4567
    },
    {
      "epoch": 0.7260733941308537,
      "grad_norm": 1.8542606830596924,
      "learning_rate": 1.8416093113823942e-06,
      "loss": 0.1481,
      "step": 4568
    },
    {
      "epoch": 0.7262323418966442,
      "grad_norm": 0.5885643362998962,
      "learning_rate": 1.8396141062848877e-06,
      "loss": 0.2906,
      "step": 4569
    },
    {
      "epoch": 0.7263912896624347,
      "grad_norm": 0.5725896954536438,
      "learning_rate": 1.8376197389007454e-06,
      "loss": 0.1554,
      "step": 4570
    },
    {
      "epoch": 0.7265502374282251,
      "grad_norm": 0.5959123373031616,
      "learning_rate": 1.8356262097586082e-06,
      "loss": 0.2131,
      "step": 4571
    },
    {
      "epoch": 0.7267091851940156,
      "grad_norm": 0.6434860825538635,
      "learning_rate": 1.8336335193868955e-06,
      "loss": 0.3191,
      "step": 4572
    },
    {
      "epoch": 0.7268681329598061,
      "grad_norm": 0.5448907017707825,
      "learning_rate": 1.8316416683138004e-06,
      "loss": 0.2277,
      "step": 4573
    },
    {
      "epoch": 0.7270270807255965,
      "grad_norm": 0.4845481514930725,
      "learning_rate": 1.829650657067298e-06,
      "loss": 0.133,
      "step": 4574
    },
    {
      "epoch": 0.727186028491387,
      "grad_norm": 0.5846055150032043,
      "learning_rate": 1.827660486175139e-06,
      "loss": 0.1754,
      "step": 4575
    },
    {
      "epoch": 0.7273449762571775,
      "grad_norm": 0.5537846684455872,
      "learning_rate": 1.8256711561648526e-06,
      "loss": 0.2148,
      "step": 4576
    },
    {
      "epoch": 0.7275039240229679,
      "grad_norm": 0.8837277293205261,
      "learning_rate": 1.8236826675637431e-06,
      "loss": 0.3131,
      "step": 4577
    },
    {
      "epoch": 0.7276628717887584,
      "grad_norm": 0.6525349020957947,
      "learning_rate": 1.8216950208988949e-06,
      "loss": 0.2232,
      "step": 4578
    },
    {
      "epoch": 0.7278218195545488,
      "grad_norm": 0.8086945414543152,
      "learning_rate": 1.8197082166971637e-06,
      "loss": 0.2478,
      "step": 4579
    },
    {
      "epoch": 0.7279807673203393,
      "grad_norm": 0.5750007033348083,
      "learning_rate": 1.8177222554851865e-06,
      "loss": 0.2486,
      "step": 4580
    },
    {
      "epoch": 0.7281397150861298,
      "grad_norm": 0.4887714982032776,
      "learning_rate": 1.8157371377893769e-06,
      "loss": 0.1579,
      "step": 4581
    },
    {
      "epoch": 0.7282986628519202,
      "grad_norm": 0.5160702466964722,
      "learning_rate": 1.8137528641359225e-06,
      "loss": 0.1522,
      "step": 4582
    },
    {
      "epoch": 0.7284576106177107,
      "grad_norm": 0.5823887586593628,
      "learning_rate": 1.811769435050789e-06,
      "loss": 0.2615,
      "step": 4583
    },
    {
      "epoch": 0.7286165583835013,
      "grad_norm": 0.6021385192871094,
      "learning_rate": 1.8097868510597178e-06,
      "loss": 0.2346,
      "step": 4584
    },
    {
      "epoch": 0.7287755061492917,
      "grad_norm": 0.5419413447380066,
      "learning_rate": 1.8078051126882274e-06,
      "loss": 0.2151,
      "step": 4585
    },
    {
      "epoch": 0.7289344539150822,
      "grad_norm": 0.6395266056060791,
      "learning_rate": 1.8058242204616072e-06,
      "loss": 0.2509,
      "step": 4586
    },
    {
      "epoch": 0.7290934016808727,
      "grad_norm": 0.5683380961418152,
      "learning_rate": 1.803844174904928e-06,
      "loss": 0.2572,
      "step": 4587
    },
    {
      "epoch": 0.7292523494466631,
      "grad_norm": 0.5783175230026245,
      "learning_rate": 1.801864976543034e-06,
      "loss": 0.254,
      "step": 4588
    },
    {
      "epoch": 0.7294112972124536,
      "grad_norm": 0.6070572733879089,
      "learning_rate": 1.7998866259005449e-06,
      "loss": 0.2521,
      "step": 4589
    },
    {
      "epoch": 0.7295702449782441,
      "grad_norm": 0.6002997756004333,
      "learning_rate": 1.7979091235018564e-06,
      "loss": 0.247,
      "step": 4590
    },
    {
      "epoch": 0.7297291927440345,
      "grad_norm": 0.5414323210716248,
      "learning_rate": 1.7959324698711378e-06,
      "loss": 0.2115,
      "step": 4591
    },
    {
      "epoch": 0.729888140509825,
      "grad_norm": 0.6487982869148254,
      "learning_rate": 1.7939566655323364e-06,
      "loss": 0.3718,
      "step": 4592
    },
    {
      "epoch": 0.7300470882756154,
      "grad_norm": 0.5100997686386108,
      "learning_rate": 1.7919817110091691e-06,
      "loss": 0.1804,
      "step": 4593
    },
    {
      "epoch": 0.7302060360414059,
      "grad_norm": 0.6221261024475098,
      "learning_rate": 1.7900076068251326e-06,
      "loss": 0.2601,
      "step": 4594
    },
    {
      "epoch": 0.7303649838071964,
      "grad_norm": 0.5236812233924866,
      "learning_rate": 1.7880343535034961e-06,
      "loss": 0.1811,
      "step": 4595
    },
    {
      "epoch": 0.7305239315729868,
      "grad_norm": 0.5073118209838867,
      "learning_rate": 1.7860619515673034e-06,
      "loss": 0.144,
      "step": 4596
    },
    {
      "epoch": 0.7306828793387773,
      "grad_norm": 0.6360734105110168,
      "learning_rate": 1.7840904015393728e-06,
      "loss": 0.204,
      "step": 4597
    },
    {
      "epoch": 0.7308418271045678,
      "grad_norm": 0.5231469869613647,
      "learning_rate": 1.7821197039422971e-06,
      "loss": 0.1545,
      "step": 4598
    },
    {
      "epoch": 0.7310007748703582,
      "grad_norm": 0.6854599714279175,
      "learning_rate": 1.7801498592984445e-06,
      "loss": 0.2138,
      "step": 4599
    },
    {
      "epoch": 0.7311597226361487,
      "grad_norm": 0.6196095943450928,
      "learning_rate": 1.7781808681299518e-06,
      "loss": 0.2718,
      "step": 4600
    },
    {
      "epoch": 0.7313186704019392,
      "grad_norm": 0.5420400500297546,
      "learning_rate": 1.7762127309587346e-06,
      "loss": 0.2544,
      "step": 4601
    },
    {
      "epoch": 0.7314776181677296,
      "grad_norm": 0.6611230969429016,
      "learning_rate": 1.7742454483064809e-06,
      "loss": 0.3095,
      "step": 4602
    },
    {
      "epoch": 0.7316365659335201,
      "grad_norm": 0.5701214075088501,
      "learning_rate": 1.7722790206946522e-06,
      "loss": 0.2204,
      "step": 4603
    },
    {
      "epoch": 0.7317955136993106,
      "grad_norm": 0.5171658396720886,
      "learning_rate": 1.770313448644483e-06,
      "loss": 0.2103,
      "step": 4604
    },
    {
      "epoch": 0.731954461465101,
      "grad_norm": 0.5152173638343811,
      "learning_rate": 1.7683487326769826e-06,
      "loss": 0.1477,
      "step": 4605
    },
    {
      "epoch": 0.7321134092308915,
      "grad_norm": 0.6750572323799133,
      "learning_rate": 1.7663848733129296e-06,
      "loss": 0.2524,
      "step": 4606
    },
    {
      "epoch": 0.7322723569966819,
      "grad_norm": 0.583953857421875,
      "learning_rate": 1.764421871072879e-06,
      "loss": 0.2591,
      "step": 4607
    },
    {
      "epoch": 0.7324313047624724,
      "grad_norm": 0.518949031829834,
      "learning_rate": 1.762459726477157e-06,
      "loss": 0.1803,
      "step": 4608
    },
    {
      "epoch": 0.7325902525282629,
      "grad_norm": 0.6400448083877563,
      "learning_rate": 1.7604984400458636e-06,
      "loss": 0.2168,
      "step": 4609
    },
    {
      "epoch": 0.7327492002940533,
      "grad_norm": 0.5927878618240356,
      "learning_rate": 1.7585380122988705e-06,
      "loss": 0.2744,
      "step": 4610
    },
    {
      "epoch": 0.7329081480598438,
      "grad_norm": 0.6255842447280884,
      "learning_rate": 1.756578443755822e-06,
      "loss": 0.3249,
      "step": 4611
    },
    {
      "epoch": 0.7330670958256343,
      "grad_norm": 0.6735660433769226,
      "learning_rate": 1.754619734936136e-06,
      "loss": 0.3846,
      "step": 4612
    },
    {
      "epoch": 0.7332260435914247,
      "grad_norm": 0.5726986527442932,
      "learning_rate": 1.752661886358999e-06,
      "loss": 0.2809,
      "step": 4613
    },
    {
      "epoch": 0.7333849913572152,
      "grad_norm": 0.5211431384086609,
      "learning_rate": 1.7507048985433716e-06,
      "loss": 0.2291,
      "step": 4614
    },
    {
      "epoch": 0.7335439391230058,
      "grad_norm": 0.6202980875968933,
      "learning_rate": 1.7487487720079881e-06,
      "loss": 0.2732,
      "step": 4615
    },
    {
      "epoch": 0.7337028868887961,
      "grad_norm": 0.5300977230072021,
      "learning_rate": 1.7467935072713515e-06,
      "loss": 0.2157,
      "step": 4616
    },
    {
      "epoch": 0.7338618346545867,
      "grad_norm": 0.4818384349346161,
      "learning_rate": 1.7448391048517378e-06,
      "loss": 0.1797,
      "step": 4617
    },
    {
      "epoch": 0.734020782420377,
      "grad_norm": 0.6115435361862183,
      "learning_rate": 1.742885565267194e-06,
      "loss": 0.1633,
      "step": 4618
    },
    {
      "epoch": 0.7341797301861676,
      "grad_norm": 0.48285385966300964,
      "learning_rate": 1.740932889035541e-06,
      "loss": 0.1557,
      "step": 4619
    },
    {
      "epoch": 0.7343386779519581,
      "grad_norm": 0.613669753074646,
      "learning_rate": 1.7389810766743642e-06,
      "loss": 0.2553,
      "step": 4620
    },
    {
      "epoch": 0.7344976257177485,
      "grad_norm": 0.5719392895698547,
      "learning_rate": 1.7370301287010261e-06,
      "loss": 0.1912,
      "step": 4621
    },
    {
      "epoch": 0.734656573483539,
      "grad_norm": 0.5557398200035095,
      "learning_rate": 1.735080045632659e-06,
      "loss": 0.2509,
      "step": 4622
    },
    {
      "epoch": 0.7348155212493295,
      "grad_norm": 0.5185472965240479,
      "learning_rate": 1.7331308279861641e-06,
      "loss": 0.1599,
      "step": 4623
    },
    {
      "epoch": 0.7349744690151199,
      "grad_norm": 0.5730633735656738,
      "learning_rate": 1.7311824762782154e-06,
      "loss": 0.2599,
      "step": 4624
    },
    {
      "epoch": 0.7351334167809104,
      "grad_norm": 0.5113499760627747,
      "learning_rate": 1.7292349910252571e-06,
      "loss": 0.2093,
      "step": 4625
    },
    {
      "epoch": 0.7352923645467009,
      "grad_norm": 0.5802496671676636,
      "learning_rate": 1.7272883727434996e-06,
      "loss": 0.2528,
      "step": 4626
    },
    {
      "epoch": 0.7354513123124913,
      "grad_norm": 0.6088331341743469,
      "learning_rate": 1.7253426219489284e-06,
      "loss": 0.1844,
      "step": 4627
    },
    {
      "epoch": 0.7356102600782818,
      "grad_norm": 0.5123031139373779,
      "learning_rate": 1.7233977391572977e-06,
      "loss": 0.2014,
      "step": 4628
    },
    {
      "epoch": 0.7357692078440723,
      "grad_norm": 0.5383166670799255,
      "learning_rate": 1.7214537248841317e-06,
      "loss": 0.2308,
      "step": 4629
    },
    {
      "epoch": 0.7359281556098627,
      "grad_norm": 0.5779910087585449,
      "learning_rate": 1.719510579644723e-06,
      "loss": 0.2484,
      "step": 4630
    },
    {
      "epoch": 0.7360871033756532,
      "grad_norm": 0.6892879605293274,
      "learning_rate": 1.7175683039541358e-06,
      "loss": 0.4105,
      "step": 4631
    },
    {
      "epoch": 0.7362460511414436,
      "grad_norm": 0.5185031294822693,
      "learning_rate": 1.7156268983272045e-06,
      "loss": 0.2045,
      "step": 4632
    },
    {
      "epoch": 0.7364049989072341,
      "grad_norm": 0.5448561310768127,
      "learning_rate": 1.7136863632785273e-06,
      "loss": 0.2455,
      "step": 4633
    },
    {
      "epoch": 0.7365639466730246,
      "grad_norm": 0.7483258843421936,
      "learning_rate": 1.7117466993224779e-06,
      "loss": 0.1168,
      "step": 4634
    },
    {
      "epoch": 0.736722894438815,
      "grad_norm": 0.5989236831665039,
      "learning_rate": 1.709807906973196e-06,
      "loss": 0.2122,
      "step": 4635
    },
    {
      "epoch": 0.7368818422046055,
      "grad_norm": 0.49984318017959595,
      "learning_rate": 1.7078699867445925e-06,
      "loss": 0.1769,
      "step": 4636
    },
    {
      "epoch": 0.737040789970396,
      "grad_norm": 0.6583788990974426,
      "learning_rate": 1.7059329391503443e-06,
      "loss": 0.2514,
      "step": 4637
    },
    {
      "epoch": 0.7371997377361864,
      "grad_norm": 0.554105818271637,
      "learning_rate": 1.703996764703899e-06,
      "loss": 0.2406,
      "step": 4638
    },
    {
      "epoch": 0.7373586855019769,
      "grad_norm": 0.5415240526199341,
      "learning_rate": 1.702061463918474e-06,
      "loss": 0.1506,
      "step": 4639
    },
    {
      "epoch": 0.7375176332677674,
      "grad_norm": 0.5999628901481628,
      "learning_rate": 1.7001270373070494e-06,
      "loss": 0.2314,
      "step": 4640
    },
    {
      "epoch": 0.7376765810335578,
      "grad_norm": 0.49636662006378174,
      "learning_rate": 1.6981934853823796e-06,
      "loss": 0.1824,
      "step": 4641
    },
    {
      "epoch": 0.7378355287993483,
      "grad_norm": 0.5688267350196838,
      "learning_rate": 1.696260808656985e-06,
      "loss": 0.1538,
      "step": 4642
    },
    {
      "epoch": 0.7379944765651388,
      "grad_norm": 0.4923887252807617,
      "learning_rate": 1.694329007643154e-06,
      "loss": 0.1693,
      "step": 4643
    },
    {
      "epoch": 0.7381534243309292,
      "grad_norm": 0.5376244187355042,
      "learning_rate": 1.6923980828529424e-06,
      "loss": 0.1515,
      "step": 4644
    },
    {
      "epoch": 0.7383123720967197,
      "grad_norm": 0.5606154799461365,
      "learning_rate": 1.6904680347981768e-06,
      "loss": 0.2052,
      "step": 4645
    },
    {
      "epoch": 0.7384713198625101,
      "grad_norm": 0.5163735747337341,
      "learning_rate": 1.6885388639904444e-06,
      "loss": 0.1821,
      "step": 4646
    },
    {
      "epoch": 0.7386302676283006,
      "grad_norm": 0.45662757754325867,
      "learning_rate": 1.6866105709411069e-06,
      "loss": 0.1404,
      "step": 4647
    },
    {
      "epoch": 0.7387892153940911,
      "grad_norm": 0.7046171426773071,
      "learning_rate": 1.6846831561612893e-06,
      "loss": 0.2869,
      "step": 4648
    },
    {
      "epoch": 0.7389481631598815,
      "grad_norm": 0.5427427291870117,
      "learning_rate": 1.682756620161889e-06,
      "loss": 0.2173,
      "step": 4649
    },
    {
      "epoch": 0.739107110925672,
      "grad_norm": 0.5605025887489319,
      "learning_rate": 1.680830963453563e-06,
      "loss": 0.1958,
      "step": 4650
    },
    {
      "epoch": 0.7392660586914626,
      "grad_norm": 0.6657209992408752,
      "learning_rate": 1.6789061865467398e-06,
      "loss": 0.3544,
      "step": 4651
    },
    {
      "epoch": 0.739425006457253,
      "grad_norm": 0.5746538639068604,
      "learning_rate": 1.6769822899516163e-06,
      "loss": 0.26,
      "step": 4652
    },
    {
      "epoch": 0.7395839542230435,
      "grad_norm": 0.5414798259735107,
      "learning_rate": 1.6750592741781496e-06,
      "loss": 0.1895,
      "step": 4653
    },
    {
      "epoch": 0.739742901988834,
      "grad_norm": 0.5704736113548279,
      "learning_rate": 1.6731371397360692e-06,
      "loss": 0.1971,
      "step": 4654
    },
    {
      "epoch": 0.7399018497546244,
      "grad_norm": 0.5443599820137024,
      "learning_rate": 1.6712158871348694e-06,
      "loss": 0.1557,
      "step": 4655
    },
    {
      "epoch": 0.7400607975204149,
      "grad_norm": 0.6310527920722961,
      "learning_rate": 1.66929551688381e-06,
      "loss": 0.2536,
      "step": 4656
    },
    {
      "epoch": 0.7402197452862053,
      "grad_norm": 0.6509154438972473,
      "learning_rate": 1.6673760294919172e-06,
      "loss": 0.3652,
      "step": 4657
    },
    {
      "epoch": 0.7403786930519958,
      "grad_norm": 0.6599335670471191,
      "learning_rate": 1.6654574254679844e-06,
      "loss": 0.1629,
      "step": 4658
    },
    {
      "epoch": 0.7405376408177863,
      "grad_norm": 0.587782084941864,
      "learning_rate": 1.6635397053205704e-06,
      "loss": 0.2487,
      "step": 4659
    },
    {
      "epoch": 0.7406965885835767,
      "grad_norm": 0.541404128074646,
      "learning_rate": 1.6616228695579967e-06,
      "loss": 0.2188,
      "step": 4660
    },
    {
      "epoch": 0.7408555363493672,
      "grad_norm": 0.6059339046478271,
      "learning_rate": 1.6597069186883518e-06,
      "loss": 0.296,
      "step": 4661
    },
    {
      "epoch": 0.7410144841151577,
      "grad_norm": 0.540317177772522,
      "learning_rate": 1.657791853219497e-06,
      "loss": 0.2128,
      "step": 4662
    },
    {
      "epoch": 0.7411734318809481,
      "grad_norm": 0.6200278401374817,
      "learning_rate": 1.6558776736590466e-06,
      "loss": 0.3056,
      "step": 4663
    },
    {
      "epoch": 0.7413323796467386,
      "grad_norm": 0.5196603536605835,
      "learning_rate": 1.6539643805143874e-06,
      "loss": 0.1179,
      "step": 4664
    },
    {
      "epoch": 0.7414913274125291,
      "grad_norm": 0.5865691900253296,
      "learning_rate": 1.6520519742926705e-06,
      "loss": 0.2586,
      "step": 4665
    },
    {
      "epoch": 0.7416502751783195,
      "grad_norm": 0.6808726191520691,
      "learning_rate": 1.6501404555008133e-06,
      "loss": 0.159,
      "step": 4666
    },
    {
      "epoch": 0.74180922294411,
      "grad_norm": 0.6664221286773682,
      "learning_rate": 1.648229824645492e-06,
      "loss": 0.2797,
      "step": 4667
    },
    {
      "epoch": 0.7419681707099005,
      "grad_norm": 0.544337809085846,
      "learning_rate": 1.6463200822331516e-06,
      "loss": 0.1447,
      "step": 4668
    },
    {
      "epoch": 0.7421271184756909,
      "grad_norm": 0.5507983565330505,
      "learning_rate": 1.6444112287700058e-06,
      "loss": 0.1831,
      "step": 4669
    },
    {
      "epoch": 0.7422860662414814,
      "grad_norm": 0.49507272243499756,
      "learning_rate": 1.6425032647620249e-06,
      "loss": 0.1735,
      "step": 4670
    },
    {
      "epoch": 0.7424450140072718,
      "grad_norm": 0.896759033203125,
      "learning_rate": 1.640596190714947e-06,
      "loss": 0.3833,
      "step": 4671
    },
    {
      "epoch": 0.7426039617730623,
      "grad_norm": 0.5984500050544739,
      "learning_rate": 1.638690007134276e-06,
      "loss": 0.2779,
      "step": 4672
    },
    {
      "epoch": 0.7427629095388528,
      "grad_norm": 0.53806072473526,
      "learning_rate": 1.6367847145252747e-06,
      "loss": 0.1639,
      "step": 4673
    },
    {
      "epoch": 0.7429218573046432,
      "grad_norm": 0.5837854146957397,
      "learning_rate": 1.6348803133929736e-06,
      "loss": 0.2083,
      "step": 4674
    },
    {
      "epoch": 0.7430808050704337,
      "grad_norm": 0.677370011806488,
      "learning_rate": 1.6329768042421684e-06,
      "loss": 0.2685,
      "step": 4675
    },
    {
      "epoch": 0.7432397528362242,
      "grad_norm": 0.9989132285118103,
      "learning_rate": 1.6310741875774166e-06,
      "loss": 0.3203,
      "step": 4676
    },
    {
      "epoch": 0.7433987006020146,
      "grad_norm": 0.6042284369468689,
      "learning_rate": 1.6291724639030353e-06,
      "loss": 0.2981,
      "step": 4677
    },
    {
      "epoch": 0.7435576483678051,
      "grad_norm": 0.4899435341358185,
      "learning_rate": 1.627271633723111e-06,
      "loss": 0.182,
      "step": 4678
    },
    {
      "epoch": 0.7437165961335956,
      "grad_norm": 0.5857667326927185,
      "learning_rate": 1.6253716975414907e-06,
      "loss": 0.2733,
      "step": 4679
    },
    {
      "epoch": 0.743875543899386,
      "grad_norm": 0.5732094645500183,
      "learning_rate": 1.623472655861782e-06,
      "loss": 0.2125,
      "step": 4680
    },
    {
      "epoch": 0.7440344916651765,
      "grad_norm": 0.5471949577331543,
      "learning_rate": 1.6215745091873576e-06,
      "loss": 0.2343,
      "step": 4681
    },
    {
      "epoch": 0.744193439430967,
      "grad_norm": 0.5657813549041748,
      "learning_rate": 1.6196772580213577e-06,
      "loss": 0.2286,
      "step": 4682
    },
    {
      "epoch": 0.7443523871967574,
      "grad_norm": 0.6515668630599976,
      "learning_rate": 1.6177809028666769e-06,
      "loss": 0.3343,
      "step": 4683
    },
    {
      "epoch": 0.744511334962548,
      "grad_norm": 0.7702920436859131,
      "learning_rate": 1.6158854442259763e-06,
      "loss": 0.2029,
      "step": 4684
    },
    {
      "epoch": 0.7446702827283384,
      "grad_norm": 0.534313440322876,
      "learning_rate": 1.6139908826016798e-06,
      "loss": 0.1891,
      "step": 4685
    },
    {
      "epoch": 0.7448292304941289,
      "grad_norm": 0.5246642231941223,
      "learning_rate": 1.6120972184959739e-06,
      "loss": 0.1985,
      "step": 4686
    },
    {
      "epoch": 0.7449881782599194,
      "grad_norm": 0.5913562178611755,
      "learning_rate": 1.6102044524108014e-06,
      "loss": 0.249,
      "step": 4687
    },
    {
      "epoch": 0.7451471260257098,
      "grad_norm": 0.5508511066436768,
      "learning_rate": 1.608312584847877e-06,
      "loss": 0.2114,
      "step": 4688
    },
    {
      "epoch": 0.7453060737915003,
      "grad_norm": 0.8264078497886658,
      "learning_rate": 1.6064216163086716e-06,
      "loss": 0.2698,
      "step": 4689
    },
    {
      "epoch": 0.7454650215572908,
      "grad_norm": 0.44462305307388306,
      "learning_rate": 1.6045315472944145e-06,
      "loss": 0.1081,
      "step": 4690
    },
    {
      "epoch": 0.7456239693230812,
      "grad_norm": 0.6515733599662781,
      "learning_rate": 1.602642378306103e-06,
      "loss": 0.2012,
      "step": 4691
    },
    {
      "epoch": 0.7457829170888717,
      "grad_norm": 0.6032635569572449,
      "learning_rate": 1.6007541098444934e-06,
      "loss": 0.2278,
      "step": 4692
    },
    {
      "epoch": 0.7459418648546622,
      "grad_norm": 0.565963625907898,
      "learning_rate": 1.5988667424101006e-06,
      "loss": 0.2018,
      "step": 4693
    },
    {
      "epoch": 0.7461008126204526,
      "grad_norm": 0.5212118029594421,
      "learning_rate": 1.5969802765032034e-06,
      "loss": 0.1676,
      "step": 4694
    },
    {
      "epoch": 0.7462597603862431,
      "grad_norm": 0.4969266653060913,
      "learning_rate": 1.595094712623843e-06,
      "loss": 0.1297,
      "step": 4695
    },
    {
      "epoch": 0.7464187081520335,
      "grad_norm": 0.6038032174110413,
      "learning_rate": 1.5932100512718213e-06,
      "loss": 0.2413,
      "step": 4696
    },
    {
      "epoch": 0.746577655917824,
      "grad_norm": 0.6362609267234802,
      "learning_rate": 1.5913262929466955e-06,
      "loss": 0.2978,
      "step": 4697
    },
    {
      "epoch": 0.7467366036836145,
      "grad_norm": 0.6655362844467163,
      "learning_rate": 1.589443438147789e-06,
      "loss": 0.2453,
      "step": 4698
    },
    {
      "epoch": 0.7468955514494049,
      "grad_norm": 0.6142799854278564,
      "learning_rate": 1.5875614873741857e-06,
      "loss": 0.2606,
      "step": 4699
    },
    {
      "epoch": 0.7470544992151954,
      "grad_norm": 0.512172281742096,
      "learning_rate": 1.585680441124724e-06,
      "loss": 0.1594,
      "step": 4700
    },
    {
      "epoch": 0.7472134469809859,
      "grad_norm": 0.5086988806724548,
      "learning_rate": 1.5838002998980107e-06,
      "loss": 0.2496,
      "step": 4701
    },
    {
      "epoch": 0.7473723947467763,
      "grad_norm": 0.5994580984115601,
      "learning_rate": 1.5819210641924093e-06,
      "loss": 0.2954,
      "step": 4702
    },
    {
      "epoch": 0.7475313425125668,
      "grad_norm": 0.591589093208313,
      "learning_rate": 1.5800427345060398e-06,
      "loss": 0.2571,
      "step": 4703
    },
    {
      "epoch": 0.7476902902783573,
      "grad_norm": 1.0153218507766724,
      "learning_rate": 1.5781653113367863e-06,
      "loss": 0.3197,
      "step": 4704
    },
    {
      "epoch": 0.7478492380441477,
      "grad_norm": 0.54511559009552,
      "learning_rate": 1.5762887951822914e-06,
      "loss": 0.217,
      "step": 4705
    },
    {
      "epoch": 0.7480081858099382,
      "grad_norm": 0.5324046015739441,
      "learning_rate": 1.5744131865399586e-06,
      "loss": 0.1849,
      "step": 4706
    },
    {
      "epoch": 0.7481671335757287,
      "grad_norm": 0.5632584691047668,
      "learning_rate": 1.5725384859069454e-06,
      "loss": 0.196,
      "step": 4707
    },
    {
      "epoch": 0.7483260813415191,
      "grad_norm": 0.5141847133636475,
      "learning_rate": 1.5706646937801766e-06,
      "loss": 0.1653,
      "step": 4708
    },
    {
      "epoch": 0.7484850291073096,
      "grad_norm": 0.3867999315261841,
      "learning_rate": 1.5687918106563326e-06,
      "loss": 0.0628,
      "step": 4709
    },
    {
      "epoch": 0.7486439768731,
      "grad_norm": 0.5677363872528076,
      "learning_rate": 1.56691983703185e-06,
      "loss": 0.2236,
      "step": 4710
    },
    {
      "epoch": 0.7488029246388905,
      "grad_norm": 0.6045436263084412,
      "learning_rate": 1.565048773402928e-06,
      "loss": 0.2328,
      "step": 4711
    },
    {
      "epoch": 0.748961872404681,
      "grad_norm": 0.5564029216766357,
      "learning_rate": 1.5631786202655242e-06,
      "loss": 0.2134,
      "step": 4712
    },
    {
      "epoch": 0.7491208201704714,
      "grad_norm": 0.6262523531913757,
      "learning_rate": 1.5613093781153503e-06,
      "loss": 0.1384,
      "step": 4713
    },
    {
      "epoch": 0.7492797679362619,
      "grad_norm": 0.6169633269309998,
      "learning_rate": 1.559441047447885e-06,
      "loss": 0.1527,
      "step": 4714
    },
    {
      "epoch": 0.7494387157020524,
      "grad_norm": 0.5779767632484436,
      "learning_rate": 1.5575736287583594e-06,
      "loss": 0.2177,
      "step": 4715
    },
    {
      "epoch": 0.7495976634678428,
      "grad_norm": 0.5188073515892029,
      "learning_rate": 1.5557071225417648e-06,
      "loss": 0.1547,
      "step": 4716
    },
    {
      "epoch": 0.7497566112336334,
      "grad_norm": 4.7865471839904785,
      "learning_rate": 1.553841529292847e-06,
      "loss": 0.1139,
      "step": 4717
    },
    {
      "epoch": 0.7499155589994239,
      "grad_norm": 0.5296529531478882,
      "learning_rate": 1.5519768495061154e-06,
      "loss": 0.1475,
      "step": 4718
    },
    {
      "epoch": 0.7500745067652143,
      "grad_norm": 0.5707878470420837,
      "learning_rate": 1.550113083675836e-06,
      "loss": 0.2284,
      "step": 4719
    },
    {
      "epoch": 0.7502334545310048,
      "grad_norm": 0.611390233039856,
      "learning_rate": 1.5482502322960257e-06,
      "loss": 0.2618,
      "step": 4720
    },
    {
      "epoch": 0.7503924022967953,
      "grad_norm": 0.5749441385269165,
      "learning_rate": 1.5463882958604698e-06,
      "loss": 0.2405,
      "step": 4721
    },
    {
      "epoch": 0.7505513500625857,
      "grad_norm": 0.5843461155891418,
      "learning_rate": 1.544527274862706e-06,
      "loss": 0.2377,
      "step": 4722
    },
    {
      "epoch": 0.7507102978283762,
      "grad_norm": 0.5702212452888489,
      "learning_rate": 1.5426671697960256e-06,
      "loss": 0.1833,
      "step": 4723
    },
    {
      "epoch": 0.7508692455941666,
      "grad_norm": 0.5702691078186035,
      "learning_rate": 1.5408079811534826e-06,
      "loss": 0.1976,
      "step": 4724
    },
    {
      "epoch": 0.7510281933599571,
      "grad_norm": 0.6022642254829407,
      "learning_rate": 1.5389497094278861e-06,
      "loss": 0.2791,
      "step": 4725
    },
    {
      "epoch": 0.7511871411257476,
      "grad_norm": 0.5741621255874634,
      "learning_rate": 1.5370923551118022e-06,
      "loss": 0.1983,
      "step": 4726
    },
    {
      "epoch": 0.751346088891538,
      "grad_norm": 0.6008171439170837,
      "learning_rate": 1.5352359186975534e-06,
      "loss": 0.2174,
      "step": 4727
    },
    {
      "epoch": 0.7515050366573285,
      "grad_norm": 0.5284619927406311,
      "learning_rate": 1.5333804006772207e-06,
      "loss": 0.1962,
      "step": 4728
    },
    {
      "epoch": 0.751663984423119,
      "grad_norm": 0.8908926844596863,
      "learning_rate": 1.5315258015426404e-06,
      "loss": 0.2868,
      "step": 4729
    },
    {
      "epoch": 0.7518229321889094,
      "grad_norm": 0.6011962890625,
      "learning_rate": 1.5296721217854028e-06,
      "loss": 0.2313,
      "step": 4730
    },
    {
      "epoch": 0.7519818799546999,
      "grad_norm": 0.8663073778152466,
      "learning_rate": 1.5278193618968584e-06,
      "loss": 0.1314,
      "step": 4731
    },
    {
      "epoch": 0.7521408277204904,
      "grad_norm": 0.7438005805015564,
      "learning_rate": 1.525967522368112e-06,
      "loss": 0.1863,
      "step": 4732
    },
    {
      "epoch": 0.7522997754862808,
      "grad_norm": 0.4933260679244995,
      "learning_rate": 1.5241166036900245e-06,
      "loss": 0.1075,
      "step": 4733
    },
    {
      "epoch": 0.7524587232520713,
      "grad_norm": 0.5220736861228943,
      "learning_rate": 1.5222666063532138e-06,
      "loss": 0.142,
      "step": 4734
    },
    {
      "epoch": 0.7526176710178617,
      "grad_norm": 0.5907411575317383,
      "learning_rate": 1.5204175308480523e-06,
      "loss": 0.2164,
      "step": 4735
    },
    {
      "epoch": 0.7527766187836522,
      "grad_norm": 0.6047559380531311,
      "learning_rate": 1.5185693776646703e-06,
      "loss": 0.2625,
      "step": 4736
    },
    {
      "epoch": 0.7529355665494427,
      "grad_norm": 0.6011402606964111,
      "learning_rate": 1.5167221472929489e-06,
      "loss": 0.2847,
      "step": 4737
    },
    {
      "epoch": 0.7530945143152331,
      "grad_norm": 0.5266034007072449,
      "learning_rate": 1.5148758402225284e-06,
      "loss": 0.1467,
      "step": 4738
    },
    {
      "epoch": 0.7532534620810236,
      "grad_norm": 0.5959731936454773,
      "learning_rate": 1.513030456942804e-06,
      "loss": 0.2842,
      "step": 4739
    },
    {
      "epoch": 0.7534124098468141,
      "grad_norm": 0.5206671953201294,
      "learning_rate": 1.5111859979429255e-06,
      "loss": 0.1751,
      "step": 4740
    },
    {
      "epoch": 0.7535713576126045,
      "grad_norm": 0.5912856459617615,
      "learning_rate": 1.509342463711797e-06,
      "loss": 0.2718,
      "step": 4741
    },
    {
      "epoch": 0.753730305378395,
      "grad_norm": 0.593135416507721,
      "learning_rate": 1.5074998547380798e-06,
      "loss": 0.2213,
      "step": 4742
    },
    {
      "epoch": 0.7538892531441855,
      "grad_norm": 0.6540502309799194,
      "learning_rate": 1.5056581715101887e-06,
      "loss": 0.247,
      "step": 4743
    },
    {
      "epoch": 0.7540482009099759,
      "grad_norm": 0.545926034450531,
      "learning_rate": 1.5038174145162898e-06,
      "loss": 0.2209,
      "step": 4744
    },
    {
      "epoch": 0.7542071486757664,
      "grad_norm": 0.5378297567367554,
      "learning_rate": 1.5019775842443084e-06,
      "loss": 0.22,
      "step": 4745
    },
    {
      "epoch": 0.7543660964415569,
      "grad_norm": 0.7389363646507263,
      "learning_rate": 1.5001386811819224e-06,
      "loss": 0.2571,
      "step": 4746
    },
    {
      "epoch": 0.7545250442073473,
      "grad_norm": 0.6402536630630493,
      "learning_rate": 1.498300705816564e-06,
      "loss": 0.2819,
      "step": 4747
    },
    {
      "epoch": 0.7546839919731378,
      "grad_norm": 0.6486392617225647,
      "learning_rate": 1.4964636586354192e-06,
      "loss": 0.2923,
      "step": 4748
    },
    {
      "epoch": 0.7548429397389282,
      "grad_norm": 0.7342207431793213,
      "learning_rate": 1.4946275401254301e-06,
      "loss": 0.4,
      "step": 4749
    },
    {
      "epoch": 0.7550018875047187,
      "grad_norm": 0.5571551322937012,
      "learning_rate": 1.4927923507732872e-06,
      "loss": 0.1904,
      "step": 4750
    },
    {
      "epoch": 0.7551608352705093,
      "grad_norm": 0.9172578454017639,
      "learning_rate": 1.4909580910654404e-06,
      "loss": 0.2846,
      "step": 4751
    },
    {
      "epoch": 0.7553197830362997,
      "grad_norm": 0.5887331366539001,
      "learning_rate": 1.4891247614880904e-06,
      "loss": 0.1987,
      "step": 4752
    },
    {
      "epoch": 0.7554787308020902,
      "grad_norm": 0.5853579640388489,
      "learning_rate": 1.4872923625271924e-06,
      "loss": 0.2685,
      "step": 4753
    },
    {
      "epoch": 0.7556376785678807,
      "grad_norm": 0.5458841323852539,
      "learning_rate": 1.4854608946684545e-06,
      "loss": 0.2032,
      "step": 4754
    },
    {
      "epoch": 0.7557966263336711,
      "grad_norm": 0.5446298122406006,
      "learning_rate": 1.4836303583973384e-06,
      "loss": 0.2016,
      "step": 4755
    },
    {
      "epoch": 0.7559555740994616,
      "grad_norm": 0.5326310396194458,
      "learning_rate": 1.4818007541990592e-06,
      "loss": 0.1769,
      "step": 4756
    },
    {
      "epoch": 0.7561145218652521,
      "grad_norm": 0.5514236092567444,
      "learning_rate": 1.4799720825585818e-06,
      "loss": 0.1948,
      "step": 4757
    },
    {
      "epoch": 0.7562734696310425,
      "grad_norm": 0.502768337726593,
      "learning_rate": 1.4781443439606274e-06,
      "loss": 0.1636,
      "step": 4758
    },
    {
      "epoch": 0.756432417396833,
      "grad_norm": 0.5372686982154846,
      "learning_rate": 1.4763175388896688e-06,
      "loss": 0.1692,
      "step": 4759
    },
    {
      "epoch": 0.7565913651626235,
      "grad_norm": 0.5803807973861694,
      "learning_rate": 1.474491667829932e-06,
      "loss": 0.2161,
      "step": 4760
    },
    {
      "epoch": 0.7567503129284139,
      "grad_norm": 0.45948249101638794,
      "learning_rate": 1.472666731265394e-06,
      "loss": 0.1339,
      "step": 4761
    },
    {
      "epoch": 0.7569092606942044,
      "grad_norm": 0.6445592045783997,
      "learning_rate": 1.4708427296797855e-06,
      "loss": 0.1345,
      "step": 4762
    },
    {
      "epoch": 0.7570682084599948,
      "grad_norm": 0.5768513679504395,
      "learning_rate": 1.4690196635565901e-06,
      "loss": 0.2714,
      "step": 4763
    },
    {
      "epoch": 0.7572271562257853,
      "grad_norm": 0.5064060688018799,
      "learning_rate": 1.467197533379039e-06,
      "loss": 0.1416,
      "step": 4764
    },
    {
      "epoch": 0.7573861039915758,
      "grad_norm": 0.604681670665741,
      "learning_rate": 1.4653763396301201e-06,
      "loss": 0.2271,
      "step": 4765
    },
    {
      "epoch": 0.7575450517573662,
      "grad_norm": 0.523898184299469,
      "learning_rate": 1.463556082792571e-06,
      "loss": 0.1844,
      "step": 4766
    },
    {
      "epoch": 0.7577039995231567,
      "grad_norm": 0.5283026099205017,
      "learning_rate": 1.4617367633488816e-06,
      "loss": 0.1315,
      "step": 4767
    },
    {
      "epoch": 0.7578629472889472,
      "grad_norm": 0.7158459424972534,
      "learning_rate": 1.4599183817812929e-06,
      "loss": 0.2076,
      "step": 4768
    },
    {
      "epoch": 0.7580218950547376,
      "grad_norm": 0.5721736550331116,
      "learning_rate": 1.4581009385717998e-06,
      "loss": 0.1625,
      "step": 4769
    },
    {
      "epoch": 0.7581808428205281,
      "grad_norm": 0.5940706133842468,
      "learning_rate": 1.456284434202142e-06,
      "loss": 0.2456,
      "step": 4770
    },
    {
      "epoch": 0.7583397905863186,
      "grad_norm": 0.5656886100769043,
      "learning_rate": 1.4544688691538162e-06,
      "loss": 0.2068,
      "step": 4771
    },
    {
      "epoch": 0.758498738352109,
      "grad_norm": 0.5593826174736023,
      "learning_rate": 1.4526542439080693e-06,
      "loss": 0.1757,
      "step": 4772
    },
    {
      "epoch": 0.7586576861178995,
      "grad_norm": 0.5818747282028198,
      "learning_rate": 1.4508405589458968e-06,
      "loss": 0.1757,
      "step": 4773
    },
    {
      "epoch": 0.7588166338836899,
      "grad_norm": 0.5635570883750916,
      "learning_rate": 1.449027814748048e-06,
      "loss": 0.2137,
      "step": 4774
    },
    {
      "epoch": 0.7589755816494804,
      "grad_norm": 0.6271249651908875,
      "learning_rate": 1.4472160117950197e-06,
      "loss": 0.2106,
      "step": 4775
    },
    {
      "epoch": 0.7591345294152709,
      "grad_norm": 0.5290951728820801,
      "learning_rate": 1.445405150567063e-06,
      "loss": 0.1529,
      "step": 4776
    },
    {
      "epoch": 0.7592934771810613,
      "grad_norm": 0.6094756126403809,
      "learning_rate": 1.4435952315441742e-06,
      "loss": 0.2327,
      "step": 4777
    },
    {
      "epoch": 0.7594524249468518,
      "grad_norm": 0.5522650480270386,
      "learning_rate": 1.441786255206104e-06,
      "loss": 0.1842,
      "step": 4778
    },
    {
      "epoch": 0.7596113727126423,
      "grad_norm": 0.6202949285507202,
      "learning_rate": 1.4399782220323515e-06,
      "loss": 0.2838,
      "step": 4779
    },
    {
      "epoch": 0.7597703204784327,
      "grad_norm": 0.5429978966712952,
      "learning_rate": 1.4381711325021674e-06,
      "loss": 0.1958,
      "step": 4780
    },
    {
      "epoch": 0.7599292682442232,
      "grad_norm": 0.5745162963867188,
      "learning_rate": 1.4363649870945495e-06,
      "loss": 0.2357,
      "step": 4781
    },
    {
      "epoch": 0.7600882160100138,
      "grad_norm": 0.45473358035087585,
      "learning_rate": 1.4345597862882487e-06,
      "loss": 0.112,
      "step": 4782
    },
    {
      "epoch": 0.7602471637758041,
      "grad_norm": 0.5610777139663696,
      "learning_rate": 1.432755530561764e-06,
      "loss": 0.182,
      "step": 4783
    },
    {
      "epoch": 0.7604061115415947,
      "grad_norm": 0.6158393621444702,
      "learning_rate": 1.4309522203933418e-06,
      "loss": 0.2559,
      "step": 4784
    },
    {
      "epoch": 0.7605650593073852,
      "grad_norm": 0.5303815007209778,
      "learning_rate": 1.4291498562609802e-06,
      "loss": 0.2177,
      "step": 4785
    },
    {
      "epoch": 0.7607240070731756,
      "grad_norm": 0.4596216380596161,
      "learning_rate": 1.4273484386424262e-06,
      "loss": 0.1464,
      "step": 4786
    },
    {
      "epoch": 0.7608829548389661,
      "grad_norm": 0.5498309135437012,
      "learning_rate": 1.4255479680151768e-06,
      "loss": 0.1865,
      "step": 4787
    },
    {
      "epoch": 0.7610419026047565,
      "grad_norm": 0.6648666262626648,
      "learning_rate": 1.4237484448564759e-06,
      "loss": 0.3026,
      "step": 4788
    },
    {
      "epoch": 0.761200850370547,
      "grad_norm": 0.6646345257759094,
      "learning_rate": 1.4219498696433192e-06,
      "loss": 0.269,
      "step": 4789
    },
    {
      "epoch": 0.7613597981363375,
      "grad_norm": 0.5068585276603699,
      "learning_rate": 1.4201522428524467e-06,
      "loss": 0.1686,
      "step": 4790
    },
    {
      "epoch": 0.7615187459021279,
      "grad_norm": 0.6241738200187683,
      "learning_rate": 1.4183555649603503e-06,
      "loss": 0.3089,
      "step": 4791
    },
    {
      "epoch": 0.7616776936679184,
      "grad_norm": 0.5402355194091797,
      "learning_rate": 1.4165598364432702e-06,
      "loss": 0.2023,
      "step": 4792
    },
    {
      "epoch": 0.7618366414337089,
      "grad_norm": 1.2169681787490845,
      "learning_rate": 1.4147650577771942e-06,
      "loss": 0.2905,
      "step": 4793
    },
    {
      "epoch": 0.7619955891994993,
      "grad_norm": 0.5779550671577454,
      "learning_rate": 1.4129712294378584e-06,
      "loss": 0.2099,
      "step": 4794
    },
    {
      "epoch": 0.7621545369652898,
      "grad_norm": 0.5927408337593079,
      "learning_rate": 1.4111783519007476e-06,
      "loss": 0.2388,
      "step": 4795
    },
    {
      "epoch": 0.7623134847310803,
      "grad_norm": 0.588175892829895,
      "learning_rate": 1.4093864256410949e-06,
      "loss": 0.2786,
      "step": 4796
    },
    {
      "epoch": 0.7624724324968707,
      "grad_norm": 0.5325313806533813,
      "learning_rate": 1.4075954511338784e-06,
      "loss": 0.1733,
      "step": 4797
    },
    {
      "epoch": 0.7626313802626612,
      "grad_norm": 0.5268360376358032,
      "learning_rate": 1.405805428853827e-06,
      "loss": 0.1998,
      "step": 4798
    },
    {
      "epoch": 0.7627903280284517,
      "grad_norm": 0.5943199992179871,
      "learning_rate": 1.4040163592754157e-06,
      "loss": 0.2358,
      "step": 4799
    },
    {
      "epoch": 0.7629492757942421,
      "grad_norm": 0.5974101424217224,
      "learning_rate": 1.402228242872868e-06,
      "loss": 0.2962,
      "step": 4800
    },
    {
      "epoch": 0.7631082235600326,
      "grad_norm": 0.5001327395439148,
      "learning_rate": 1.400441080120154e-06,
      "loss": 0.1691,
      "step": 4801
    },
    {
      "epoch": 0.763267171325823,
      "grad_norm": 0.5293874740600586,
      "learning_rate": 1.3986548714909908e-06,
      "loss": 0.1552,
      "step": 4802
    },
    {
      "epoch": 0.7634261190916135,
      "grad_norm": 0.6238923072814941,
      "learning_rate": 1.396869617458846e-06,
      "loss": 0.2431,
      "step": 4803
    },
    {
      "epoch": 0.763585066857404,
      "grad_norm": 0.7118439674377441,
      "learning_rate": 1.395085318496926e-06,
      "loss": 0.436,
      "step": 4804
    },
    {
      "epoch": 0.7637440146231944,
      "grad_norm": 0.5331268906593323,
      "learning_rate": 1.3933019750781923e-06,
      "loss": 0.154,
      "step": 4805
    },
    {
      "epoch": 0.7639029623889849,
      "grad_norm": 0.5291786789894104,
      "learning_rate": 1.3915195876753495e-06,
      "loss": 0.2175,
      "step": 4806
    },
    {
      "epoch": 0.7640619101547754,
      "grad_norm": 0.6685997247695923,
      "learning_rate": 1.3897381567608498e-06,
      "loss": 0.2593,
      "step": 4807
    },
    {
      "epoch": 0.7642208579205658,
      "grad_norm": 0.7082316875457764,
      "learning_rate": 1.3879576828068903e-06,
      "loss": 0.2887,
      "step": 4808
    },
    {
      "epoch": 0.7643798056863563,
      "grad_norm": 0.7696083188056946,
      "learning_rate": 1.3861781662854162e-06,
      "loss": 0.1229,
      "step": 4809
    },
    {
      "epoch": 0.7645387534521468,
      "grad_norm": 0.5328101515769958,
      "learning_rate": 1.3843996076681205e-06,
      "loss": 0.2047,
      "step": 4810
    },
    {
      "epoch": 0.7646977012179372,
      "grad_norm": 0.612440288066864,
      "learning_rate": 1.3826220074264351e-06,
      "loss": 0.2161,
      "step": 4811
    },
    {
      "epoch": 0.7648566489837277,
      "grad_norm": 0.5401546359062195,
      "learning_rate": 1.3808453660315446e-06,
      "loss": 0.1994,
      "step": 4812
    },
    {
      "epoch": 0.7650155967495181,
      "grad_norm": 0.6836903691291809,
      "learning_rate": 1.3790696839543816e-06,
      "loss": 0.3464,
      "step": 4813
    },
    {
      "epoch": 0.7651745445153086,
      "grad_norm": 0.4756588935852051,
      "learning_rate": 1.3772949616656156e-06,
      "loss": 0.1153,
      "step": 4814
    },
    {
      "epoch": 0.7653334922810991,
      "grad_norm": 0.6349432468414307,
      "learning_rate": 1.3755211996356687e-06,
      "loss": 0.3149,
      "step": 4815
    },
    {
      "epoch": 0.7654924400468895,
      "grad_norm": 0.971352756023407,
      "learning_rate": 1.3737483983347073e-06,
      "loss": 0.2027,
      "step": 4816
    },
    {
      "epoch": 0.76565138781268,
      "grad_norm": 0.477731317281723,
      "learning_rate": 1.371976558232639e-06,
      "loss": 0.0981,
      "step": 4817
    },
    {
      "epoch": 0.7658103355784706,
      "grad_norm": 0.5354423522949219,
      "learning_rate": 1.3702056797991214e-06,
      "loss": 0.2119,
      "step": 4818
    },
    {
      "epoch": 0.765969283344261,
      "grad_norm": 0.7303240895271301,
      "learning_rate": 1.368435763503555e-06,
      "loss": 0.2111,
      "step": 4819
    },
    {
      "epoch": 0.7661282311100515,
      "grad_norm": 0.5529564619064331,
      "learning_rate": 1.3666668098150892e-06,
      "loss": 0.1765,
      "step": 4820
    },
    {
      "epoch": 0.766287178875842,
      "grad_norm": 0.5313181281089783,
      "learning_rate": 1.3648988192026108e-06,
      "loss": 0.23,
      "step": 4821
    },
    {
      "epoch": 0.7664461266416324,
      "grad_norm": 0.5966297388076782,
      "learning_rate": 1.3631317921347564e-06,
      "loss": 0.1196,
      "step": 4822
    },
    {
      "epoch": 0.7666050744074229,
      "grad_norm": 0.5755588412284851,
      "learning_rate": 1.3613657290799088e-06,
      "loss": 0.2096,
      "step": 4823
    },
    {
      "epoch": 0.7667640221732134,
      "grad_norm": 0.5059018731117249,
      "learning_rate": 1.3596006305061888e-06,
      "loss": 0.1537,
      "step": 4824
    },
    {
      "epoch": 0.7669229699390038,
      "grad_norm": 0.6933345794677734,
      "learning_rate": 1.3578364968814657e-06,
      "loss": 0.3462,
      "step": 4825
    },
    {
      "epoch": 0.7670819177047943,
      "grad_norm": 0.5769397616386414,
      "learning_rate": 1.3560733286733574e-06,
      "loss": 0.2614,
      "step": 4826
    },
    {
      "epoch": 0.7672408654705847,
      "grad_norm": 0.5684523582458496,
      "learning_rate": 1.3543111263492165e-06,
      "loss": 0.212,
      "step": 4827
    },
    {
      "epoch": 0.7673998132363752,
      "grad_norm": 0.675443708896637,
      "learning_rate": 1.3525498903761458e-06,
      "loss": 0.3028,
      "step": 4828
    },
    {
      "epoch": 0.7675587610021657,
      "grad_norm": 0.5432729125022888,
      "learning_rate": 1.3507896212209902e-06,
      "loss": 0.2172,
      "step": 4829
    },
    {
      "epoch": 0.7677177087679561,
      "grad_norm": 0.6205757260322571,
      "learning_rate": 1.3490303193503412e-06,
      "loss": 0.262,
      "step": 4830
    },
    {
      "epoch": 0.7678766565337466,
      "grad_norm": 0.5983182191848755,
      "learning_rate": 1.3472719852305271e-06,
      "loss": 0.2259,
      "step": 4831
    },
    {
      "epoch": 0.7680356042995371,
      "grad_norm": 0.6256371736526489,
      "learning_rate": 1.3455146193276248e-06,
      "loss": 0.2134,
      "step": 4832
    },
    {
      "epoch": 0.7681945520653275,
      "grad_norm": 0.5866715908050537,
      "learning_rate": 1.3437582221074574e-06,
      "loss": 0.2533,
      "step": 4833
    },
    {
      "epoch": 0.768353499831118,
      "grad_norm": 2.167267322540283,
      "learning_rate": 1.342002794035584e-06,
      "loss": 0.2291,
      "step": 4834
    },
    {
      "epoch": 0.7685124475969085,
      "grad_norm": 0.5599920749664307,
      "learning_rate": 1.3402483355773105e-06,
      "loss": 0.1614,
      "step": 4835
    },
    {
      "epoch": 0.7686713953626989,
      "grad_norm": 0.6551170349121094,
      "learning_rate": 1.3384948471976878e-06,
      "loss": 0.3594,
      "step": 4836
    },
    {
      "epoch": 0.7688303431284894,
      "grad_norm": 0.6698915362358093,
      "learning_rate": 1.3367423293615039e-06,
      "loss": 0.1945,
      "step": 4837
    },
    {
      "epoch": 0.7689892908942799,
      "grad_norm": 0.6373311877250671,
      "learning_rate": 1.3349907825332942e-06,
      "loss": 0.1717,
      "step": 4838
    },
    {
      "epoch": 0.7691482386600703,
      "grad_norm": 0.6729482412338257,
      "learning_rate": 1.3332402071773376e-06,
      "loss": 0.1737,
      "step": 4839
    },
    {
      "epoch": 0.7693071864258608,
      "grad_norm": 0.5726364254951477,
      "learning_rate": 1.3314906037576542e-06,
      "loss": 0.2543,
      "step": 4840
    },
    {
      "epoch": 0.7694661341916512,
      "grad_norm": 0.6043804883956909,
      "learning_rate": 1.3297419727380024e-06,
      "loss": 0.2446,
      "step": 4841
    },
    {
      "epoch": 0.7696250819574417,
      "grad_norm": 0.8478478193283081,
      "learning_rate": 1.3279943145818874e-06,
      "loss": 0.1999,
      "step": 4842
    },
    {
      "epoch": 0.7697840297232322,
      "grad_norm": 0.5693264007568359,
      "learning_rate": 1.3262476297525572e-06,
      "loss": 0.2053,
      "step": 4843
    },
    {
      "epoch": 0.7699429774890226,
      "grad_norm": 0.5778273344039917,
      "learning_rate": 1.3245019187129971e-06,
      "loss": 0.281,
      "step": 4844
    },
    {
      "epoch": 0.7701019252548131,
      "grad_norm": 0.6362568140029907,
      "learning_rate": 1.322757181925937e-06,
      "loss": 0.2961,
      "step": 4845
    },
    {
      "epoch": 0.7702608730206036,
      "grad_norm": 0.4702948033809662,
      "learning_rate": 1.3210134198538533e-06,
      "loss": 0.1403,
      "step": 4846
    },
    {
      "epoch": 0.770419820786394,
      "grad_norm": 0.5593932271003723,
      "learning_rate": 1.3192706329589544e-06,
      "loss": 0.2269,
      "step": 4847
    },
    {
      "epoch": 0.7705787685521845,
      "grad_norm": 0.45109668374061584,
      "learning_rate": 1.3175288217031974e-06,
      "loss": 0.1265,
      "step": 4848
    },
    {
      "epoch": 0.770737716317975,
      "grad_norm": 0.5611804723739624,
      "learning_rate": 1.3157879865482787e-06,
      "loss": 0.2635,
      "step": 4849
    },
    {
      "epoch": 0.7708966640837654,
      "grad_norm": 0.5734713673591614,
      "learning_rate": 1.3140481279556366e-06,
      "loss": 0.2577,
      "step": 4850
    },
    {
      "epoch": 0.771055611849556,
      "grad_norm": 0.5672350525856018,
      "learning_rate": 1.3123092463864456e-06,
      "loss": 0.2385,
      "step": 4851
    },
    {
      "epoch": 0.7712145596153465,
      "grad_norm": 0.5363733172416687,
      "learning_rate": 1.3105713423016304e-06,
      "loss": 0.1778,
      "step": 4852
    },
    {
      "epoch": 0.7713735073811369,
      "grad_norm": 0.6124812364578247,
      "learning_rate": 1.3088344161618517e-06,
      "loss": 0.2286,
      "step": 4853
    },
    {
      "epoch": 0.7715324551469274,
      "grad_norm": 0.699820876121521,
      "learning_rate": 1.3070984684275074e-06,
      "loss": 0.2818,
      "step": 4854
    },
    {
      "epoch": 0.7716914029127178,
      "grad_norm": 0.4712533950805664,
      "learning_rate": 1.3053634995587415e-06,
      "loss": 0.1082,
      "step": 4855
    },
    {
      "epoch": 0.7718503506785083,
      "grad_norm": 0.6150553822517395,
      "learning_rate": 1.3036295100154378e-06,
      "loss": 0.2048,
      "step": 4856
    },
    {
      "epoch": 0.7720092984442988,
      "grad_norm": 0.5178515911102295,
      "learning_rate": 1.301896500257217e-06,
      "loss": 0.182,
      "step": 4857
    },
    {
      "epoch": 0.7721682462100892,
      "grad_norm": 0.5625852346420288,
      "learning_rate": 1.3001644707434418e-06,
      "loss": 0.2006,
      "step": 4858
    },
    {
      "epoch": 0.7723271939758797,
      "grad_norm": 1.0107171535491943,
      "learning_rate": 1.298433421933219e-06,
      "loss": 0.2341,
      "step": 4859
    },
    {
      "epoch": 0.7724861417416702,
      "grad_norm": 0.5890126824378967,
      "learning_rate": 1.2967033542853918e-06,
      "loss": 0.2303,
      "step": 4860
    },
    {
      "epoch": 0.7726450895074606,
      "grad_norm": 0.6573005318641663,
      "learning_rate": 1.2949742682585415e-06,
      "loss": 0.2494,
      "step": 4861
    },
    {
      "epoch": 0.7728040372732511,
      "grad_norm": 0.6013880968093872,
      "learning_rate": 1.2932461643109917e-06,
      "loss": 0.1833,
      "step": 4862
    },
    {
      "epoch": 0.7729629850390416,
      "grad_norm": 0.5462217330932617,
      "learning_rate": 1.2915190429008084e-06,
      "loss": 0.1959,
      "step": 4863
    },
    {
      "epoch": 0.773121932804832,
      "grad_norm": 0.6985298991203308,
      "learning_rate": 1.2897929044857882e-06,
      "loss": 0.3492,
      "step": 4864
    },
    {
      "epoch": 0.7732808805706225,
      "grad_norm": 0.6246711015701294,
      "learning_rate": 1.2880677495234784e-06,
      "loss": 0.285,
      "step": 4865
    },
    {
      "epoch": 0.7734398283364129,
      "grad_norm": 0.593027651309967,
      "learning_rate": 1.2863435784711597e-06,
      "loss": 0.2413,
      "step": 4866
    },
    {
      "epoch": 0.7735987761022034,
      "grad_norm": 0.570166826248169,
      "learning_rate": 1.2846203917858508e-06,
      "loss": 0.1399,
      "step": 4867
    },
    {
      "epoch": 0.7737577238679939,
      "grad_norm": 0.7110410928726196,
      "learning_rate": 1.2828981899243115e-06,
      "loss": 0.3394,
      "step": 4868
    },
    {
      "epoch": 0.7739166716337843,
      "grad_norm": 0.6291881203651428,
      "learning_rate": 1.2811769733430406e-06,
      "loss": 0.2779,
      "step": 4869
    },
    {
      "epoch": 0.7740756193995748,
      "grad_norm": 0.4791875183582306,
      "learning_rate": 1.2794567424982773e-06,
      "loss": 0.1916,
      "step": 4870
    },
    {
      "epoch": 0.7742345671653653,
      "grad_norm": 0.6421029567718506,
      "learning_rate": 1.2777374978459928e-06,
      "loss": 0.2486,
      "step": 4871
    },
    {
      "epoch": 0.7743935149311557,
      "grad_norm": 0.5424535274505615,
      "learning_rate": 1.2760192398419069e-06,
      "loss": 0.2074,
      "step": 4872
    },
    {
      "epoch": 0.7745524626969462,
      "grad_norm": 0.5439659357070923,
      "learning_rate": 1.274301968941472e-06,
      "loss": 0.1938,
      "step": 4873
    },
    {
      "epoch": 0.7747114104627367,
      "grad_norm": 0.5235009789466858,
      "learning_rate": 1.2725856855998776e-06,
      "loss": 0.1476,
      "step": 4874
    },
    {
      "epoch": 0.7748703582285271,
      "grad_norm": 0.6690760850906372,
      "learning_rate": 1.2708703902720538e-06,
      "loss": 0.329,
      "step": 4875
    },
    {
      "epoch": 0.7750293059943176,
      "grad_norm": 0.5924209952354431,
      "learning_rate": 1.2691560834126686e-06,
      "loss": 0.2385,
      "step": 4876
    },
    {
      "epoch": 0.7751882537601081,
      "grad_norm": 0.5003466010093689,
      "learning_rate": 1.2674427654761284e-06,
      "loss": 0.1458,
      "step": 4877
    },
    {
      "epoch": 0.7753472015258985,
      "grad_norm": 0.608899712562561,
      "learning_rate": 1.2657304369165768e-06,
      "loss": 0.2736,
      "step": 4878
    },
    {
      "epoch": 0.775506149291689,
      "grad_norm": 0.6237805485725403,
      "learning_rate": 1.2640190981878947e-06,
      "loss": 0.2544,
      "step": 4879
    },
    {
      "epoch": 0.7756650970574794,
      "grad_norm": 0.5797126889228821,
      "learning_rate": 1.2623087497437037e-06,
      "loss": 0.3007,
      "step": 4880
    },
    {
      "epoch": 0.7758240448232699,
      "grad_norm": 0.5663464069366455,
      "learning_rate": 1.260599392037356e-06,
      "loss": 0.185,
      "step": 4881
    },
    {
      "epoch": 0.7759829925890604,
      "grad_norm": 0.6076790690422058,
      "learning_rate": 1.2588910255219484e-06,
      "loss": 0.1857,
      "step": 4882
    },
    {
      "epoch": 0.7761419403548508,
      "grad_norm": 0.6192803382873535,
      "learning_rate": 1.2571836506503127e-06,
      "loss": 0.2531,
      "step": 4883
    },
    {
      "epoch": 0.7763008881206414,
      "grad_norm": 0.44810599088668823,
      "learning_rate": 1.2554772678750133e-06,
      "loss": 0.0874,
      "step": 4884
    },
    {
      "epoch": 0.7764598358864319,
      "grad_norm": 0.6180688142776489,
      "learning_rate": 1.2537718776483598e-06,
      "loss": 0.2096,
      "step": 4885
    },
    {
      "epoch": 0.7766187836522223,
      "grad_norm": 0.6528534293174744,
      "learning_rate": 1.2520674804223931e-06,
      "loss": 0.2706,
      "step": 4886
    },
    {
      "epoch": 0.7767777314180128,
      "grad_norm": 0.5351464748382568,
      "learning_rate": 1.250364076648894e-06,
      "loss": 0.1888,
      "step": 4887
    },
    {
      "epoch": 0.7769366791838033,
      "grad_norm": 0.5475015044212341,
      "learning_rate": 1.248661666779375e-06,
      "loss": 0.2088,
      "step": 4888
    },
    {
      "epoch": 0.7770956269495937,
      "grad_norm": 0.45320677757263184,
      "learning_rate": 1.2469602512650902e-06,
      "loss": 0.1408,
      "step": 4889
    },
    {
      "epoch": 0.7772545747153842,
      "grad_norm": 0.4962955415248871,
      "learning_rate": 1.2452598305570285e-06,
      "loss": 0.1352,
      "step": 4890
    },
    {
      "epoch": 0.7774135224811747,
      "grad_norm": 3.8875858783721924,
      "learning_rate": 1.2435604051059142e-06,
      "loss": 0.2374,
      "step": 4891
    },
    {
      "epoch": 0.7775724702469651,
      "grad_norm": 0.5598005056381226,
      "learning_rate": 1.2418619753622097e-06,
      "loss": 0.2043,
      "step": 4892
    },
    {
      "epoch": 0.7777314180127556,
      "grad_norm": 0.5859190225601196,
      "learning_rate": 1.2401645417761126e-06,
      "loss": 0.2487,
      "step": 4893
    },
    {
      "epoch": 0.777890365778546,
      "grad_norm": 0.5438156723976135,
      "learning_rate": 1.2384681047975544e-06,
      "loss": 0.1824,
      "step": 4894
    },
    {
      "epoch": 0.7780493135443365,
      "grad_norm": 0.5281738042831421,
      "learning_rate": 1.2367726648762047e-06,
      "loss": 0.1687,
      "step": 4895
    },
    {
      "epoch": 0.778208261310127,
      "grad_norm": 0.6214610934257507,
      "learning_rate": 1.2350782224614689e-06,
      "loss": 0.2094,
      "step": 4896
    },
    {
      "epoch": 0.7783672090759174,
      "grad_norm": 0.636614203453064,
      "learning_rate": 1.233384778002487e-06,
      "loss": 0.1594,
      "step": 4897
    },
    {
      "epoch": 0.7785261568417079,
      "grad_norm": 0.870259702205658,
      "learning_rate": 1.2316923319481355e-06,
      "loss": 0.3306,
      "step": 4898
    },
    {
      "epoch": 0.7786851046074984,
      "grad_norm": 0.5044201016426086,
      "learning_rate": 1.2300008847470252e-06,
      "loss": 0.1278,
      "step": 4899
    },
    {
      "epoch": 0.7788440523732888,
      "grad_norm": 0.42086347937583923,
      "learning_rate": 1.228310436847504e-06,
      "loss": 0.0955,
      "step": 4900
    },
    {
      "epoch": 0.7790030001390793,
      "grad_norm": 0.5451317429542542,
      "learning_rate": 1.226620988697651e-06,
      "loss": 0.1626,
      "step": 4901
    },
    {
      "epoch": 0.7791619479048698,
      "grad_norm": 0.49166780710220337,
      "learning_rate": 1.224932540745284e-06,
      "loss": 0.1642,
      "step": 4902
    },
    {
      "epoch": 0.7793208956706602,
      "grad_norm": 0.6308409571647644,
      "learning_rate": 1.2232450934379541e-06,
      "loss": 0.2008,
      "step": 4903
    },
    {
      "epoch": 0.7794798434364507,
      "grad_norm": 0.5750482678413391,
      "learning_rate": 1.2215586472229485e-06,
      "loss": 0.2429,
      "step": 4904
    },
    {
      "epoch": 0.7796387912022411,
      "grad_norm": 0.5251038074493408,
      "learning_rate": 1.2198732025472876e-06,
      "loss": 0.1669,
      "step": 4905
    },
    {
      "epoch": 0.7797977389680316,
      "grad_norm": 0.4656011760234833,
      "learning_rate": 1.2181887598577263e-06,
      "loss": 0.1081,
      "step": 4906
    },
    {
      "epoch": 0.7799566867338221,
      "grad_norm": 0.7281908392906189,
      "learning_rate": 1.2165053196007565e-06,
      "loss": 0.2613,
      "step": 4907
    },
    {
      "epoch": 0.7801156344996125,
      "grad_norm": 0.4759036898612976,
      "learning_rate": 1.2148228822225994e-06,
      "loss": 0.1621,
      "step": 4908
    },
    {
      "epoch": 0.780274582265403,
      "grad_norm": 0.5850310921669006,
      "learning_rate": 1.2131414481692144e-06,
      "loss": 0.2286,
      "step": 4909
    },
    {
      "epoch": 0.7804335300311935,
      "grad_norm": 0.7417809367179871,
      "learning_rate": 1.2114610178862945e-06,
      "loss": 0.1369,
      "step": 4910
    },
    {
      "epoch": 0.7805924777969839,
      "grad_norm": 0.5806775093078613,
      "learning_rate": 1.2097815918192652e-06,
      "loss": 0.1712,
      "step": 4911
    },
    {
      "epoch": 0.7807514255627744,
      "grad_norm": 0.5765805840492249,
      "learning_rate": 1.2081031704132866e-06,
      "loss": 0.205,
      "step": 4912
    },
    {
      "epoch": 0.7809103733285649,
      "grad_norm": 0.5148953795433044,
      "learning_rate": 1.2064257541132545e-06,
      "loss": 0.082,
      "step": 4913
    },
    {
      "epoch": 0.7810693210943553,
      "grad_norm": 0.6047179698944092,
      "learning_rate": 1.2047493433637935e-06,
      "loss": 0.2822,
      "step": 4914
    },
    {
      "epoch": 0.7812282688601458,
      "grad_norm": 0.5683769583702087,
      "learning_rate": 1.203073938609265e-06,
      "loss": 0.2383,
      "step": 4915
    },
    {
      "epoch": 0.7813872166259364,
      "grad_norm": 0.6732951402664185,
      "learning_rate": 1.201399540293764e-06,
      "loss": 0.3523,
      "step": 4916
    },
    {
      "epoch": 0.7815461643917267,
      "grad_norm": 0.6169383525848389,
      "learning_rate": 1.1997261488611173e-06,
      "loss": 0.2481,
      "step": 4917
    },
    {
      "epoch": 0.7817051121575173,
      "grad_norm": 0.5067146420478821,
      "learning_rate": 1.1980537647548857e-06,
      "loss": 0.1549,
      "step": 4918
    },
    {
      "epoch": 0.7818640599233077,
      "grad_norm": 0.5436502695083618,
      "learning_rate": 1.1963823884183629e-06,
      "loss": 0.1781,
      "step": 4919
    },
    {
      "epoch": 0.7820230076890982,
      "grad_norm": 0.5717412829399109,
      "learning_rate": 1.1947120202945762e-06,
      "loss": 0.2495,
      "step": 4920
    },
    {
      "epoch": 0.7821819554548887,
      "grad_norm": 0.472483366727829,
      "learning_rate": 1.193042660826282e-06,
      "loss": 0.1505,
      "step": 4921
    },
    {
      "epoch": 0.7823409032206791,
      "grad_norm": 0.5652009844779968,
      "learning_rate": 1.1913743104559738e-06,
      "loss": 0.217,
      "step": 4922
    },
    {
      "epoch": 0.7824998509864696,
      "grad_norm": 0.6698163747787476,
      "learning_rate": 1.1897069696258756e-06,
      "loss": 0.3673,
      "step": 4923
    },
    {
      "epoch": 0.7826587987522601,
      "grad_norm": 0.5690168738365173,
      "learning_rate": 1.1880406387779442e-06,
      "loss": 0.1929,
      "step": 4924
    },
    {
      "epoch": 0.7828177465180505,
      "grad_norm": 0.6025419235229492,
      "learning_rate": 1.186375318353869e-06,
      "loss": 0.276,
      "step": 4925
    },
    {
      "epoch": 0.782976694283841,
      "grad_norm": 0.6709197163581848,
      "learning_rate": 1.1847110087950702e-06,
      "loss": 0.1864,
      "step": 4926
    },
    {
      "epoch": 0.7831356420496315,
      "grad_norm": 0.5743758678436279,
      "learning_rate": 1.183047710542703e-06,
      "loss": 0.2603,
      "step": 4927
    },
    {
      "epoch": 0.7832945898154219,
      "grad_norm": 0.5897690057754517,
      "learning_rate": 1.1813854240376499e-06,
      "loss": 0.2084,
      "step": 4928
    },
    {
      "epoch": 0.7834535375812124,
      "grad_norm": 5.292455196380615,
      "learning_rate": 1.1797241497205285e-06,
      "loss": 0.2401,
      "step": 4929
    },
    {
      "epoch": 0.7836124853470029,
      "grad_norm": 0.6213736534118652,
      "learning_rate": 1.1780638880316886e-06,
      "loss": 0.2613,
      "step": 4930
    },
    {
      "epoch": 0.7837714331127933,
      "grad_norm": 0.8353186249732971,
      "learning_rate": 1.17640463941121e-06,
      "loss": 0.2254,
      "step": 4931
    },
    {
      "epoch": 0.7839303808785838,
      "grad_norm": 0.6528946757316589,
      "learning_rate": 1.1747464042989037e-06,
      "loss": 0.2245,
      "step": 4932
    },
    {
      "epoch": 0.7840893286443742,
      "grad_norm": 0.8554261922836304,
      "learning_rate": 1.173089183134315e-06,
      "loss": 0.144,
      "step": 4933
    },
    {
      "epoch": 0.7842482764101647,
      "grad_norm": 0.5804234743118286,
      "learning_rate": 1.1714329763567151e-06,
      "loss": 0.2466,
      "step": 4934
    },
    {
      "epoch": 0.7844072241759552,
      "grad_norm": 0.5508853793144226,
      "learning_rate": 1.1697777844051105e-06,
      "loss": 0.2427,
      "step": 4935
    },
    {
      "epoch": 0.7845661719417456,
      "grad_norm": 0.6403095126152039,
      "learning_rate": 1.1681236077182385e-06,
      "loss": 0.1718,
      "step": 4936
    },
    {
      "epoch": 0.7847251197075361,
      "grad_norm": 0.578853964805603,
      "learning_rate": 1.1664704467345655e-06,
      "loss": 0.2072,
      "step": 4937
    },
    {
      "epoch": 0.7848840674733266,
      "grad_norm": 0.6059966683387756,
      "learning_rate": 1.1648183018922898e-06,
      "loss": 0.2352,
      "step": 4938
    },
    {
      "epoch": 0.785043015239117,
      "grad_norm": 1.4744778871536255,
      "learning_rate": 1.163167173629341e-06,
      "loss": 0.2285,
      "step": 4939
    },
    {
      "epoch": 0.7852019630049075,
      "grad_norm": 0.5970579981803894,
      "learning_rate": 1.1615170623833788e-06,
      "loss": 0.306,
      "step": 4940
    },
    {
      "epoch": 0.785360910770698,
      "grad_norm": 0.5566478371620178,
      "learning_rate": 1.1598679685917901e-06,
      "loss": 0.2668,
      "step": 4941
    },
    {
      "epoch": 0.7855198585364884,
      "grad_norm": 0.6445592641830444,
      "learning_rate": 1.1582198926916972e-06,
      "loss": 0.2814,
      "step": 4942
    },
    {
      "epoch": 0.7856788063022789,
      "grad_norm": 0.6147517561912537,
      "learning_rate": 1.156572835119949e-06,
      "loss": 0.122,
      "step": 4943
    },
    {
      "epoch": 0.7858377540680693,
      "grad_norm": 0.5970109105110168,
      "learning_rate": 1.1549267963131273e-06,
      "loss": 0.2513,
      "step": 4944
    },
    {
      "epoch": 0.7859967018338598,
      "grad_norm": 0.5848625898361206,
      "learning_rate": 1.1532817767075406e-06,
      "loss": 0.243,
      "step": 4945
    },
    {
      "epoch": 0.7861556495996503,
      "grad_norm": 0.5301192402839661,
      "learning_rate": 1.1516377767392306e-06,
      "loss": 0.1864,
      "step": 4946
    },
    {
      "epoch": 0.7863145973654407,
      "grad_norm": 0.5340188145637512,
      "learning_rate": 1.1499947968439673e-06,
      "loss": 0.1754,
      "step": 4947
    },
    {
      "epoch": 0.7864735451312312,
      "grad_norm": 0.47319239377975464,
      "learning_rate": 1.1483528374572483e-06,
      "loss": 0.1224,
      "step": 4948
    },
    {
      "epoch": 0.7866324928970218,
      "grad_norm": 0.6012560725212097,
      "learning_rate": 1.1467118990143035e-06,
      "loss": 0.1933,
      "step": 4949
    },
    {
      "epoch": 0.7867914406628121,
      "grad_norm": 0.6544812917709351,
      "learning_rate": 1.1450719819500906e-06,
      "loss": 0.2724,
      "step": 4950
    },
    {
      "epoch": 0.7869503884286027,
      "grad_norm": 0.5591773390769958,
      "learning_rate": 1.1434330866992976e-06,
      "loss": 0.1487,
      "step": 4951
    },
    {
      "epoch": 0.7871093361943932,
      "grad_norm": 0.5337806344032288,
      "learning_rate": 1.1417952136963417e-06,
      "loss": 0.2422,
      "step": 4952
    },
    {
      "epoch": 0.7872682839601836,
      "grad_norm": 0.6285317540168762,
      "learning_rate": 1.1401583633753683e-06,
      "loss": 0.2037,
      "step": 4953
    },
    {
      "epoch": 0.7874272317259741,
      "grad_norm": 0.5459457635879517,
      "learning_rate": 1.1385225361702534e-06,
      "loss": 0.1852,
      "step": 4954
    },
    {
      "epoch": 0.7875861794917646,
      "grad_norm": 0.5770204067230225,
      "learning_rate": 1.1368877325145971e-06,
      "loss": 0.1755,
      "step": 4955
    },
    {
      "epoch": 0.787745127257555,
      "grad_norm": 0.5741292834281921,
      "learning_rate": 1.1352539528417345e-06,
      "loss": 0.2129,
      "step": 4956
    },
    {
      "epoch": 0.7879040750233455,
      "grad_norm": 0.5422133803367615,
      "learning_rate": 1.133621197584725e-06,
      "loss": 0.2054,
      "step": 4957
    },
    {
      "epoch": 0.7880630227891359,
      "grad_norm": 0.49877700209617615,
      "learning_rate": 1.1319894671763581e-06,
      "loss": 0.1501,
      "step": 4958
    },
    {
      "epoch": 0.7882219705549264,
      "grad_norm": 0.6503729224205017,
      "learning_rate": 1.1303587620491513e-06,
      "loss": 0.3037,
      "step": 4959
    },
    {
      "epoch": 0.7883809183207169,
      "grad_norm": 0.5571382641792297,
      "learning_rate": 1.128729082635352e-06,
      "loss": 0.1934,
      "step": 4960
    },
    {
      "epoch": 0.7885398660865073,
      "grad_norm": 0.6039332747459412,
      "learning_rate": 1.1271004293669319e-06,
      "loss": 0.1724,
      "step": 4961
    },
    {
      "epoch": 0.7886988138522978,
      "grad_norm": 0.5474473237991333,
      "learning_rate": 1.125472802675593e-06,
      "loss": 0.1585,
      "step": 4962
    },
    {
      "epoch": 0.7888577616180883,
      "grad_norm": 0.5986809730529785,
      "learning_rate": 1.123846202992766e-06,
      "loss": 0.2647,
      "step": 4963
    },
    {
      "epoch": 0.7890167093838787,
      "grad_norm": 0.5760001540184021,
      "learning_rate": 1.1222206307496082e-06,
      "loss": 0.2376,
      "step": 4964
    },
    {
      "epoch": 0.7891756571496692,
      "grad_norm": 0.5975209474563599,
      "learning_rate": 1.120596086377005e-06,
      "loss": 0.2745,
      "step": 4965
    },
    {
      "epoch": 0.7893346049154597,
      "grad_norm": 2.055208921432495,
      "learning_rate": 1.1189725703055686e-06,
      "loss": 0.2075,
      "step": 4966
    },
    {
      "epoch": 0.7894935526812501,
      "grad_norm": 0.5900917053222656,
      "learning_rate": 1.117350082965641e-06,
      "loss": 0.2445,
      "step": 4967
    },
    {
      "epoch": 0.7896525004470406,
      "grad_norm": 7.905290603637695,
      "learning_rate": 1.1157286247872873e-06,
      "loss": 0.1807,
      "step": 4968
    },
    {
      "epoch": 0.7898114482128311,
      "grad_norm": 0.5635653734207153,
      "learning_rate": 1.114108196200303e-06,
      "loss": 0.2463,
      "step": 4969
    },
    {
      "epoch": 0.7899703959786215,
      "grad_norm": 0.9786689877510071,
      "learning_rate": 1.1124887976342103e-06,
      "loss": 0.2864,
      "step": 4970
    },
    {
      "epoch": 0.790129343744412,
      "grad_norm": 0.5653505325317383,
      "learning_rate": 1.1108704295182582e-06,
      "loss": 0.1911,
      "step": 4971
    },
    {
      "epoch": 0.7902882915102024,
      "grad_norm": 0.625954270362854,
      "learning_rate": 1.1092530922814216e-06,
      "loss": 0.2464,
      "step": 4972
    },
    {
      "epoch": 0.7904472392759929,
      "grad_norm": 0.8341166973114014,
      "learning_rate": 1.1076367863524034e-06,
      "loss": 0.1444,
      "step": 4973
    },
    {
      "epoch": 0.7906061870417834,
      "grad_norm": 0.5508140921592712,
      "learning_rate": 1.1060215121596341e-06,
      "loss": 0.2179,
      "step": 4974
    },
    {
      "epoch": 0.7907651348075738,
      "grad_norm": 0.6571102142333984,
      "learning_rate": 1.1044072701312658e-06,
      "loss": 0.2642,
      "step": 4975
    },
    {
      "epoch": 0.7909240825733643,
      "grad_norm": 0.5439332723617554,
      "learning_rate": 1.1027940606951814e-06,
      "loss": 0.1907,
      "step": 4976
    },
    {
      "epoch": 0.7910830303391548,
      "grad_norm": 0.5919657945632935,
      "learning_rate": 1.1011818842789928e-06,
      "loss": 0.2249,
      "step": 4977
    },
    {
      "epoch": 0.7912419781049452,
      "grad_norm": 0.5820972323417664,
      "learning_rate": 1.0995707413100309e-06,
      "loss": 0.2716,
      "step": 4978
    },
    {
      "epoch": 0.7914009258707357,
      "grad_norm": 0.5837458968162537,
      "learning_rate": 1.0979606322153563e-06,
      "loss": 0.1637,
      "step": 4979
    },
    {
      "epoch": 0.7915598736365262,
      "grad_norm": 0.516440212726593,
      "learning_rate": 1.0963515574217582e-06,
      "loss": 0.1757,
      "step": 4980
    },
    {
      "epoch": 0.7917188214023166,
      "grad_norm": 0.5726364254951477,
      "learning_rate": 1.0947435173557452e-06,
      "loss": 0.2095,
      "step": 4981
    },
    {
      "epoch": 0.7918777691681071,
      "grad_norm": 0.525216281414032,
      "learning_rate": 1.0931365124435573e-06,
      "loss": 0.1415,
      "step": 4982
    },
    {
      "epoch": 0.7920367169338975,
      "grad_norm": 0.580227255821228,
      "learning_rate": 1.0915305431111561e-06,
      "loss": 0.2645,
      "step": 4983
    },
    {
      "epoch": 0.792195664699688,
      "grad_norm": 0.4973246455192566,
      "learning_rate": 1.0899256097842358e-06,
      "loss": 0.1623,
      "step": 4984
    },
    {
      "epoch": 0.7923546124654786,
      "grad_norm": 0.58563232421875,
      "learning_rate": 1.0883217128882062e-06,
      "loss": 0.2237,
      "step": 4985
    },
    {
      "epoch": 0.792513560231269,
      "grad_norm": 0.6936249136924744,
      "learning_rate": 1.0867188528482087e-06,
      "loss": 0.1513,
      "step": 4986
    },
    {
      "epoch": 0.7926725079970595,
      "grad_norm": 0.7053700685501099,
      "learning_rate": 1.0851170300891089e-06,
      "loss": 0.2314,
      "step": 4987
    },
    {
      "epoch": 0.79283145576285,
      "grad_norm": 0.8820890188217163,
      "learning_rate": 1.0835162450354958e-06,
      "loss": 0.2911,
      "step": 4988
    },
    {
      "epoch": 0.7929904035286404,
      "grad_norm": 0.5499732494354248,
      "learning_rate": 1.0819164981116825e-06,
      "loss": 0.2176,
      "step": 4989
    },
    {
      "epoch": 0.7931493512944309,
      "grad_norm": 0.5839048624038696,
      "learning_rate": 1.0803177897417138e-06,
      "loss": 0.1437,
      "step": 4990
    },
    {
      "epoch": 0.7933082990602214,
      "grad_norm": 0.6027366518974304,
      "learning_rate": 1.0787201203493503e-06,
      "loss": 0.2521,
      "step": 4991
    },
    {
      "epoch": 0.7934672468260118,
      "grad_norm": 0.5368335247039795,
      "learning_rate": 1.0771234903580818e-06,
      "loss": 0.1359,
      "step": 4992
    },
    {
      "epoch": 0.7936261945918023,
      "grad_norm": 0.6641193628311157,
      "learning_rate": 1.0755279001911223e-06,
      "loss": 0.2358,
      "step": 4993
    },
    {
      "epoch": 0.7937851423575928,
      "grad_norm": 0.6774844527244568,
      "learning_rate": 1.0739333502714117e-06,
      "loss": 0.3546,
      "step": 4994
    },
    {
      "epoch": 0.7939440901233832,
      "grad_norm": 0.6001861095428467,
      "learning_rate": 1.0723398410216085e-06,
      "loss": 0.2571,
      "step": 4995
    },
    {
      "epoch": 0.7941030378891737,
      "grad_norm": 0.6366515755653381,
      "learning_rate": 1.0707473728640993e-06,
      "loss": 0.2503,
      "step": 4996
    },
    {
      "epoch": 0.7942619856549641,
      "grad_norm": 0.6139877438545227,
      "learning_rate": 1.0691559462209989e-06,
      "loss": 0.182,
      "step": 4997
    },
    {
      "epoch": 0.7944209334207546,
      "grad_norm": 0.6406282782554626,
      "learning_rate": 1.0675655615141378e-06,
      "loss": 0.1717,
      "step": 4998
    },
    {
      "epoch": 0.7945798811865451,
      "grad_norm": 0.6634507775306702,
      "learning_rate": 1.0659762191650751e-06,
      "loss": 0.3073,
      "step": 4999
    },
    {
      "epoch": 0.7947388289523355,
      "grad_norm": 0.6659855842590332,
      "learning_rate": 1.064387919595094e-06,
      "loss": 0.2999,
      "step": 5000
    },
    {
      "epoch": 0.794897776718126,
      "grad_norm": 0.6507472395896912,
      "learning_rate": 1.0628006632251975e-06,
      "loss": 0.3325,
      "step": 5001
    },
    {
      "epoch": 0.7950567244839165,
      "grad_norm": 0.47422847151756287,
      "learning_rate": 1.0612144504761147e-06,
      "loss": 0.1581,
      "step": 5002
    },
    {
      "epoch": 0.7952156722497069,
      "grad_norm": 0.5647984743118286,
      "learning_rate": 1.0596292817683006e-06,
      "loss": 0.2116,
      "step": 5003
    },
    {
      "epoch": 0.7953746200154974,
      "grad_norm": 0.6260308623313904,
      "learning_rate": 1.0580451575219304e-06,
      "loss": 0.3264,
      "step": 5004
    },
    {
      "epoch": 0.7955335677812879,
      "grad_norm": 0.5689645409584045,
      "learning_rate": 1.0564620781569006e-06,
      "loss": 0.2112,
      "step": 5005
    },
    {
      "epoch": 0.7956925155470783,
      "grad_norm": 0.5339750647544861,
      "learning_rate": 1.0548800440928343e-06,
      "loss": 0.1543,
      "step": 5006
    },
    {
      "epoch": 0.7958514633128688,
      "grad_norm": 0.38168948888778687,
      "learning_rate": 1.0532990557490768e-06,
      "loss": 0.0871,
      "step": 5007
    },
    {
      "epoch": 0.7960104110786593,
      "grad_norm": 0.5842487215995789,
      "learning_rate": 1.0517191135446937e-06,
      "loss": 0.2205,
      "step": 5008
    },
    {
      "epoch": 0.7961693588444497,
      "grad_norm": 0.535912275314331,
      "learning_rate": 1.050140217898475e-06,
      "loss": 0.1707,
      "step": 5009
    },
    {
      "epoch": 0.7963283066102402,
      "grad_norm": 0.5305049419403076,
      "learning_rate": 1.0485623692289375e-06,
      "loss": 0.2171,
      "step": 5010
    },
    {
      "epoch": 0.7964872543760306,
      "grad_norm": 0.6252942085266113,
      "learning_rate": 1.0469855679543124e-06,
      "loss": 0.2228,
      "step": 5011
    },
    {
      "epoch": 0.7966462021418211,
      "grad_norm": 0.6003150343894958,
      "learning_rate": 1.045409814492559e-06,
      "loss": 0.1823,
      "step": 5012
    },
    {
      "epoch": 0.7968051499076116,
      "grad_norm": 0.7037010192871094,
      "learning_rate": 1.043835109261357e-06,
      "loss": 0.2118,
      "step": 5013
    },
    {
      "epoch": 0.796964097673402,
      "grad_norm": 0.6136401891708374,
      "learning_rate": 1.04226145267811e-06,
      "loss": 0.2309,
      "step": 5014
    },
    {
      "epoch": 0.7971230454391925,
      "grad_norm": 0.6035086512565613,
      "learning_rate": 1.0406888451599377e-06,
      "loss": 0.1412,
      "step": 5015
    },
    {
      "epoch": 0.797281993204983,
      "grad_norm": 0.5510026812553406,
      "learning_rate": 1.0391172871236904e-06,
      "loss": 0.2122,
      "step": 5016
    },
    {
      "epoch": 0.7974409409707734,
      "grad_norm": 0.540544867515564,
      "learning_rate": 1.037546778985936e-06,
      "loss": 0.1512,
      "step": 5017
    },
    {
      "epoch": 0.797599888736564,
      "grad_norm": 0.5238738059997559,
      "learning_rate": 1.0359773211629614e-06,
      "loss": 0.168,
      "step": 5018
    },
    {
      "epoch": 0.7977588365023545,
      "grad_norm": 0.5050973296165466,
      "learning_rate": 1.034408914070779e-06,
      "loss": 0.1719,
      "step": 5019
    },
    {
      "epoch": 0.7979177842681449,
      "grad_norm": 0.5704385638237,
      "learning_rate": 1.0328415581251217e-06,
      "loss": 0.1957,
      "step": 5020
    },
    {
      "epoch": 0.7980767320339354,
      "grad_norm": 0.5327521562576294,
      "learning_rate": 1.0312752537414445e-06,
      "loss": 0.2023,
      "step": 5021
    },
    {
      "epoch": 0.7982356797997258,
      "grad_norm": 0.547287106513977,
      "learning_rate": 1.0297100013349181e-06,
      "loss": 0.1363,
      "step": 5022
    },
    {
      "epoch": 0.7983946275655163,
      "grad_norm": 0.6631003022193909,
      "learning_rate": 1.0281458013204442e-06,
      "loss": 0.3005,
      "step": 5023
    },
    {
      "epoch": 0.7985535753313068,
      "grad_norm": 0.7432478666305542,
      "learning_rate": 1.02658265411264e-06,
      "loss": 0.1357,
      "step": 5024
    },
    {
      "epoch": 0.7987125230970972,
      "grad_norm": 0.7315962314605713,
      "learning_rate": 1.0250205601258407e-06,
      "loss": 0.3741,
      "step": 5025
    },
    {
      "epoch": 0.7988714708628877,
      "grad_norm": 0.5805230140686035,
      "learning_rate": 1.023459519774107e-06,
      "loss": 0.2185,
      "step": 5026
    },
    {
      "epoch": 0.7990304186286782,
      "grad_norm": 0.4807003140449524,
      "learning_rate": 1.0218995334712205e-06,
      "loss": 0.1282,
      "step": 5027
    },
    {
      "epoch": 0.7991893663944686,
      "grad_norm": 0.5396150946617126,
      "learning_rate": 1.0203406016306783e-06,
      "loss": 0.21,
      "step": 5028
    },
    {
      "epoch": 0.7993483141602591,
      "grad_norm": 0.577015221118927,
      "learning_rate": 1.0187827246657038e-06,
      "loss": 0.1926,
      "step": 5029
    },
    {
      "epoch": 0.7995072619260496,
      "grad_norm": 0.5273228883743286,
      "learning_rate": 1.017225902989239e-06,
      "loss": 0.1731,
      "step": 5030
    },
    {
      "epoch": 0.79966620969184,
      "grad_norm": 0.6692138910293579,
      "learning_rate": 1.0156701370139454e-06,
      "loss": 0.3022,
      "step": 5031
    },
    {
      "epoch": 0.7998251574576305,
      "grad_norm": 0.5764380097389221,
      "learning_rate": 1.014115427152203e-06,
      "loss": 0.21,
      "step": 5032
    },
    {
      "epoch": 0.799984105223421,
      "grad_norm": 0.6150026321411133,
      "learning_rate": 1.0125617738161154e-06,
      "loss": 0.2275,
      "step": 5033
    },
    {
      "epoch": 0.8001430529892114,
      "grad_norm": 0.5501856207847595,
      "learning_rate": 1.0110091774175052e-06,
      "loss": 0.1667,
      "step": 5034
    },
    {
      "epoch": 0.8003020007550019,
      "grad_norm": 0.5729860067367554,
      "learning_rate": 1.0094576383679106e-06,
      "loss": 0.2032,
      "step": 5035
    },
    {
      "epoch": 0.8004609485207923,
      "grad_norm": 0.5093410015106201,
      "learning_rate": 1.007907157078597e-06,
      "loss": 0.1588,
      "step": 5036
    },
    {
      "epoch": 0.8006198962865828,
      "grad_norm": 0.7212458848953247,
      "learning_rate": 1.0063577339605452e-06,
      "loss": 0.4525,
      "step": 5037
    },
    {
      "epoch": 0.8007788440523733,
      "grad_norm": 0.6352447271347046,
      "learning_rate": 1.0048093694244532e-06,
      "loss": 0.1464,
      "step": 5038
    },
    {
      "epoch": 0.8009377918181637,
      "grad_norm": 0.52130126953125,
      "learning_rate": 1.0032620638807429e-06,
      "loss": 0.1738,
      "step": 5039
    },
    {
      "epoch": 0.8010967395839542,
      "grad_norm": 0.5330791473388672,
      "learning_rate": 1.0017158177395531e-06,
      "loss": 0.187,
      "step": 5040
    },
    {
      "epoch": 0.8012556873497447,
      "grad_norm": 0.6412980556488037,
      "learning_rate": 1.0001706314107428e-06,
      "loss": 0.2765,
      "step": 5041
    },
    {
      "epoch": 0.8014146351155351,
      "grad_norm": 0.5676277279853821,
      "learning_rate": 9.986265053038891e-07,
      "loss": 0.1147,
      "step": 5042
    },
    {
      "epoch": 0.8015735828813256,
      "grad_norm": 0.598970890045166,
      "learning_rate": 9.970834398282887e-07,
      "loss": 0.2117,
      "step": 5043
    },
    {
      "epoch": 0.8017325306471161,
      "grad_norm": 0.5783520936965942,
      "learning_rate": 9.955414353929582e-07,
      "loss": 0.2598,
      "step": 5044
    },
    {
      "epoch": 0.8018914784129065,
      "grad_norm": 0.5856274366378784,
      "learning_rate": 9.940004924066294e-07,
      "loss": 0.212,
      "step": 5045
    },
    {
      "epoch": 0.802050426178697,
      "grad_norm": 0.4624192714691162,
      "learning_rate": 9.924606112777563e-07,
      "loss": 0.1167,
      "step": 5046
    },
    {
      "epoch": 0.8022093739444875,
      "grad_norm": 0.6280301213264465,
      "learning_rate": 9.909217924145114e-07,
      "loss": 0.2958,
      "step": 5047
    },
    {
      "epoch": 0.8023683217102779,
      "grad_norm": 0.4953036308288574,
      "learning_rate": 9.893840362247809e-07,
      "loss": 0.163,
      "step": 5048
    },
    {
      "epoch": 0.8025272694760684,
      "grad_norm": 0.5575889945030212,
      "learning_rate": 9.878473431161767e-07,
      "loss": 0.2074,
      "step": 5049
    },
    {
      "epoch": 0.8026862172418588,
      "grad_norm": 0.5440628528594971,
      "learning_rate": 9.863117134960242e-07,
      "loss": 0.1935,
      "step": 5050
    },
    {
      "epoch": 0.8028451650076494,
      "grad_norm": 0.5747299194335938,
      "learning_rate": 9.847771477713686e-07,
      "loss": 0.2013,
      "step": 5051
    },
    {
      "epoch": 0.8030041127734399,
      "grad_norm": 0.5967569351196289,
      "learning_rate": 9.832436463489696e-07,
      "loss": 0.2629,
      "step": 5052
    },
    {
      "epoch": 0.8031630605392303,
      "grad_norm": 0.5704938173294067,
      "learning_rate": 9.817112096353094e-07,
      "loss": 0.2611,
      "step": 5053
    },
    {
      "epoch": 0.8033220083050208,
      "grad_norm": 0.6117363572120667,
      "learning_rate": 9.801798380365851e-07,
      "loss": 0.2913,
      "step": 5054
    },
    {
      "epoch": 0.8034809560708113,
      "grad_norm": 0.5994119644165039,
      "learning_rate": 9.786495319587136e-07,
      "loss": 0.1868,
      "step": 5055
    },
    {
      "epoch": 0.8036399038366017,
      "grad_norm": 0.5890229940414429,
      "learning_rate": 9.77120291807328e-07,
      "loss": 0.2289,
      "step": 5056
    },
    {
      "epoch": 0.8037988516023922,
      "grad_norm": 0.5477012991905212,
      "learning_rate": 9.755921179877797e-07,
      "loss": 0.1862,
      "step": 5057
    },
    {
      "epoch": 0.8039577993681827,
      "grad_norm": 0.6027255654335022,
      "learning_rate": 9.740650109051348e-07,
      "loss": 0.2804,
      "step": 5058
    },
    {
      "epoch": 0.8041167471339731,
      "grad_norm": 0.6638216972351074,
      "learning_rate": 9.725389709641803e-07,
      "loss": 0.1627,
      "step": 5059
    },
    {
      "epoch": 0.8042756948997636,
      "grad_norm": 0.5345104336738586,
      "learning_rate": 9.710139985694177e-07,
      "loss": 0.2025,
      "step": 5060
    },
    {
      "epoch": 0.804434642665554,
      "grad_norm": 0.7197561860084534,
      "learning_rate": 9.694900941250674e-07,
      "loss": 0.2396,
      "step": 5061
    },
    {
      "epoch": 0.8045935904313445,
      "grad_norm": 0.6889321804046631,
      "learning_rate": 9.679672580350652e-07,
      "loss": 0.1655,
      "step": 5062
    },
    {
      "epoch": 0.804752538197135,
      "grad_norm": 0.5803075432777405,
      "learning_rate": 9.664454907030651e-07,
      "loss": 0.147,
      "step": 5063
    },
    {
      "epoch": 0.8049114859629254,
      "grad_norm": 0.6066774129867554,
      "learning_rate": 9.64924792532438e-07,
      "loss": 0.2303,
      "step": 5064
    },
    {
      "epoch": 0.8050704337287159,
      "grad_norm": 0.5154781341552734,
      "learning_rate": 9.634051639262682e-07,
      "loss": 0.1835,
      "step": 5065
    },
    {
      "epoch": 0.8052293814945064,
      "grad_norm": 0.6307493448257446,
      "learning_rate": 9.618866052873594e-07,
      "loss": 0.1186,
      "step": 5066
    },
    {
      "epoch": 0.8053883292602968,
      "grad_norm": 0.7506091594696045,
      "learning_rate": 9.603691170182316e-07,
      "loss": 0.2889,
      "step": 5067
    },
    {
      "epoch": 0.8055472770260873,
      "grad_norm": 0.9594642519950867,
      "learning_rate": 9.588526995211212e-07,
      "loss": 0.2706,
      "step": 5068
    },
    {
      "epoch": 0.8057062247918778,
      "grad_norm": 0.5891799330711365,
      "learning_rate": 9.573373531979785e-07,
      "loss": 0.205,
      "step": 5069
    },
    {
      "epoch": 0.8058651725576682,
      "grad_norm": 0.4984038174152374,
      "learning_rate": 9.55823078450473e-07,
      "loss": 0.1644,
      "step": 5070
    },
    {
      "epoch": 0.8060241203234587,
      "grad_norm": 0.4284984767436981,
      "learning_rate": 9.54309875679989e-07,
      "loss": 0.0907,
      "step": 5071
    },
    {
      "epoch": 0.8061830680892492,
      "grad_norm": 0.6243993639945984,
      "learning_rate": 9.527977452876241e-07,
      "loss": 0.2559,
      "step": 5072
    },
    {
      "epoch": 0.8063420158550396,
      "grad_norm": 0.5636743307113647,
      "learning_rate": 9.512866876741949e-07,
      "loss": 0.2241,
      "step": 5073
    },
    {
      "epoch": 0.8065009636208301,
      "grad_norm": 0.5249810814857483,
      "learning_rate": 9.497767032402333e-07,
      "loss": 0.1821,
      "step": 5074
    },
    {
      "epoch": 0.8066599113866205,
      "grad_norm": 0.8083112835884094,
      "learning_rate": 9.482677923859857e-07,
      "loss": 0.3402,
      "step": 5075
    },
    {
      "epoch": 0.806818859152411,
      "grad_norm": 0.5852286219596863,
      "learning_rate": 9.467599555114137e-07,
      "loss": 0.1723,
      "step": 5076
    },
    {
      "epoch": 0.8069778069182015,
      "grad_norm": 0.5979335904121399,
      "learning_rate": 9.452531930161962e-07,
      "loss": 0.2833,
      "step": 5077
    },
    {
      "epoch": 0.8071367546839919,
      "grad_norm": 0.6189119219779968,
      "learning_rate": 9.437475052997241e-07,
      "loss": 0.1916,
      "step": 5078
    },
    {
      "epoch": 0.8072957024497824,
      "grad_norm": 0.5138951539993286,
      "learning_rate": 9.42242892761106e-07,
      "loss": 0.1585,
      "step": 5079
    },
    {
      "epoch": 0.8074546502155729,
      "grad_norm": 0.5903080105781555,
      "learning_rate": 9.407393557991651e-07,
      "loss": 0.2467,
      "step": 5080
    },
    {
      "epoch": 0.8076135979813633,
      "grad_norm": 0.9443912506103516,
      "learning_rate": 9.39236894812438e-07,
      "loss": 0.25,
      "step": 5081
    },
    {
      "epoch": 0.8077725457471538,
      "grad_norm": 0.6739230751991272,
      "learning_rate": 9.377355101991786e-07,
      "loss": 0.3623,
      "step": 5082
    },
    {
      "epoch": 0.8079314935129444,
      "grad_norm": 0.5954989194869995,
      "learning_rate": 9.362352023573534e-07,
      "loss": 0.1691,
      "step": 5083
    },
    {
      "epoch": 0.8080904412787348,
      "grad_norm": 0.5523777008056641,
      "learning_rate": 9.347359716846455e-07,
      "loss": 0.2075,
      "step": 5084
    },
    {
      "epoch": 0.8082493890445253,
      "grad_norm": 0.5710440874099731,
      "learning_rate": 9.332378185784491e-07,
      "loss": 0.2326,
      "step": 5085
    },
    {
      "epoch": 0.8084083368103158,
      "grad_norm": 0.8402722477912903,
      "learning_rate": 9.317407434358755e-07,
      "loss": 0.3463,
      "step": 5086
    },
    {
      "epoch": 0.8085672845761062,
      "grad_norm": 0.6501270532608032,
      "learning_rate": 9.302447466537496e-07,
      "loss": 0.2705,
      "step": 5087
    },
    {
      "epoch": 0.8087262323418967,
      "grad_norm": 0.48072779178619385,
      "learning_rate": 9.287498286286112e-07,
      "loss": 0.1536,
      "step": 5088
    },
    {
      "epoch": 0.8088851801076871,
      "grad_norm": 0.6272901892662048,
      "learning_rate": 9.272559897567124e-07,
      "loss": 0.251,
      "step": 5089
    },
    {
      "epoch": 0.8090441278734776,
      "grad_norm": 0.7661260962486267,
      "learning_rate": 9.257632304340209e-07,
      "loss": 0.2533,
      "step": 5090
    },
    {
      "epoch": 0.8092030756392681,
      "grad_norm": 0.613484799861908,
      "learning_rate": 9.242715510562195e-07,
      "loss": 0.2727,
      "step": 5091
    },
    {
      "epoch": 0.8093620234050585,
      "grad_norm": 0.5094044208526611,
      "learning_rate": 9.227809520186992e-07,
      "loss": 0.1518,
      "step": 5092
    },
    {
      "epoch": 0.809520971170849,
      "grad_norm": 0.9167469143867493,
      "learning_rate": 9.212914337165696e-07,
      "loss": 0.2138,
      "step": 5093
    },
    {
      "epoch": 0.8096799189366395,
      "grad_norm": 0.5711380839347839,
      "learning_rate": 9.198029965446537e-07,
      "loss": 0.1832,
      "step": 5094
    },
    {
      "epoch": 0.8098388667024299,
      "grad_norm": 0.465616375207901,
      "learning_rate": 9.183156408974858e-07,
      "loss": 0.1221,
      "step": 5095
    },
    {
      "epoch": 0.8099978144682204,
      "grad_norm": 0.571886420249939,
      "learning_rate": 9.168293671693145e-07,
      "loss": 0.2008,
      "step": 5096
    },
    {
      "epoch": 0.8101567622340109,
      "grad_norm": 0.5604726076126099,
      "learning_rate": 9.153441757541026e-07,
      "loss": 0.1476,
      "step": 5097
    },
    {
      "epoch": 0.8103157099998013,
      "grad_norm": 0.6711360216140747,
      "learning_rate": 9.13860067045525e-07,
      "loss": 0.3229,
      "step": 5098
    },
    {
      "epoch": 0.8104746577655918,
      "grad_norm": 0.4790533781051636,
      "learning_rate": 9.123770414369675e-07,
      "loss": 0.1545,
      "step": 5099
    },
    {
      "epoch": 0.8106336055313822,
      "grad_norm": 0.585150957107544,
      "learning_rate": 9.108950993215332e-07,
      "loss": 0.1614,
      "step": 5100
    },
    {
      "epoch": 0.8107925532971727,
      "grad_norm": 0.5145779848098755,
      "learning_rate": 9.094142410920343e-07,
      "loss": 0.1719,
      "step": 5101
    },
    {
      "epoch": 0.8109515010629632,
      "grad_norm": 0.6244105696678162,
      "learning_rate": 9.079344671409979e-07,
      "loss": 0.2183,
      "step": 5102
    },
    {
      "epoch": 0.8111104488287536,
      "grad_norm": 1.046056866645813,
      "learning_rate": 9.064557778606631e-07,
      "loss": 0.2721,
      "step": 5103
    },
    {
      "epoch": 0.8112693965945441,
      "grad_norm": 0.5632663369178772,
      "learning_rate": 9.049781736429819e-07,
      "loss": 0.2044,
      "step": 5104
    },
    {
      "epoch": 0.8114283443603346,
      "grad_norm": 0.504764974117279,
      "learning_rate": 9.035016548796166e-07,
      "loss": 0.1645,
      "step": 5105
    },
    {
      "epoch": 0.811587292126125,
      "grad_norm": 0.48500555753707886,
      "learning_rate": 9.020262219619436e-07,
      "loss": 0.1622,
      "step": 5106
    },
    {
      "epoch": 0.8117462398919155,
      "grad_norm": 0.5265368819236755,
      "learning_rate": 9.005518752810516e-07,
      "loss": 0.1469,
      "step": 5107
    },
    {
      "epoch": 0.811905187657706,
      "grad_norm": 0.45965513586997986,
      "learning_rate": 8.990786152277408e-07,
      "loss": 0.1132,
      "step": 5108
    },
    {
      "epoch": 0.8120641354234964,
      "grad_norm": 0.5350756049156189,
      "learning_rate": 8.97606442192524e-07,
      "loss": 0.1698,
      "step": 5109
    },
    {
      "epoch": 0.8122230831892869,
      "grad_norm": 0.6228773593902588,
      "learning_rate": 8.961353565656245e-07,
      "loss": 0.1927,
      "step": 5110
    },
    {
      "epoch": 0.8123820309550774,
      "grad_norm": 0.6617995500564575,
      "learning_rate": 8.946653587369803e-07,
      "loss": 0.1154,
      "step": 5111
    },
    {
      "epoch": 0.8125409787208678,
      "grad_norm": 0.43364188075065613,
      "learning_rate": 8.931964490962364e-07,
      "loss": 0.1148,
      "step": 5112
    },
    {
      "epoch": 0.8126999264866583,
      "grad_norm": 0.5186904072761536,
      "learning_rate": 8.91728628032753e-07,
      "loss": 0.1594,
      "step": 5113
    },
    {
      "epoch": 0.8128588742524487,
      "grad_norm": 0.5325304269790649,
      "learning_rate": 8.902618959356007e-07,
      "loss": 0.1528,
      "step": 5114
    },
    {
      "epoch": 0.8130178220182392,
      "grad_norm": 0.5829012393951416,
      "learning_rate": 8.887962531935612e-07,
      "loss": 0.2595,
      "step": 5115
    },
    {
      "epoch": 0.8131767697840298,
      "grad_norm": 0.4600343108177185,
      "learning_rate": 8.873317001951287e-07,
      "loss": 0.1113,
      "step": 5116
    },
    {
      "epoch": 0.8133357175498201,
      "grad_norm": 0.6456276774406433,
      "learning_rate": 8.858682373285065e-07,
      "loss": 0.3121,
      "step": 5117
    },
    {
      "epoch": 0.8134946653156107,
      "grad_norm": 0.6030002236366272,
      "learning_rate": 8.844058649816123e-07,
      "loss": 0.1443,
      "step": 5118
    },
    {
      "epoch": 0.8136536130814012,
      "grad_norm": 0.5263372659683228,
      "learning_rate": 8.829445835420691e-07,
      "loss": 0.1486,
      "step": 5119
    },
    {
      "epoch": 0.8138125608471916,
      "grad_norm": 0.6305311322212219,
      "learning_rate": 8.814843933972155e-07,
      "loss": 0.3233,
      "step": 5120
    },
    {
      "epoch": 0.8139715086129821,
      "grad_norm": 0.6356010437011719,
      "learning_rate": 8.800252949340998e-07,
      "loss": 0.2355,
      "step": 5121
    },
    {
      "epoch": 0.8141304563787726,
      "grad_norm": 0.5371612310409546,
      "learning_rate": 8.785672885394802e-07,
      "loss": 0.1891,
      "step": 5122
    },
    {
      "epoch": 0.814289404144563,
      "grad_norm": 0.49405190348625183,
      "learning_rate": 8.771103745998255e-07,
      "loss": 0.1917,
      "step": 5123
    },
    {
      "epoch": 0.8144483519103535,
      "grad_norm": 0.5482827425003052,
      "learning_rate": 8.756545535013172e-07,
      "loss": 0.1512,
      "step": 5124
    },
    {
      "epoch": 0.814607299676144,
      "grad_norm": 0.5823887586593628,
      "learning_rate": 8.741998256298423e-07,
      "loss": 0.2133,
      "step": 5125
    },
    {
      "epoch": 0.8147662474419344,
      "grad_norm": 0.5518028736114502,
      "learning_rate": 8.727461913710022e-07,
      "loss": 0.209,
      "step": 5126
    },
    {
      "epoch": 0.8149251952077249,
      "grad_norm": 0.6665867567062378,
      "learning_rate": 8.712936511101056e-07,
      "loss": 0.0977,
      "step": 5127
    },
    {
      "epoch": 0.8150841429735153,
      "grad_norm": 0.5787787437438965,
      "learning_rate": 8.698422052321764e-07,
      "loss": 0.2335,
      "step": 5128
    },
    {
      "epoch": 0.8152430907393058,
      "grad_norm": 0.6813176870346069,
      "learning_rate": 8.683918541219411e-07,
      "loss": 0.2539,
      "step": 5129
    },
    {
      "epoch": 0.8154020385050963,
      "grad_norm": 0.7084543704986572,
      "learning_rate": 8.669425981638413e-07,
      "loss": 0.3435,
      "step": 5130
    },
    {
      "epoch": 0.8155609862708867,
      "grad_norm": 0.5830370783805847,
      "learning_rate": 8.654944377420272e-07,
      "loss": 0.2294,
      "step": 5131
    },
    {
      "epoch": 0.8157199340366772,
      "grad_norm": 0.6069748401641846,
      "learning_rate": 8.640473732403554e-07,
      "loss": 0.2398,
      "step": 5132
    },
    {
      "epoch": 0.8158788818024677,
      "grad_norm": 0.4745335280895233,
      "learning_rate": 8.62601405042397e-07,
      "loss": 0.1474,
      "step": 5133
    },
    {
      "epoch": 0.8160378295682581,
      "grad_norm": 0.6280860304832458,
      "learning_rate": 8.611565335314292e-07,
      "loss": 0.2619,
      "step": 5134
    },
    {
      "epoch": 0.8161967773340486,
      "grad_norm": 0.5745616555213928,
      "learning_rate": 8.597127590904397e-07,
      "loss": 0.2024,
      "step": 5135
    },
    {
      "epoch": 0.8163557250998391,
      "grad_norm": 0.6350835561752319,
      "learning_rate": 8.582700821021251e-07,
      "loss": 0.2592,
      "step": 5136
    },
    {
      "epoch": 0.8165146728656295,
      "grad_norm": 0.7377936840057373,
      "learning_rate": 8.568285029488916e-07,
      "loss": 0.3018,
      "step": 5137
    },
    {
      "epoch": 0.81667362063142,
      "grad_norm": 0.6884215474128723,
      "learning_rate": 8.553880220128546e-07,
      "loss": 0.1925,
      "step": 5138
    },
    {
      "epoch": 0.8168325683972104,
      "grad_norm": 0.7531446814537048,
      "learning_rate": 8.539486396758357e-07,
      "loss": 0.1929,
      "step": 5139
    },
    {
      "epoch": 0.8169915161630009,
      "grad_norm": 0.5866856575012207,
      "learning_rate": 8.525103563193671e-07,
      "loss": 0.2334,
      "step": 5140
    },
    {
      "epoch": 0.8171504639287914,
      "grad_norm": 0.4980357885360718,
      "learning_rate": 8.51073172324694e-07,
      "loss": 0.1853,
      "step": 5141
    },
    {
      "epoch": 0.8173094116945818,
      "grad_norm": 0.5793187022209167,
      "learning_rate": 8.496370880727622e-07,
      "loss": 0.2413,
      "step": 5142
    },
    {
      "epoch": 0.8174683594603723,
      "grad_norm": 0.5221664309501648,
      "learning_rate": 8.482021039442312e-07,
      "loss": 0.1586,
      "step": 5143
    },
    {
      "epoch": 0.8176273072261628,
      "grad_norm": 0.5583126544952393,
      "learning_rate": 8.467682203194689e-07,
      "loss": 0.1804,
      "step": 5144
    },
    {
      "epoch": 0.8177862549919532,
      "grad_norm": 0.49307677149772644,
      "learning_rate": 8.453354375785477e-07,
      "loss": 0.1398,
      "step": 5145
    },
    {
      "epoch": 0.8179452027577437,
      "grad_norm": 0.5539213418960571,
      "learning_rate": 8.439037561012526e-07,
      "loss": 0.2113,
      "step": 5146
    },
    {
      "epoch": 0.8181041505235342,
      "grad_norm": 0.5701041221618652,
      "learning_rate": 8.424731762670723e-07,
      "loss": 0.2247,
      "step": 5147
    },
    {
      "epoch": 0.8182630982893246,
      "grad_norm": 0.5894398093223572,
      "learning_rate": 8.410436984552112e-07,
      "loss": 0.1575,
      "step": 5148
    },
    {
      "epoch": 0.8184220460551151,
      "grad_norm": 0.4739728569984436,
      "learning_rate": 8.396153230445714e-07,
      "loss": 0.0791,
      "step": 5149
    },
    {
      "epoch": 0.8185809938209057,
      "grad_norm": 0.648276686668396,
      "learning_rate": 8.381880504137696e-07,
      "loss": 0.1918,
      "step": 5150
    },
    {
      "epoch": 0.818739941586696,
      "grad_norm": 0.5579016208648682,
      "learning_rate": 8.367618809411299e-07,
      "loss": 0.1831,
      "step": 5151
    },
    {
      "epoch": 0.8188988893524866,
      "grad_norm": 0.5793287754058838,
      "learning_rate": 8.353368150046798e-07,
      "loss": 0.2299,
      "step": 5152
    },
    {
      "epoch": 0.819057837118277,
      "grad_norm": 0.6418459415435791,
      "learning_rate": 8.339128529821566e-07,
      "loss": 0.3082,
      "step": 5153
    },
    {
      "epoch": 0.8192167848840675,
      "grad_norm": 0.5804905891418457,
      "learning_rate": 8.324899952510096e-07,
      "loss": 0.1705,
      "step": 5154
    },
    {
      "epoch": 0.819375732649858,
      "grad_norm": 0.5199766159057617,
      "learning_rate": 8.31068242188387e-07,
      "loss": 0.2114,
      "step": 5155
    },
    {
      "epoch": 0.8195346804156484,
      "grad_norm": 0.5380457043647766,
      "learning_rate": 8.296475941711496e-07,
      "loss": 0.1783,
      "step": 5156
    },
    {
      "epoch": 0.8196936281814389,
      "grad_norm": 0.6383441686630249,
      "learning_rate": 8.282280515758639e-07,
      "loss": 0.2712,
      "step": 5157
    },
    {
      "epoch": 0.8198525759472294,
      "grad_norm": 0.5011864900588989,
      "learning_rate": 8.268096147788057e-07,
      "loss": 0.1382,
      "step": 5158
    },
    {
      "epoch": 0.8200115237130198,
      "grad_norm": 0.5534237623214722,
      "learning_rate": 8.253922841559519e-07,
      "loss": 0.2294,
      "step": 5159
    },
    {
      "epoch": 0.8201704714788103,
      "grad_norm": 0.49952176213264465,
      "learning_rate": 8.239760600829904e-07,
      "loss": 0.1232,
      "step": 5160
    },
    {
      "epoch": 0.8203294192446008,
      "grad_norm": 0.6275164484977722,
      "learning_rate": 8.225609429353187e-07,
      "loss": 0.2463,
      "step": 5161
    },
    {
      "epoch": 0.8204883670103912,
      "grad_norm": 0.698001503944397,
      "learning_rate": 8.211469330880334e-07,
      "loss": 0.226,
      "step": 5162
    },
    {
      "epoch": 0.8206473147761817,
      "grad_norm": 0.5523274540901184,
      "learning_rate": 8.197340309159429e-07,
      "loss": 0.1807,
      "step": 5163
    },
    {
      "epoch": 0.8208062625419722,
      "grad_norm": 0.5735259652137756,
      "learning_rate": 8.183222367935612e-07,
      "loss": 0.2463,
      "step": 5164
    },
    {
      "epoch": 0.8209652103077626,
      "grad_norm": 0.486935555934906,
      "learning_rate": 8.169115510951087e-07,
      "loss": 0.1173,
      "step": 5165
    },
    {
      "epoch": 0.8211241580735531,
      "grad_norm": 0.6495457887649536,
      "learning_rate": 8.15501974194508e-07,
      "loss": 0.2824,
      "step": 5166
    },
    {
      "epoch": 0.8212831058393435,
      "grad_norm": 0.5931691527366638,
      "learning_rate": 8.140935064653949e-07,
      "loss": 0.2519,
      "step": 5167
    },
    {
      "epoch": 0.821442053605134,
      "grad_norm": 0.5560269951820374,
      "learning_rate": 8.126861482811066e-07,
      "loss": 0.1388,
      "step": 5168
    },
    {
      "epoch": 0.8216010013709245,
      "grad_norm": 0.6348720192909241,
      "learning_rate": 8.112799000146853e-07,
      "loss": 0.2558,
      "step": 5169
    },
    {
      "epoch": 0.8217599491367149,
      "grad_norm": 0.5494504570960999,
      "learning_rate": 8.098747620388819e-07,
      "loss": 0.1489,
      "step": 5170
    },
    {
      "epoch": 0.8219188969025054,
      "grad_norm": 0.5681217312812805,
      "learning_rate": 8.084707347261533e-07,
      "loss": 0.2261,
      "step": 5171
    },
    {
      "epoch": 0.8220778446682959,
      "grad_norm": 0.6066958904266357,
      "learning_rate": 8.070678184486575e-07,
      "loss": 0.2253,
      "step": 5172
    },
    {
      "epoch": 0.8222367924340863,
      "grad_norm": 0.5705200433731079,
      "learning_rate": 8.056660135782606e-07,
      "loss": 0.2282,
      "step": 5173
    },
    {
      "epoch": 0.8223957401998768,
      "grad_norm": 0.6346669793128967,
      "learning_rate": 8.042653204865386e-07,
      "loss": 0.1984,
      "step": 5174
    },
    {
      "epoch": 0.8225546879656673,
      "grad_norm": 0.549437403678894,
      "learning_rate": 8.02865739544767e-07,
      "loss": 0.1915,
      "step": 5175
    },
    {
      "epoch": 0.8227136357314577,
      "grad_norm": 0.5989531874656677,
      "learning_rate": 8.014672711239269e-07,
      "loss": 0.2189,
      "step": 5176
    },
    {
      "epoch": 0.8228725834972482,
      "grad_norm": 0.7054913640022278,
      "learning_rate": 8.000699155947067e-07,
      "loss": 0.3052,
      "step": 5177
    },
    {
      "epoch": 0.8230315312630386,
      "grad_norm": 0.6759990453720093,
      "learning_rate": 7.986736733274997e-07,
      "loss": 0.2143,
      "step": 5178
    },
    {
      "epoch": 0.8231904790288291,
      "grad_norm": 0.5993037819862366,
      "learning_rate": 7.972785446924008e-07,
      "loss": 0.2252,
      "step": 5179
    },
    {
      "epoch": 0.8233494267946196,
      "grad_norm": 0.657580554485321,
      "learning_rate": 7.95884530059215e-07,
      "loss": 0.3529,
      "step": 5180
    },
    {
      "epoch": 0.82350837456041,
      "grad_norm": 0.672444224357605,
      "learning_rate": 7.944916297974498e-07,
      "loss": 0.2511,
      "step": 5181
    },
    {
      "epoch": 0.8236673223262005,
      "grad_norm": 0.8601559400558472,
      "learning_rate": 7.930998442763138e-07,
      "loss": 0.1901,
      "step": 5182
    },
    {
      "epoch": 0.823826270091991,
      "grad_norm": 0.6170982122421265,
      "learning_rate": 7.917091738647254e-07,
      "loss": 0.2507,
      "step": 5183
    },
    {
      "epoch": 0.8239852178577814,
      "grad_norm": 0.7699064612388611,
      "learning_rate": 7.903196189313039e-07,
      "loss": 0.2937,
      "step": 5184
    },
    {
      "epoch": 0.824144165623572,
      "grad_norm": 0.5933076739311218,
      "learning_rate": 7.88931179844376e-07,
      "loss": 0.1874,
      "step": 5185
    },
    {
      "epoch": 0.8243031133893625,
      "grad_norm": 0.5228163599967957,
      "learning_rate": 7.875438569719674e-07,
      "loss": 0.1568,
      "step": 5186
    },
    {
      "epoch": 0.8244620611551529,
      "grad_norm": 0.5554296374320984,
      "learning_rate": 7.861576506818147e-07,
      "loss": 0.2328,
      "step": 5187
    },
    {
      "epoch": 0.8246210089209434,
      "grad_norm": 0.542794406414032,
      "learning_rate": 7.847725613413554e-07,
      "loss": 0.1938,
      "step": 5188
    },
    {
      "epoch": 0.8247799566867339,
      "grad_norm": 0.628739058971405,
      "learning_rate": 7.833885893177273e-07,
      "loss": 0.2117,
      "step": 5189
    },
    {
      "epoch": 0.8249389044525243,
      "grad_norm": 0.6329929828643799,
      "learning_rate": 7.820057349777782e-07,
      "loss": 0.2822,
      "step": 5190
    },
    {
      "epoch": 0.8250978522183148,
      "grad_norm": 0.5385845303535461,
      "learning_rate": 7.806239986880565e-07,
      "loss": 0.2112,
      "step": 5191
    },
    {
      "epoch": 0.8252567999841052,
      "grad_norm": 0.554689347743988,
      "learning_rate": 7.79243380814812e-07,
      "loss": 0.1951,
      "step": 5192
    },
    {
      "epoch": 0.8254157477498957,
      "grad_norm": 0.5335491299629211,
      "learning_rate": 7.778638817240042e-07,
      "loss": 0.2298,
      "step": 5193
    },
    {
      "epoch": 0.8255746955156862,
      "grad_norm": 0.6307651996612549,
      "learning_rate": 7.764855017812911e-07,
      "loss": 0.2612,
      "step": 5194
    },
    {
      "epoch": 0.8257336432814766,
      "grad_norm": 0.6698426604270935,
      "learning_rate": 7.751082413520367e-07,
      "loss": 0.1711,
      "step": 5195
    },
    {
      "epoch": 0.8258925910472671,
      "grad_norm": 0.6066961288452148,
      "learning_rate": 7.737321008013044e-07,
      "loss": 0.2491,
      "step": 5196
    },
    {
      "epoch": 0.8260515388130576,
      "grad_norm": 0.5462948083877563,
      "learning_rate": 7.723570804938646e-07,
      "loss": 0.1963,
      "step": 5197
    },
    {
      "epoch": 0.826210486578848,
      "grad_norm": 0.6493976712226868,
      "learning_rate": 7.709831807941909e-07,
      "loss": 0.3351,
      "step": 5198
    },
    {
      "epoch": 0.8263694343446385,
      "grad_norm": 0.7322526574134827,
      "learning_rate": 7.696104020664552e-07,
      "loss": 0.1263,
      "step": 5199
    },
    {
      "epoch": 0.826528382110429,
      "grad_norm": 0.5184734463691711,
      "learning_rate": 7.682387446745388e-07,
      "loss": 0.1759,
      "step": 5200
    },
    {
      "epoch": 0.8266873298762194,
      "grad_norm": 0.5429056882858276,
      "learning_rate": 7.668682089820223e-07,
      "loss": 0.1899,
      "step": 5201
    },
    {
      "epoch": 0.8268462776420099,
      "grad_norm": 0.5621997714042664,
      "learning_rate": 7.654987953521875e-07,
      "loss": 0.2006,
      "step": 5202
    },
    {
      "epoch": 0.8270052254078004,
      "grad_norm": 0.5853160619735718,
      "learning_rate": 7.641305041480207e-07,
      "loss": 0.2492,
      "step": 5203
    },
    {
      "epoch": 0.8271641731735908,
      "grad_norm": 0.7132025361061096,
      "learning_rate": 7.627633357322112e-07,
      "loss": 0.3011,
      "step": 5204
    },
    {
      "epoch": 0.8273231209393813,
      "grad_norm": 0.6369962692260742,
      "learning_rate": 7.613972904671496e-07,
      "loss": 0.2259,
      "step": 5205
    },
    {
      "epoch": 0.8274820687051717,
      "grad_norm": 0.4949358105659485,
      "learning_rate": 7.600323687149297e-07,
      "loss": 0.1557,
      "step": 5206
    },
    {
      "epoch": 0.8276410164709622,
      "grad_norm": 0.4933927059173584,
      "learning_rate": 7.586685708373464e-07,
      "loss": 0.1301,
      "step": 5207
    },
    {
      "epoch": 0.8277999642367527,
      "grad_norm": 0.5568404793739319,
      "learning_rate": 7.573058971958985e-07,
      "loss": 0.1359,
      "step": 5208
    },
    {
      "epoch": 0.8279589120025431,
      "grad_norm": 0.8412277102470398,
      "learning_rate": 7.559443481517831e-07,
      "loss": 0.2636,
      "step": 5209
    },
    {
      "epoch": 0.8281178597683336,
      "grad_norm": 1.137943983078003,
      "learning_rate": 7.545839240659037e-07,
      "loss": 0.2132,
      "step": 5210
    },
    {
      "epoch": 0.8282768075341241,
      "grad_norm": 0.5662497878074646,
      "learning_rate": 7.532246252988617e-07,
      "loss": 0.239,
      "step": 5211
    },
    {
      "epoch": 0.8284357552999145,
      "grad_norm": 0.7229511737823486,
      "learning_rate": 7.518664522109636e-07,
      "loss": 0.2661,
      "step": 5212
    },
    {
      "epoch": 0.828594703065705,
      "grad_norm": 0.5943858623504639,
      "learning_rate": 7.505094051622158e-07,
      "loss": 0.1898,
      "step": 5213
    },
    {
      "epoch": 0.8287536508314955,
      "grad_norm": 0.617996871471405,
      "learning_rate": 7.491534845123261e-07,
      "loss": 0.2672,
      "step": 5214
    },
    {
      "epoch": 0.8289125985972859,
      "grad_norm": 0.5237953662872314,
      "learning_rate": 7.477986906207052e-07,
      "loss": 0.1642,
      "step": 5215
    },
    {
      "epoch": 0.8290715463630765,
      "grad_norm": 0.5654807686805725,
      "learning_rate": 7.464450238464621e-07,
      "loss": 0.2574,
      "step": 5216
    },
    {
      "epoch": 0.8292304941288668,
      "grad_norm": 0.6005872488021851,
      "learning_rate": 7.450924845484092e-07,
      "loss": 0.2065,
      "step": 5217
    },
    {
      "epoch": 0.8293894418946574,
      "grad_norm": 0.4716067314147949,
      "learning_rate": 7.437410730850608e-07,
      "loss": 0.1473,
      "step": 5218
    },
    {
      "epoch": 0.8295483896604479,
      "grad_norm": 0.8965067863464355,
      "learning_rate": 7.423907898146305e-07,
      "loss": 0.1331,
      "step": 5219
    },
    {
      "epoch": 0.8297073374262383,
      "grad_norm": 0.7949405908584595,
      "learning_rate": 7.410416350950333e-07,
      "loss": 0.3125,
      "step": 5220
    },
    {
      "epoch": 0.8298662851920288,
      "grad_norm": 0.7016488313674927,
      "learning_rate": 7.396936092838874e-07,
      "loss": 0.3217,
      "step": 5221
    },
    {
      "epoch": 0.8300252329578193,
      "grad_norm": 0.7202214002609253,
      "learning_rate": 7.383467127385069e-07,
      "loss": 0.3413,
      "step": 5222
    },
    {
      "epoch": 0.8301841807236097,
      "grad_norm": 0.873652994632721,
      "learning_rate": 7.370009458159099e-07,
      "loss": 0.2022,
      "step": 5223
    },
    {
      "epoch": 0.8303431284894002,
      "grad_norm": 0.5814166069030762,
      "learning_rate": 7.356563088728158e-07,
      "loss": 0.219,
      "step": 5224
    },
    {
      "epoch": 0.8305020762551907,
      "grad_norm": 0.8274084329605103,
      "learning_rate": 7.343128022656421e-07,
      "loss": 0.223,
      "step": 5225
    },
    {
      "epoch": 0.8306610240209811,
      "grad_norm": 0.6219092011451721,
      "learning_rate": 7.329704263505089e-07,
      "loss": 0.2607,
      "step": 5226
    },
    {
      "epoch": 0.8308199717867716,
      "grad_norm": 0.5947937369346619,
      "learning_rate": 7.316291814832338e-07,
      "loss": 0.2221,
      "step": 5227
    },
    {
      "epoch": 0.8309789195525621,
      "grad_norm": 0.6082834601402283,
      "learning_rate": 7.302890680193392e-07,
      "loss": 0.2861,
      "step": 5228
    },
    {
      "epoch": 0.8311378673183525,
      "grad_norm": 0.5663710236549377,
      "learning_rate": 7.289500863140414e-07,
      "loss": 0.261,
      "step": 5229
    },
    {
      "epoch": 0.831296815084143,
      "grad_norm": 0.5892620086669922,
      "learning_rate": 7.276122367222616e-07,
      "loss": 0.2644,
      "step": 5230
    },
    {
      "epoch": 0.8314557628499334,
      "grad_norm": 0.5010237097740173,
      "learning_rate": 7.262755195986188e-07,
      "loss": 0.1384,
      "step": 5231
    },
    {
      "epoch": 0.8316147106157239,
      "grad_norm": 0.6132262349128723,
      "learning_rate": 7.249399352974323e-07,
      "loss": 0.2427,
      "step": 5232
    },
    {
      "epoch": 0.8317736583815144,
      "grad_norm": 0.8665134906768799,
      "learning_rate": 7.236054841727219e-07,
      "loss": 0.1378,
      "step": 5233
    },
    {
      "epoch": 0.8319326061473048,
      "grad_norm": 0.7396792769432068,
      "learning_rate": 7.222721665782056e-07,
      "loss": 0.3413,
      "step": 5234
    },
    {
      "epoch": 0.8320915539130953,
      "grad_norm": 0.617120623588562,
      "learning_rate": 7.20939982867303e-07,
      "loss": 0.2935,
      "step": 5235
    },
    {
      "epoch": 0.8322505016788858,
      "grad_norm": 0.49745139479637146,
      "learning_rate": 7.1960893339313e-07,
      "loss": 0.1489,
      "step": 5236
    },
    {
      "epoch": 0.8324094494446762,
      "grad_norm": 0.6202538013458252,
      "learning_rate": 7.182790185085037e-07,
      "loss": 0.3046,
      "step": 5237
    },
    {
      "epoch": 0.8325683972104667,
      "grad_norm": 0.6692953705787659,
      "learning_rate": 7.16950238565941e-07,
      "loss": 0.2417,
      "step": 5238
    },
    {
      "epoch": 0.8327273449762572,
      "grad_norm": 0.5992241501808167,
      "learning_rate": 7.156225939176576e-07,
      "loss": 0.2508,
      "step": 5239
    },
    {
      "epoch": 0.8328862927420476,
      "grad_norm": 0.6118277311325073,
      "learning_rate": 7.142960849155672e-07,
      "loss": 0.2376,
      "step": 5240
    },
    {
      "epoch": 0.8330452405078381,
      "grad_norm": 0.5880197882652283,
      "learning_rate": 7.129707119112838e-07,
      "loss": 0.1666,
      "step": 5241
    },
    {
      "epoch": 0.8332041882736286,
      "grad_norm": 0.6281706094741821,
      "learning_rate": 7.116464752561209e-07,
      "loss": 0.2045,
      "step": 5242
    },
    {
      "epoch": 0.833363136039419,
      "grad_norm": 0.5624768137931824,
      "learning_rate": 7.10323375301088e-07,
      "loss": 0.1977,
      "step": 5243
    },
    {
      "epoch": 0.8335220838052095,
      "grad_norm": 0.6412067413330078,
      "learning_rate": 7.090014123968947e-07,
      "loss": 0.257,
      "step": 5244
    },
    {
      "epoch": 0.8336810315709999,
      "grad_norm": 0.6200507283210754,
      "learning_rate": 7.076805868939507e-07,
      "loss": 0.2692,
      "step": 5245
    },
    {
      "epoch": 0.8338399793367904,
      "grad_norm": 0.5757462978363037,
      "learning_rate": 7.063608991423621e-07,
      "loss": 0.1899,
      "step": 5246
    },
    {
      "epoch": 0.833998927102581,
      "grad_norm": 0.4929793179035187,
      "learning_rate": 7.05042349491935e-07,
      "loss": 0.1599,
      "step": 5247
    },
    {
      "epoch": 0.8341578748683713,
      "grad_norm": 0.6266489028930664,
      "learning_rate": 7.03724938292174e-07,
      "loss": 0.2896,
      "step": 5248
    },
    {
      "epoch": 0.8343168226341618,
      "grad_norm": 0.6011296510696411,
      "learning_rate": 7.02408665892279e-07,
      "loss": 0.2703,
      "step": 5249
    },
    {
      "epoch": 0.8344757703999524,
      "grad_norm": 0.5514360070228577,
      "learning_rate": 7.010935326411511e-07,
      "loss": 0.2272,
      "step": 5250
    },
    {
      "epoch": 0.8346347181657428,
      "grad_norm": 0.5888495445251465,
      "learning_rate": 6.997795388873879e-07,
      "loss": 0.227,
      "step": 5251
    },
    {
      "epoch": 0.8347936659315333,
      "grad_norm": 0.6298144459724426,
      "learning_rate": 6.984666849792865e-07,
      "loss": 0.2753,
      "step": 5252
    },
    {
      "epoch": 0.8349526136973238,
      "grad_norm": 0.5947603583335876,
      "learning_rate": 6.971549712648401e-07,
      "loss": 0.2046,
      "step": 5253
    },
    {
      "epoch": 0.8351115614631142,
      "grad_norm": 0.5661028027534485,
      "learning_rate": 6.958443980917406e-07,
      "loss": 0.2105,
      "step": 5254
    },
    {
      "epoch": 0.8352705092289047,
      "grad_norm": 0.49591147899627686,
      "learning_rate": 6.945349658073791e-07,
      "loss": 0.1573,
      "step": 5255
    },
    {
      "epoch": 0.8354294569946951,
      "grad_norm": 0.5621508359909058,
      "learning_rate": 6.932266747588395e-07,
      "loss": 0.2033,
      "step": 5256
    },
    {
      "epoch": 0.8355884047604856,
      "grad_norm": 1.017637014389038,
      "learning_rate": 6.919195252929084e-07,
      "loss": 0.1875,
      "step": 5257
    },
    {
      "epoch": 0.8357473525262761,
      "grad_norm": 0.6380801200866699,
      "learning_rate": 6.906135177560674e-07,
      "loss": 0.2474,
      "step": 5258
    },
    {
      "epoch": 0.8359063002920665,
      "grad_norm": 0.5860897898674011,
      "learning_rate": 6.893086524944953e-07,
      "loss": 0.1994,
      "step": 5259
    },
    {
      "epoch": 0.836065248057857,
      "grad_norm": 0.5261589884757996,
      "learning_rate": 6.880049298540686e-07,
      "loss": 0.1572,
      "step": 5260
    },
    {
      "epoch": 0.8362241958236475,
      "grad_norm": 0.5463826656341553,
      "learning_rate": 6.86702350180361e-07,
      "loss": 0.2047,
      "step": 5261
    },
    {
      "epoch": 0.8363831435894379,
      "grad_norm": 0.6006201505661011,
      "learning_rate": 6.854009138186451e-07,
      "loss": 0.209,
      "step": 5262
    },
    {
      "epoch": 0.8365420913552284,
      "grad_norm": 0.5352632403373718,
      "learning_rate": 6.841006211138851e-07,
      "loss": 0.1499,
      "step": 5263
    },
    {
      "epoch": 0.8367010391210189,
      "grad_norm": 0.6611131429672241,
      "learning_rate": 6.828014724107468e-07,
      "loss": 0.2793,
      "step": 5264
    },
    {
      "epoch": 0.8368599868868093,
      "grad_norm": 0.5795993804931641,
      "learning_rate": 6.815034680535915e-07,
      "loss": 0.2169,
      "step": 5265
    },
    {
      "epoch": 0.8370189346525998,
      "grad_norm": 0.5512064099311829,
      "learning_rate": 6.802066083864772e-07,
      "loss": 0.1935,
      "step": 5266
    },
    {
      "epoch": 0.8371778824183903,
      "grad_norm": 0.6262628436088562,
      "learning_rate": 6.78910893753158e-07,
      "loss": 0.1926,
      "step": 5267
    },
    {
      "epoch": 0.8373368301841807,
      "grad_norm": 0.563650369644165,
      "learning_rate": 6.776163244970863e-07,
      "loss": 0.1693,
      "step": 5268
    },
    {
      "epoch": 0.8374957779499712,
      "grad_norm": 0.6040608286857605,
      "learning_rate": 6.76322900961407e-07,
      "loss": 0.147,
      "step": 5269
    },
    {
      "epoch": 0.8376547257157616,
      "grad_norm": 0.5158515572547913,
      "learning_rate": 6.750306234889647e-07,
      "loss": 0.161,
      "step": 5270
    },
    {
      "epoch": 0.8378136734815521,
      "grad_norm": 0.5868968963623047,
      "learning_rate": 6.737394924223e-07,
      "loss": 0.2401,
      "step": 5271
    },
    {
      "epoch": 0.8379726212473426,
      "grad_norm": 0.5925242900848389,
      "learning_rate": 6.724495081036475e-07,
      "loss": 0.2246,
      "step": 5272
    },
    {
      "epoch": 0.838131569013133,
      "grad_norm": 0.598065197467804,
      "learning_rate": 6.711606708749408e-07,
      "loss": 0.207,
      "step": 5273
    },
    {
      "epoch": 0.8382905167789235,
      "grad_norm": 0.7652209401130676,
      "learning_rate": 6.698729810778065e-07,
      "loss": 0.1803,
      "step": 5274
    },
    {
      "epoch": 0.838449464544714,
      "grad_norm": 0.6999357342720032,
      "learning_rate": 6.685864390535707e-07,
      "loss": 0.1783,
      "step": 5275
    },
    {
      "epoch": 0.8386084123105044,
      "grad_norm": 0.7137114405632019,
      "learning_rate": 6.673010451432499e-07,
      "loss": 0.3266,
      "step": 5276
    },
    {
      "epoch": 0.8387673600762949,
      "grad_norm": 0.6187711954116821,
      "learning_rate": 6.660167996875605e-07,
      "loss": 0.2628,
      "step": 5277
    },
    {
      "epoch": 0.8389263078420854,
      "grad_norm": 0.6543564796447754,
      "learning_rate": 6.647337030269136e-07,
      "loss": 0.2627,
      "step": 5278
    },
    {
      "epoch": 0.8390852556078758,
      "grad_norm": 0.44157636165618896,
      "learning_rate": 6.634517555014152e-07,
      "loss": 0.1151,
      "step": 5279
    },
    {
      "epoch": 0.8392442033736663,
      "grad_norm": 0.7914366722106934,
      "learning_rate": 6.621709574508678e-07,
      "loss": 0.3575,
      "step": 5280
    },
    {
      "epoch": 0.8394031511394568,
      "grad_norm": 2.091554641723633,
      "learning_rate": 6.608913092147679e-07,
      "loss": 0.3389,
      "step": 5281
    },
    {
      "epoch": 0.8395620989052472,
      "grad_norm": 0.5728489756584167,
      "learning_rate": 6.596128111323086e-07,
      "loss": 0.2459,
      "step": 5282
    },
    {
      "epoch": 0.8397210466710378,
      "grad_norm": 0.5668396949768066,
      "learning_rate": 6.583354635423755e-07,
      "loss": 0.1755,
      "step": 5283
    },
    {
      "epoch": 0.8398799944368281,
      "grad_norm": 0.6122517585754395,
      "learning_rate": 6.570592667835518e-07,
      "loss": 0.2612,
      "step": 5284
    },
    {
      "epoch": 0.8400389422026187,
      "grad_norm": 0.5109537839889526,
      "learning_rate": 6.557842211941151e-07,
      "loss": 0.0798,
      "step": 5285
    },
    {
      "epoch": 0.8401978899684092,
      "grad_norm": 0.5299604535102844,
      "learning_rate": 6.545103271120379e-07,
      "loss": 0.1356,
      "step": 5286
    },
    {
      "epoch": 0.8403568377341996,
      "grad_norm": 0.6239209175109863,
      "learning_rate": 6.532375848749866e-07,
      "loss": 0.2359,
      "step": 5287
    },
    {
      "epoch": 0.8405157854999901,
      "grad_norm": 0.5459164977073669,
      "learning_rate": 6.519659948203244e-07,
      "loss": 0.1502,
      "step": 5288
    },
    {
      "epoch": 0.8406747332657806,
      "grad_norm": 0.6294271349906921,
      "learning_rate": 6.506955572851059e-07,
      "loss": 0.2719,
      "step": 5289
    },
    {
      "epoch": 0.840833681031571,
      "grad_norm": 0.4628596901893616,
      "learning_rate": 6.494262726060818e-07,
      "loss": 0.1109,
      "step": 5290
    },
    {
      "epoch": 0.8409926287973615,
      "grad_norm": 0.590440571308136,
      "learning_rate": 6.481581411196975e-07,
      "loss": 0.1529,
      "step": 5291
    },
    {
      "epoch": 0.841151576563152,
      "grad_norm": 0.7137967944145203,
      "learning_rate": 6.46891163162095e-07,
      "loss": 0.3171,
      "step": 5292
    },
    {
      "epoch": 0.8413105243289424,
      "grad_norm": 7.445056915283203,
      "learning_rate": 6.456253390691048e-07,
      "loss": 0.1798,
      "step": 5293
    },
    {
      "epoch": 0.8414694720947329,
      "grad_norm": 0.545428991317749,
      "learning_rate": 6.443606691762566e-07,
      "loss": 0.2088,
      "step": 5294
    },
    {
      "epoch": 0.8416284198605233,
      "grad_norm": 0.5568026304244995,
      "learning_rate": 6.430971538187725e-07,
      "loss": 0.1852,
      "step": 5295
    },
    {
      "epoch": 0.8417873676263138,
      "grad_norm": 0.5593206286430359,
      "learning_rate": 6.418347933315672e-07,
      "loss": 0.1722,
      "step": 5296
    },
    {
      "epoch": 0.8419463153921043,
      "grad_norm": 0.5186006426811218,
      "learning_rate": 6.405735880492514e-07,
      "loss": 0.111,
      "step": 5297
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.7446725368499756,
      "learning_rate": 6.393135383061277e-07,
      "loss": 0.2269,
      "step": 5298
    },
    {
      "epoch": 0.8422642109236852,
      "grad_norm": 0.6542748808860779,
      "learning_rate": 6.380546444361962e-07,
      "loss": 0.2364,
      "step": 5299
    },
    {
      "epoch": 0.8424231586894757,
      "grad_norm": 0.5693116188049316,
      "learning_rate": 6.36796906773145e-07,
      "loss": 0.1817,
      "step": 5300
    },
    {
      "epoch": 0.8425821064552661,
      "grad_norm": 0.5025913715362549,
      "learning_rate": 6.355403256503595e-07,
      "loss": 0.186,
      "step": 5301
    },
    {
      "epoch": 0.8427410542210566,
      "grad_norm": 0.7049078941345215,
      "learning_rate": 6.342849014009189e-07,
      "loss": 0.2287,
      "step": 5302
    },
    {
      "epoch": 0.8429000019868471,
      "grad_norm": 9.87330150604248,
      "learning_rate": 6.330306343575926e-07,
      "loss": 0.2142,
      "step": 5303
    },
    {
      "epoch": 0.8430589497526375,
      "grad_norm": 0.4938904047012329,
      "learning_rate": 6.317775248528446e-07,
      "loss": 0.1493,
      "step": 5304
    },
    {
      "epoch": 0.843217897518428,
      "grad_norm": 0.559800922870636,
      "learning_rate": 6.305255732188359e-07,
      "loss": 0.1949,
      "step": 5305
    },
    {
      "epoch": 0.8433768452842185,
      "grad_norm": 0.5757213234901428,
      "learning_rate": 6.292747797874149e-07,
      "loss": 0.2208,
      "step": 5306
    },
    {
      "epoch": 0.8435357930500089,
      "grad_norm": 0.5724876523017883,
      "learning_rate": 6.280251448901253e-07,
      "loss": 0.186,
      "step": 5307
    },
    {
      "epoch": 0.8436947408157994,
      "grad_norm": 0.57298743724823,
      "learning_rate": 6.267766688582044e-07,
      "loss": 0.1853,
      "step": 5308
    },
    {
      "epoch": 0.8438536885815898,
      "grad_norm": 0.6107838153839111,
      "learning_rate": 6.25529352022583e-07,
      "loss": 0.2511,
      "step": 5309
    },
    {
      "epoch": 0.8440126363473803,
      "grad_norm": 0.49893584847450256,
      "learning_rate": 6.242831947138806e-07,
      "loss": 0.1557,
      "step": 5310
    },
    {
      "epoch": 0.8441715841131708,
      "grad_norm": 0.5741137266159058,
      "learning_rate": 6.230381972624128e-07,
      "loss": 0.1817,
      "step": 5311
    },
    {
      "epoch": 0.8443305318789612,
      "grad_norm": 0.5914755463600159,
      "learning_rate": 6.217943599981902e-07,
      "loss": 0.2144,
      "step": 5312
    },
    {
      "epoch": 0.8444894796447517,
      "grad_norm": 0.5847634077072144,
      "learning_rate": 6.205516832509089e-07,
      "loss": 0.2254,
      "step": 5313
    },
    {
      "epoch": 0.8446484274105422,
      "grad_norm": 0.4631386697292328,
      "learning_rate": 6.193101673499635e-07,
      "loss": 0.1467,
      "step": 5314
    },
    {
      "epoch": 0.8448073751763326,
      "grad_norm": 0.502629280090332,
      "learning_rate": 6.180698126244383e-07,
      "loss": 0.1483,
      "step": 5315
    },
    {
      "epoch": 0.8449663229421231,
      "grad_norm": 0.5828874707221985,
      "learning_rate": 6.168306194031093e-07,
      "loss": 0.1691,
      "step": 5316
    },
    {
      "epoch": 0.8451252707079137,
      "grad_norm": 0.6502352952957153,
      "learning_rate": 6.155925880144442e-07,
      "loss": 0.3069,
      "step": 5317
    },
    {
      "epoch": 0.845284218473704,
      "grad_norm": 0.8693103194236755,
      "learning_rate": 6.143557187866073e-07,
      "loss": 0.1624,
      "step": 5318
    },
    {
      "epoch": 0.8454431662394946,
      "grad_norm": 1.8732210397720337,
      "learning_rate": 6.131200120474512e-07,
      "loss": 0.2233,
      "step": 5319
    },
    {
      "epoch": 0.8456021140052851,
      "grad_norm": 0.5286125540733337,
      "learning_rate": 6.118854681245184e-07,
      "loss": 0.2104,
      "step": 5320
    },
    {
      "epoch": 0.8457610617710755,
      "grad_norm": 0.6616365909576416,
      "learning_rate": 6.106520873450467e-07,
      "loss": 0.3375,
      "step": 5321
    },
    {
      "epoch": 0.845920009536866,
      "grad_norm": 0.5883885622024536,
      "learning_rate": 6.094198700359655e-07,
      "loss": 0.191,
      "step": 5322
    },
    {
      "epoch": 0.8460789573026564,
      "grad_norm": 0.5905061364173889,
      "learning_rate": 6.081888165238925e-07,
      "loss": 0.2075,
      "step": 5323
    },
    {
      "epoch": 0.8462379050684469,
      "grad_norm": 0.5338964462280273,
      "learning_rate": 6.06958927135139e-07,
      "loss": 0.1754,
      "step": 5324
    },
    {
      "epoch": 0.8463968528342374,
      "grad_norm": 0.5697534084320068,
      "learning_rate": 6.057302021957113e-07,
      "loss": 0.2274,
      "step": 5325
    },
    {
      "epoch": 0.8465558006000278,
      "grad_norm": 0.5343055725097656,
      "learning_rate": 6.045026420312999e-07,
      "loss": 0.1949,
      "step": 5326
    },
    {
      "epoch": 0.8467147483658183,
      "grad_norm": 0.5199815630912781,
      "learning_rate": 6.032762469672914e-07,
      "loss": 0.2097,
      "step": 5327
    },
    {
      "epoch": 0.8468736961316088,
      "grad_norm": 0.4864135980606079,
      "learning_rate": 6.020510173287636e-07,
      "loss": 0.1097,
      "step": 5328
    },
    {
      "epoch": 0.8470326438973992,
      "grad_norm": 0.5863295197486877,
      "learning_rate": 6.008269534404837e-07,
      "loss": 0.2187,
      "step": 5329
    },
    {
      "epoch": 0.8471915916631897,
      "grad_norm": 0.6237091422080994,
      "learning_rate": 5.996040556269079e-07,
      "loss": 0.2705,
      "step": 5330
    },
    {
      "epoch": 0.8473505394289802,
      "grad_norm": 0.4978206157684326,
      "learning_rate": 5.983823242121888e-07,
      "loss": 0.1433,
      "step": 5331
    },
    {
      "epoch": 0.8475094871947706,
      "grad_norm": 0.45995643734931946,
      "learning_rate": 5.971617595201667e-07,
      "loss": 0.1208,
      "step": 5332
    },
    {
      "epoch": 0.8476684349605611,
      "grad_norm": 0.6397894620895386,
      "learning_rate": 5.959423618743715e-07,
      "loss": 0.2477,
      "step": 5333
    },
    {
      "epoch": 0.8478273827263515,
      "grad_norm": 0.5335755944252014,
      "learning_rate": 5.947241315980251e-07,
      "loss": 0.1517,
      "step": 5334
    },
    {
      "epoch": 0.847986330492142,
      "grad_norm": 0.5457378029823303,
      "learning_rate": 5.935070690140415e-07,
      "loss": 0.1771,
      "step": 5335
    },
    {
      "epoch": 0.8481452782579325,
      "grad_norm": 0.5889420509338379,
      "learning_rate": 5.92291174445021e-07,
      "loss": 0.1964,
      "step": 5336
    },
    {
      "epoch": 0.8483042260237229,
      "grad_norm": 0.5320444107055664,
      "learning_rate": 5.910764482132575e-07,
      "loss": 0.1472,
      "step": 5337
    },
    {
      "epoch": 0.8484631737895134,
      "grad_norm": 0.48106899857521057,
      "learning_rate": 5.898628906407361e-07,
      "loss": 0.1167,
      "step": 5338
    },
    {
      "epoch": 0.8486221215553039,
      "grad_norm": 0.5296915173530579,
      "learning_rate": 5.886505020491312e-07,
      "loss": 0.1988,
      "step": 5339
    },
    {
      "epoch": 0.8487810693210943,
      "grad_norm": 0.4872887134552002,
      "learning_rate": 5.874392827598041e-07,
      "loss": 0.1242,
      "step": 5340
    },
    {
      "epoch": 0.8489400170868848,
      "grad_norm": 0.47567519545555115,
      "learning_rate": 5.862292330938102e-07,
      "loss": 0.1632,
      "step": 5341
    },
    {
      "epoch": 0.8490989648526753,
      "grad_norm": 0.918804943561554,
      "learning_rate": 5.850203533718945e-07,
      "loss": 0.1719,
      "step": 5342
    },
    {
      "epoch": 0.8492579126184657,
      "grad_norm": 0.6600958108901978,
      "learning_rate": 5.838126439144875e-07,
      "loss": 0.3196,
      "step": 5343
    },
    {
      "epoch": 0.8494168603842562,
      "grad_norm": 0.5289995074272156,
      "learning_rate": 5.826061050417164e-07,
      "loss": 0.1601,
      "step": 5344
    },
    {
      "epoch": 0.8495758081500467,
      "grad_norm": 0.5593529939651489,
      "learning_rate": 5.814007370733943e-07,
      "loss": 0.1741,
      "step": 5345
    },
    {
      "epoch": 0.8497347559158371,
      "grad_norm": 0.5375287532806396,
      "learning_rate": 5.801965403290221e-07,
      "loss": 0.2209,
      "step": 5346
    },
    {
      "epoch": 0.8498937036816276,
      "grad_norm": 0.5213130712509155,
      "learning_rate": 5.789935151277936e-07,
      "loss": 0.1827,
      "step": 5347
    },
    {
      "epoch": 0.850052651447418,
      "grad_norm": 0.4784313440322876,
      "learning_rate": 5.777916617885909e-07,
      "loss": 0.1128,
      "step": 5348
    },
    {
      "epoch": 0.8502115992132085,
      "grad_norm": 0.5108962655067444,
      "learning_rate": 5.765909806299863e-07,
      "loss": 0.1177,
      "step": 5349
    },
    {
      "epoch": 0.850370546978999,
      "grad_norm": 0.6341196298599243,
      "learning_rate": 5.753914719702375e-07,
      "loss": 0.2215,
      "step": 5350
    },
    {
      "epoch": 0.8505294947447894,
      "grad_norm": 0.6153829097747803,
      "learning_rate": 5.741931361272973e-07,
      "loss": 0.1916,
      "step": 5351
    },
    {
      "epoch": 0.85068844251058,
      "grad_norm": 0.7309033870697021,
      "learning_rate": 5.729959734188051e-07,
      "loss": 0.3238,
      "step": 5352
    },
    {
      "epoch": 0.8508473902763705,
      "grad_norm": 0.5200229287147522,
      "learning_rate": 5.71799984162087e-07,
      "loss": 0.1957,
      "step": 5353
    },
    {
      "epoch": 0.8510063380421609,
      "grad_norm": 0.5390526652336121,
      "learning_rate": 5.706051686741604e-07,
      "loss": 0.129,
      "step": 5354
    },
    {
      "epoch": 0.8511652858079514,
      "grad_norm": 0.5920892357826233,
      "learning_rate": 5.694115272717326e-07,
      "loss": 0.2047,
      "step": 5355
    },
    {
      "epoch": 0.8513242335737419,
      "grad_norm": 0.6046930551528931,
      "learning_rate": 5.682190602711951e-07,
      "loss": 0.2046,
      "step": 5356
    },
    {
      "epoch": 0.8514831813395323,
      "grad_norm": 0.4883935749530792,
      "learning_rate": 5.670277679886349e-07,
      "loss": 0.1531,
      "step": 5357
    },
    {
      "epoch": 0.8516421291053228,
      "grad_norm": 0.6303908824920654,
      "learning_rate": 5.658376507398222e-07,
      "loss": 0.1871,
      "step": 5358
    },
    {
      "epoch": 0.8518010768711133,
      "grad_norm": 0.5925692319869995,
      "learning_rate": 5.646487088402191e-07,
      "loss": 0.2215,
      "step": 5359
    },
    {
      "epoch": 0.8519600246369037,
      "grad_norm": 0.6064540147781372,
      "learning_rate": 5.634609426049731e-07,
      "loss": 0.2742,
      "step": 5360
    },
    {
      "epoch": 0.8521189724026942,
      "grad_norm": 0.7203641533851624,
      "learning_rate": 5.622743523489216e-07,
      "loss": 0.1701,
      "step": 5361
    },
    {
      "epoch": 0.8522779201684846,
      "grad_norm": 0.5668803453445435,
      "learning_rate": 5.61088938386592e-07,
      "loss": 0.2334,
      "step": 5362
    },
    {
      "epoch": 0.8524368679342751,
      "grad_norm": 0.5683552026748657,
      "learning_rate": 5.599047010321945e-07,
      "loss": 0.2008,
      "step": 5363
    },
    {
      "epoch": 0.8525958157000656,
      "grad_norm": 0.5656195878982544,
      "learning_rate": 5.587216405996343e-07,
      "loss": 0.161,
      "step": 5364
    },
    {
      "epoch": 0.852754763465856,
      "grad_norm": 0.5937590599060059,
      "learning_rate": 5.575397574025021e-07,
      "loss": 0.253,
      "step": 5365
    },
    {
      "epoch": 0.8529137112316465,
      "grad_norm": 0.8012312054634094,
      "learning_rate": 5.563590517540729e-07,
      "loss": 0.2128,
      "step": 5366
    },
    {
      "epoch": 0.853072658997437,
      "grad_norm": 0.6834984421730042,
      "learning_rate": 5.551795239673146e-07,
      "loss": 0.3656,
      "step": 5367
    },
    {
      "epoch": 0.8532316067632274,
      "grad_norm": 0.6775521636009216,
      "learning_rate": 5.5400117435488e-07,
      "loss": 0.3183,
      "step": 5368
    },
    {
      "epoch": 0.8533905545290179,
      "grad_norm": 0.49892666935920715,
      "learning_rate": 5.52824003229111e-07,
      "loss": 0.1177,
      "step": 5369
    },
    {
      "epoch": 0.8535495022948084,
      "grad_norm": 0.6188675165176392,
      "learning_rate": 5.516480109020361e-07,
      "loss": 0.2437,
      "step": 5370
    },
    {
      "epoch": 0.8537084500605988,
      "grad_norm": 0.6723346710205078,
      "learning_rate": 5.504731976853727e-07,
      "loss": 0.2126,
      "step": 5371
    },
    {
      "epoch": 0.8538673978263893,
      "grad_norm": 0.5583329796791077,
      "learning_rate": 5.492995638905247e-07,
      "loss": 0.1922,
      "step": 5372
    },
    {
      "epoch": 0.8540263455921798,
      "grad_norm": 0.7653595805168152,
      "learning_rate": 5.481271098285818e-07,
      "loss": 0.2404,
      "step": 5373
    },
    {
      "epoch": 0.8541852933579702,
      "grad_norm": 0.6222205758094788,
      "learning_rate": 5.469558358103238e-07,
      "loss": 0.2099,
      "step": 5374
    },
    {
      "epoch": 0.8543442411237607,
      "grad_norm": 0.5844885110855103,
      "learning_rate": 5.457857421462165e-07,
      "loss": 0.2075,
      "step": 5375
    },
    {
      "epoch": 0.8545031888895511,
      "grad_norm": 0.7006544470787048,
      "learning_rate": 5.446168291464132e-07,
      "loss": 0.3129,
      "step": 5376
    },
    {
      "epoch": 0.8546621366553416,
      "grad_norm": 0.4952125549316406,
      "learning_rate": 5.434490971207534e-07,
      "loss": 0.169,
      "step": 5377
    },
    {
      "epoch": 0.8548210844211321,
      "grad_norm": 0.5815903544425964,
      "learning_rate": 5.42282546378764e-07,
      "loss": 0.2139,
      "step": 5378
    },
    {
      "epoch": 0.8549800321869225,
      "grad_norm": 0.5408383011817932,
      "learning_rate": 5.411171772296609e-07,
      "loss": 0.1803,
      "step": 5379
    },
    {
      "epoch": 0.855138979952713,
      "grad_norm": 0.5262282490730286,
      "learning_rate": 5.399529899823413e-07,
      "loss": 0.204,
      "step": 5380
    },
    {
      "epoch": 0.8552979277185035,
      "grad_norm": 0.6685867309570312,
      "learning_rate": 5.387899849453942e-07,
      "loss": 0.2613,
      "step": 5381
    },
    {
      "epoch": 0.8554568754842939,
      "grad_norm": 0.7772260308265686,
      "learning_rate": 5.376281624270946e-07,
      "loss": 0.1944,
      "step": 5382
    },
    {
      "epoch": 0.8556158232500845,
      "grad_norm": 0.6354942321777344,
      "learning_rate": 5.364675227354016e-07,
      "loss": 0.1808,
      "step": 5383
    },
    {
      "epoch": 0.855774771015875,
      "grad_norm": 10.890698432922363,
      "learning_rate": 5.35308066177963e-07,
      "loss": 0.2051,
      "step": 5384
    },
    {
      "epoch": 0.8559337187816654,
      "grad_norm": 0.5497143268585205,
      "learning_rate": 5.34149793062112e-07,
      "loss": 0.1645,
      "step": 5385
    },
    {
      "epoch": 0.8560926665474559,
      "grad_norm": 0.6911033391952515,
      "learning_rate": 5.329927036948695e-07,
      "loss": 0.2893,
      "step": 5386
    },
    {
      "epoch": 0.8562516143132463,
      "grad_norm": 0.6328007578849792,
      "learning_rate": 5.318367983829393e-07,
      "loss": 0.2634,
      "step": 5387
    },
    {
      "epoch": 0.8564105620790368,
      "grad_norm": 0.46947842836380005,
      "learning_rate": 5.306820774327148e-07,
      "loss": 0.1375,
      "step": 5388
    },
    {
      "epoch": 0.8565695098448273,
      "grad_norm": 0.6170996427536011,
      "learning_rate": 5.295285411502738e-07,
      "loss": 0.1834,
      "step": 5389
    },
    {
      "epoch": 0.8567284576106177,
      "grad_norm": 0.5887640714645386,
      "learning_rate": 5.283761898413808e-07,
      "loss": 0.2138,
      "step": 5390
    },
    {
      "epoch": 0.8568874053764082,
      "grad_norm": 0.4966014623641968,
      "learning_rate": 5.272250238114857e-07,
      "loss": 0.1537,
      "step": 5391
    },
    {
      "epoch": 0.8570463531421987,
      "grad_norm": 0.5717016458511353,
      "learning_rate": 5.260750433657252e-07,
      "loss": 0.1359,
      "step": 5392
    },
    {
      "epoch": 0.8572053009079891,
      "grad_norm": 0.5944435596466064,
      "learning_rate": 5.249262488089191e-07,
      "loss": 0.2125,
      "step": 5393
    },
    {
      "epoch": 0.8573642486737796,
      "grad_norm": 0.574312150478363,
      "learning_rate": 5.237786404455764e-07,
      "loss": 0.1491,
      "step": 5394
    },
    {
      "epoch": 0.8575231964395701,
      "grad_norm": 0.7612040042877197,
      "learning_rate": 5.226322185798888e-07,
      "loss": 0.241,
      "step": 5395
    },
    {
      "epoch": 0.8576821442053605,
      "grad_norm": 0.5088971853256226,
      "learning_rate": 5.214869835157355e-07,
      "loss": 0.1641,
      "step": 5396
    },
    {
      "epoch": 0.857841091971151,
      "grad_norm": 0.5836439728736877,
      "learning_rate": 5.203429355566797e-07,
      "loss": 0.2153,
      "step": 5397
    },
    {
      "epoch": 0.8580000397369415,
      "grad_norm": 0.5517075657844543,
      "learning_rate": 5.192000750059712e-07,
      "loss": 0.1872,
      "step": 5398
    },
    {
      "epoch": 0.8581589875027319,
      "grad_norm": 1.3388314247131348,
      "learning_rate": 5.180584021665447e-07,
      "loss": 0.1356,
      "step": 5399
    },
    {
      "epoch": 0.8583179352685224,
      "grad_norm": 0.6646894812583923,
      "learning_rate": 5.169179173410178e-07,
      "loss": 0.2691,
      "step": 5400
    },
    {
      "epoch": 0.8584768830343128,
      "grad_norm": 0.6790227293968201,
      "learning_rate": 5.157786208316967e-07,
      "loss": 0.2626,
      "step": 5401
    },
    {
      "epoch": 0.8586358308001033,
      "grad_norm": 0.5241948366165161,
      "learning_rate": 5.146405129405707e-07,
      "loss": 0.1847,
      "step": 5402
    },
    {
      "epoch": 0.8587947785658938,
      "grad_norm": 0.5691669583320618,
      "learning_rate": 5.13503593969315e-07,
      "loss": 0.2104,
      "step": 5403
    },
    {
      "epoch": 0.8589537263316842,
      "grad_norm": 0.8078901767730713,
      "learning_rate": 5.123678642192881e-07,
      "loss": 0.16,
      "step": 5404
    },
    {
      "epoch": 0.8591126740974747,
      "grad_norm": 0.6003509759902954,
      "learning_rate": 5.112333239915351e-07,
      "loss": 0.2401,
      "step": 5405
    },
    {
      "epoch": 0.8592716218632652,
      "grad_norm": 0.6614202857017517,
      "learning_rate": 5.10099973586785e-07,
      "loss": 0.2579,
      "step": 5406
    },
    {
      "epoch": 0.8594305696290556,
      "grad_norm": 0.5567089319229126,
      "learning_rate": 5.089678133054504e-07,
      "loss": 0.2271,
      "step": 5407
    },
    {
      "epoch": 0.8595895173948461,
      "grad_norm": 0.708136796951294,
      "learning_rate": 5.078368434476294e-07,
      "loss": 0.1636,
      "step": 5408
    },
    {
      "epoch": 0.8597484651606366,
      "grad_norm": 0.8363385796546936,
      "learning_rate": 5.067070643131056e-07,
      "loss": 0.1847,
      "step": 5409
    },
    {
      "epoch": 0.859907412926427,
      "grad_norm": 0.6908143758773804,
      "learning_rate": 5.055784762013455e-07,
      "loss": 0.1757,
      "step": 5410
    },
    {
      "epoch": 0.8600663606922175,
      "grad_norm": 4.108592510223389,
      "learning_rate": 5.044510794114998e-07,
      "loss": 0.0873,
      "step": 5411
    },
    {
      "epoch": 0.860225308458008,
      "grad_norm": 0.5230985879898071,
      "learning_rate": 5.033248742424057e-07,
      "loss": 0.1592,
      "step": 5412
    },
    {
      "epoch": 0.8603842562237984,
      "grad_norm": 0.6103776097297668,
      "learning_rate": 5.021998609925805e-07,
      "loss": 0.2198,
      "step": 5413
    },
    {
      "epoch": 0.860543203989589,
      "grad_norm": 0.6708590984344482,
      "learning_rate": 5.010760399602288e-07,
      "loss": 0.1683,
      "step": 5414
    },
    {
      "epoch": 0.8607021517553793,
      "grad_norm": 0.4915487766265869,
      "learning_rate": 4.999534114432386e-07,
      "loss": 0.1126,
      "step": 5415
    },
    {
      "epoch": 0.8608610995211698,
      "grad_norm": 0.5975590944290161,
      "learning_rate": 4.988319757391807e-07,
      "loss": 0.2241,
      "step": 5416
    },
    {
      "epoch": 0.8610200472869604,
      "grad_norm": 0.669450044631958,
      "learning_rate": 4.977117331453113e-07,
      "loss": 0.3124,
      "step": 5417
    },
    {
      "epoch": 0.8611789950527508,
      "grad_norm": 0.5845165848731995,
      "learning_rate": 4.965926839585688e-07,
      "loss": 0.1862,
      "step": 5418
    },
    {
      "epoch": 0.8613379428185413,
      "grad_norm": 0.5958472490310669,
      "learning_rate": 4.954748284755773e-07,
      "loss": 0.1755,
      "step": 5419
    },
    {
      "epoch": 0.8614968905843318,
      "grad_norm": 0.5824451446533203,
      "learning_rate": 4.943581669926411e-07,
      "loss": 0.2306,
      "step": 5420
    },
    {
      "epoch": 0.8616558383501222,
      "grad_norm": 0.6320850253105164,
      "learning_rate": 4.932426998057516e-07,
      "loss": 0.2333,
      "step": 5421
    },
    {
      "epoch": 0.8618147861159127,
      "grad_norm": 0.9054102301597595,
      "learning_rate": 4.921284272105814e-07,
      "loss": 0.3285,
      "step": 5422
    },
    {
      "epoch": 0.8619737338817032,
      "grad_norm": 0.5871725678443909,
      "learning_rate": 4.910153495024877e-07,
      "loss": 0.1899,
      "step": 5423
    },
    {
      "epoch": 0.8621326816474936,
      "grad_norm": 0.6630383133888245,
      "learning_rate": 4.899034669765101e-07,
      "loss": 0.2238,
      "step": 5424
    },
    {
      "epoch": 0.8622916294132841,
      "grad_norm": 0.7181174159049988,
      "learning_rate": 4.887927799273717e-07,
      "loss": 0.1943,
      "step": 5425
    },
    {
      "epoch": 0.8624505771790745,
      "grad_norm": 0.4755006730556488,
      "learning_rate": 4.876832886494798e-07,
      "loss": 0.1308,
      "step": 5426
    },
    {
      "epoch": 0.862609524944865,
      "grad_norm": 0.5880542397499084,
      "learning_rate": 4.865749934369224e-07,
      "loss": 0.2318,
      "step": 5427
    },
    {
      "epoch": 0.8627684727106555,
      "grad_norm": 0.6023221611976624,
      "learning_rate": 4.854678945834717e-07,
      "loss": 0.2741,
      "step": 5428
    },
    {
      "epoch": 0.8629274204764459,
      "grad_norm": 0.6980167031288147,
      "learning_rate": 4.843619923825832e-07,
      "loss": 0.3079,
      "step": 5429
    },
    {
      "epoch": 0.8630863682422364,
      "grad_norm": 0.6073682904243469,
      "learning_rate": 4.83257287127395e-07,
      "loss": 0.2637,
      "step": 5430
    },
    {
      "epoch": 0.8632453160080269,
      "grad_norm": 0.5926015377044678,
      "learning_rate": 4.821537791107278e-07,
      "loss": 0.1855,
      "step": 5431
    },
    {
      "epoch": 0.8634042637738173,
      "grad_norm": 0.5855545401573181,
      "learning_rate": 4.810514686250856e-07,
      "loss": 0.2446,
      "step": 5432
    },
    {
      "epoch": 0.8635632115396078,
      "grad_norm": 0.5215252637863159,
      "learning_rate": 4.799503559626528e-07,
      "loss": 0.1311,
      "step": 5433
    },
    {
      "epoch": 0.8637221593053983,
      "grad_norm": 0.6307319402694702,
      "learning_rate": 4.788504414152989e-07,
      "loss": 0.1726,
      "step": 5434
    },
    {
      "epoch": 0.8638811070711887,
      "grad_norm": 0.583821177482605,
      "learning_rate": 4.777517252745739e-07,
      "loss": 0.2014,
      "step": 5435
    },
    {
      "epoch": 0.8640400548369792,
      "grad_norm": 0.6030639410018921,
      "learning_rate": 4.766542078317121e-07,
      "loss": 0.2695,
      "step": 5436
    },
    {
      "epoch": 0.8641990026027697,
      "grad_norm": 0.5331628322601318,
      "learning_rate": 4.75557889377628e-07,
      "loss": 0.1448,
      "step": 5437
    },
    {
      "epoch": 0.8643579503685601,
      "grad_norm": 0.5764408111572266,
      "learning_rate": 4.744627702029192e-07,
      "loss": 0.2169,
      "step": 5438
    },
    {
      "epoch": 0.8645168981343506,
      "grad_norm": 0.6023643612861633,
      "learning_rate": 4.733688505978673e-07,
      "loss": 0.2529,
      "step": 5439
    },
    {
      "epoch": 0.864675845900141,
      "grad_norm": 0.575624942779541,
      "learning_rate": 4.7227613085243096e-07,
      "loss": 0.2372,
      "step": 5440
    },
    {
      "epoch": 0.8648347936659315,
      "grad_norm": 0.5853845477104187,
      "learning_rate": 4.711846112562557e-07,
      "loss": 0.2124,
      "step": 5441
    },
    {
      "epoch": 0.864993741431722,
      "grad_norm": 0.6182443499565125,
      "learning_rate": 4.700942920986673e-07,
      "loss": 0.1823,
      "step": 5442
    },
    {
      "epoch": 0.8651526891975124,
      "grad_norm": 0.5252624154090881,
      "learning_rate": 4.690051736686724e-07,
      "loss": 0.1621,
      "step": 5443
    },
    {
      "epoch": 0.8653116369633029,
      "grad_norm": 0.5771817564964294,
      "learning_rate": 4.6791725625496054e-07,
      "loss": 0.1874,
      "step": 5444
    },
    {
      "epoch": 0.8654705847290934,
      "grad_norm": 0.5621160864830017,
      "learning_rate": 4.668305401459022e-07,
      "loss": 0.1824,
      "step": 5445
    },
    {
      "epoch": 0.8656295324948838,
      "grad_norm": 0.5408514142036438,
      "learning_rate": 4.6574502562955147e-07,
      "loss": 0.2026,
      "step": 5446
    },
    {
      "epoch": 0.8657884802606743,
      "grad_norm": 0.5538657903671265,
      "learning_rate": 4.6466071299363923e-07,
      "loss": 0.1198,
      "step": 5447
    },
    {
      "epoch": 0.8659474280264648,
      "grad_norm": 0.6183229088783264,
      "learning_rate": 4.6357760252558284e-07,
      "loss": 0.2781,
      "step": 5448
    },
    {
      "epoch": 0.8661063757922552,
      "grad_norm": 0.4760313928127289,
      "learning_rate": 4.6249569451247755e-07,
      "loss": 0.1566,
      "step": 5449
    },
    {
      "epoch": 0.8662653235580458,
      "grad_norm": 0.7196807265281677,
      "learning_rate": 4.614149892411024e-07,
      "loss": 0.2895,
      "step": 5450
    },
    {
      "epoch": 0.8664242713238363,
      "grad_norm": 0.5736609101295471,
      "learning_rate": 4.603354869979165e-07,
      "loss": 0.2389,
      "step": 5451
    },
    {
      "epoch": 0.8665832190896267,
      "grad_norm": 0.5809625387191772,
      "learning_rate": 4.592571880690594e-07,
      "loss": 0.1979,
      "step": 5452
    },
    {
      "epoch": 0.8667421668554172,
      "grad_norm": 0.5835968852043152,
      "learning_rate": 4.5818009274035344e-07,
      "loss": 0.2227,
      "step": 5453
    },
    {
      "epoch": 0.8669011146212076,
      "grad_norm": 0.5942614078521729,
      "learning_rate": 4.571042012972993e-07,
      "loss": 0.2234,
      "step": 5454
    },
    {
      "epoch": 0.8670600623869981,
      "grad_norm": 0.6596614718437195,
      "learning_rate": 4.5602951402507924e-07,
      "loss": 0.2797,
      "step": 5455
    },
    {
      "epoch": 0.8672190101527886,
      "grad_norm": 0.7149418592453003,
      "learning_rate": 4.54956031208561e-07,
      "loss": 0.3478,
      "step": 5456
    },
    {
      "epoch": 0.867377957918579,
      "grad_norm": 0.5507453680038452,
      "learning_rate": 4.5388375313228595e-07,
      "loss": 0.1626,
      "step": 5457
    },
    {
      "epoch": 0.8675369056843695,
      "grad_norm": 0.6252632141113281,
      "learning_rate": 4.5281268008048054e-07,
      "loss": 0.2397,
      "step": 5458
    },
    {
      "epoch": 0.86769585345016,
      "grad_norm": 0.44193705916404724,
      "learning_rate": 4.5174281233705154e-07,
      "loss": 0.1166,
      "step": 5459
    },
    {
      "epoch": 0.8678548012159504,
      "grad_norm": 0.5782414674758911,
      "learning_rate": 4.5067415018558324e-07,
      "loss": 0.199,
      "step": 5460
    },
    {
      "epoch": 0.8680137489817409,
      "grad_norm": 0.5790163278579712,
      "learning_rate": 4.4960669390934353e-07,
      "loss": 0.176,
      "step": 5461
    },
    {
      "epoch": 0.8681726967475314,
      "grad_norm": 0.6595093011856079,
      "learning_rate": 4.485404437912788e-07,
      "loss": 0.1381,
      "step": 5462
    },
    {
      "epoch": 0.8683316445133218,
      "grad_norm": 0.5439010262489319,
      "learning_rate": 4.4747540011401913e-07,
      "loss": 0.1996,
      "step": 5463
    },
    {
      "epoch": 0.8684905922791123,
      "grad_norm": 0.5309194922447205,
      "learning_rate": 4.464115631598698e-07,
      "loss": 0.1227,
      "step": 5464
    },
    {
      "epoch": 0.8686495400449027,
      "grad_norm": 0.5063791871070862,
      "learning_rate": 4.453489332108196e-07,
      "loss": 0.1239,
      "step": 5465
    },
    {
      "epoch": 0.8688084878106932,
      "grad_norm": 0.8735625743865967,
      "learning_rate": 4.4428751054853725e-07,
      "loss": 0.1214,
      "step": 5466
    },
    {
      "epoch": 0.8689674355764837,
      "grad_norm": 0.6270895004272461,
      "learning_rate": 4.432272954543682e-07,
      "loss": 0.312,
      "step": 5467
    },
    {
      "epoch": 0.8691263833422741,
      "grad_norm": 0.5684782266616821,
      "learning_rate": 4.421682882093414e-07,
      "loss": 0.1712,
      "step": 5468
    },
    {
      "epoch": 0.8692853311080646,
      "grad_norm": 0.6592613458633423,
      "learning_rate": 4.4111048909416644e-07,
      "loss": 0.1695,
      "step": 5469
    },
    {
      "epoch": 0.8694442788738551,
      "grad_norm": 0.5123958587646484,
      "learning_rate": 4.400538983892283e-07,
      "loss": 0.1643,
      "step": 5470
    },
    {
      "epoch": 0.8696032266396455,
      "grad_norm": 0.6610479354858398,
      "learning_rate": 4.3899851637459467e-07,
      "loss": 0.2666,
      "step": 5471
    },
    {
      "epoch": 0.869762174405436,
      "grad_norm": 0.5057366490364075,
      "learning_rate": 4.379443433300129e-07,
      "loss": 0.1458,
      "step": 5472
    },
    {
      "epoch": 0.8699211221712265,
      "grad_norm": 0.7489348649978638,
      "learning_rate": 4.368913795349095e-07,
      "loss": 0.2574,
      "step": 5473
    },
    {
      "epoch": 0.8700800699370169,
      "grad_norm": 0.4571205973625183,
      "learning_rate": 4.358396252683889e-07,
      "loss": 0.115,
      "step": 5474
    },
    {
      "epoch": 0.8702390177028074,
      "grad_norm": 0.46888768672943115,
      "learning_rate": 4.347890808092359e-07,
      "loss": 0.0825,
      "step": 5475
    },
    {
      "epoch": 0.8703979654685979,
      "grad_norm": 0.634303867816925,
      "learning_rate": 4.337397464359178e-07,
      "loss": 0.2274,
      "step": 5476
    },
    {
      "epoch": 0.8705569132343883,
      "grad_norm": 0.5731578469276428,
      "learning_rate": 4.326916224265759e-07,
      "loss": 0.1946,
      "step": 5477
    },
    {
      "epoch": 0.8707158610001788,
      "grad_norm": 0.660735011100769,
      "learning_rate": 4.3164470905903365e-07,
      "loss": 0.3581,
      "step": 5478
    },
    {
      "epoch": 0.8708748087659692,
      "grad_norm": 0.632419764995575,
      "learning_rate": 4.3059900661079403e-07,
      "loss": 0.2054,
      "step": 5479
    },
    {
      "epoch": 0.8710337565317597,
      "grad_norm": 0.6053255200386047,
      "learning_rate": 4.295545153590358e-07,
      "loss": 0.2122,
      "step": 5480
    },
    {
      "epoch": 0.8711927042975502,
      "grad_norm": 0.6640059351921082,
      "learning_rate": 4.2851123558061927e-07,
      "loss": 0.1819,
      "step": 5481
    },
    {
      "epoch": 0.8713516520633406,
      "grad_norm": 0.6001180410385132,
      "learning_rate": 4.274691675520853e-07,
      "loss": 0.181,
      "step": 5482
    },
    {
      "epoch": 0.8715105998291311,
      "grad_norm": 0.819240152835846,
      "learning_rate": 4.264283115496515e-07,
      "loss": 0.2682,
      "step": 5483
    },
    {
      "epoch": 0.8716695475949217,
      "grad_norm": 0.5865567922592163,
      "learning_rate": 4.2538866784921195e-07,
      "loss": 0.2325,
      "step": 5484
    },
    {
      "epoch": 0.871828495360712,
      "grad_norm": 0.7857955098152161,
      "learning_rate": 4.2435023672634247e-07,
      "loss": 0.2793,
      "step": 5485
    },
    {
      "epoch": 0.8719874431265026,
      "grad_norm": 1.6912845373153687,
      "learning_rate": 4.2331301845629833e-07,
      "loss": 0.187,
      "step": 5486
    },
    {
      "epoch": 0.8721463908922931,
      "grad_norm": 0.5537949204444885,
      "learning_rate": 4.2227701331400974e-07,
      "loss": 0.1956,
      "step": 5487
    },
    {
      "epoch": 0.8723053386580835,
      "grad_norm": 0.5715062022209167,
      "learning_rate": 4.212422215740869e-07,
      "loss": 0.1533,
      "step": 5488
    },
    {
      "epoch": 0.872464286423874,
      "grad_norm": 0.5691898465156555,
      "learning_rate": 4.2020864351082157e-07,
      "loss": 0.2097,
      "step": 5489
    },
    {
      "epoch": 0.8726232341896645,
      "grad_norm": 0.44402509927749634,
      "learning_rate": 4.1917627939817793e-07,
      "loss": 0.0965,
      "step": 5490
    },
    {
      "epoch": 0.8727821819554549,
      "grad_norm": 0.5381616950035095,
      "learning_rate": 4.181451295098027e-07,
      "loss": 0.1704,
      "step": 5491
    },
    {
      "epoch": 0.8729411297212454,
      "grad_norm": 0.5252076983451843,
      "learning_rate": 4.171151941190199e-07,
      "loss": 0.1365,
      "step": 5492
    },
    {
      "epoch": 0.8731000774870358,
      "grad_norm": 0.6656051278114319,
      "learning_rate": 4.1608647349883123e-07,
      "loss": 0.2389,
      "step": 5493
    },
    {
      "epoch": 0.8732590252528263,
      "grad_norm": 0.5804893970489502,
      "learning_rate": 4.150589679219141e-07,
      "loss": 0.2171,
      "step": 5494
    },
    {
      "epoch": 0.8734179730186168,
      "grad_norm": 0.5413508415222168,
      "learning_rate": 4.140326776606285e-07,
      "loss": 0.1609,
      "step": 5495
    },
    {
      "epoch": 0.8735769207844072,
      "grad_norm": 0.5357456803321838,
      "learning_rate": 4.130076029870106e-07,
      "loss": 0.151,
      "step": 5496
    },
    {
      "epoch": 0.8737358685501977,
      "grad_norm": 0.5705618262290955,
      "learning_rate": 4.119837441727714e-07,
      "loss": 0.2141,
      "step": 5497
    },
    {
      "epoch": 0.8738948163159882,
      "grad_norm": 0.5578245520591736,
      "learning_rate": 4.109611014893028e-07,
      "loss": 0.1885,
      "step": 5498
    },
    {
      "epoch": 0.8740537640817786,
      "grad_norm": 0.628532886505127,
      "learning_rate": 4.0993967520767455e-07,
      "loss": 0.2594,
      "step": 5499
    },
    {
      "epoch": 0.8742127118475691,
      "grad_norm": 0.6211357712745667,
      "learning_rate": 4.089194655986306e-07,
      "loss": 0.2891,
      "step": 5500
    },
    {
      "epoch": 0.8743716596133596,
      "grad_norm": 0.693645179271698,
      "learning_rate": 4.0790047293259525e-07,
      "loss": 0.3474,
      "step": 5501
    },
    {
      "epoch": 0.87453060737915,
      "grad_norm": 1.054413080215454,
      "learning_rate": 4.068826974796708e-07,
      "loss": 0.1554,
      "step": 5502
    },
    {
      "epoch": 0.8746895551449405,
      "grad_norm": 0.6203240156173706,
      "learning_rate": 4.0586613950963584e-07,
      "loss": 0.2535,
      "step": 5503
    },
    {
      "epoch": 0.8748485029107309,
      "grad_norm": 0.6333214044570923,
      "learning_rate": 4.048507992919448e-07,
      "loss": 0.2721,
      "step": 5504
    },
    {
      "epoch": 0.8750074506765214,
      "grad_norm": 0.6671112775802612,
      "learning_rate": 4.0383667709573083e-07,
      "loss": 0.2941,
      "step": 5505
    },
    {
      "epoch": 0.8751663984423119,
      "grad_norm": 0.6533381342887878,
      "learning_rate": 4.028237731898055e-07,
      "loss": 0.2337,
      "step": 5506
    },
    {
      "epoch": 0.8753253462081023,
      "grad_norm": 0.5570139288902283,
      "learning_rate": 4.0181208784265344e-07,
      "loss": 0.2087,
      "step": 5507
    },
    {
      "epoch": 0.8754842939738928,
      "grad_norm": 0.5669202208518982,
      "learning_rate": 4.008016213224408e-07,
      "loss": 0.2024,
      "step": 5508
    },
    {
      "epoch": 0.8756432417396833,
      "grad_norm": 0.535402774810791,
      "learning_rate": 3.997923738970094e-07,
      "loss": 0.1841,
      "step": 5509
    },
    {
      "epoch": 0.8758021895054737,
      "grad_norm": 0.7820526361465454,
      "learning_rate": 3.9878434583387526e-07,
      "loss": 0.1534,
      "step": 5510
    },
    {
      "epoch": 0.8759611372712642,
      "grad_norm": 0.6342607140541077,
      "learning_rate": 3.9777753740023404e-07,
      "loss": 0.2153,
      "step": 5511
    },
    {
      "epoch": 0.8761200850370547,
      "grad_norm": 0.6057013869285583,
      "learning_rate": 3.967719488629573e-07,
      "loss": 0.1726,
      "step": 5512
    },
    {
      "epoch": 0.8762790328028451,
      "grad_norm": 0.7439248561859131,
      "learning_rate": 3.9576758048859355e-07,
      "loss": 0.1621,
      "step": 5513
    },
    {
      "epoch": 0.8764379805686356,
      "grad_norm": 0.6075390577316284,
      "learning_rate": 3.947644325433653e-07,
      "loss": 0.1665,
      "step": 5514
    },
    {
      "epoch": 0.8765969283344262,
      "grad_norm": 0.5667276978492737,
      "learning_rate": 3.937625052931765e-07,
      "loss": 0.156,
      "step": 5515
    },
    {
      "epoch": 0.8767558761002165,
      "grad_norm": 0.5368517637252808,
      "learning_rate": 3.927617990036048e-07,
      "loss": 0.1848,
      "step": 5516
    },
    {
      "epoch": 0.876914823866007,
      "grad_norm": 0.6466311812400818,
      "learning_rate": 3.9176231393990183e-07,
      "loss": 0.2508,
      "step": 5517
    },
    {
      "epoch": 0.8770737716317974,
      "grad_norm": 0.5887893438339233,
      "learning_rate": 3.907640503669996e-07,
      "loss": 0.1388,
      "step": 5518
    },
    {
      "epoch": 0.877232719397588,
      "grad_norm": 0.6308535933494568,
      "learning_rate": 3.8976700854950423e-07,
      "loss": 0.2377,
      "step": 5519
    },
    {
      "epoch": 0.8773916671633785,
      "grad_norm": 0.6165814995765686,
      "learning_rate": 3.8877118875169815e-07,
      "loss": 0.2303,
      "step": 5520
    },
    {
      "epoch": 0.8775506149291689,
      "grad_norm": 0.6389968991279602,
      "learning_rate": 3.877765912375403e-07,
      "loss": 0.2686,
      "step": 5521
    },
    {
      "epoch": 0.8777095626949594,
      "grad_norm": 0.5893436670303345,
      "learning_rate": 3.867832162706658e-07,
      "loss": 0.2174,
      "step": 5522
    },
    {
      "epoch": 0.8778685104607499,
      "grad_norm": 0.6307796239852905,
      "learning_rate": 3.8579106411438636e-07,
      "loss": 0.2222,
      "step": 5523
    },
    {
      "epoch": 0.8780274582265403,
      "grad_norm": 0.4897208511829376,
      "learning_rate": 3.84800135031686e-07,
      "loss": 0.0856,
      "step": 5524
    },
    {
      "epoch": 0.8781864059923308,
      "grad_norm": 0.6312372088432312,
      "learning_rate": 3.838104292852285e-07,
      "loss": 0.1953,
      "step": 5525
    },
    {
      "epoch": 0.8783453537581213,
      "grad_norm": 0.6304824948310852,
      "learning_rate": 3.8282194713735286e-07,
      "loss": 0.1929,
      "step": 5526
    },
    {
      "epoch": 0.8785043015239117,
      "grad_norm": 0.6402720212936401,
      "learning_rate": 3.8183468885007013e-07,
      "loss": 0.2011,
      "step": 5527
    },
    {
      "epoch": 0.8786632492897022,
      "grad_norm": 0.6808223724365234,
      "learning_rate": 3.808486546850726e-07,
      "loss": 0.3161,
      "step": 5528
    },
    {
      "epoch": 0.8788221970554927,
      "grad_norm": 0.6142199635505676,
      "learning_rate": 3.7986384490372395e-07,
      "loss": 0.3042,
      "step": 5529
    },
    {
      "epoch": 0.8789811448212831,
      "grad_norm": 0.6975628137588501,
      "learning_rate": 3.78880259767066e-07,
      "loss": 0.2605,
      "step": 5530
    },
    {
      "epoch": 0.8791400925870736,
      "grad_norm": 0.5026935338973999,
      "learning_rate": 3.778978995358118e-07,
      "loss": 0.131,
      "step": 5531
    },
    {
      "epoch": 0.879299040352864,
      "grad_norm": 0.6673456430435181,
      "learning_rate": 3.769167644703542e-07,
      "loss": 0.2873,
      "step": 5532
    },
    {
      "epoch": 0.8794579881186545,
      "grad_norm": 0.6995898485183716,
      "learning_rate": 3.759368548307596e-07,
      "loss": 0.1347,
      "step": 5533
    },
    {
      "epoch": 0.879616935884445,
      "grad_norm": 0.6111075282096863,
      "learning_rate": 3.7495817087676856e-07,
      "loss": 0.171,
      "step": 5534
    },
    {
      "epoch": 0.8797758836502354,
      "grad_norm": 0.4436146914958954,
      "learning_rate": 3.739807128677986e-07,
      "loss": 0.0784,
      "step": 5535
    },
    {
      "epoch": 0.8799348314160259,
      "grad_norm": 0.606215238571167,
      "learning_rate": 3.730044810629413e-07,
      "loss": 0.2633,
      "step": 5536
    },
    {
      "epoch": 0.8800937791818164,
      "grad_norm": 0.5573348999023438,
      "learning_rate": 3.720294757209625e-07,
      "loss": 0.1615,
      "step": 5537
    },
    {
      "epoch": 0.8802527269476068,
      "grad_norm": 0.5554392337799072,
      "learning_rate": 3.710556971003043e-07,
      "loss": 0.1907,
      "step": 5538
    },
    {
      "epoch": 0.8804116747133973,
      "grad_norm": 0.6228495836257935,
      "learning_rate": 3.700831454590831e-07,
      "loss": 0.2612,
      "step": 5539
    },
    {
      "epoch": 0.8805706224791878,
      "grad_norm": 0.4577306807041168,
      "learning_rate": 3.691118210550898e-07,
      "loss": 0.1171,
      "step": 5540
    },
    {
      "epoch": 0.8807295702449782,
      "grad_norm": 0.5895100831985474,
      "learning_rate": 3.6814172414579075e-07,
      "loss": 0.2453,
      "step": 5541
    },
    {
      "epoch": 0.8808885180107687,
      "grad_norm": 0.5280901789665222,
      "learning_rate": 3.6717285498832636e-07,
      "loss": 0.1445,
      "step": 5542
    },
    {
      "epoch": 0.8810474657765591,
      "grad_norm": 0.6431505680084229,
      "learning_rate": 3.662052138395117e-07,
      "loss": 0.2649,
      "step": 5543
    },
    {
      "epoch": 0.8812064135423496,
      "grad_norm": 0.4402691423892975,
      "learning_rate": 3.6523880095583554e-07,
      "loss": 0.0876,
      "step": 5544
    },
    {
      "epoch": 0.8813653613081401,
      "grad_norm": 0.6054850220680237,
      "learning_rate": 3.6427361659346184e-07,
      "loss": 0.2262,
      "step": 5545
    },
    {
      "epoch": 0.8815243090739305,
      "grad_norm": 0.6427701711654663,
      "learning_rate": 3.6330966100822985e-07,
      "loss": 0.2283,
      "step": 5546
    },
    {
      "epoch": 0.881683256839721,
      "grad_norm": 0.8147629499435425,
      "learning_rate": 3.6234693445565185e-07,
      "loss": 0.1359,
      "step": 5547
    },
    {
      "epoch": 0.8818422046055115,
      "grad_norm": 0.5546709299087524,
      "learning_rate": 3.6138543719091477e-07,
      "loss": 0.1867,
      "step": 5548
    },
    {
      "epoch": 0.8820011523713019,
      "grad_norm": 0.6746136546134949,
      "learning_rate": 3.604251694688793e-07,
      "loss": 0.2381,
      "step": 5549
    },
    {
      "epoch": 0.8821601001370925,
      "grad_norm": 0.9719400405883789,
      "learning_rate": 3.5946613154408115e-07,
      "loss": 0.2026,
      "step": 5550
    },
    {
      "epoch": 0.882319047902883,
      "grad_norm": 0.5902006030082703,
      "learning_rate": 3.5850832367072876e-07,
      "loss": 0.1851,
      "step": 5551
    },
    {
      "epoch": 0.8824779956686734,
      "grad_norm": 0.5596015453338623,
      "learning_rate": 3.57551746102705e-07,
      "loss": 0.1563,
      "step": 5552
    },
    {
      "epoch": 0.8826369434344639,
      "grad_norm": 0.5279175639152527,
      "learning_rate": 3.5659639909356725e-07,
      "loss": 0.168,
      "step": 5553
    },
    {
      "epoch": 0.8827958912002544,
      "grad_norm": 0.6253581643104553,
      "learning_rate": 3.5564228289654615e-07,
      "loss": 0.2868,
      "step": 5554
    },
    {
      "epoch": 0.8829548389660448,
      "grad_norm": 0.45462316274642944,
      "learning_rate": 3.546893977645466e-07,
      "loss": 0.1042,
      "step": 5555
    },
    {
      "epoch": 0.8831137867318353,
      "grad_norm": 0.8659124970436096,
      "learning_rate": 3.5373774395014715e-07,
      "loss": 0.3194,
      "step": 5556
    },
    {
      "epoch": 0.8832727344976257,
      "grad_norm": 0.5669200420379639,
      "learning_rate": 3.5278732170559824e-07,
      "loss": 0.1727,
      "step": 5557
    },
    {
      "epoch": 0.8834316822634162,
      "grad_norm": 0.5776064991950989,
      "learning_rate": 3.5183813128282616e-07,
      "loss": 0.1824,
      "step": 5558
    },
    {
      "epoch": 0.8835906300292067,
      "grad_norm": 0.48660168051719666,
      "learning_rate": 3.5089017293342965e-07,
      "loss": 0.1459,
      "step": 5559
    },
    {
      "epoch": 0.8837495777949971,
      "grad_norm": 0.6185184121131897,
      "learning_rate": 3.499434469086804e-07,
      "loss": 0.2509,
      "step": 5560
    },
    {
      "epoch": 0.8839085255607876,
      "grad_norm": 0.608456015586853,
      "learning_rate": 3.48997953459525e-07,
      "loss": 0.2252,
      "step": 5561
    },
    {
      "epoch": 0.8840674733265781,
      "grad_norm": 0.4736011326313019,
      "learning_rate": 3.480536928365824e-07,
      "loss": 0.1042,
      "step": 5562
    },
    {
      "epoch": 0.8842264210923685,
      "grad_norm": 0.5696917176246643,
      "learning_rate": 3.471106652901446e-07,
      "loss": 0.1668,
      "step": 5563
    },
    {
      "epoch": 0.884385368858159,
      "grad_norm": 0.612294614315033,
      "learning_rate": 3.4616887107017606e-07,
      "loss": 0.1615,
      "step": 5564
    },
    {
      "epoch": 0.8845443166239495,
      "grad_norm": 0.6201488375663757,
      "learning_rate": 3.45228310426316e-07,
      "loss": 0.2846,
      "step": 5565
    },
    {
      "epoch": 0.8847032643897399,
      "grad_norm": 0.6646962761878967,
      "learning_rate": 3.44288983607875e-07,
      "loss": 0.229,
      "step": 5566
    },
    {
      "epoch": 0.8848622121555304,
      "grad_norm": 0.6319987177848816,
      "learning_rate": 3.433508908638383e-07,
      "loss": 0.2769,
      "step": 5567
    },
    {
      "epoch": 0.8850211599213209,
      "grad_norm": 0.6774297952651978,
      "learning_rate": 3.424140324428626e-07,
      "loss": 0.2876,
      "step": 5568
    },
    {
      "epoch": 0.8851801076871113,
      "grad_norm": 0.6054096817970276,
      "learning_rate": 3.414784085932782e-07,
      "loss": 0.2382,
      "step": 5569
    },
    {
      "epoch": 0.8853390554529018,
      "grad_norm": 0.5663732886314392,
      "learning_rate": 3.405440195630888e-07,
      "loss": 0.1829,
      "step": 5570
    },
    {
      "epoch": 0.8854980032186922,
      "grad_norm": 0.6335579752922058,
      "learning_rate": 3.39610865599968e-07,
      "loss": 0.2118,
      "step": 5571
    },
    {
      "epoch": 0.8856569509844827,
      "grad_norm": 0.6538615822792053,
      "learning_rate": 3.386789469512647e-07,
      "loss": 0.1866,
      "step": 5572
    },
    {
      "epoch": 0.8858158987502732,
      "grad_norm": 0.6206294894218445,
      "learning_rate": 3.3774826386400004e-07,
      "loss": 0.2704,
      "step": 5573
    },
    {
      "epoch": 0.8859748465160636,
      "grad_norm": 0.6384494304656982,
      "learning_rate": 3.3681881658486684e-07,
      "loss": 0.2648,
      "step": 5574
    },
    {
      "epoch": 0.8861337942818541,
      "grad_norm": 0.520107626914978,
      "learning_rate": 3.358906053602312e-07,
      "loss": 0.1055,
      "step": 5575
    },
    {
      "epoch": 0.8862927420476446,
      "grad_norm": 0.704952597618103,
      "learning_rate": 3.349636304361309e-07,
      "loss": 0.2622,
      "step": 5576
    },
    {
      "epoch": 0.886451689813435,
      "grad_norm": 0.5746229290962219,
      "learning_rate": 3.34037892058276e-07,
      "loss": 0.2288,
      "step": 5577
    },
    {
      "epoch": 0.8866106375792255,
      "grad_norm": 0.5641633868217468,
      "learning_rate": 3.331133904720485e-07,
      "loss": 0.1777,
      "step": 5578
    },
    {
      "epoch": 0.886769585345016,
      "grad_norm": 0.5766741037368774,
      "learning_rate": 3.3219012592250357e-07,
      "loss": 0.2164,
      "step": 5579
    },
    {
      "epoch": 0.8869285331108064,
      "grad_norm": 0.723477840423584,
      "learning_rate": 3.3126809865436817e-07,
      "loss": 0.307,
      "step": 5580
    },
    {
      "epoch": 0.887087480876597,
      "grad_norm": 0.7511512041091919,
      "learning_rate": 3.3034730891204126e-07,
      "loss": 0.3538,
      "step": 5581
    },
    {
      "epoch": 0.8872464286423873,
      "grad_norm": 0.5208916068077087,
      "learning_rate": 3.294277569395932e-07,
      "loss": 0.183,
      "step": 5582
    },
    {
      "epoch": 0.8874053764081778,
      "grad_norm": 0.5447949767112732,
      "learning_rate": 3.285094429807673e-07,
      "loss": 0.1807,
      "step": 5583
    },
    {
      "epoch": 0.8875643241739684,
      "grad_norm": 0.6468092203140259,
      "learning_rate": 3.275923672789771e-07,
      "loss": 0.2826,
      "step": 5584
    },
    {
      "epoch": 0.8877232719397588,
      "grad_norm": 0.6146380305290222,
      "learning_rate": 3.2667653007730946e-07,
      "loss": 0.2276,
      "step": 5585
    },
    {
      "epoch": 0.8878822197055493,
      "grad_norm": 0.6551127433776855,
      "learning_rate": 3.257619316185223e-07,
      "loss": 0.3388,
      "step": 5586
    },
    {
      "epoch": 0.8880411674713398,
      "grad_norm": 0.4392760992050171,
      "learning_rate": 3.248485721450456e-07,
      "loss": 0.0973,
      "step": 5587
    },
    {
      "epoch": 0.8882001152371302,
      "grad_norm": 0.5961509943008423,
      "learning_rate": 3.2393645189898017e-07,
      "loss": 0.2284,
      "step": 5588
    },
    {
      "epoch": 0.8883590630029207,
      "grad_norm": 0.651301383972168,
      "learning_rate": 3.230255711220992e-07,
      "loss": 0.2824,
      "step": 5589
    },
    {
      "epoch": 0.8885180107687112,
      "grad_norm": 0.6211098432540894,
      "learning_rate": 3.221159300558474e-07,
      "loss": 0.2721,
      "step": 5590
    },
    {
      "epoch": 0.8886769585345016,
      "grad_norm": 0.8478052616119385,
      "learning_rate": 3.212075289413391e-07,
      "loss": 0.2438,
      "step": 5591
    },
    {
      "epoch": 0.8888359063002921,
      "grad_norm": 0.5846343636512756,
      "learning_rate": 3.2030036801936226e-07,
      "loss": 0.2448,
      "step": 5592
    },
    {
      "epoch": 0.8889948540660826,
      "grad_norm": 0.6427006721496582,
      "learning_rate": 3.1939444753037454e-07,
      "loss": 0.208,
      "step": 5593
    },
    {
      "epoch": 0.889153801831873,
      "grad_norm": 0.686878502368927,
      "learning_rate": 3.18489767714506e-07,
      "loss": 0.204,
      "step": 5594
    },
    {
      "epoch": 0.8893127495976635,
      "grad_norm": 0.5415601134300232,
      "learning_rate": 3.175863288115566e-07,
      "loss": 0.1965,
      "step": 5595
    },
    {
      "epoch": 0.8894716973634539,
      "grad_norm": 0.6251381039619446,
      "learning_rate": 3.166841310609986e-07,
      "loss": 0.2246,
      "step": 5596
    },
    {
      "epoch": 0.8896306451292444,
      "grad_norm": 0.6060336232185364,
      "learning_rate": 3.157831747019746e-07,
      "loss": 0.2802,
      "step": 5597
    },
    {
      "epoch": 0.8897895928950349,
      "grad_norm": 0.5222782492637634,
      "learning_rate": 3.1488345997329806e-07,
      "loss": 0.185,
      "step": 5598
    },
    {
      "epoch": 0.8899485406608253,
      "grad_norm": 0.6411468982696533,
      "learning_rate": 3.139849871134526e-07,
      "loss": 0.2798,
      "step": 5599
    },
    {
      "epoch": 0.8901074884266158,
      "grad_norm": 0.5842201113700867,
      "learning_rate": 3.1308775636059497e-07,
      "loss": 0.1967,
      "step": 5600
    },
    {
      "epoch": 0.8902664361924063,
      "grad_norm": 0.6477906107902527,
      "learning_rate": 3.121917679525505e-07,
      "loss": 0.2317,
      "step": 5601
    },
    {
      "epoch": 0.8904253839581967,
      "grad_norm": 0.6033560633659363,
      "learning_rate": 3.112970221268158e-07,
      "loss": 0.2847,
      "step": 5602
    },
    {
      "epoch": 0.8905843317239872,
      "grad_norm": 0.5915786027908325,
      "learning_rate": 3.1040351912055956e-07,
      "loss": 0.2232,
      "step": 5603
    },
    {
      "epoch": 0.8907432794897777,
      "grad_norm": 0.5435436964035034,
      "learning_rate": 3.095112591706179e-07,
      "loss": 0.1876,
      "step": 5604
    },
    {
      "epoch": 0.8909022272555681,
      "grad_norm": 0.5011565685272217,
      "learning_rate": 3.0862024251350043e-07,
      "loss": 0.1226,
      "step": 5605
    },
    {
      "epoch": 0.8910611750213586,
      "grad_norm": 0.6903202533721924,
      "learning_rate": 3.077304693853855e-07,
      "loss": 0.3675,
      "step": 5606
    },
    {
      "epoch": 0.8912201227871491,
      "grad_norm": 0.5000305771827698,
      "learning_rate": 3.0684194002212287e-07,
      "loss": 0.1639,
      "step": 5607
    },
    {
      "epoch": 0.8913790705529395,
      "grad_norm": 0.5047497749328613,
      "learning_rate": 3.0595465465923235e-07,
      "loss": 0.17,
      "step": 5608
    },
    {
      "epoch": 0.89153801831873,
      "grad_norm": 0.5885273218154907,
      "learning_rate": 3.050686135319031e-07,
      "loss": 0.2322,
      "step": 5609
    },
    {
      "epoch": 0.8916969660845204,
      "grad_norm": 0.5580249428749084,
      "learning_rate": 3.0418381687499667e-07,
      "loss": 0.2161,
      "step": 5610
    },
    {
      "epoch": 0.8918559138503109,
      "grad_norm": 0.6365066766738892,
      "learning_rate": 3.0330026492304153e-07,
      "loss": 0.338,
      "step": 5611
    },
    {
      "epoch": 0.8920148616161014,
      "grad_norm": 0.8598815202713013,
      "learning_rate": 3.0241795791023874e-07,
      "loss": 0.1334,
      "step": 5612
    },
    {
      "epoch": 0.8921738093818918,
      "grad_norm": 0.5996711850166321,
      "learning_rate": 3.015368960704584e-07,
      "loss": 0.2328,
      "step": 5613
    },
    {
      "epoch": 0.8923327571476823,
      "grad_norm": 0.5999890565872192,
      "learning_rate": 3.00657079637241e-07,
      "loss": 0.1653,
      "step": 5614
    },
    {
      "epoch": 0.8924917049134728,
      "grad_norm": 0.6215875744819641,
      "learning_rate": 2.997785088437966e-07,
      "loss": 0.2007,
      "step": 5615
    },
    {
      "epoch": 0.8926506526792632,
      "grad_norm": 0.5428317785263062,
      "learning_rate": 2.9890118392300493e-07,
      "loss": 0.1523,
      "step": 5616
    },
    {
      "epoch": 0.8928096004450538,
      "grad_norm": 0.5287836194038391,
      "learning_rate": 2.980251051074162e-07,
      "loss": 0.1786,
      "step": 5617
    },
    {
      "epoch": 0.8929685482108443,
      "grad_norm": 0.6072830557823181,
      "learning_rate": 2.971502726292491e-07,
      "loss": 0.2528,
      "step": 5618
    },
    {
      "epoch": 0.8931274959766347,
      "grad_norm": 0.5652567744255066,
      "learning_rate": 2.962766867203926e-07,
      "loss": 0.1886,
      "step": 5619
    },
    {
      "epoch": 0.8932864437424252,
      "grad_norm": 0.5364199876785278,
      "learning_rate": 2.954043476124069e-07,
      "loss": 0.162,
      "step": 5620
    },
    {
      "epoch": 0.8934453915082156,
      "grad_norm": 0.6264187693595886,
      "learning_rate": 2.945332555365188e-07,
      "loss": 0.2397,
      "step": 5621
    },
    {
      "epoch": 0.8936043392740061,
      "grad_norm": 0.47128331661224365,
      "learning_rate": 2.9366341072362526e-07,
      "loss": 0.1646,
      "step": 5622
    },
    {
      "epoch": 0.8937632870397966,
      "grad_norm": 0.6398730874061584,
      "learning_rate": 2.927948134042952e-07,
      "loss": 0.2665,
      "step": 5623
    },
    {
      "epoch": 0.893922234805587,
      "grad_norm": 0.5847477316856384,
      "learning_rate": 2.9192746380876326e-07,
      "loss": 0.2101,
      "step": 5624
    },
    {
      "epoch": 0.8940811825713775,
      "grad_norm": 0.39388468861579895,
      "learning_rate": 2.910613621669356e-07,
      "loss": 0.0733,
      "step": 5625
    },
    {
      "epoch": 0.894240130337168,
      "grad_norm": 0.63807213306427,
      "learning_rate": 2.901965087083858e-07,
      "loss": 0.2431,
      "step": 5626
    },
    {
      "epoch": 0.8943990781029584,
      "grad_norm": 0.5171424150466919,
      "learning_rate": 2.89332903662361e-07,
      "loss": 0.1545,
      "step": 5627
    },
    {
      "epoch": 0.8945580258687489,
      "grad_norm": 0.5731002688407898,
      "learning_rate": 2.884705472577709e-07,
      "loss": 0.1708,
      "step": 5628
    },
    {
      "epoch": 0.8947169736345394,
      "grad_norm": 1.8378584384918213,
      "learning_rate": 2.876094397231993e-07,
      "loss": 0.1814,
      "step": 5629
    },
    {
      "epoch": 0.8948759214003298,
      "grad_norm": 0.6851761341094971,
      "learning_rate": 2.8674958128689754e-07,
      "loss": 0.3186,
      "step": 5630
    },
    {
      "epoch": 0.8950348691661203,
      "grad_norm": 0.7006382346153259,
      "learning_rate": 2.8589097217678383e-07,
      "loss": 0.3474,
      "step": 5631
    },
    {
      "epoch": 0.8951938169319108,
      "grad_norm": 0.6592326760292053,
      "learning_rate": 2.850336126204467e-07,
      "loss": 0.2718,
      "step": 5632
    },
    {
      "epoch": 0.8953527646977012,
      "grad_norm": 0.9765591025352478,
      "learning_rate": 2.841775028451471e-07,
      "loss": 0.2584,
      "step": 5633
    },
    {
      "epoch": 0.8955117124634917,
      "grad_norm": 0.5553449392318726,
      "learning_rate": 2.83322643077808e-07,
      "loss": 0.1889,
      "step": 5634
    },
    {
      "epoch": 0.8956706602292821,
      "grad_norm": 0.6522796750068665,
      "learning_rate": 2.824690335450253e-07,
      "loss": 0.2247,
      "step": 5635
    },
    {
      "epoch": 0.8958296079950726,
      "grad_norm": 0.6430442929267883,
      "learning_rate": 2.816166744730625e-07,
      "loss": 0.2211,
      "step": 5636
    },
    {
      "epoch": 0.8959885557608631,
      "grad_norm": 0.7426128387451172,
      "learning_rate": 2.807655660878533e-07,
      "loss": 0.2012,
      "step": 5637
    },
    {
      "epoch": 0.8961475035266535,
      "grad_norm": 0.5406410694122314,
      "learning_rate": 2.799157086149956e-07,
      "loss": 0.1945,
      "step": 5638
    },
    {
      "epoch": 0.896306451292444,
      "grad_norm": 0.5448052883148193,
      "learning_rate": 2.790671022797586e-07,
      "loss": 0.2237,
      "step": 5639
    },
    {
      "epoch": 0.8964653990582345,
      "grad_norm": 0.6034783124923706,
      "learning_rate": 2.78219747307083e-07,
      "loss": 0.2137,
      "step": 5640
    },
    {
      "epoch": 0.8966243468240249,
      "grad_norm": 0.6043321490287781,
      "learning_rate": 2.773736439215707e-07,
      "loss": 0.2012,
      "step": 5641
    },
    {
      "epoch": 0.8967832945898154,
      "grad_norm": 0.6520718336105347,
      "learning_rate": 2.765287923474974e-07,
      "loss": 0.255,
      "step": 5642
    },
    {
      "epoch": 0.8969422423556059,
      "grad_norm": 0.5765202641487122,
      "learning_rate": 2.756851928088056e-07,
      "loss": 0.1975,
      "step": 5643
    },
    {
      "epoch": 0.8971011901213963,
      "grad_norm": 0.44092756509780884,
      "learning_rate": 2.7484284552910357e-07,
      "loss": 0.1022,
      "step": 5644
    },
    {
      "epoch": 0.8972601378871868,
      "grad_norm": 0.6031515598297119,
      "learning_rate": 2.740017507316706e-07,
      "loss": 0.2497,
      "step": 5645
    },
    {
      "epoch": 0.8974190856529773,
      "grad_norm": 0.6534261107444763,
      "learning_rate": 2.731619086394538e-07,
      "loss": 0.2511,
      "step": 5646
    },
    {
      "epoch": 0.8975780334187677,
      "grad_norm": 0.5441156625747681,
      "learning_rate": 2.723233194750674e-07,
      "loss": 0.1881,
      "step": 5647
    },
    {
      "epoch": 0.8977369811845582,
      "grad_norm": 0.6004547476768494,
      "learning_rate": 2.714859834607925e-07,
      "loss": 0.2588,
      "step": 5648
    },
    {
      "epoch": 0.8978959289503486,
      "grad_norm": 0.5962799787521362,
      "learning_rate": 2.706499008185798e-07,
      "loss": 0.2001,
      "step": 5649
    },
    {
      "epoch": 0.8980548767161391,
      "grad_norm": 0.610146701335907,
      "learning_rate": 2.6981507177004705e-07,
      "loss": 0.2505,
      "step": 5650
    },
    {
      "epoch": 0.8982138244819297,
      "grad_norm": 0.6613786220550537,
      "learning_rate": 2.68981496536479e-07,
      "loss": 0.2226,
      "step": 5651
    },
    {
      "epoch": 0.89837277224772,
      "grad_norm": 0.5829212665557861,
      "learning_rate": 2.681491753388282e-07,
      "loss": 0.1759,
      "step": 5652
    },
    {
      "epoch": 0.8985317200135106,
      "grad_norm": 0.6461073160171509,
      "learning_rate": 2.6731810839771776e-07,
      "loss": 0.2516,
      "step": 5653
    },
    {
      "epoch": 0.8986906677793011,
      "grad_norm": 0.6211381554603577,
      "learning_rate": 2.664882959334347e-07,
      "loss": 0.2095,
      "step": 5654
    },
    {
      "epoch": 0.8988496155450915,
      "grad_norm": 0.5851185917854309,
      "learning_rate": 2.6565973816593424e-07,
      "loss": 0.1577,
      "step": 5655
    },
    {
      "epoch": 0.899008563310882,
      "grad_norm": 0.6267214417457581,
      "learning_rate": 2.648324353148396e-07,
      "loss": 0.2525,
      "step": 5656
    },
    {
      "epoch": 0.8991675110766725,
      "grad_norm": 0.46727004647254944,
      "learning_rate": 2.6400638759944253e-07,
      "loss": 0.1398,
      "step": 5657
    },
    {
      "epoch": 0.8993264588424629,
      "grad_norm": 0.6546604633331299,
      "learning_rate": 2.6318159523869846e-07,
      "loss": 0.2347,
      "step": 5658
    },
    {
      "epoch": 0.8994854066082534,
      "grad_norm": 0.602888286113739,
      "learning_rate": 2.6235805845123475e-07,
      "loss": 0.1909,
      "step": 5659
    },
    {
      "epoch": 0.8996443543740438,
      "grad_norm": 0.6032105684280396,
      "learning_rate": 2.615357774553434e-07,
      "loss": 0.1926,
      "step": 5660
    },
    {
      "epoch": 0.8998033021398343,
      "grad_norm": 0.6131497621536255,
      "learning_rate": 2.607147524689829e-07,
      "loss": 0.2743,
      "step": 5661
    },
    {
      "epoch": 0.8999622499056248,
      "grad_norm": 0.6385132670402527,
      "learning_rate": 2.5989498370977973e-07,
      "loss": 0.2309,
      "step": 5662
    },
    {
      "epoch": 0.9001211976714152,
      "grad_norm": 0.6058750748634338,
      "learning_rate": 2.5907647139502776e-07,
      "loss": 0.2079,
      "step": 5663
    },
    {
      "epoch": 0.9002801454372057,
      "grad_norm": 0.5943047404289246,
      "learning_rate": 2.58259215741688e-07,
      "loss": 0.2197,
      "step": 5664
    },
    {
      "epoch": 0.9004390932029962,
      "grad_norm": 0.5364805459976196,
      "learning_rate": 2.574432169663854e-07,
      "loss": 0.1435,
      "step": 5665
    },
    {
      "epoch": 0.9005980409687866,
      "grad_norm": 0.602878749370575,
      "learning_rate": 2.5662847528541703e-07,
      "loss": 0.2724,
      "step": 5666
    },
    {
      "epoch": 0.9007569887345771,
      "grad_norm": 0.5192853808403015,
      "learning_rate": 2.558149909147434e-07,
      "loss": 0.1331,
      "step": 5667
    },
    {
      "epoch": 0.9009159365003676,
      "grad_norm": 0.6996191143989563,
      "learning_rate": 2.5500276406999093e-07,
      "loss": 0.2017,
      "step": 5668
    },
    {
      "epoch": 0.901074884266158,
      "grad_norm": 0.6245152950286865,
      "learning_rate": 2.541917949664546e-07,
      "loss": 0.134,
      "step": 5669
    },
    {
      "epoch": 0.9012338320319485,
      "grad_norm": 0.5359548926353455,
      "learning_rate": 2.533820838190959e-07,
      "loss": 0.1614,
      "step": 5670
    },
    {
      "epoch": 0.901392779797739,
      "grad_norm": 0.5726162195205688,
      "learning_rate": 2.5257363084254026e-07,
      "loss": 0.1606,
      "step": 5671
    },
    {
      "epoch": 0.9015517275635294,
      "grad_norm": 0.6777915954589844,
      "learning_rate": 2.517664362510841e-07,
      "loss": 0.2479,
      "step": 5672
    },
    {
      "epoch": 0.9017106753293199,
      "grad_norm": 0.49521058797836304,
      "learning_rate": 2.5096050025868734e-07,
      "loss": 0.1418,
      "step": 5673
    },
    {
      "epoch": 0.9018696230951103,
      "grad_norm": 0.6709275841712952,
      "learning_rate": 2.501558230789769e-07,
      "loss": 0.3167,
      "step": 5674
    },
    {
      "epoch": 0.9020285708609008,
      "grad_norm": 0.5866944789886475,
      "learning_rate": 2.4935240492524546e-07,
      "loss": 0.2269,
      "step": 5675
    },
    {
      "epoch": 0.9021875186266913,
      "grad_norm": 0.5263093709945679,
      "learning_rate": 2.4855024601045274e-07,
      "loss": 0.133,
      "step": 5676
    },
    {
      "epoch": 0.9023464663924817,
      "grad_norm": 0.7385549545288086,
      "learning_rate": 2.477493465472247e-07,
      "loss": 0.2486,
      "step": 5677
    },
    {
      "epoch": 0.9025054141582722,
      "grad_norm": 0.9244599938392639,
      "learning_rate": 2.4694970674785155e-07,
      "loss": 0.2006,
      "step": 5678
    },
    {
      "epoch": 0.9026643619240627,
      "grad_norm": 0.6025487780570984,
      "learning_rate": 2.461513268242938e-07,
      "loss": 0.1632,
      "step": 5679
    },
    {
      "epoch": 0.9028233096898531,
      "grad_norm": 0.582086980342865,
      "learning_rate": 2.453542069881748e-07,
      "loss": 0.1143,
      "step": 5680
    },
    {
      "epoch": 0.9029822574556436,
      "grad_norm": 0.5720257759094238,
      "learning_rate": 2.445583474507829e-07,
      "loss": 0.1894,
      "step": 5681
    },
    {
      "epoch": 0.9031412052214342,
      "grad_norm": 0.6456061601638794,
      "learning_rate": 2.437637484230759e-07,
      "loss": 0.3069,
      "step": 5682
    },
    {
      "epoch": 0.9033001529872245,
      "grad_norm": 0.5528994202613831,
      "learning_rate": 2.4297041011567433e-07,
      "loss": 0.1474,
      "step": 5683
    },
    {
      "epoch": 0.903459100753015,
      "grad_norm": 0.577001690864563,
      "learning_rate": 2.421783327388666e-07,
      "loss": 0.1879,
      "step": 5684
    },
    {
      "epoch": 0.9036180485188056,
      "grad_norm": 0.4366679787635803,
      "learning_rate": 2.4138751650260585e-07,
      "loss": 0.0781,
      "step": 5685
    },
    {
      "epoch": 0.903776996284596,
      "grad_norm": 2.2434661388397217,
      "learning_rate": 2.405979616165116e-07,
      "loss": 0.1126,
      "step": 5686
    },
    {
      "epoch": 0.9039359440503865,
      "grad_norm": 0.5150943994522095,
      "learning_rate": 2.3980966828986874e-07,
      "loss": 0.123,
      "step": 5687
    },
    {
      "epoch": 0.9040948918161769,
      "grad_norm": 0.5797251462936401,
      "learning_rate": 2.390226367316262e-07,
      "loss": 0.1957,
      "step": 5688
    },
    {
      "epoch": 0.9042538395819674,
      "grad_norm": 0.5906414985656738,
      "learning_rate": 2.382368671504015e-07,
      "loss": 0.2362,
      "step": 5689
    },
    {
      "epoch": 0.9044127873477579,
      "grad_norm": 0.6946527361869812,
      "learning_rate": 2.374523597544759e-07,
      "loss": 0.3047,
      "step": 5690
    },
    {
      "epoch": 0.9045717351135483,
      "grad_norm": 0.5499741435050964,
      "learning_rate": 2.366691147517941e-07,
      "loss": 0.1609,
      "step": 5691
    },
    {
      "epoch": 0.9047306828793388,
      "grad_norm": 0.6371880173683167,
      "learning_rate": 2.3588713234997173e-07,
      "loss": 0.2644,
      "step": 5692
    },
    {
      "epoch": 0.9048896306451293,
      "grad_norm": 2.15622615814209,
      "learning_rate": 2.351064127562841e-07,
      "loss": 0.15,
      "step": 5693
    },
    {
      "epoch": 0.9050485784109197,
      "grad_norm": 0.6325417757034302,
      "learning_rate": 2.3432695617767565e-07,
      "loss": 0.2791,
      "step": 5694
    },
    {
      "epoch": 0.9052075261767102,
      "grad_norm": 0.5118553638458252,
      "learning_rate": 2.3354876282075222e-07,
      "loss": 0.1885,
      "step": 5695
    },
    {
      "epoch": 0.9053664739425007,
      "grad_norm": 0.5883464217185974,
      "learning_rate": 2.3277183289178883e-07,
      "loss": 0.2453,
      "step": 5696
    },
    {
      "epoch": 0.9055254217082911,
      "grad_norm": 0.6881358623504639,
      "learning_rate": 2.3199616659672352e-07,
      "loss": 0.2654,
      "step": 5697
    },
    {
      "epoch": 0.9056843694740816,
      "grad_norm": 0.5390136241912842,
      "learning_rate": 2.3122176414115904e-07,
      "loss": 0.1275,
      "step": 5698
    },
    {
      "epoch": 0.905843317239872,
      "grad_norm": 0.5580120086669922,
      "learning_rate": 2.3044862573036397e-07,
      "loss": 0.1259,
      "step": 5699
    },
    {
      "epoch": 0.9060022650056625,
      "grad_norm": 0.6533976197242737,
      "learning_rate": 2.296767515692727e-07,
      "loss": 0.3135,
      "step": 5700
    },
    {
      "epoch": 0.906161212771453,
      "grad_norm": 0.548783004283905,
      "learning_rate": 2.2890614186248162e-07,
      "loss": 0.1629,
      "step": 5701
    },
    {
      "epoch": 0.9063201605372434,
      "grad_norm": 0.5408409833908081,
      "learning_rate": 2.2813679681425505e-07,
      "loss": 0.1837,
      "step": 5702
    },
    {
      "epoch": 0.9064791083030339,
      "grad_norm": 0.7260799407958984,
      "learning_rate": 2.2736871662852045e-07,
      "loss": 0.2333,
      "step": 5703
    },
    {
      "epoch": 0.9066380560688244,
      "grad_norm": 0.6511386632919312,
      "learning_rate": 2.2660190150887052e-07,
      "loss": 0.2849,
      "step": 5704
    },
    {
      "epoch": 0.9067970038346148,
      "grad_norm": 0.6022015810012817,
      "learning_rate": 2.258363516585621e-07,
      "loss": 0.232,
      "step": 5705
    },
    {
      "epoch": 0.9069559516004053,
      "grad_norm": 0.6585937142372131,
      "learning_rate": 2.2507206728051732e-07,
      "loss": 0.1916,
      "step": 5706
    },
    {
      "epoch": 0.9071148993661958,
      "grad_norm": 0.654815137386322,
      "learning_rate": 2.2430904857732306e-07,
      "loss": 0.2903,
      "step": 5707
    },
    {
      "epoch": 0.9072738471319862,
      "grad_norm": 0.531707763671875,
      "learning_rate": 2.2354729575122968e-07,
      "loss": 0.1875,
      "step": 5708
    },
    {
      "epoch": 0.9074327948977767,
      "grad_norm": 0.5915542840957642,
      "learning_rate": 2.2278680900415183e-07,
      "loss": 0.2471,
      "step": 5709
    },
    {
      "epoch": 0.9075917426635672,
      "grad_norm": 0.6309864521026611,
      "learning_rate": 2.220275885376705e-07,
      "loss": 0.2992,
      "step": 5710
    },
    {
      "epoch": 0.9077506904293576,
      "grad_norm": 0.4829151928424835,
      "learning_rate": 2.2126963455302963e-07,
      "loss": 0.1466,
      "step": 5711
    },
    {
      "epoch": 0.9079096381951481,
      "grad_norm": 0.4952552914619446,
      "learning_rate": 2.2051294725113746e-07,
      "loss": 0.1358,
      "step": 5712
    },
    {
      "epoch": 0.9080685859609385,
      "grad_norm": 0.5553587079048157,
      "learning_rate": 2.1975752683256634e-07,
      "loss": 0.1343,
      "step": 5713
    },
    {
      "epoch": 0.908227533726729,
      "grad_norm": 0.5713031888008118,
      "learning_rate": 2.190033734975544e-07,
      "loss": 0.2293,
      "step": 5714
    },
    {
      "epoch": 0.9083864814925195,
      "grad_norm": 0.47123315930366516,
      "learning_rate": 2.1825048744600062e-07,
      "loss": 0.1113,
      "step": 5715
    },
    {
      "epoch": 0.9085454292583099,
      "grad_norm": 0.6099966764450073,
      "learning_rate": 2.174988688774715e-07,
      "loss": 0.2282,
      "step": 5716
    },
    {
      "epoch": 0.9087043770241005,
      "grad_norm": 0.5495582818984985,
      "learning_rate": 2.16748517991196e-07,
      "loss": 0.1742,
      "step": 5717
    },
    {
      "epoch": 0.908863324789891,
      "grad_norm": 0.4963033199310303,
      "learning_rate": 2.1599943498606667e-07,
      "loss": 0.1725,
      "step": 5718
    },
    {
      "epoch": 0.9090222725556814,
      "grad_norm": 0.584916889667511,
      "learning_rate": 2.1525162006064136e-07,
      "loss": 0.2598,
      "step": 5719
    },
    {
      "epoch": 0.9091812203214719,
      "grad_norm": 0.5978434085845947,
      "learning_rate": 2.1450507341314098e-07,
      "loss": 0.2539,
      "step": 5720
    },
    {
      "epoch": 0.9093401680872624,
      "grad_norm": 0.5383991003036499,
      "learning_rate": 2.1375979524144942e-07,
      "loss": 0.1766,
      "step": 5721
    },
    {
      "epoch": 0.9094991158530528,
      "grad_norm": 0.4587726891040802,
      "learning_rate": 2.130157857431153e-07,
      "loss": 0.1037,
      "step": 5722
    },
    {
      "epoch": 0.9096580636188433,
      "grad_norm": 0.5788512229919434,
      "learning_rate": 2.1227304511535097e-07,
      "loss": 0.1754,
      "step": 5723
    },
    {
      "epoch": 0.9098170113846338,
      "grad_norm": 0.6405856013298035,
      "learning_rate": 2.1153157355503274e-07,
      "loss": 0.2792,
      "step": 5724
    },
    {
      "epoch": 0.9099759591504242,
      "grad_norm": 0.5995966196060181,
      "learning_rate": 2.1079137125870008e-07,
      "loss": 0.2382,
      "step": 5725
    },
    {
      "epoch": 0.9101349069162147,
      "grad_norm": 0.7023861408233643,
      "learning_rate": 2.1005243842255552e-07,
      "loss": 0.2663,
      "step": 5726
    },
    {
      "epoch": 0.9102938546820051,
      "grad_norm": 0.621183454990387,
      "learning_rate": 2.093147752424668e-07,
      "loss": 0.1688,
      "step": 5727
    },
    {
      "epoch": 0.9104528024477956,
      "grad_norm": 0.656590461730957,
      "learning_rate": 2.0857838191396195e-07,
      "loss": 0.2453,
      "step": 5728
    },
    {
      "epoch": 0.9106117502135861,
      "grad_norm": 0.5271715521812439,
      "learning_rate": 2.0784325863223598e-07,
      "loss": 0.1503,
      "step": 5729
    },
    {
      "epoch": 0.9107706979793765,
      "grad_norm": 0.5395373106002808,
      "learning_rate": 2.0710940559214466e-07,
      "loss": 0.2066,
      "step": 5730
    },
    {
      "epoch": 0.910929645745167,
      "grad_norm": 0.5792484879493713,
      "learning_rate": 2.063768229882085e-07,
      "loss": 0.223,
      "step": 5731
    },
    {
      "epoch": 0.9110885935109575,
      "grad_norm": 0.6569997668266296,
      "learning_rate": 2.056455110146116e-07,
      "loss": 0.223,
      "step": 5732
    },
    {
      "epoch": 0.9112475412767479,
      "grad_norm": 0.6449548006057739,
      "learning_rate": 2.0491546986519896e-07,
      "loss": 0.2229,
      "step": 5733
    },
    {
      "epoch": 0.9114064890425384,
      "grad_norm": 0.6290199160575867,
      "learning_rate": 2.0418669973348238e-07,
      "loss": 0.206,
      "step": 5734
    },
    {
      "epoch": 0.9115654368083289,
      "grad_norm": 0.621579110622406,
      "learning_rate": 2.0345920081263182e-07,
      "loss": 0.213,
      "step": 5735
    },
    {
      "epoch": 0.9117243845741193,
      "grad_norm": 0.6396324038505554,
      "learning_rate": 2.0273297329548525e-07,
      "loss": 0.2233,
      "step": 5736
    },
    {
      "epoch": 0.9118833323399098,
      "grad_norm": 0.8266154527664185,
      "learning_rate": 2.020080173745409e-07,
      "loss": 0.206,
      "step": 5737
    },
    {
      "epoch": 0.9120422801057002,
      "grad_norm": 0.5732751488685608,
      "learning_rate": 2.0128433324196005e-07,
      "loss": 0.2223,
      "step": 5738
    },
    {
      "epoch": 0.9122012278714907,
      "grad_norm": 0.5982019901275635,
      "learning_rate": 2.0056192108956762e-07,
      "loss": 0.1788,
      "step": 5739
    },
    {
      "epoch": 0.9123601756372812,
      "grad_norm": 0.59881991147995,
      "learning_rate": 1.9984078110885096e-07,
      "loss": 0.2284,
      "step": 5740
    },
    {
      "epoch": 0.9125191234030716,
      "grad_norm": 0.5485894083976746,
      "learning_rate": 1.9912091349096163e-07,
      "loss": 0.1426,
      "step": 5741
    },
    {
      "epoch": 0.9126780711688621,
      "grad_norm": 0.5437374711036682,
      "learning_rate": 1.9840231842671087e-07,
      "loss": 0.2229,
      "step": 5742
    },
    {
      "epoch": 0.9128370189346526,
      "grad_norm": 0.6002019643783569,
      "learning_rate": 1.9768499610657466e-07,
      "loss": 0.1777,
      "step": 5743
    },
    {
      "epoch": 0.912995966700443,
      "grad_norm": 0.582617998123169,
      "learning_rate": 1.96968946720692e-07,
      "loss": 0.2126,
      "step": 5744
    },
    {
      "epoch": 0.9131549144662335,
      "grad_norm": 0.630961000919342,
      "learning_rate": 1.962541704588633e-07,
      "loss": 0.2663,
      "step": 5745
    },
    {
      "epoch": 0.913313862232024,
      "grad_norm": 0.5453625917434692,
      "learning_rate": 1.9554066751055255e-07,
      "loss": 0.1742,
      "step": 5746
    },
    {
      "epoch": 0.9134728099978144,
      "grad_norm": 0.6048874855041504,
      "learning_rate": 1.9482843806488572e-07,
      "loss": 0.1589,
      "step": 5747
    },
    {
      "epoch": 0.913631757763605,
      "grad_norm": 0.7857603430747986,
      "learning_rate": 1.9411748231065065e-07,
      "loss": 0.2418,
      "step": 5748
    },
    {
      "epoch": 0.9137907055293955,
      "grad_norm": 0.5481094121932983,
      "learning_rate": 1.934078004362977e-07,
      "loss": 0.1794,
      "step": 5749
    },
    {
      "epoch": 0.9139496532951858,
      "grad_norm": 0.572287380695343,
      "learning_rate": 1.9269939262994085e-07,
      "loss": 0.2027,
      "step": 5750
    },
    {
      "epoch": 0.9141086010609764,
      "grad_norm": 0.5925062298774719,
      "learning_rate": 1.9199225907935492e-07,
      "loss": 0.2669,
      "step": 5751
    },
    {
      "epoch": 0.9142675488267668,
      "grad_norm": 0.6051456928253174,
      "learning_rate": 1.9128639997197828e-07,
      "loss": 0.2024,
      "step": 5752
    },
    {
      "epoch": 0.9144264965925573,
      "grad_norm": 0.5129668712615967,
      "learning_rate": 1.9058181549490962e-07,
      "loss": 0.1656,
      "step": 5753
    },
    {
      "epoch": 0.9145854443583478,
      "grad_norm": 0.7325616478919983,
      "learning_rate": 1.8987850583491284e-07,
      "loss": 0.3555,
      "step": 5754
    },
    {
      "epoch": 0.9147443921241382,
      "grad_norm": 0.555299699306488,
      "learning_rate": 1.8917647117840943e-07,
      "loss": 0.2319,
      "step": 5755
    },
    {
      "epoch": 0.9149033398899287,
      "grad_norm": 0.5667076110839844,
      "learning_rate": 1.8847571171148715e-07,
      "loss": 0.1647,
      "step": 5756
    },
    {
      "epoch": 0.9150622876557192,
      "grad_norm": 0.6104046702384949,
      "learning_rate": 1.8777622761989355e-07,
      "loss": 0.2098,
      "step": 5757
    },
    {
      "epoch": 0.9152212354215096,
      "grad_norm": 0.6268574595451355,
      "learning_rate": 1.8707801908903867e-07,
      "loss": 0.2546,
      "step": 5758
    },
    {
      "epoch": 0.9153801831873001,
      "grad_norm": 0.660149097442627,
      "learning_rate": 1.8638108630399443e-07,
      "loss": 0.2618,
      "step": 5759
    },
    {
      "epoch": 0.9155391309530906,
      "grad_norm": 0.5299475789070129,
      "learning_rate": 1.8568542944949474e-07,
      "loss": 0.1635,
      "step": 5760
    },
    {
      "epoch": 0.915698078718881,
      "grad_norm": 0.563897430896759,
      "learning_rate": 1.8499104870993546e-07,
      "loss": 0.1408,
      "step": 5761
    },
    {
      "epoch": 0.9158570264846715,
      "grad_norm": 0.5948531031608582,
      "learning_rate": 1.8429794426937263e-07,
      "loss": 0.2735,
      "step": 5762
    },
    {
      "epoch": 0.916015974250462,
      "grad_norm": 0.5466645956039429,
      "learning_rate": 1.8360611631152602e-07,
      "loss": 0.1204,
      "step": 5763
    },
    {
      "epoch": 0.9161749220162524,
      "grad_norm": 0.5969355702400208,
      "learning_rate": 1.8291556501977613e-07,
      "loss": 0.2056,
      "step": 5764
    },
    {
      "epoch": 0.9163338697820429,
      "grad_norm": 0.6260245442390442,
      "learning_rate": 1.82226290577166e-07,
      "loss": 0.2747,
      "step": 5765
    },
    {
      "epoch": 0.9164928175478333,
      "grad_norm": 0.5925267934799194,
      "learning_rate": 1.8153829316639782e-07,
      "loss": 0.2377,
      "step": 5766
    },
    {
      "epoch": 0.9166517653136238,
      "grad_norm": 0.5731110572814941,
      "learning_rate": 1.80851572969839e-07,
      "loss": 0.1889,
      "step": 5767
    },
    {
      "epoch": 0.9168107130794143,
      "grad_norm": 0.7672419548034668,
      "learning_rate": 1.80166130169514e-07,
      "loss": 0.2429,
      "step": 5768
    },
    {
      "epoch": 0.9169696608452047,
      "grad_norm": 0.5495866537094116,
      "learning_rate": 1.794819649471119e-07,
      "loss": 0.174,
      "step": 5769
    },
    {
      "epoch": 0.9171286086109952,
      "grad_norm": 0.516154944896698,
      "learning_rate": 1.787990774839815e-07,
      "loss": 0.1605,
      "step": 5770
    },
    {
      "epoch": 0.9172875563767857,
      "grad_norm": 0.6731554865837097,
      "learning_rate": 1.7811746796113584e-07,
      "loss": 0.2982,
      "step": 5771
    },
    {
      "epoch": 0.9174465041425761,
      "grad_norm": 0.5616608262062073,
      "learning_rate": 1.774371365592442e-07,
      "loss": 0.1868,
      "step": 5772
    },
    {
      "epoch": 0.9176054519083666,
      "grad_norm": 0.6900479793548584,
      "learning_rate": 1.7675808345864188e-07,
      "loss": 0.278,
      "step": 5773
    },
    {
      "epoch": 0.9177643996741571,
      "grad_norm": 0.5813642144203186,
      "learning_rate": 1.760803088393226e-07,
      "loss": 0.1247,
      "step": 5774
    },
    {
      "epoch": 0.9179233474399475,
      "grad_norm": 0.5688587427139282,
      "learning_rate": 1.7540381288094154e-07,
      "loss": 0.1479,
      "step": 5775
    },
    {
      "epoch": 0.918082295205738,
      "grad_norm": 0.5834347009658813,
      "learning_rate": 1.747285957628153e-07,
      "loss": 0.2347,
      "step": 5776
    },
    {
      "epoch": 0.9182412429715284,
      "grad_norm": 0.56699138879776,
      "learning_rate": 1.7405465766392182e-07,
      "loss": 0.1843,
      "step": 5777
    },
    {
      "epoch": 0.9184001907373189,
      "grad_norm": 0.5725494623184204,
      "learning_rate": 1.7338199876289984e-07,
      "loss": 0.1897,
      "step": 5778
    },
    {
      "epoch": 0.9185591385031094,
      "grad_norm": 0.7095893621444702,
      "learning_rate": 1.7271061923804843e-07,
      "loss": 0.3104,
      "step": 5779
    },
    {
      "epoch": 0.9187180862688998,
      "grad_norm": 0.4819110929965973,
      "learning_rate": 1.7204051926732858e-07,
      "loss": 0.1441,
      "step": 5780
    },
    {
      "epoch": 0.9188770340346903,
      "grad_norm": 0.611372709274292,
      "learning_rate": 1.7137169902836203e-07,
      "loss": 0.2385,
      "step": 5781
    },
    {
      "epoch": 0.9190359818004809,
      "grad_norm": 0.5774780511856079,
      "learning_rate": 1.7070415869842926e-07,
      "loss": 0.2102,
      "step": 5782
    },
    {
      "epoch": 0.9191949295662712,
      "grad_norm": 0.59087735414505,
      "learning_rate": 1.700378984544737e-07,
      "loss": 0.2229,
      "step": 5783
    },
    {
      "epoch": 0.9193538773320618,
      "grad_norm": 1.024739384651184,
      "learning_rate": 1.6937291847309968e-07,
      "loss": 0.0967,
      "step": 5784
    },
    {
      "epoch": 0.9195128250978523,
      "grad_norm": 1.8681288957595825,
      "learning_rate": 1.6870921893057e-07,
      "loss": 0.2748,
      "step": 5785
    },
    {
      "epoch": 0.9196717728636427,
      "grad_norm": 0.6801071763038635,
      "learning_rate": 1.680468000028107e-07,
      "loss": 0.226,
      "step": 5786
    },
    {
      "epoch": 0.9198307206294332,
      "grad_norm": 0.5496395826339722,
      "learning_rate": 1.6738566186540628e-07,
      "loss": 0.208,
      "step": 5787
    },
    {
      "epoch": 0.9199896683952237,
      "grad_norm": 1.1222636699676514,
      "learning_rate": 1.6672580469360212e-07,
      "loss": 0.2137,
      "step": 5788
    },
    {
      "epoch": 0.9201486161610141,
      "grad_norm": 0.8331660628318787,
      "learning_rate": 1.6606722866230497e-07,
      "loss": 0.1937,
      "step": 5789
    },
    {
      "epoch": 0.9203075639268046,
      "grad_norm": 0.5024392604827881,
      "learning_rate": 1.6540993394608074e-07,
      "loss": 0.1396,
      "step": 5790
    },
    {
      "epoch": 0.920466511692595,
      "grad_norm": 0.6691266298294067,
      "learning_rate": 1.6475392071915842e-07,
      "loss": 0.2827,
      "step": 5791
    },
    {
      "epoch": 0.9206254594583855,
      "grad_norm": 0.5203375220298767,
      "learning_rate": 1.6409918915542278e-07,
      "loss": 0.1995,
      "step": 5792
    },
    {
      "epoch": 0.920784407224176,
      "grad_norm": 0.6381954550743103,
      "learning_rate": 1.6344573942842333e-07,
      "loss": 0.2545,
      "step": 5793
    },
    {
      "epoch": 0.9209433549899664,
      "grad_norm": 0.5261420607566833,
      "learning_rate": 1.6279357171136768e-07,
      "loss": 0.1815,
      "step": 5794
    },
    {
      "epoch": 0.9211023027557569,
      "grad_norm": 0.5460843443870544,
      "learning_rate": 1.6214268617712247e-07,
      "loss": 0.177,
      "step": 5795
    },
    {
      "epoch": 0.9212612505215474,
      "grad_norm": 0.6055781245231628,
      "learning_rate": 1.6149308299821643e-07,
      "loss": 0.2118,
      "step": 5796
    },
    {
      "epoch": 0.9214201982873378,
      "grad_norm": 0.6169345378875732,
      "learning_rate": 1.60844762346839e-07,
      "loss": 0.2727,
      "step": 5797
    },
    {
      "epoch": 0.9215791460531283,
      "grad_norm": 0.5942063927650452,
      "learning_rate": 1.601977243948377e-07,
      "loss": 0.182,
      "step": 5798
    },
    {
      "epoch": 0.9217380938189188,
      "grad_norm": 0.9644187688827515,
      "learning_rate": 1.5955196931371985e-07,
      "loss": 0.2265,
      "step": 5799
    },
    {
      "epoch": 0.9218970415847092,
      "grad_norm": 0.7057997584342957,
      "learning_rate": 1.5890749727465516e-07,
      "loss": 0.2612,
      "step": 5800
    },
    {
      "epoch": 0.9220559893504997,
      "grad_norm": 0.6273391842842102,
      "learning_rate": 1.5826430844847086e-07,
      "loss": 0.2005,
      "step": 5801
    },
    {
      "epoch": 0.9222149371162902,
      "grad_norm": 0.5255541205406189,
      "learning_rate": 1.5762240300565557e-07,
      "loss": 0.1729,
      "step": 5802
    },
    {
      "epoch": 0.9223738848820806,
      "grad_norm": 0.6277754306793213,
      "learning_rate": 1.5698178111635543e-07,
      "loss": 0.2697,
      "step": 5803
    },
    {
      "epoch": 0.9225328326478711,
      "grad_norm": 0.5585470199584961,
      "learning_rate": 1.563424429503807e-07,
      "loss": 0.1888,
      "step": 5804
    },
    {
      "epoch": 0.9226917804136615,
      "grad_norm": 0.5677226781845093,
      "learning_rate": 1.5570438867719695e-07,
      "loss": 0.1486,
      "step": 5805
    },
    {
      "epoch": 0.922850728179452,
      "grad_norm": 0.6118375658988953,
      "learning_rate": 1.550676184659311e-07,
      "loss": 0.2488,
      "step": 5806
    },
    {
      "epoch": 0.9230096759452425,
      "grad_norm": 0.5533744692802429,
      "learning_rate": 1.5443213248537091e-07,
      "loss": 0.1976,
      "step": 5807
    },
    {
      "epoch": 0.9231686237110329,
      "grad_norm": 0.5267797112464905,
      "learning_rate": 1.537979309039622e-07,
      "loss": 0.138,
      "step": 5808
    },
    {
      "epoch": 0.9233275714768234,
      "grad_norm": 0.5265167951583862,
      "learning_rate": 1.531650138898094e-07,
      "loss": 0.1347,
      "step": 5809
    },
    {
      "epoch": 0.9234865192426139,
      "grad_norm": 0.6174057722091675,
      "learning_rate": 1.5253338161067943e-07,
      "loss": 0.2519,
      "step": 5810
    },
    {
      "epoch": 0.9236454670084043,
      "grad_norm": 0.6138233542442322,
      "learning_rate": 1.5190303423399722e-07,
      "loss": 0.1295,
      "step": 5811
    },
    {
      "epoch": 0.9238044147741948,
      "grad_norm": 0.46155452728271484,
      "learning_rate": 1.5127397192684522e-07,
      "loss": 0.1122,
      "step": 5812
    },
    {
      "epoch": 0.9239633625399853,
      "grad_norm": 0.5745490789413452,
      "learning_rate": 1.5064619485596843e-07,
      "loss": 0.1981,
      "step": 5813
    },
    {
      "epoch": 0.9241223103057757,
      "grad_norm": 0.5101983547210693,
      "learning_rate": 1.500197031877698e-07,
      "loss": 0.1612,
      "step": 5814
    },
    {
      "epoch": 0.9242812580715662,
      "grad_norm": 0.658789873123169,
      "learning_rate": 1.4939449708830988e-07,
      "loss": 0.2738,
      "step": 5815
    },
    {
      "epoch": 0.9244402058373566,
      "grad_norm": 0.5741316676139832,
      "learning_rate": 1.4877057672331108e-07,
      "loss": 0.1945,
      "step": 5816
    },
    {
      "epoch": 0.9245991536031472,
      "grad_norm": 0.5803076028823853,
      "learning_rate": 1.4814794225815443e-07,
      "loss": 0.1746,
      "step": 5817
    },
    {
      "epoch": 0.9247581013689377,
      "grad_norm": 0.5678512454032898,
      "learning_rate": 1.475265938578796e-07,
      "loss": 0.2155,
      "step": 5818
    },
    {
      "epoch": 0.924917049134728,
      "grad_norm": 0.6263664364814758,
      "learning_rate": 1.4690653168718428e-07,
      "loss": 0.2588,
      "step": 5819
    },
    {
      "epoch": 0.9250759969005186,
      "grad_norm": 0.4938642680644989,
      "learning_rate": 1.4628775591042754e-07,
      "loss": 0.1677,
      "step": 5820
    },
    {
      "epoch": 0.9252349446663091,
      "grad_norm": 0.6709261536598206,
      "learning_rate": 1.4567026669162598e-07,
      "loss": 0.272,
      "step": 5821
    },
    {
      "epoch": 0.9253938924320995,
      "grad_norm": 0.6072070002555847,
      "learning_rate": 1.4505406419445422e-07,
      "loss": 0.1387,
      "step": 5822
    },
    {
      "epoch": 0.92555284019789,
      "grad_norm": 0.6337776184082031,
      "learning_rate": 1.4443914858224938e-07,
      "loss": 0.2257,
      "step": 5823
    },
    {
      "epoch": 0.9257117879636805,
      "grad_norm": 0.6710230112075806,
      "learning_rate": 1.4382552001800388e-07,
      "loss": 0.3447,
      "step": 5824
    },
    {
      "epoch": 0.9258707357294709,
      "grad_norm": 0.564074695110321,
      "learning_rate": 1.4321317866437036e-07,
      "loss": 0.1915,
      "step": 5825
    },
    {
      "epoch": 0.9260296834952614,
      "grad_norm": 0.5189679265022278,
      "learning_rate": 1.4260212468366009e-07,
      "loss": 0.1496,
      "step": 5826
    },
    {
      "epoch": 0.9261886312610519,
      "grad_norm": 0.5332596302032471,
      "learning_rate": 1.4199235823784295e-07,
      "loss": 0.1744,
      "step": 5827
    },
    {
      "epoch": 0.9263475790268423,
      "grad_norm": 0.9544984102249146,
      "learning_rate": 1.4138387948854915e-07,
      "loss": 0.2691,
      "step": 5828
    },
    {
      "epoch": 0.9265065267926328,
      "grad_norm": 0.86985182762146,
      "learning_rate": 1.4077668859706407e-07,
      "loss": 0.2139,
      "step": 5829
    },
    {
      "epoch": 0.9266654745584232,
      "grad_norm": 0.558355987071991,
      "learning_rate": 1.4017078572433507e-07,
      "loss": 0.2001,
      "step": 5830
    },
    {
      "epoch": 0.9268244223242137,
      "grad_norm": 0.579369306564331,
      "learning_rate": 1.3956617103096814e-07,
      "loss": 0.2412,
      "step": 5831
    },
    {
      "epoch": 0.9269833700900042,
      "grad_norm": 0.47904500365257263,
      "learning_rate": 1.3896284467722398e-07,
      "loss": 0.0845,
      "step": 5832
    },
    {
      "epoch": 0.9271423178557946,
      "grad_norm": 0.6588994264602661,
      "learning_rate": 1.3836080682302633e-07,
      "loss": 0.2247,
      "step": 5833
    },
    {
      "epoch": 0.9273012656215851,
      "grad_norm": 0.5428709387779236,
      "learning_rate": 1.3776005762795474e-07,
      "loss": 0.2046,
      "step": 5834
    },
    {
      "epoch": 0.9274602133873756,
      "grad_norm": 0.5949673056602478,
      "learning_rate": 1.3716059725124687e-07,
      "loss": 0.2397,
      "step": 5835
    },
    {
      "epoch": 0.927619161153166,
      "grad_norm": 0.49733710289001465,
      "learning_rate": 1.3656242585180112e-07,
      "loss": 0.1444,
      "step": 5836
    },
    {
      "epoch": 0.9277781089189565,
      "grad_norm": 0.6756420731544495,
      "learning_rate": 1.3596554358817293e-07,
      "loss": 0.281,
      "step": 5837
    },
    {
      "epoch": 0.927937056684747,
      "grad_norm": 0.49401018023490906,
      "learning_rate": 1.3536995061857573e-07,
      "loss": 0.1615,
      "step": 5838
    },
    {
      "epoch": 0.9280960044505374,
      "grad_norm": 0.5460599660873413,
      "learning_rate": 1.3477564710088097e-07,
      "loss": 0.0769,
      "step": 5839
    },
    {
      "epoch": 0.9282549522163279,
      "grad_norm": 0.46973833441734314,
      "learning_rate": 1.341826331926188e-07,
      "loss": 0.113,
      "step": 5840
    },
    {
      "epoch": 0.9284138999821184,
      "grad_norm": 0.6515845656394958,
      "learning_rate": 1.335909090509785e-07,
      "loss": 0.3861,
      "step": 5841
    },
    {
      "epoch": 0.9285728477479088,
      "grad_norm": 0.4958741068840027,
      "learning_rate": 1.3300047483280453e-07,
      "loss": 0.0981,
      "step": 5842
    },
    {
      "epoch": 0.9287317955136993,
      "grad_norm": 0.6989699006080627,
      "learning_rate": 1.3241133069460343e-07,
      "loss": 0.1636,
      "step": 5843
    },
    {
      "epoch": 0.9288907432794897,
      "grad_norm": 0.7255101203918457,
      "learning_rate": 1.3182347679253748e-07,
      "loss": 0.1736,
      "step": 5844
    },
    {
      "epoch": 0.9290496910452802,
      "grad_norm": 0.695456862449646,
      "learning_rate": 1.3123691328242593e-07,
      "loss": 0.1783,
      "step": 5845
    },
    {
      "epoch": 0.9292086388110707,
      "grad_norm": 0.6058527827262878,
      "learning_rate": 1.306516403197483e-07,
      "loss": 0.1324,
      "step": 5846
    },
    {
      "epoch": 0.9293675865768611,
      "grad_norm": 0.5683726668357849,
      "learning_rate": 1.300676580596405e-07,
      "loss": 0.1761,
      "step": 5847
    },
    {
      "epoch": 0.9295265343426516,
      "grad_norm": 0.5993254780769348,
      "learning_rate": 1.294849666568976e-07,
      "loss": 0.17,
      "step": 5848
    },
    {
      "epoch": 0.9296854821084422,
      "grad_norm": 0.8561686873435974,
      "learning_rate": 1.28903566265971e-07,
      "loss": 0.1394,
      "step": 5849
    },
    {
      "epoch": 0.9298444298742325,
      "grad_norm": 0.577073872089386,
      "learning_rate": 1.2832345704097082e-07,
      "loss": 0.1411,
      "step": 5850
    },
    {
      "epoch": 0.930003377640023,
      "grad_norm": 0.6263895630836487,
      "learning_rate": 1.2774463913566572e-07,
      "loss": 0.1944,
      "step": 5851
    },
    {
      "epoch": 0.9301623254058136,
      "grad_norm": 0.575381875038147,
      "learning_rate": 1.2716711270347905e-07,
      "loss": 0.206,
      "step": 5852
    },
    {
      "epoch": 0.930321273171604,
      "grad_norm": 0.4547244608402252,
      "learning_rate": 1.2659087789749557e-07,
      "loss": 0.1239,
      "step": 5853
    },
    {
      "epoch": 0.9304802209373945,
      "grad_norm": 0.6127362847328186,
      "learning_rate": 1.2601593487045537e-07,
      "loss": 0.2793,
      "step": 5854
    },
    {
      "epoch": 0.930639168703185,
      "grad_norm": 0.6143684387207031,
      "learning_rate": 1.2544228377475654e-07,
      "loss": 0.2526,
      "step": 5855
    },
    {
      "epoch": 0.9307981164689754,
      "grad_norm": 0.5692608952522278,
      "learning_rate": 1.2486992476245575e-07,
      "loss": 0.1962,
      "step": 5856
    },
    {
      "epoch": 0.9309570642347659,
      "grad_norm": 0.6330912113189697,
      "learning_rate": 1.2429885798526608e-07,
      "loss": 0.2455,
      "step": 5857
    },
    {
      "epoch": 0.9311160120005563,
      "grad_norm": 0.7242267727851868,
      "learning_rate": 1.2372908359455815e-07,
      "loss": 0.2213,
      "step": 5858
    },
    {
      "epoch": 0.9312749597663468,
      "grad_norm": 0.5004313588142395,
      "learning_rate": 1.2316060174136e-07,
      "loss": 0.165,
      "step": 5859
    },
    {
      "epoch": 0.9314339075321373,
      "grad_norm": 0.6543777585029602,
      "learning_rate": 1.2259341257635783e-07,
      "loss": 0.2867,
      "step": 5860
    },
    {
      "epoch": 0.9315928552979277,
      "grad_norm": 0.6990213394165039,
      "learning_rate": 1.2202751624989407e-07,
      "loss": 0.2245,
      "step": 5861
    },
    {
      "epoch": 0.9317518030637182,
      "grad_norm": 0.6328830122947693,
      "learning_rate": 1.2146291291196933e-07,
      "loss": 0.2024,
      "step": 5862
    },
    {
      "epoch": 0.9319107508295087,
      "grad_norm": 0.534829318523407,
      "learning_rate": 1.2089960271224112e-07,
      "loss": 0.1812,
      "step": 5863
    },
    {
      "epoch": 0.9320696985952991,
      "grad_norm": 0.8738043904304504,
      "learning_rate": 1.2033758580002498e-07,
      "loss": 0.1732,
      "step": 5864
    },
    {
      "epoch": 0.9322286463610896,
      "grad_norm": 1.1760225296020508,
      "learning_rate": 1.197768623242923e-07,
      "loss": 0.2025,
      "step": 5865
    },
    {
      "epoch": 0.9323875941268801,
      "grad_norm": 0.5324599742889404,
      "learning_rate": 1.19217432433672e-07,
      "loss": 0.1686,
      "step": 5866
    },
    {
      "epoch": 0.9325465418926705,
      "grad_norm": 0.6033931374549866,
      "learning_rate": 1.1865929627645045e-07,
      "loss": 0.2805,
      "step": 5867
    },
    {
      "epoch": 0.932705489658461,
      "grad_norm": 0.5386634469032288,
      "learning_rate": 1.1810245400057152e-07,
      "loss": 0.1659,
      "step": 5868
    },
    {
      "epoch": 0.9328644374242514,
      "grad_norm": 0.43057793378829956,
      "learning_rate": 1.1754690575363493e-07,
      "loss": 0.1278,
      "step": 5869
    },
    {
      "epoch": 0.9330233851900419,
      "grad_norm": 0.5574998259544373,
      "learning_rate": 1.1699265168289898e-07,
      "loss": 0.2489,
      "step": 5870
    },
    {
      "epoch": 0.9331823329558324,
      "grad_norm": 0.6862756013870239,
      "learning_rate": 1.1643969193527783e-07,
      "loss": 0.2561,
      "step": 5871
    },
    {
      "epoch": 0.9333412807216228,
      "grad_norm": 0.5599533915519714,
      "learning_rate": 1.1588802665734144e-07,
      "loss": 0.2158,
      "step": 5872
    },
    {
      "epoch": 0.9335002284874133,
      "grad_norm": 0.6684290170669556,
      "learning_rate": 1.1533765599531954e-07,
      "loss": 0.3357,
      "step": 5873
    },
    {
      "epoch": 0.9336591762532038,
      "grad_norm": 0.6027215719223022,
      "learning_rate": 1.1478858009509653e-07,
      "loss": 0.1786,
      "step": 5874
    },
    {
      "epoch": 0.9338181240189942,
      "grad_norm": 0.573299765586853,
      "learning_rate": 1.1424079910221375e-07,
      "loss": 0.2181,
      "step": 5875
    },
    {
      "epoch": 0.9339770717847847,
      "grad_norm": 0.6689953207969666,
      "learning_rate": 1.1369431316187063e-07,
      "loss": 0.3291,
      "step": 5876
    },
    {
      "epoch": 0.9341360195505752,
      "grad_norm": 1.2587931156158447,
      "learning_rate": 1.1314912241892184e-07,
      "loss": 0.1814,
      "step": 5877
    },
    {
      "epoch": 0.9342949673163656,
      "grad_norm": 0.5039864778518677,
      "learning_rate": 1.1260522701788012e-07,
      "loss": 0.1909,
      "step": 5878
    },
    {
      "epoch": 0.9344539150821561,
      "grad_norm": 0.5920742154121399,
      "learning_rate": 1.1206262710291294e-07,
      "loss": 0.2626,
      "step": 5879
    },
    {
      "epoch": 0.9346128628479466,
      "grad_norm": 0.6525774002075195,
      "learning_rate": 1.1152132281784578e-07,
      "loss": 0.1783,
      "step": 5880
    },
    {
      "epoch": 0.934771810613737,
      "grad_norm": 0.4995085299015045,
      "learning_rate": 1.109813143061611e-07,
      "loss": 0.1645,
      "step": 5881
    },
    {
      "epoch": 0.9349307583795275,
      "grad_norm": 0.553683340549469,
      "learning_rate": 1.1044260171099664e-07,
      "loss": 0.19,
      "step": 5882
    },
    {
      "epoch": 0.935089706145318,
      "grad_norm": 0.7007175087928772,
      "learning_rate": 1.0990518517514759e-07,
      "loss": 0.2019,
      "step": 5883
    },
    {
      "epoch": 0.9352486539111085,
      "grad_norm": 0.693837583065033,
      "learning_rate": 1.0936906484106446e-07,
      "loss": 0.2863,
      "step": 5884
    },
    {
      "epoch": 0.935407601676899,
      "grad_norm": 0.5129731297492981,
      "learning_rate": 1.0883424085085692e-07,
      "loss": 0.184,
      "step": 5885
    },
    {
      "epoch": 0.9355665494426894,
      "grad_norm": 0.7180479764938354,
      "learning_rate": 1.0830071334628655e-07,
      "loss": 0.3326,
      "step": 5886
    },
    {
      "epoch": 0.9357254972084799,
      "grad_norm": 0.6017835736274719,
      "learning_rate": 1.0776848246877525e-07,
      "loss": 0.2412,
      "step": 5887
    },
    {
      "epoch": 0.9358844449742704,
      "grad_norm": 0.6401113271713257,
      "learning_rate": 1.0723754835939903e-07,
      "loss": 0.3504,
      "step": 5888
    },
    {
      "epoch": 0.9360433927400608,
      "grad_norm": 0.6650501489639282,
      "learning_rate": 1.0670791115889146e-07,
      "loss": 0.2872,
      "step": 5889
    },
    {
      "epoch": 0.9362023405058513,
      "grad_norm": 0.5604833960533142,
      "learning_rate": 1.0617957100764187e-07,
      "loss": 0.1903,
      "step": 5890
    },
    {
      "epoch": 0.9363612882716418,
      "grad_norm": 0.5668051838874817,
      "learning_rate": 1.0565252804569548e-07,
      "loss": 0.1726,
      "step": 5891
    },
    {
      "epoch": 0.9365202360374322,
      "grad_norm": 0.5561589598655701,
      "learning_rate": 1.0512678241275386e-07,
      "loss": 0.186,
      "step": 5892
    },
    {
      "epoch": 0.9366791838032227,
      "grad_norm": 0.5783126354217529,
      "learning_rate": 1.046023342481739e-07,
      "loss": 0.1711,
      "step": 5893
    },
    {
      "epoch": 0.9368381315690132,
      "grad_norm": 0.6497146487236023,
      "learning_rate": 1.0407918369097103e-07,
      "loss": 0.2827,
      "step": 5894
    },
    {
      "epoch": 0.9369970793348036,
      "grad_norm": 0.5884693264961243,
      "learning_rate": 1.035573308798138e-07,
      "loss": 0.2393,
      "step": 5895
    },
    {
      "epoch": 0.9371560271005941,
      "grad_norm": 0.5730445981025696,
      "learning_rate": 1.0303677595302819e-07,
      "loss": 0.1708,
      "step": 5896
    },
    {
      "epoch": 0.9373149748663845,
      "grad_norm": 0.6341437697410583,
      "learning_rate": 1.0251751904859663e-07,
      "loss": 0.2473,
      "step": 5897
    },
    {
      "epoch": 0.937473922632175,
      "grad_norm": 0.5779324173927307,
      "learning_rate": 1.0199956030415736e-07,
      "loss": 0.1887,
      "step": 5898
    },
    {
      "epoch": 0.9376328703979655,
      "grad_norm": 0.6551051139831543,
      "learning_rate": 1.0148289985700222e-07,
      "loss": 0.3202,
      "step": 5899
    },
    {
      "epoch": 0.9377918181637559,
      "grad_norm": 0.6159623265266418,
      "learning_rate": 1.009675378440822e-07,
      "loss": 0.2343,
      "step": 5900
    },
    {
      "epoch": 0.9379507659295464,
      "grad_norm": 0.6691659092903137,
      "learning_rate": 1.0045347440200192e-07,
      "loss": 0.2949,
      "step": 5901
    },
    {
      "epoch": 0.9381097136953369,
      "grad_norm": 0.6098811030387878,
      "learning_rate": 9.994070966702296e-08,
      "loss": 0.1337,
      "step": 5902
    },
    {
      "epoch": 0.9382686614611273,
      "grad_norm": 0.8542904257774353,
      "learning_rate": 9.942924377506214e-08,
      "loss": 0.1907,
      "step": 5903
    },
    {
      "epoch": 0.9384276092269178,
      "grad_norm": 0.6431005597114563,
      "learning_rate": 9.891907686169211e-08,
      "loss": 0.3089,
      "step": 5904
    },
    {
      "epoch": 0.9385865569927083,
      "grad_norm": 0.8043825030326843,
      "learning_rate": 9.841020906214193e-08,
      "loss": 0.1686,
      "step": 5905
    },
    {
      "epoch": 0.9387455047584987,
      "grad_norm": 0.5002923607826233,
      "learning_rate": 9.790264051129372e-08,
      "loss": 0.124,
      "step": 5906
    },
    {
      "epoch": 0.9389044525242892,
      "grad_norm": 0.5704474449157715,
      "learning_rate": 9.739637134368817e-08,
      "loss": 0.1733,
      "step": 5907
    },
    {
      "epoch": 0.9390634002900796,
      "grad_norm": 0.5921096801757812,
      "learning_rate": 9.689140169352074e-08,
      "loss": 0.1708,
      "step": 5908
    },
    {
      "epoch": 0.9392223480558701,
      "grad_norm": 0.5004736185073853,
      "learning_rate": 9.638773169464155e-08,
      "loss": 0.1159,
      "step": 5909
    },
    {
      "epoch": 0.9393812958216606,
      "grad_norm": 0.5225231051445007,
      "learning_rate": 9.58853614805566e-08,
      "loss": 0.1614,
      "step": 5910
    },
    {
      "epoch": 0.939540243587451,
      "grad_norm": 0.5702873468399048,
      "learning_rate": 9.538429118442882e-08,
      "loss": 0.217,
      "step": 5911
    },
    {
      "epoch": 0.9396991913532415,
      "grad_norm": 0.5449793338775635,
      "learning_rate": 9.488452093907364e-08,
      "loss": 0.1286,
      "step": 5912
    },
    {
      "epoch": 0.939858139119032,
      "grad_norm": 0.5246747136116028,
      "learning_rate": 9.43860508769645e-08,
      "loss": 0.1974,
      "step": 5913
    },
    {
      "epoch": 0.9400170868848224,
      "grad_norm": 0.8252929449081421,
      "learning_rate": 9.38888811302291e-08,
      "loss": 0.2789,
      "step": 5914
    },
    {
      "epoch": 0.940176034650613,
      "grad_norm": 0.7236567139625549,
      "learning_rate": 9.339301183065086e-08,
      "loss": 0.2525,
      "step": 5915
    },
    {
      "epoch": 0.9403349824164035,
      "grad_norm": 0.6269292831420898,
      "learning_rate": 9.2898443109668e-08,
      "loss": 0.2197,
      "step": 5916
    },
    {
      "epoch": 0.9404939301821938,
      "grad_norm": 0.7604420185089111,
      "learning_rate": 9.2405175098374e-08,
      "loss": 0.1803,
      "step": 5917
    },
    {
      "epoch": 0.9406528779479844,
      "grad_norm": 0.9506263732910156,
      "learning_rate": 9.191320792751867e-08,
      "loss": 0.2216,
      "step": 5918
    },
    {
      "epoch": 0.9408118257137749,
      "grad_norm": 0.5470197796821594,
      "learning_rate": 9.142254172750498e-08,
      "loss": 0.1697,
      "step": 5919
    },
    {
      "epoch": 0.9409707734795653,
      "grad_norm": 0.6397852897644043,
      "learning_rate": 9.09331766283933e-08,
      "loss": 0.2613,
      "step": 5920
    },
    {
      "epoch": 0.9411297212453558,
      "grad_norm": 0.5295003652572632,
      "learning_rate": 9.044511275989709e-08,
      "loss": 0.2017,
      "step": 5921
    },
    {
      "epoch": 0.9412886690111462,
      "grad_norm": 0.5280351042747498,
      "learning_rate": 8.995835025138677e-08,
      "loss": 0.1803,
      "step": 5922
    },
    {
      "epoch": 0.9414476167769367,
      "grad_norm": 0.6281114220619202,
      "learning_rate": 8.947288923188691e-08,
      "loss": 0.218,
      "step": 5923
    },
    {
      "epoch": 0.9416065645427272,
      "grad_norm": 0.5949898958206177,
      "learning_rate": 8.898872983007622e-08,
      "loss": 0.2046,
      "step": 5924
    },
    {
      "epoch": 0.9417655123085176,
      "grad_norm": 0.6866498589515686,
      "learning_rate": 8.850587217429096e-08,
      "loss": 0.1772,
      "step": 5925
    },
    {
      "epoch": 0.9419244600743081,
      "grad_norm": 0.5170334577560425,
      "learning_rate": 8.802431639251874e-08,
      "loss": 0.1586,
      "step": 5926
    },
    {
      "epoch": 0.9420834078400986,
      "grad_norm": 0.6531432271003723,
      "learning_rate": 8.754406261240467e-08,
      "loss": 0.2546,
      "step": 5927
    },
    {
      "epoch": 0.942242355605889,
      "grad_norm": 0.5505150556564331,
      "learning_rate": 8.706511096124858e-08,
      "loss": 0.1728,
      "step": 5928
    },
    {
      "epoch": 0.9424013033716795,
      "grad_norm": 0.647783100605011,
      "learning_rate": 8.658746156600394e-08,
      "loss": 0.2727,
      "step": 5929
    },
    {
      "epoch": 0.94256025113747,
      "grad_norm": 0.5939198732376099,
      "learning_rate": 8.611111455328058e-08,
      "loss": 0.2025,
      "step": 5930
    },
    {
      "epoch": 0.9427191989032604,
      "grad_norm": 0.5863103866577148,
      "learning_rate": 8.563607004934193e-08,
      "loss": 0.2264,
      "step": 5931
    },
    {
      "epoch": 0.9428781466690509,
      "grad_norm": 0.4955776333808899,
      "learning_rate": 8.516232818010561e-08,
      "loss": 0.1336,
      "step": 5932
    },
    {
      "epoch": 0.9430370944348414,
      "grad_norm": 0.6792314648628235,
      "learning_rate": 8.468988907114617e-08,
      "loss": 0.2233,
      "step": 5933
    },
    {
      "epoch": 0.9431960422006318,
      "grad_norm": 0.5819187760353088,
      "learning_rate": 8.421875284769065e-08,
      "loss": 0.1945,
      "step": 5934
    },
    {
      "epoch": 0.9433549899664223,
      "grad_norm": 0.5950755476951599,
      "learning_rate": 8.374891963462251e-08,
      "loss": 0.2583,
      "step": 5935
    },
    {
      "epoch": 0.9435139377322127,
      "grad_norm": 0.6327186226844788,
      "learning_rate": 8.328038955647821e-08,
      "loss": 0.3399,
      "step": 5936
    },
    {
      "epoch": 0.9436728854980032,
      "grad_norm": 0.6578527092933655,
      "learning_rate": 8.281316273744955e-08,
      "loss": 0.1905,
      "step": 5937
    },
    {
      "epoch": 0.9438318332637937,
      "grad_norm": 0.6191351413726807,
      "learning_rate": 8.234723930138356e-08,
      "loss": 0.1684,
      "step": 5938
    },
    {
      "epoch": 0.9439907810295841,
      "grad_norm": 0.5779718160629272,
      "learning_rate": 8.188261937177977e-08,
      "loss": 0.2425,
      "step": 5939
    },
    {
      "epoch": 0.9441497287953746,
      "grad_norm": 0.583446204662323,
      "learning_rate": 8.141930307179468e-08,
      "loss": 0.2575,
      "step": 5940
    },
    {
      "epoch": 0.9443086765611651,
      "grad_norm": 0.5832498073577881,
      "learning_rate": 8.095729052423729e-08,
      "loss": 0.1874,
      "step": 5941
    },
    {
      "epoch": 0.9444676243269555,
      "grad_norm": 0.626411497592926,
      "learning_rate": 8.049658185157238e-08,
      "loss": 0.2237,
      "step": 5942
    },
    {
      "epoch": 0.944626572092746,
      "grad_norm": 0.5880846381187439,
      "learning_rate": 8.003717717591786e-08,
      "loss": 0.2248,
      "step": 5943
    },
    {
      "epoch": 0.9447855198585365,
      "grad_norm": 0.5944864749908447,
      "learning_rate": 7.95790766190474e-08,
      "loss": 0.253,
      "step": 5944
    },
    {
      "epoch": 0.9449444676243269,
      "grad_norm": 0.6072530150413513,
      "learning_rate": 7.912228030238834e-08,
      "loss": 0.186,
      "step": 5945
    },
    {
      "epoch": 0.9451034153901174,
      "grad_norm": 0.5427780747413635,
      "learning_rate": 7.866678834702157e-08,
      "loss": 0.1501,
      "step": 5946
    },
    {
      "epoch": 0.9452623631559078,
      "grad_norm": 0.6035347580909729,
      "learning_rate": 7.821260087368221e-08,
      "loss": 0.1882,
      "step": 5947
    },
    {
      "epoch": 0.9454213109216983,
      "grad_norm": 0.6150995492935181,
      "learning_rate": 7.775971800276228e-08,
      "loss": 0.2527,
      "step": 5948
    },
    {
      "epoch": 0.9455802586874889,
      "grad_norm": 0.6391603350639343,
      "learning_rate": 7.730813985430407e-08,
      "loss": 0.3015,
      "step": 5949
    },
    {
      "epoch": 0.9457392064532792,
      "grad_norm": 0.5454193949699402,
      "learning_rate": 7.685786654800687e-08,
      "loss": 0.1612,
      "step": 5950
    },
    {
      "epoch": 0.9458981542190698,
      "grad_norm": 0.5049736499786377,
      "learning_rate": 7.64088982032235e-08,
      "loss": 0.1291,
      "step": 5951
    },
    {
      "epoch": 0.9460571019848603,
      "grad_norm": 0.48640841245651245,
      "learning_rate": 7.59612349389599e-08,
      "loss": 0.1246,
      "step": 5952
    },
    {
      "epoch": 0.9462160497506507,
      "grad_norm": 0.5528362393379211,
      "learning_rate": 7.551487687387726e-08,
      "loss": 0.1416,
      "step": 5953
    },
    {
      "epoch": 0.9463749975164412,
      "grad_norm": 1.8615161180496216,
      "learning_rate": 7.506982412628871e-08,
      "loss": 0.1445,
      "step": 5954
    },
    {
      "epoch": 0.9465339452822317,
      "grad_norm": 0.5744749307632446,
      "learning_rate": 7.4626076814166e-08,
      "loss": 0.1775,
      "step": 5955
    },
    {
      "epoch": 0.9466928930480221,
      "grad_norm": 0.6218185424804688,
      "learning_rate": 7.418363505512894e-08,
      "loss": 0.2811,
      "step": 5956
    },
    {
      "epoch": 0.9468518408138126,
      "grad_norm": 0.5644074082374573,
      "learning_rate": 7.374249896645536e-08,
      "loss": 0.1735,
      "step": 5957
    },
    {
      "epoch": 0.9470107885796031,
      "grad_norm": 0.5930606126785278,
      "learning_rate": 7.330266866507618e-08,
      "loss": 0.2163,
      "step": 5958
    },
    {
      "epoch": 0.9471697363453935,
      "grad_norm": 0.5662022233009338,
      "learning_rate": 7.286414426757483e-08,
      "loss": 0.1185,
      "step": 5959
    },
    {
      "epoch": 0.947328684111184,
      "grad_norm": 0.6152905225753784,
      "learning_rate": 7.242692589018996e-08,
      "loss": 0.269,
      "step": 5960
    },
    {
      "epoch": 0.9474876318769744,
      "grad_norm": 0.48678916692733765,
      "learning_rate": 7.199101364881389e-08,
      "loss": 0.1316,
      "step": 5961
    },
    {
      "epoch": 0.9476465796427649,
      "grad_norm": 0.527799129486084,
      "learning_rate": 7.155640765899252e-08,
      "loss": 0.1873,
      "step": 5962
    },
    {
      "epoch": 0.9478055274085554,
      "grad_norm": 1.015041708946228,
      "learning_rate": 7.112310803592537e-08,
      "loss": 0.1233,
      "step": 5963
    },
    {
      "epoch": 0.9479644751743458,
      "grad_norm": 0.6231568455696106,
      "learning_rate": 7.069111489446556e-08,
      "loss": 0.1925,
      "step": 5964
    },
    {
      "epoch": 0.9481234229401363,
      "grad_norm": 0.596373438835144,
      "learning_rate": 7.026042834912039e-08,
      "loss": 0.1866,
      "step": 5965
    },
    {
      "epoch": 0.9482823707059268,
      "grad_norm": 0.5898705720901489,
      "learning_rate": 6.98310485140502e-08,
      "loss": 0.2366,
      "step": 5966
    },
    {
      "epoch": 0.9484413184717172,
      "grad_norm": 0.44026878476142883,
      "learning_rate": 6.940297550306895e-08,
      "loss": 0.0924,
      "step": 5967
    },
    {
      "epoch": 0.9486002662375077,
      "grad_norm": 0.5786784291267395,
      "learning_rate": 6.89762094296459e-08,
      "loss": 0.1893,
      "step": 5968
    },
    {
      "epoch": 0.9487592140032982,
      "grad_norm": 0.5270757675170898,
      "learning_rate": 6.855075040690163e-08,
      "loss": 0.1756,
      "step": 5969
    },
    {
      "epoch": 0.9489181617690886,
      "grad_norm": 0.5706472396850586,
      "learning_rate": 6.81265985476115e-08,
      "loss": 0.1357,
      "step": 5970
    },
    {
      "epoch": 0.9490771095348791,
      "grad_norm": 0.6019094586372375,
      "learning_rate": 6.770375396420393e-08,
      "loss": 0.2334,
      "step": 5971
    },
    {
      "epoch": 0.9492360573006696,
      "grad_norm": 0.5209446549415588,
      "learning_rate": 6.728221676876146e-08,
      "loss": 0.1584,
      "step": 5972
    },
    {
      "epoch": 0.94939500506646,
      "grad_norm": 0.6100060343742371,
      "learning_rate": 6.686198707301861e-08,
      "loss": 0.1039,
      "step": 5973
    },
    {
      "epoch": 0.9495539528322505,
      "grad_norm": 0.7180062532424927,
      "learning_rate": 6.644306498836517e-08,
      "loss": 0.2226,
      "step": 5974
    },
    {
      "epoch": 0.9497129005980409,
      "grad_norm": 0.5915995836257935,
      "learning_rate": 6.602545062584342e-08,
      "loss": 0.2359,
      "step": 5975
    },
    {
      "epoch": 0.9498718483638314,
      "grad_norm": 0.5847732424736023,
      "learning_rate": 6.560914409614872e-08,
      "loss": 0.1871,
      "step": 5976
    },
    {
      "epoch": 0.9500307961296219,
      "grad_norm": 0.802061140537262,
      "learning_rate": 6.519414550962999e-08,
      "loss": 0.3489,
      "step": 5977
    },
    {
      "epoch": 0.9501897438954123,
      "grad_norm": 0.47734466195106506,
      "learning_rate": 6.478045497629038e-08,
      "loss": 0.1138,
      "step": 5978
    },
    {
      "epoch": 0.9503486916612028,
      "grad_norm": 0.6995063424110413,
      "learning_rate": 6.436807260578437e-08,
      "loss": 0.1754,
      "step": 5979
    },
    {
      "epoch": 0.9505076394269933,
      "grad_norm": 0.5515444278717041,
      "learning_rate": 6.39569985074212e-08,
      "loss": 0.1984,
      "step": 5980
    },
    {
      "epoch": 0.9506665871927837,
      "grad_norm": 0.5647537112236023,
      "learning_rate": 6.354723279016373e-08,
      "loss": 0.2015,
      "step": 5981
    },
    {
      "epoch": 0.9508255349585742,
      "grad_norm": 0.4957877993583679,
      "learning_rate": 6.31387755626267e-08,
      "loss": 0.1273,
      "step": 5982
    },
    {
      "epoch": 0.9509844827243648,
      "grad_norm": 0.5678027272224426,
      "learning_rate": 6.273162693307855e-08,
      "loss": 0.153,
      "step": 5983
    },
    {
      "epoch": 0.9511434304901552,
      "grad_norm": 0.80265873670578,
      "learning_rate": 6.232578700944069e-08,
      "loss": 0.229,
      "step": 5984
    },
    {
      "epoch": 0.9513023782559457,
      "grad_norm": 0.5976451635360718,
      "learning_rate": 6.192125589928821e-08,
      "loss": 0.2802,
      "step": 5985
    },
    {
      "epoch": 0.951461326021736,
      "grad_norm": 0.6456010937690735,
      "learning_rate": 6.15180337098481e-08,
      "loss": 0.2484,
      "step": 5986
    },
    {
      "epoch": 0.9516202737875266,
      "grad_norm": 0.6162883043289185,
      "learning_rate": 6.111612054800209e-08,
      "loss": 0.2284,
      "step": 5987
    },
    {
      "epoch": 0.9517792215533171,
      "grad_norm": 0.957615315914154,
      "learning_rate": 6.07155165202844e-08,
      "loss": 0.1932,
      "step": 5988
    },
    {
      "epoch": 0.9519381693191075,
      "grad_norm": 0.7687402367591858,
      "learning_rate": 6.03162217328801e-08,
      "loss": 0.2828,
      "step": 5989
    },
    {
      "epoch": 0.952097117084898,
      "grad_norm": 0.563519299030304,
      "learning_rate": 5.991823629163007e-08,
      "loss": 0.2236,
      "step": 5990
    },
    {
      "epoch": 0.9522560648506885,
      "grad_norm": 0.5570054650306702,
      "learning_rate": 5.952156030202716e-08,
      "loss": 0.1518,
      "step": 5991
    },
    {
      "epoch": 0.9524150126164789,
      "grad_norm": 0.5744234323501587,
      "learning_rate": 5.912619386921725e-08,
      "loss": 0.2006,
      "step": 5992
    },
    {
      "epoch": 0.9525739603822694,
      "grad_norm": 0.5930953025817871,
      "learning_rate": 5.873213709799763e-08,
      "loss": 0.2142,
      "step": 5993
    },
    {
      "epoch": 0.9527329081480599,
      "grad_norm": 0.6645255088806152,
      "learning_rate": 5.833939009282086e-08,
      "loss": 0.1773,
      "step": 5994
    },
    {
      "epoch": 0.9528918559138503,
      "grad_norm": 0.5294626951217651,
      "learning_rate": 5.794795295779088e-08,
      "loss": 0.1908,
      "step": 5995
    },
    {
      "epoch": 0.9530508036796408,
      "grad_norm": 0.5178340673446655,
      "learning_rate": 5.755782579666469e-08,
      "loss": 0.1777,
      "step": 5996
    },
    {
      "epoch": 0.9532097514454313,
      "grad_norm": 0.5445032119750977,
      "learning_rate": 5.7169008712851245e-08,
      "loss": 0.1983,
      "step": 5997
    },
    {
      "epoch": 0.9533686992112217,
      "grad_norm": 0.5971226692199707,
      "learning_rate": 5.678150180941422e-08,
      "loss": 0.2146,
      "step": 5998
    },
    {
      "epoch": 0.9535276469770122,
      "grad_norm": 0.5023627281188965,
      "learning_rate": 5.639530518906755e-08,
      "loss": 0.1424,
      "step": 5999
    },
    {
      "epoch": 0.9536865947428026,
      "grad_norm": 0.516232430934906,
      "learning_rate": 5.601041895417991e-08,
      "loss": 0.1206,
      "step": 6000
    },
    {
      "epoch": 0.9538455425085931,
      "grad_norm": 0.6465812921524048,
      "learning_rate": 5.5626843206772474e-08,
      "loss": 0.1548,
      "step": 6001
    },
    {
      "epoch": 0.9540044902743836,
      "grad_norm": 0.5756213068962097,
      "learning_rate": 5.5244578048517796e-08,
      "loss": 0.1663,
      "step": 6002
    },
    {
      "epoch": 0.954163438040174,
      "grad_norm": 0.6126556992530823,
      "learning_rate": 5.486362358074093e-08,
      "loss": 0.2588,
      "step": 6003
    },
    {
      "epoch": 0.9543223858059645,
      "grad_norm": 0.559592604637146,
      "learning_rate": 5.448397990442167e-08,
      "loss": 0.186,
      "step": 6004
    },
    {
      "epoch": 0.954481333571755,
      "grad_norm": 0.6527518630027771,
      "learning_rate": 5.410564712019006e-08,
      "loss": 0.1694,
      "step": 6005
    },
    {
      "epoch": 0.9546402813375454,
      "grad_norm": 0.6249748468399048,
      "learning_rate": 5.3728625328329234e-08,
      "loss": 0.1871,
      "step": 6006
    },
    {
      "epoch": 0.9547992291033359,
      "grad_norm": 0.7051063776016235,
      "learning_rate": 5.335291462877645e-08,
      "loss": 0.2692,
      "step": 6007
    },
    {
      "epoch": 0.9549581768691264,
      "grad_norm": 0.5056400895118713,
      "learning_rate": 5.297851512111873e-08,
      "loss": 0.1306,
      "step": 6008
    },
    {
      "epoch": 0.9551171246349168,
      "grad_norm": 0.6150949001312256,
      "learning_rate": 5.2605426904598356e-08,
      "loss": 0.2282,
      "step": 6009
    },
    {
      "epoch": 0.9552760724007073,
      "grad_norm": 0.6075279116630554,
      "learning_rate": 5.223365007810732e-08,
      "loss": 0.2455,
      "step": 6010
    },
    {
      "epoch": 0.9554350201664978,
      "grad_norm": 0.5533087253570557,
      "learning_rate": 5.186318474019181e-08,
      "loss": 0.185,
      "step": 6011
    },
    {
      "epoch": 0.9555939679322882,
      "grad_norm": 0.5233679413795471,
      "learning_rate": 5.1494030989049926e-08,
      "loss": 0.0758,
      "step": 6012
    },
    {
      "epoch": 0.9557529156980787,
      "grad_norm": 0.6591793894767761,
      "learning_rate": 5.1126188922532294e-08,
      "loss": 0.1762,
      "step": 6013
    },
    {
      "epoch": 0.9559118634638691,
      "grad_norm": 0.5288386940956116,
      "learning_rate": 5.075965863814092e-08,
      "loss": 0.1767,
      "step": 6014
    },
    {
      "epoch": 0.9560708112296596,
      "grad_norm": 0.6306567192077637,
      "learning_rate": 5.0394440233031975e-08,
      "loss": 0.2772,
      "step": 6015
    },
    {
      "epoch": 0.9562297589954502,
      "grad_norm": 0.5223923325538635,
      "learning_rate": 5.0030533804011905e-08,
      "loss": 0.2086,
      "step": 6016
    },
    {
      "epoch": 0.9563887067612405,
      "grad_norm": 0.6255812048912048,
      "learning_rate": 4.966793944754022e-08,
      "loss": 0.1898,
      "step": 6017
    },
    {
      "epoch": 0.956547654527031,
      "grad_norm": 0.5715478658676147,
      "learning_rate": 4.930665725972894e-08,
      "loss": 0.1401,
      "step": 6018
    },
    {
      "epoch": 0.9567066022928216,
      "grad_norm": 0.42647767066955566,
      "learning_rate": 4.894668733634145e-08,
      "loss": 0.0841,
      "step": 6019
    },
    {
      "epoch": 0.956865550058612,
      "grad_norm": 0.6244663000106812,
      "learning_rate": 4.8588029772794755e-08,
      "loss": 0.2244,
      "step": 6020
    },
    {
      "epoch": 0.9570244978244025,
      "grad_norm": 0.6520752906799316,
      "learning_rate": 4.823068466415615e-08,
      "loss": 0.1346,
      "step": 6021
    },
    {
      "epoch": 0.957183445590193,
      "grad_norm": 0.6752116680145264,
      "learning_rate": 4.7874652105146526e-08,
      "loss": 0.2076,
      "step": 6022
    },
    {
      "epoch": 0.9573423933559834,
      "grad_norm": 0.6353322267532349,
      "learning_rate": 4.7519932190138174e-08,
      "loss": 0.2621,
      "step": 6023
    },
    {
      "epoch": 0.9575013411217739,
      "grad_norm": 0.5948399901390076,
      "learning_rate": 4.716652501315533e-08,
      "loss": 0.2227,
      "step": 6024
    },
    {
      "epoch": 0.9576602888875643,
      "grad_norm": 0.4665481746196747,
      "learning_rate": 4.6814430667874166e-08,
      "loss": 0.1082,
      "step": 6025
    },
    {
      "epoch": 0.9578192366533548,
      "grad_norm": 0.6764541268348694,
      "learning_rate": 4.646364924762447e-08,
      "loss": 0.2685,
      "step": 6026
    },
    {
      "epoch": 0.9579781844191453,
      "grad_norm": 0.4883629381656647,
      "learning_rate": 4.611418084538577e-08,
      "loss": 0.1527,
      "step": 6027
    },
    {
      "epoch": 0.9581371321849357,
      "grad_norm": 0.6444650888442993,
      "learning_rate": 4.5766025553790616e-08,
      "loss": 0.2466,
      "step": 6028
    },
    {
      "epoch": 0.9582960799507262,
      "grad_norm": 0.566510796546936,
      "learning_rate": 4.5419183465123526e-08,
      "loss": 0.1782,
      "step": 6029
    },
    {
      "epoch": 0.9584550277165167,
      "grad_norm": 0.5683048367500305,
      "learning_rate": 4.5073654671320965e-08,
      "loss": 0.1949,
      "step": 6030
    },
    {
      "epoch": 0.9586139754823071,
      "grad_norm": 0.5883103609085083,
      "learning_rate": 4.472943926397078e-08,
      "loss": 0.2518,
      "step": 6031
    },
    {
      "epoch": 0.9587729232480976,
      "grad_norm": 0.5898303389549255,
      "learning_rate": 4.4386537334313303e-08,
      "loss": 0.247,
      "step": 6032
    },
    {
      "epoch": 0.9589318710138881,
      "grad_norm": 0.538709819316864,
      "learning_rate": 4.4044948973240855e-08,
      "loss": 0.1788,
      "step": 6033
    },
    {
      "epoch": 0.9590908187796785,
      "grad_norm": 2.6387243270874023,
      "learning_rate": 4.370467427129654e-08,
      "loss": 0.232,
      "step": 6034
    },
    {
      "epoch": 0.959249766545469,
      "grad_norm": 0.6120802760124207,
      "learning_rate": 4.336571331867601e-08,
      "loss": 0.227,
      "step": 6035
    },
    {
      "epoch": 0.9594087143112595,
      "grad_norm": 0.5733144879341125,
      "learning_rate": 4.302806620522681e-08,
      "loss": 0.1792,
      "step": 6036
    },
    {
      "epoch": 0.9595676620770499,
      "grad_norm": 0.6535589098930359,
      "learning_rate": 4.269173302044738e-08,
      "loss": 0.238,
      "step": 6037
    },
    {
      "epoch": 0.9597266098428404,
      "grad_norm": 0.5727499127388,
      "learning_rate": 4.235671385348916e-08,
      "loss": 0.2058,
      "step": 6038
    },
    {
      "epoch": 0.9598855576086308,
      "grad_norm": 0.7173056602478027,
      "learning_rate": 4.202300879315446e-08,
      "loss": 0.3674,
      "step": 6039
    },
    {
      "epoch": 0.9600445053744213,
      "grad_norm": 0.5529748201370239,
      "learning_rate": 4.169061792789697e-08,
      "loss": 0.2262,
      "step": 6040
    },
    {
      "epoch": 0.9602034531402118,
      "grad_norm": 0.6231774091720581,
      "learning_rate": 4.1359541345822877e-08,
      "loss": 0.1948,
      "step": 6041
    },
    {
      "epoch": 0.9603624009060022,
      "grad_norm": 0.660707414150238,
      "learning_rate": 4.1029779134690305e-08,
      "loss": 0.2168,
      "step": 6042
    },
    {
      "epoch": 0.9605213486717927,
      "grad_norm": 0.6799184083938599,
      "learning_rate": 4.0701331381906574e-08,
      "loss": 0.2272,
      "step": 6043
    },
    {
      "epoch": 0.9606802964375832,
      "grad_norm": 0.5560060143470764,
      "learning_rate": 4.03741981745337e-08,
      "loss": 0.1662,
      "step": 6044
    },
    {
      "epoch": 0.9608392442033736,
      "grad_norm": 0.47211188077926636,
      "learning_rate": 4.004837959928287e-08,
      "loss": 0.1499,
      "step": 6045
    },
    {
      "epoch": 0.9609981919691641,
      "grad_norm": 0.617865264415741,
      "learning_rate": 3.972387574251835e-08,
      "loss": 0.296,
      "step": 6046
    },
    {
      "epoch": 0.9611571397349546,
      "grad_norm": 0.5632998943328857,
      "learning_rate": 3.9400686690255205e-08,
      "loss": 0.2078,
      "step": 6047
    },
    {
      "epoch": 0.961316087500745,
      "grad_norm": 0.7541374564170837,
      "learning_rate": 3.907881252816048e-08,
      "loss": 0.2995,
      "step": 6048
    },
    {
      "epoch": 0.9614750352665355,
      "grad_norm": 0.5285220146179199,
      "learning_rate": 3.875825334155148e-08,
      "loss": 0.1518,
      "step": 6049
    },
    {
      "epoch": 0.9616339830323261,
      "grad_norm": 0.5353869199752808,
      "learning_rate": 3.8439009215398557e-08,
      "loss": 0.125,
      "step": 6050
    },
    {
      "epoch": 0.9617929307981165,
      "grad_norm": 0.7251685857772827,
      "learning_rate": 3.8121080234322374e-08,
      "loss": 0.2815,
      "step": 6051
    },
    {
      "epoch": 0.961951878563907,
      "grad_norm": 0.6651597619056702,
      "learning_rate": 3.78044664825955e-08,
      "loss": 0.2763,
      "step": 6052
    },
    {
      "epoch": 0.9621108263296974,
      "grad_norm": 0.534669041633606,
      "learning_rate": 3.7489168044141375e-08,
      "loss": 0.2023,
      "step": 6053
    },
    {
      "epoch": 0.9622697740954879,
      "grad_norm": 0.5469881296157837,
      "learning_rate": 3.717518500253592e-08,
      "loss": 0.1731,
      "step": 6054
    },
    {
      "epoch": 0.9624287218612784,
      "grad_norm": 0.5704291462898254,
      "learning_rate": 3.686251744100533e-08,
      "loss": 0.1855,
      "step": 6055
    },
    {
      "epoch": 0.9625876696270688,
      "grad_norm": 0.5560706257820129,
      "learning_rate": 3.6551165442426653e-08,
      "loss": 0.176,
      "step": 6056
    },
    {
      "epoch": 0.9627466173928593,
      "grad_norm": 0.5011825561523438,
      "learning_rate": 3.6241129089329416e-08,
      "loss": 0.1519,
      "step": 6057
    },
    {
      "epoch": 0.9629055651586498,
      "grad_norm": 0.6493728756904602,
      "learning_rate": 3.593240846389401e-08,
      "loss": 0.2282,
      "step": 6058
    },
    {
      "epoch": 0.9630645129244402,
      "grad_norm": 0.6069329977035522,
      "learning_rate": 3.562500364795218e-08,
      "loss": 0.2366,
      "step": 6059
    },
    {
      "epoch": 0.9632234606902307,
      "grad_norm": 0.5389962196350098,
      "learning_rate": 3.5318914722987096e-08,
      "loss": 0.1668,
      "step": 6060
    },
    {
      "epoch": 0.9633824084560212,
      "grad_norm": 0.6136285066604614,
      "learning_rate": 3.501414177013163e-08,
      "loss": 0.1307,
      "step": 6061
    },
    {
      "epoch": 0.9635413562218116,
      "grad_norm": 0.583102285861969,
      "learning_rate": 3.4710684870172264e-08,
      "loss": 0.228,
      "step": 6062
    },
    {
      "epoch": 0.9637003039876021,
      "grad_norm": 0.5142478942871094,
      "learning_rate": 3.4408544103544663e-08,
      "loss": 0.1608,
      "step": 6063
    },
    {
      "epoch": 0.9638592517533925,
      "grad_norm": 0.5499671697616577,
      "learning_rate": 3.410771955033587e-08,
      "loss": 0.2473,
      "step": 6064
    },
    {
      "epoch": 0.964018199519183,
      "grad_norm": 0.6619262099266052,
      "learning_rate": 3.3808211290284886e-08,
      "loss": 0.2416,
      "step": 6065
    },
    {
      "epoch": 0.9641771472849735,
      "grad_norm": 0.4746816158294678,
      "learning_rate": 3.351001940278209e-08,
      "loss": 0.1214,
      "step": 6066
    },
    {
      "epoch": 0.9643360950507639,
      "grad_norm": 0.6386532187461853,
      "learning_rate": 3.321314396686759e-08,
      "loss": 0.2641,
      "step": 6067
    },
    {
      "epoch": 0.9644950428165544,
      "grad_norm": 0.7347900867462158,
      "learning_rate": 3.291758506123288e-08,
      "loss": 0.116,
      "step": 6068
    },
    {
      "epoch": 0.9646539905823449,
      "grad_norm": 0.5486184358596802,
      "learning_rate": 3.262334276422141e-08,
      "loss": 0.2212,
      "step": 6069
    },
    {
      "epoch": 0.9648129383481353,
      "grad_norm": 0.6224411725997925,
      "learning_rate": 3.23304171538269e-08,
      "loss": 0.2397,
      "step": 6070
    },
    {
      "epoch": 0.9649718861139258,
      "grad_norm": 0.6094860434532166,
      "learning_rate": 3.20388083076939e-08,
      "loss": 0.2487,
      "step": 6071
    },
    {
      "epoch": 0.9651308338797163,
      "grad_norm": 0.6999749541282654,
      "learning_rate": 3.1748516303118926e-08,
      "loss": 0.2923,
      "step": 6072
    },
    {
      "epoch": 0.9652897816455067,
      "grad_norm": 0.6644551753997803,
      "learning_rate": 3.14595412170482e-08,
      "loss": 0.2838,
      "step": 6073
    },
    {
      "epoch": 0.9654487294112972,
      "grad_norm": 0.5943095088005066,
      "learning_rate": 3.117188312607933e-08,
      "loss": 0.269,
      "step": 6074
    },
    {
      "epoch": 0.9656076771770877,
      "grad_norm": 0.601154088973999,
      "learning_rate": 3.088554210646133e-08,
      "loss": 0.2335,
      "step": 6075
    },
    {
      "epoch": 0.9657666249428781,
      "grad_norm": 0.8032014966011047,
      "learning_rate": 3.0600518234092936e-08,
      "loss": 0.2646,
      "step": 6076
    },
    {
      "epoch": 0.9659255727086686,
      "grad_norm": 0.5128433704376221,
      "learning_rate": 3.0316811584525375e-08,
      "loss": 0.1252,
      "step": 6077
    },
    {
      "epoch": 0.966084520474459,
      "grad_norm": 0.5639660358428955,
      "learning_rate": 3.00344222329596e-08,
      "loss": 0.158,
      "step": 6078
    },
    {
      "epoch": 0.9662434682402495,
      "grad_norm": 0.4746869206428528,
      "learning_rate": 2.975335025424797e-08,
      "loss": 0.1255,
      "step": 6079
    },
    {
      "epoch": 0.96640241600604,
      "grad_norm": 0.6313459277153015,
      "learning_rate": 2.9473595722892546e-08,
      "loss": 0.2842,
      "step": 6080
    },
    {
      "epoch": 0.9665613637718304,
      "grad_norm": 1.1877467632293701,
      "learning_rate": 2.9195158713047345e-08,
      "loss": 0.1276,
      "step": 6081
    },
    {
      "epoch": 0.966720311537621,
      "grad_norm": 0.5709788203239441,
      "learning_rate": 2.891803929851722e-08,
      "loss": 0.2626,
      "step": 6082
    },
    {
      "epoch": 0.9668792593034115,
      "grad_norm": 0.5954764485359192,
      "learning_rate": 2.8642237552756746e-08,
      "loss": 0.2254,
      "step": 6083
    },
    {
      "epoch": 0.9670382070692018,
      "grad_norm": 0.5964211225509644,
      "learning_rate": 2.8367753548871335e-08,
      "loss": 0.1694,
      "step": 6084
    },
    {
      "epoch": 0.9671971548349924,
      "grad_norm": 0.6431143879890442,
      "learning_rate": 2.8094587359618897e-08,
      "loss": 0.2552,
      "step": 6085
    },
    {
      "epoch": 0.9673561026007829,
      "grad_norm": 0.6099144220352173,
      "learning_rate": 2.7822739057405957e-08,
      "loss": 0.2369,
      "step": 6086
    },
    {
      "epoch": 0.9675150503665733,
      "grad_norm": 0.5767268538475037,
      "learning_rate": 2.7552208714290428e-08,
      "loss": 0.2064,
      "step": 6087
    },
    {
      "epoch": 0.9676739981323638,
      "grad_norm": 0.7065362930297852,
      "learning_rate": 2.7282996401981067e-08,
      "loss": 0.2327,
      "step": 6088
    },
    {
      "epoch": 0.9678329458981543,
      "grad_norm": 0.7673761248588562,
      "learning_rate": 2.701510219183745e-08,
      "loss": 0.3522,
      "step": 6089
    },
    {
      "epoch": 0.9679918936639447,
      "grad_norm": 0.6004851460456848,
      "learning_rate": 2.674852615486889e-08,
      "loss": 0.2148,
      "step": 6090
    },
    {
      "epoch": 0.9681508414297352,
      "grad_norm": 0.5676980018615723,
      "learning_rate": 2.6483268361736093e-08,
      "loss": 0.1784,
      "step": 6091
    },
    {
      "epoch": 0.9683097891955256,
      "grad_norm": 0.6144287586212158,
      "learning_rate": 2.6219328882749475e-08,
      "loss": 0.2809,
      "step": 6092
    },
    {
      "epoch": 0.9684687369613161,
      "grad_norm": 0.5935353636741638,
      "learning_rate": 2.595670778787196e-08,
      "loss": 0.208,
      "step": 6093
    },
    {
      "epoch": 0.9686276847271066,
      "grad_norm": 0.5687280297279358,
      "learning_rate": 2.5695405146714537e-08,
      "loss": 0.207,
      "step": 6094
    },
    {
      "epoch": 0.968786632492897,
      "grad_norm": 0.6116154789924622,
      "learning_rate": 2.543542102854013e-08,
      "loss": 0.2545,
      "step": 6095
    },
    {
      "epoch": 0.9689455802586875,
      "grad_norm": 0.5903085470199585,
      "learning_rate": 2.5176755502262505e-08,
      "loss": 0.2303,
      "step": 6096
    },
    {
      "epoch": 0.969104528024478,
      "grad_norm": 0.47081175446510315,
      "learning_rate": 2.4919408636444596e-08,
      "loss": 0.1312,
      "step": 6097
    },
    {
      "epoch": 0.9692634757902684,
      "grad_norm": 0.6563540697097778,
      "learning_rate": 2.4663380499300726e-08,
      "loss": 0.2608,
      "step": 6098
    },
    {
      "epoch": 0.9694224235560589,
      "grad_norm": 0.5474043488502502,
      "learning_rate": 2.4408671158695495e-08,
      "loss": 0.1829,
      "step": 6099
    },
    {
      "epoch": 0.9695813713218494,
      "grad_norm": 0.6005026698112488,
      "learning_rate": 2.415528068214379e-08,
      "loss": 0.2324,
      "step": 6100
    },
    {
      "epoch": 0.9697403190876398,
      "grad_norm": 0.6175879836082458,
      "learning_rate": 2.390320913681077e-08,
      "loss": 0.2114,
      "step": 6101
    },
    {
      "epoch": 0.9698992668534303,
      "grad_norm": 0.7975525856018066,
      "learning_rate": 2.3652456589512983e-08,
      "loss": 0.269,
      "step": 6102
    },
    {
      "epoch": 0.9700582146192207,
      "grad_norm": 0.5270713567733765,
      "learning_rate": 2.340302310671616e-08,
      "loss": 0.1856,
      "step": 6103
    },
    {
      "epoch": 0.9702171623850112,
      "grad_norm": 0.5971087217330933,
      "learning_rate": 2.3154908754536852e-08,
      "loss": 0.2419,
      "step": 6104
    },
    {
      "epoch": 0.9703761101508017,
      "grad_norm": 0.6323041915893555,
      "learning_rate": 2.2908113598741344e-08,
      "loss": 0.2206,
      "step": 6105
    },
    {
      "epoch": 0.9705350579165921,
      "grad_norm": 0.8235565423965454,
      "learning_rate": 2.266263770474786e-08,
      "loss": 0.3139,
      "step": 6106
    },
    {
      "epoch": 0.9706940056823826,
      "grad_norm": 0.6457856297492981,
      "learning_rate": 2.2418481137623793e-08,
      "loss": 0.249,
      "step": 6107
    },
    {
      "epoch": 0.9708529534481731,
      "grad_norm": 0.6240760087966919,
      "learning_rate": 2.2175643962085712e-08,
      "loss": 0.2458,
      "step": 6108
    },
    {
      "epoch": 0.9710119012139635,
      "grad_norm": 0.5680970549583435,
      "learning_rate": 2.193412624250324e-08,
      "loss": 0.2018,
      "step": 6109
    },
    {
      "epoch": 0.971170848979754,
      "grad_norm": 0.643031895160675,
      "learning_rate": 2.1693928042894052e-08,
      "loss": 0.3302,
      "step": 6110
    },
    {
      "epoch": 0.9713297967455445,
      "grad_norm": 0.614176869392395,
      "learning_rate": 2.1455049426926666e-08,
      "loss": 0.2544,
      "step": 6111
    },
    {
      "epoch": 0.9714887445113349,
      "grad_norm": 0.5496387481689453,
      "learning_rate": 2.1217490457919876e-08,
      "loss": 0.2332,
      "step": 6112
    },
    {
      "epoch": 0.9716476922771254,
      "grad_norm": 0.6085795760154724,
      "learning_rate": 2.0981251198842756e-08,
      "loss": 0.1437,
      "step": 6113
    },
    {
      "epoch": 0.971806640042916,
      "grad_norm": 0.5716191530227661,
      "learning_rate": 2.0746331712314106e-08,
      "loss": 0.1654,
      "step": 6114
    },
    {
      "epoch": 0.9719655878087063,
      "grad_norm": 0.5348349213600159,
      "learning_rate": 2.0512732060604113e-08,
      "loss": 0.1918,
      "step": 6115
    },
    {
      "epoch": 0.9721245355744969,
      "grad_norm": 1.1497946977615356,
      "learning_rate": 2.0280452305631582e-08,
      "loss": 0.2108,
      "step": 6116
    },
    {
      "epoch": 0.9722834833402872,
      "grad_norm": 2.3983047008514404,
      "learning_rate": 2.004949250896615e-08,
      "loss": 0.0939,
      "step": 6117
    },
    {
      "epoch": 0.9724424311060778,
      "grad_norm": 0.6377684473991394,
      "learning_rate": 1.9819852731828294e-08,
      "loss": 0.3202,
      "step": 6118
    },
    {
      "epoch": 0.9726013788718683,
      "grad_norm": 0.698045015335083,
      "learning_rate": 1.9591533035087097e-08,
      "loss": 0.3611,
      "step": 6119
    },
    {
      "epoch": 0.9727603266376587,
      "grad_norm": 0.4693402647972107,
      "learning_rate": 1.9364533479263036e-08,
      "loss": 0.0877,
      "step": 6120
    },
    {
      "epoch": 0.9729192744034492,
      "grad_norm": 0.564551830291748,
      "learning_rate": 1.9138854124525765e-08,
      "loss": 0.2089,
      "step": 6121
    },
    {
      "epoch": 0.9730782221692397,
      "grad_norm": 0.6100526452064514,
      "learning_rate": 1.8914495030695755e-08,
      "loss": 0.233,
      "step": 6122
    },
    {
      "epoch": 0.9732371699350301,
      "grad_norm": 0.5963647365570068,
      "learning_rate": 1.8691456257243223e-08,
      "loss": 0.2231,
      "step": 6123
    },
    {
      "epoch": 0.9733961177008206,
      "grad_norm": 0.7759073972702026,
      "learning_rate": 1.846973786328754e-08,
      "loss": 0.2678,
      "step": 6124
    },
    {
      "epoch": 0.9735550654666111,
      "grad_norm": 0.6674140095710754,
      "learning_rate": 1.8249339907600027e-08,
      "loss": 0.3301,
      "step": 6125
    },
    {
      "epoch": 0.9737140132324015,
      "grad_norm": 0.5586940050125122,
      "learning_rate": 1.8030262448600068e-08,
      "loss": 0.1614,
      "step": 6126
    },
    {
      "epoch": 0.973872960998192,
      "grad_norm": 0.5679897665977478,
      "learning_rate": 1.7812505544357873e-08,
      "loss": 0.2008,
      "step": 6127
    },
    {
      "epoch": 0.9740319087639825,
      "grad_norm": 0.5939606428146362,
      "learning_rate": 1.7596069252594496e-08,
      "loss": 0.2256,
      "step": 6128
    },
    {
      "epoch": 0.9741908565297729,
      "grad_norm": 0.5225945115089417,
      "learning_rate": 1.7380953630678488e-08,
      "loss": 0.1416,
      "step": 6129
    },
    {
      "epoch": 0.9743498042955634,
      "grad_norm": 0.6842223405838013,
      "learning_rate": 1.7167158735630908e-08,
      "loss": 0.354,
      "step": 6130
    },
    {
      "epoch": 0.9745087520613538,
      "grad_norm": 0.5841791033744812,
      "learning_rate": 1.695468462412142e-08,
      "loss": 0.2322,
      "step": 6131
    },
    {
      "epoch": 0.9746676998271443,
      "grad_norm": 0.5570619106292725,
      "learning_rate": 1.6743531352469977e-08,
      "loss": 0.2057,
      "step": 6132
    },
    {
      "epoch": 0.9748266475929348,
      "grad_norm": 1.2103185653686523,
      "learning_rate": 1.6533698976645695e-08,
      "loss": 0.1661,
      "step": 6133
    },
    {
      "epoch": 0.9749855953587252,
      "grad_norm": 0.6735875010490417,
      "learning_rate": 1.6325187552269084e-08,
      "loss": 0.3221,
      "step": 6134
    },
    {
      "epoch": 0.9751445431245157,
      "grad_norm": 0.6510778069496155,
      "learning_rate": 1.6117997134609263e-08,
      "loss": 0.2718,
      "step": 6135
    },
    {
      "epoch": 0.9753034908903062,
      "grad_norm": 0.5227544903755188,
      "learning_rate": 1.5912127778585086e-08,
      "loss": 0.1487,
      "step": 6136
    },
    {
      "epoch": 0.9754624386560966,
      "grad_norm": 0.5207587480545044,
      "learning_rate": 1.5707579538766227e-08,
      "loss": 0.1684,
      "step": 6137
    },
    {
      "epoch": 0.9756213864218871,
      "grad_norm": 0.6968748569488525,
      "learning_rate": 1.5504352469371543e-08,
      "loss": 0.1923,
      "step": 6138
    },
    {
      "epoch": 0.9757803341876776,
      "grad_norm": 0.5572572350502014,
      "learning_rate": 1.5302446624269605e-08,
      "loss": 0.2311,
      "step": 6139
    },
    {
      "epoch": 0.975939281953468,
      "grad_norm": 0.6526645421981812,
      "learning_rate": 1.5101862056978723e-08,
      "loss": 0.2552,
      "step": 6140
    },
    {
      "epoch": 0.9760982297192585,
      "grad_norm": 0.5722535252571106,
      "learning_rate": 1.4902598820668023e-08,
      "loss": 0.2018,
      "step": 6141
    },
    {
      "epoch": 0.9762571774850489,
      "grad_norm": 0.532094419002533,
      "learning_rate": 1.4704656968154708e-08,
      "loss": 0.1379,
      "step": 6142
    },
    {
      "epoch": 0.9764161252508394,
      "grad_norm": 0.6586899161338806,
      "learning_rate": 1.4508036551906801e-08,
      "loss": 0.3654,
      "step": 6143
    },
    {
      "epoch": 0.9765750730166299,
      "grad_norm": 0.6356963515281677,
      "learning_rate": 1.4312737624042062e-08,
      "loss": 0.284,
      "step": 6144
    },
    {
      "epoch": 0.9767340207824203,
      "grad_norm": 0.5901169776916504,
      "learning_rate": 1.4118760236327966e-08,
      "loss": 0.2196,
      "step": 6145
    },
    {
      "epoch": 0.9768929685482108,
      "grad_norm": 0.5849719643592834,
      "learning_rate": 1.3926104440181165e-08,
      "loss": 0.1709,
      "step": 6146
    },
    {
      "epoch": 0.9770519163140013,
      "grad_norm": 0.5625726580619812,
      "learning_rate": 1.373477028666803e-08,
      "loss": 0.2184,
      "step": 6147
    },
    {
      "epoch": 0.9772108640797917,
      "grad_norm": 0.5783213973045349,
      "learning_rate": 1.3544757826505216e-08,
      "loss": 0.1946,
      "step": 6148
    },
    {
      "epoch": 0.9773698118455822,
      "grad_norm": 0.5679669380187988,
      "learning_rate": 1.33560671100591e-08,
      "loss": 0.2206,
      "step": 6149
    },
    {
      "epoch": 0.9775287596113728,
      "grad_norm": 0.647891640663147,
      "learning_rate": 1.3168698187344674e-08,
      "loss": 0.3212,
      "step": 6150
    },
    {
      "epoch": 0.9776877073771632,
      "grad_norm": 0.6474673748016357,
      "learning_rate": 1.2982651108027211e-08,
      "loss": 0.2416,
      "step": 6151
    },
    {
      "epoch": 0.9778466551429537,
      "grad_norm": 0.7178419232368469,
      "learning_rate": 1.279792592142226e-08,
      "loss": 0.278,
      "step": 6152
    },
    {
      "epoch": 0.9780056029087442,
      "grad_norm": 0.6931488513946533,
      "learning_rate": 1.2614522676493435e-08,
      "loss": 0.3849,
      "step": 6153
    },
    {
      "epoch": 0.9781645506745346,
      "grad_norm": 1.7166179418563843,
      "learning_rate": 1.2432441421855735e-08,
      "loss": 0.1773,
      "step": 6154
    },
    {
      "epoch": 0.9783234984403251,
      "grad_norm": 0.6229935884475708,
      "learning_rate": 1.2251682205772775e-08,
      "loss": 0.2597,
      "step": 6155
    },
    {
      "epoch": 0.9784824462061155,
      "grad_norm": 0.5528509616851807,
      "learning_rate": 1.2072245076156786e-08,
      "loss": 0.1853,
      "step": 6156
    },
    {
      "epoch": 0.978641393971906,
      "grad_norm": 0.4959483742713928,
      "learning_rate": 1.1894130080571942e-08,
      "loss": 0.1284,
      "step": 6157
    },
    {
      "epoch": 0.9788003417376965,
      "grad_norm": 0.6790298223495483,
      "learning_rate": 1.1717337266229367e-08,
      "loss": 0.2937,
      "step": 6158
    },
    {
      "epoch": 0.9789592895034869,
      "grad_norm": 0.6645418405532837,
      "learning_rate": 1.1541866679992131e-08,
      "loss": 0.3314,
      "step": 6159
    },
    {
      "epoch": 0.9791182372692774,
      "grad_norm": 0.46984854340553284,
      "learning_rate": 1.136771836837136e-08,
      "loss": 0.1231,
      "step": 6160
    },
    {
      "epoch": 0.9792771850350679,
      "grad_norm": 0.6752116084098816,
      "learning_rate": 1.1194892377527355e-08,
      "loss": 0.2787,
      "step": 6161
    },
    {
      "epoch": 0.9794361328008583,
      "grad_norm": 0.45551925897598267,
      "learning_rate": 1.1023388753270692e-08,
      "loss": 0.102,
      "step": 6162
    },
    {
      "epoch": 0.9795950805666488,
      "grad_norm": 0.6350070238113403,
      "learning_rate": 1.0853207541061672e-08,
      "loss": 0.2305,
      "step": 6163
    },
    {
      "epoch": 0.9797540283324393,
      "grad_norm": 0.6176276803016663,
      "learning_rate": 1.0684348786009769e-08,
      "loss": 0.1787,
      "step": 6164
    },
    {
      "epoch": 0.9799129760982297,
      "grad_norm": 0.5372783541679382,
      "learning_rate": 1.0516812532873622e-08,
      "loss": 0.1791,
      "step": 6165
    },
    {
      "epoch": 0.9800719238640202,
      "grad_norm": 0.6466304659843445,
      "learning_rate": 1.0350598826061598e-08,
      "loss": 0.2266,
      "step": 6166
    },
    {
      "epoch": 0.9802308716298107,
      "grad_norm": 0.592513918876648,
      "learning_rate": 1.0185707709631232e-08,
      "loss": 0.2287,
      "step": 6167
    },
    {
      "epoch": 0.9803898193956011,
      "grad_norm": 0.5556148886680603,
      "learning_rate": 1.0022139227289784e-08,
      "loss": 0.2201,
      "step": 6168
    },
    {
      "epoch": 0.9805487671613916,
      "grad_norm": 0.5741563439369202,
      "learning_rate": 9.85989342239424e-09,
      "loss": 0.1903,
      "step": 6169
    },
    {
      "epoch": 0.980707714927182,
      "grad_norm": 0.5764386653900146,
      "learning_rate": 9.698970337949642e-09,
      "loss": 0.1912,
      "step": 6170
    },
    {
      "epoch": 0.9808666626929725,
      "grad_norm": 0.6045875549316406,
      "learning_rate": 9.53937001661187e-09,
      "loss": 0.2198,
      "step": 6171
    },
    {
      "epoch": 0.981025610458763,
      "grad_norm": 0.5454893708229065,
      "learning_rate": 9.381092500685974e-09,
      "loss": 0.2002,
      "step": 6172
    },
    {
      "epoch": 0.9811845582245534,
      "grad_norm": 0.6559426188468933,
      "learning_rate": 9.224137832126168e-09,
      "loss": 0.2631,
      "step": 6173
    },
    {
      "epoch": 0.9813435059903439,
      "grad_norm": 0.5718615055084229,
      "learning_rate": 9.068506052534732e-09,
      "loss": 0.1842,
      "step": 6174
    },
    {
      "epoch": 0.9815024537561344,
      "grad_norm": 0.5373934507369995,
      "learning_rate": 8.914197203165886e-09,
      "loss": 0.1686,
      "step": 6175
    },
    {
      "epoch": 0.9816614015219248,
      "grad_norm": 0.5574659109115601,
      "learning_rate": 8.761211324920804e-09,
      "loss": 0.1905,
      "step": 6176
    },
    {
      "epoch": 0.9818203492877153,
      "grad_norm": 0.6125251054763794,
      "learning_rate": 8.609548458351492e-09,
      "loss": 0.2579,
      "step": 6177
    },
    {
      "epoch": 0.9819792970535058,
      "grad_norm": 0.6762794256210327,
      "learning_rate": 8.459208643659122e-09,
      "loss": 0.2329,
      "step": 6178
    },
    {
      "epoch": 0.9821382448192962,
      "grad_norm": 0.5895337462425232,
      "learning_rate": 8.310191920692933e-09,
      "loss": 0.2401,
      "step": 6179
    },
    {
      "epoch": 0.9822971925850867,
      "grad_norm": 0.45299091935157776,
      "learning_rate": 8.162498328952439e-09,
      "loss": 0.122,
      "step": 6180
    },
    {
      "epoch": 0.9824561403508771,
      "grad_norm": 0.5137027502059937,
      "learning_rate": 8.016127907586879e-09,
      "loss": 0.1433,
      "step": 6181
    },
    {
      "epoch": 0.9826150881166676,
      "grad_norm": 0.5872660279273987,
      "learning_rate": 7.871080695393551e-09,
      "loss": 0.1757,
      "step": 6182
    },
    {
      "epoch": 0.9827740358824582,
      "grad_norm": 0.6181851029396057,
      "learning_rate": 7.727356730820035e-09,
      "loss": 0.2126,
      "step": 6183
    },
    {
      "epoch": 0.9829329836482485,
      "grad_norm": 0.5806825160980225,
      "learning_rate": 7.584956051962522e-09,
      "loss": 0.1554,
      "step": 6184
    },
    {
      "epoch": 0.983091931414039,
      "grad_norm": 0.6255704760551453,
      "learning_rate": 7.4438786965669305e-09,
      "loss": 0.2634,
      "step": 6185
    },
    {
      "epoch": 0.9832508791798296,
      "grad_norm": 0.5168105959892273,
      "learning_rate": 7.304124702028348e-09,
      "loss": 0.1331,
      "step": 6186
    },
    {
      "epoch": 0.98340982694562,
      "grad_norm": 1.3513208627700806,
      "learning_rate": 7.165694105390475e-09,
      "loss": 0.2012,
      "step": 6187
    },
    {
      "epoch": 0.9835687747114105,
      "grad_norm": 0.652400016784668,
      "learning_rate": 7.028586943346738e-09,
      "loss": 0.1907,
      "step": 6188
    },
    {
      "epoch": 0.983727722477201,
      "grad_norm": 0.6600069403648376,
      "learning_rate": 6.892803252240287e-09,
      "loss": 0.2198,
      "step": 6189
    },
    {
      "epoch": 0.9838866702429914,
      "grad_norm": 0.5850692391395569,
      "learning_rate": 6.758343068061779e-09,
      "loss": 0.2456,
      "step": 6190
    },
    {
      "epoch": 0.9840456180087819,
      "grad_norm": 0.5807332396507263,
      "learning_rate": 6.625206426453257e-09,
      "loss": 0.1841,
      "step": 6191
    },
    {
      "epoch": 0.9842045657745724,
      "grad_norm": 0.6241579651832581,
      "learning_rate": 6.49339336270427e-09,
      "loss": 0.2308,
      "step": 6192
    },
    {
      "epoch": 0.9843635135403628,
      "grad_norm": 0.6687770485877991,
      "learning_rate": 6.362903911754092e-09,
      "loss": 0.2652,
      "step": 6193
    },
    {
      "epoch": 0.9845224613061533,
      "grad_norm": 0.559242844581604,
      "learning_rate": 6.2337381081911674e-09,
      "loss": 0.1125,
      "step": 6194
    },
    {
      "epoch": 0.9846814090719437,
      "grad_norm": 0.6495649814605713,
      "learning_rate": 6.105895986253108e-09,
      "loss": 0.136,
      "step": 6195
    },
    {
      "epoch": 0.9848403568377342,
      "grad_norm": 0.568026602268219,
      "learning_rate": 5.979377579826695e-09,
      "loss": 0.1999,
      "step": 6196
    },
    {
      "epoch": 0.9849993046035247,
      "grad_norm": 0.5901483297348022,
      "learning_rate": 5.854182922447882e-09,
      "loss": 0.2312,
      "step": 6197
    },
    {
      "epoch": 0.9851582523693151,
      "grad_norm": 0.5244900584220886,
      "learning_rate": 5.730312047301234e-09,
      "loss": 0.151,
      "step": 6198
    },
    {
      "epoch": 0.9853172001351056,
      "grad_norm": 0.5461331009864807,
      "learning_rate": 5.607764987221043e-09,
      "loss": 0.1691,
      "step": 6199
    },
    {
      "epoch": 0.9854761479008961,
      "grad_norm": 0.697554349899292,
      "learning_rate": 5.486541774690213e-09,
      "loss": 0.2078,
      "step": 6200
    },
    {
      "epoch": 0.9856350956666865,
      "grad_norm": 0.7255027294158936,
      "learning_rate": 5.366642441841374e-09,
      "loss": 0.2801,
      "step": 6201
    },
    {
      "epoch": 0.985794043432477,
      "grad_norm": 0.5731355547904968,
      "learning_rate": 5.248067020455771e-09,
      "loss": 0.1769,
      "step": 6202
    },
    {
      "epoch": 0.9859529911982675,
      "grad_norm": 0.5951522588729858,
      "learning_rate": 5.1308155419638184e-09,
      "loss": 0.1691,
      "step": 6203
    },
    {
      "epoch": 0.9861119389640579,
      "grad_norm": 0.6392390727996826,
      "learning_rate": 5.014888037444543e-09,
      "loss": 0.2877,
      "step": 6204
    },
    {
      "epoch": 0.9862708867298484,
      "grad_norm": 0.7379722595214844,
      "learning_rate": 4.900284537626698e-09,
      "loss": 0.1272,
      "step": 6205
    },
    {
      "epoch": 0.9864298344956389,
      "grad_norm": 0.8515641689300537,
      "learning_rate": 4.787005072888207e-09,
      "loss": 0.1839,
      "step": 6206
    },
    {
      "epoch": 0.9865887822614293,
      "grad_norm": 0.6573711037635803,
      "learning_rate": 4.675049673255605e-09,
      "loss": 0.2587,
      "step": 6207
    },
    {
      "epoch": 0.9867477300272198,
      "grad_norm": 1.0769315958023071,
      "learning_rate": 4.5644183684040446e-09,
      "loss": 0.1043,
      "step": 6208
    },
    {
      "epoch": 0.9869066777930102,
      "grad_norm": 0.5307577848434448,
      "learning_rate": 4.455111187658956e-09,
      "loss": 0.1715,
      "step": 6209
    },
    {
      "epoch": 0.9870656255588007,
      "grad_norm": 2.3527708053588867,
      "learning_rate": 4.347128159993829e-09,
      "loss": 0.2373,
      "step": 6210
    },
    {
      "epoch": 0.9872245733245912,
      "grad_norm": 0.5449434518814087,
      "learning_rate": 4.240469314030771e-09,
      "loss": 0.2174,
      "step": 6211
    },
    {
      "epoch": 0.9873835210903816,
      "grad_norm": 0.5900614857673645,
      "learning_rate": 4.135134678042163e-09,
      "loss": 0.2312,
      "step": 6212
    },
    {
      "epoch": 0.9875424688561721,
      "grad_norm": 0.5429792404174805,
      "learning_rate": 4.031124279948451e-09,
      "loss": 0.1592,
      "step": 6213
    },
    {
      "epoch": 0.9877014166219626,
      "grad_norm": 0.5004132986068726,
      "learning_rate": 3.928438147319247e-09,
      "loss": 0.165,
      "step": 6214
    },
    {
      "epoch": 0.987860364387753,
      "grad_norm": 0.5619422793388367,
      "learning_rate": 3.82707630737389e-09,
      "loss": 0.1722,
      "step": 6215
    },
    {
      "epoch": 0.9880193121535435,
      "grad_norm": 0.4739964008331299,
      "learning_rate": 3.727038786978665e-09,
      "loss": 0.124,
      "step": 6216
    },
    {
      "epoch": 0.9881782599193341,
      "grad_norm": 0.5786401629447937,
      "learning_rate": 3.6283256126518063e-09,
      "loss": 0.1833,
      "step": 6217
    },
    {
      "epoch": 0.9883372076851245,
      "grad_norm": 2.400120973587036,
      "learning_rate": 3.530936810557939e-09,
      "loss": 0.1928,
      "step": 6218
    },
    {
      "epoch": 0.988496155450915,
      "grad_norm": 0.5959671139717102,
      "learning_rate": 3.4348724065119687e-09,
      "loss": 0.2384,
      "step": 6219
    },
    {
      "epoch": 0.9886551032167054,
      "grad_norm": 0.5958523750305176,
      "learning_rate": 3.3401324259768607e-09,
      "loss": 0.2271,
      "step": 6220
    },
    {
      "epoch": 0.9888140509824959,
      "grad_norm": 0.6262861490249634,
      "learning_rate": 3.24671689406586e-09,
      "loss": 0.2329,
      "step": 6221
    },
    {
      "epoch": 0.9889729987482864,
      "grad_norm": 0.509164035320282,
      "learning_rate": 3.154625835539715e-09,
      "loss": 0.129,
      "step": 6222
    },
    {
      "epoch": 0.9891319465140768,
      "grad_norm": 0.6374543309211731,
      "learning_rate": 3.0638592748089e-09,
      "loss": 0.2274,
      "step": 6223
    },
    {
      "epoch": 0.9892908942798673,
      "grad_norm": 0.5330493450164795,
      "learning_rate": 2.974417235932503e-09,
      "loss": 0.1436,
      "step": 6224
    },
    {
      "epoch": 0.9894498420456578,
      "grad_norm": 0.6301711201667786,
      "learning_rate": 2.886299742618226e-09,
      "loss": 0.2443,
      "step": 6225
    },
    {
      "epoch": 0.9896087898114482,
      "grad_norm": 0.6797201633453369,
      "learning_rate": 2.7995068182246064e-09,
      "loss": 0.2931,
      "step": 6226
    },
    {
      "epoch": 0.9897677375772387,
      "grad_norm": 0.4932902157306671,
      "learning_rate": 2.7140384857554657e-09,
      "loss": 0.1687,
      "step": 6227
    },
    {
      "epoch": 0.9899266853430292,
      "grad_norm": 0.6040745973587036,
      "learning_rate": 2.62989476786768e-09,
      "loss": 0.2093,
      "step": 6228
    },
    {
      "epoch": 0.9900856331088196,
      "grad_norm": 1.4134999513626099,
      "learning_rate": 2.5470756868634096e-09,
      "loss": 0.226,
      "step": 6229
    },
    {
      "epoch": 0.9902445808746101,
      "grad_norm": 0.5622237920761108,
      "learning_rate": 2.465581264695649e-09,
      "loss": 0.165,
      "step": 6230
    },
    {
      "epoch": 0.9904035286404006,
      "grad_norm": 0.6072794795036316,
      "learning_rate": 2.385411522966563e-09,
      "loss": 0.1725,
      "step": 6231
    },
    {
      "epoch": 0.990562476406191,
      "grad_norm": 0.6394106149673462,
      "learning_rate": 2.3065664829252654e-09,
      "loss": 0.2949,
      "step": 6232
    },
    {
      "epoch": 0.9907214241719815,
      "grad_norm": 0.6047061681747437,
      "learning_rate": 2.2290461654722594e-09,
      "loss": 0.2081,
      "step": 6233
    },
    {
      "epoch": 0.9908803719377719,
      "grad_norm": 0.7499260902404785,
      "learning_rate": 2.152850591154998e-09,
      "loss": 0.2828,
      "step": 6234
    },
    {
      "epoch": 0.9910393197035624,
      "grad_norm": 0.5345280766487122,
      "learning_rate": 2.077979780170103e-09,
      "loss": 0.1606,
      "step": 6235
    },
    {
      "epoch": 0.9911982674693529,
      "grad_norm": 0.5206522941589355,
      "learning_rate": 2.004433752363366e-09,
      "loss": 0.1383,
      "step": 6236
    },
    {
      "epoch": 0.9913572152351433,
      "grad_norm": 0.5099197626113892,
      "learning_rate": 1.9322125272297488e-09,
      "loss": 0.1521,
      "step": 6237
    },
    {
      "epoch": 0.9915161630009338,
      "grad_norm": 0.7277432084083557,
      "learning_rate": 1.8613161239128263e-09,
      "loss": 0.2786,
      "step": 6238
    },
    {
      "epoch": 0.9916751107667243,
      "grad_norm": 0.6437929272651672,
      "learning_rate": 1.791744561204789e-09,
      "loss": 0.2993,
      "step": 6239
    },
    {
      "epoch": 0.9918340585325147,
      "grad_norm": 0.577767014503479,
      "learning_rate": 1.7234978575464411e-09,
      "loss": 0.1671,
      "step": 6240
    },
    {
      "epoch": 0.9919930062983052,
      "grad_norm": 1.1975878477096558,
      "learning_rate": 1.6565760310277568e-09,
      "loss": 0.2481,
      "step": 6241
    },
    {
      "epoch": 0.9921519540640957,
      "grad_norm": 0.6274316906929016,
      "learning_rate": 1.5909790993878793e-09,
      "loss": 0.2779,
      "step": 6242
    },
    {
      "epoch": 0.9923109018298861,
      "grad_norm": 0.556292712688446,
      "learning_rate": 1.5267070800140116e-09,
      "loss": 0.1935,
      "step": 6243
    },
    {
      "epoch": 0.9924698495956766,
      "grad_norm": 0.5060172080993652,
      "learning_rate": 1.463759989943081e-09,
      "loss": 0.1227,
      "step": 6244
    },
    {
      "epoch": 0.9926287973614671,
      "grad_norm": 0.6030095219612122,
      "learning_rate": 1.402137845858964e-09,
      "loss": 0.1701,
      "step": 6245
    },
    {
      "epoch": 0.9927877451272575,
      "grad_norm": 0.5856626629829407,
      "learning_rate": 1.3418406640969272e-09,
      "loss": 0.1895,
      "step": 6246
    },
    {
      "epoch": 0.992946692893048,
      "grad_norm": 0.5988450050354004,
      "learning_rate": 1.2828684606397412e-09,
      "loss": 0.2801,
      "step": 6247
    },
    {
      "epoch": 0.9931056406588384,
      "grad_norm": 0.6693652868270874,
      "learning_rate": 1.225221251118236e-09,
      "loss": 0.2199,
      "step": 6248
    },
    {
      "epoch": 0.993264588424629,
      "grad_norm": 0.6184322237968445,
      "learning_rate": 1.168899050812966e-09,
      "loss": 0.2126,
      "step": 6249
    },
    {
      "epoch": 0.9934235361904195,
      "grad_norm": 0.8174020051956177,
      "learning_rate": 1.1139018746536556e-09,
      "loss": 0.255,
      "step": 6250
    },
    {
      "epoch": 0.9935824839562098,
      "grad_norm": 0.6208107471466064,
      "learning_rate": 1.0602297372169778e-09,
      "loss": 0.2399,
      "step": 6251
    },
    {
      "epoch": 0.9937414317220004,
      "grad_norm": 0.6055753827095032,
      "learning_rate": 1.007882652730996e-09,
      "loss": 0.2673,
      "step": 6252
    },
    {
      "epoch": 0.9939003794877909,
      "grad_norm": 0.6265192627906799,
      "learning_rate": 9.56860635070722e-10,
      "loss": 0.1864,
      "step": 6253
    },
    {
      "epoch": 0.9940593272535813,
      "grad_norm": 0.6490647196769714,
      "learning_rate": 9.071636977603382e-10,
      "loss": 0.186,
      "step": 6254
    },
    {
      "epoch": 0.9942182750193718,
      "grad_norm": 0.5040691494941711,
      "learning_rate": 8.587918539726403e-10,
      "loss": 0.1306,
      "step": 6255
    },
    {
      "epoch": 0.9943772227851623,
      "grad_norm": 0.5996784567832947,
      "learning_rate": 8.117451165301493e-10,
      "loss": 0.2112,
      "step": 6256
    },
    {
      "epoch": 0.9945361705509527,
      "grad_norm": 0.63359135389328,
      "learning_rate": 7.660234979023351e-10,
      "loss": 0.1972,
      "step": 6257
    },
    {
      "epoch": 0.9946951183167432,
      "grad_norm": 0.5125207901000977,
      "learning_rate": 7.216270102089473e-10,
      "loss": 0.1708,
      "step": 6258
    },
    {
      "epoch": 0.9948540660825336,
      "grad_norm": 0.5970312356948853,
      "learning_rate": 6.785556652177949e-10,
      "loss": 0.2191,
      "step": 6259
    },
    {
      "epoch": 0.9950130138483241,
      "grad_norm": 0.5121725797653198,
      "learning_rate": 6.368094743464114e-10,
      "loss": 0.1308,
      "step": 6260
    },
    {
      "epoch": 0.9951719616141146,
      "grad_norm": 0.6854589581489563,
      "learning_rate": 5.963884486598348e-10,
      "loss": 0.1869,
      "step": 6261
    },
    {
      "epoch": 0.995330909379905,
      "grad_norm": 0.5127755403518677,
      "learning_rate": 5.572925988722721e-10,
      "loss": 0.1414,
      "step": 6262
    },
    {
      "epoch": 0.9954898571456955,
      "grad_norm": 0.5282209515571594,
      "learning_rate": 5.195219353465453e-10,
      "loss": 0.1739,
      "step": 6263
    },
    {
      "epoch": 0.995648804911486,
      "grad_norm": 0.613673985004425,
      "learning_rate": 4.830764680946453e-10,
      "loss": 0.2091,
      "step": 6264
    },
    {
      "epoch": 0.9958077526772764,
      "grad_norm": 0.5282139182090759,
      "learning_rate": 4.479562067777332e-10,
      "loss": 0.1937,
      "step": 6265
    },
    {
      "epoch": 0.9959667004430669,
      "grad_norm": 0.49094364047050476,
      "learning_rate": 4.1416116070391865e-10,
      "loss": 0.1524,
      "step": 6266
    },
    {
      "epoch": 0.9961256482088574,
      "grad_norm": 0.5835339426994324,
      "learning_rate": 3.816913388315913e-10,
      "loss": 0.2189,
      "step": 6267
    },
    {
      "epoch": 0.9962845959746478,
      "grad_norm": 0.48360782861709595,
      "learning_rate": 3.5054674976719993e-10,
      "loss": 0.1454,
      "step": 6268
    },
    {
      "epoch": 0.9964435437404383,
      "grad_norm": 0.5901581645011902,
      "learning_rate": 3.2072740176636307e-10,
      "loss": 0.1867,
      "step": 6269
    },
    {
      "epoch": 0.9966024915062288,
      "grad_norm": 0.7165740132331848,
      "learning_rate": 2.9223330273331354e-10,
      "loss": 0.2093,
      "step": 6270
    },
    {
      "epoch": 0.9967614392720192,
      "grad_norm": 0.6029147505760193,
      "learning_rate": 2.650644602208985e-10,
      "loss": 0.238,
      "step": 6271
    },
    {
      "epoch": 0.9969203870378097,
      "grad_norm": 0.6402097940444946,
      "learning_rate": 2.3922088143057963e-10,
      "loss": 0.2421,
      "step": 6272
    },
    {
      "epoch": 0.9970793348036001,
      "grad_norm": 0.5145372152328491,
      "learning_rate": 2.1470257321298815e-10,
      "loss": 0.1769,
      "step": 6273
    },
    {
      "epoch": 0.9972382825693906,
      "grad_norm": 0.569433867931366,
      "learning_rate": 1.915095420662594e-10,
      "loss": 0.159,
      "step": 6274
    },
    {
      "epoch": 0.9973972303351811,
      "grad_norm": 0.656237781047821,
      "learning_rate": 1.6964179413825332e-10,
      "loss": 0.232,
      "step": 6275
    },
    {
      "epoch": 0.9975561781009715,
      "grad_norm": 0.565403163433075,
      "learning_rate": 1.490993352259995e-10,
      "loss": 0.1939,
      "step": 6276
    },
    {
      "epoch": 0.997715125866762,
      "grad_norm": 0.5787002444267273,
      "learning_rate": 1.2988217077458676e-10,
      "loss": 0.1752,
      "step": 6277
    },
    {
      "epoch": 0.9978740736325525,
      "grad_norm": 0.6376954317092896,
      "learning_rate": 1.119903058771632e-10,
      "loss": 0.2808,
      "step": 6278
    },
    {
      "epoch": 0.9980330213983429,
      "grad_norm": 0.567293107509613,
      "learning_rate": 9.54237452771567e-11,
      "loss": 0.1907,
      "step": 6279
    },
    {
      "epoch": 0.9981919691641334,
      "grad_norm": 0.6041332483291626,
      "learning_rate": 8.018249336494421e-11,
      "loss": 0.2158,
      "step": 6280
    },
    {
      "epoch": 0.998350916929924,
      "grad_norm": 0.5610771179199219,
      "learning_rate": 6.626655418118244e-11,
      "loss": 0.1757,
      "step": 6281
    },
    {
      "epoch": 0.9985098646957143,
      "grad_norm": 0.5457638502120972,
      "learning_rate": 5.3675931413477156e-11,
      "loss": 0.1922,
      "step": 6282
    },
    {
      "epoch": 0.9986688124615049,
      "grad_norm": 0.5180662870407104,
      "learning_rate": 4.2410628400824104e-11,
      "loss": 0.1681,
      "step": 6283
    },
    {
      "epoch": 0.9988277602272954,
      "grad_norm": 0.6286496520042419,
      "learning_rate": 3.247064812805789e-11,
      "loss": 0.2587,
      "step": 6284
    },
    {
      "epoch": 0.9989867079930858,
      "grad_norm": 0.7019057273864746,
      "learning_rate": 2.3855993230292862e-11,
      "loss": 0.2388,
      "step": 6285
    },
    {
      "epoch": 0.9991456557588763,
      "grad_norm": 0.6324349641799927,
      "learning_rate": 1.656666599070267e-11,
      "loss": 0.2322,
      "step": 6286
    },
    {
      "epoch": 0.9993046035246667,
      "grad_norm": 0.604141354560852,
      "learning_rate": 1.0602668341630485e-11,
      "loss": 0.1773,
      "step": 6287
    },
    {
      "epoch": 0.9994635512904572,
      "grad_norm": 0.6597546339035034,
      "learning_rate": 5.964001864589008e-12,
      "loss": 0.2916,
      "step": 6288
    },
    {
      "epoch": 0.9996224990562477,
      "grad_norm": 0.6255418062210083,
      "learning_rate": 2.6506677880400177e-12,
      "loss": 0.2542,
      "step": 6289
    },
    {
      "epoch": 0.9997814468220381,
      "grad_norm": 0.6034247875213623,
      "learning_rate": 6.626669907250361e-13,
      "loss": 0.2325,
      "step": 6290
    },
    {
      "epoch": 0.9999403945878286,
      "grad_norm": 0.587345540523529,
      "learning_rate": 0.0,
      "loss": 0.1886,
      "step": 6291
    },
    {
      "epoch": 0.9999403945878286,
      "step": 6291,
      "total_flos": 1.7142640608536429e+19,
      "train_loss": 0.23706275611130503,
      "train_runtime": 216590.2201,
      "train_samples_per_second": 7.436,
      "train_steps_per_second": 0.029
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 6291,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7142640608536429e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
