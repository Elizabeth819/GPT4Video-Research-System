#!/usr/bin/env python3
"""
DriveMMå…¬å¹³æ¯”è¾ƒAzureä½œä¸šæäº¤è„šæœ¬
"""

import os
import sys
import subprocess
from datetime import datetime

def create_fair_comparison_job():
    """åˆ›å»ºDriveMMå…¬å¹³æ¯”è¾ƒä½œä¸šé…ç½®"""
    
    job_yaml = f"""$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
code: ./
command: python azure_drivemm_fair_comparison.py
environment: azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10
compute: drivemm-a100-cluster
experiment_name: drivemm_fair_comparison
display_name: DriveMM_Fair_Comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}
description: Fair comparison of DriveMM using same prompts as GPT-4o and Gemini models
tags:
  model: DriveMM-Fair-Comparison
  dataset: DADA-2000
  task: ghost_probing_detection
  gpu: A100-80GB
  mode: fair_comparison
  prompt: balanced_gpt41_compatible
"""
    
    with open("drivemm_fair_comparison_job.yml", "w") as f:
        f.write(job_yaml)
    
    return "drivemm_fair_comparison_job.yml"

def submit_fair_comparison_job():
    """æäº¤DriveMMå…¬å¹³æ¯”è¾ƒä½œä¸š"""
    print("ğŸš€ æäº¤DriveMMå…¬å¹³æ¯”è¾ƒAzure A100ä½œä¸š...")
    print("ğŸ“‹ ä½¿ç”¨ä¸GPT-4oå’ŒGeminiç›¸åŒçš„å¹³è¡¡ç‰ˆprompt")
    print("=" * 60)
    
    try:
        # åˆ›å»ºä½œä¸šé…ç½®
        job_file = create_fair_comparison_job()
        print(f"âœ… ä½œä¸šé…ç½®æ–‡ä»¶: {job_file}")
        
        # æ£€æŸ¥è„šæœ¬æ˜¯å¦å­˜åœ¨
        if not os.path.exists("azure_drivemm_fair_comparison.py"):
            print("âŒ å…¬å¹³æ¯”è¾ƒè„šæœ¬ä¸å­˜åœ¨")
            return None
        
        print(f"âœ… å¤„ç†å™¨è„šæœ¬: azure_drivemm_fair_comparison.py")
        
        # æäº¤ä½œä¸š
        cmd = [
            "az", "ml", "job", "create",
            "--file", job_file,
            "--workspace-name", "drivelm-ml-workspace",
            "--resource-group", "drivelm-rg"
        ]
        
        print("ğŸ”„ æäº¤Azure MLä½œä¸š...")
        result = subprocess.run(cmd, capture_output=True, text=True, check=True)
        
        # è§£æä½œä¸šåç§°
        import json
        job_info = json.loads(result.stdout)
        job_name = job_info.get("name", "unknown")
        
        print(f"âœ… DriveMMå…¬å¹³æ¯”è¾ƒä½œä¸šæäº¤æˆåŠŸ!")
        print(f"ğŸ†” ä½œä¸šåç§°: {job_name}")
        print(f"ğŸ”— ç›‘æ§é“¾æ¥: https://ml.azure.com/experiments/drivemm_fair_comparison/runs/{job_name}")
        
        return job_name
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return None
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ DRIVEMM å…¬å¹³æ¯”è¾ƒ AZURE A100 åˆ†æ")
    print("=" * 50)
    print("ğŸ¤– ä½¿ç”¨ä¸GPT-4oå’ŒGeminiç›¸åŒçš„å¹³è¡¡ç‰ˆprompt")
    print("ğŸ“Š ç¡®ä¿å…¬å¹³çš„æ¨¡å‹æ¯”è¾ƒå®éªŒ")
    print("ğŸ’ åœ¨Azure A100 GPUä¸Šè¿è¡Œ")
    print("ğŸš¨ æ ‡å‡†åŒ–é¬¼æ¢å¤´æ£€æµ‹criteria")
    print("=" * 50)
    
    # æäº¤å…¬å¹³æ¯”è¾ƒä½œä¸š
    job_name = submit_fair_comparison_job()
    
    if job_name:
        print("\nğŸ‰ DriveMMå…¬å¹³æ¯”è¾ƒä½œä¸šå¯åŠ¨æˆåŠŸ!")
        print(f"ğŸ“‹ ä½œä¸šåç§°: {job_name}")
        print("ğŸ“Š Azure ML Studioç›‘æ§: https://ml.azure.com/")
        print("\nğŸ“ ä¸‹ä¸€æ­¥:")
        print("  1. åœ¨Azure ML Studioä¸­ç›‘æ§ä½œä¸šè¿›åº¦")
        print("  2. ç­‰å¾…ä½œä¸šå®Œæˆ(é¢„è®¡5-8åˆ†é’Ÿ)")
        print("  3. ä¸‹è½½å…¬å¹³æ¯”è¾ƒç»“æœ")
        print("  4. ä¸GPT-4oå’ŒGeminiç»“æœè¿›è¡Œå¯¹æ¯”")
        print("\nğŸ”§ å…¬å¹³æ¯”è¾ƒç‰¹æ€§:")
        print("  - ä½¿ç”¨ç›¸åŒçš„å¹³è¡¡ç‰ˆpromptç»“æ„")
        print("  - ä¸‰å±‚æ£€æµ‹æœºåˆ¶(é«˜ç¡®ä¿¡åº¦/æ½œåœ¨/æ­£å¸¸)")
        print("  - ç»Ÿä¸€çš„JSONè¾“å‡ºæ ¼å¼")
        print("  - ç¯å¢ƒä¸Šä¸‹æ–‡ç†è§£")
        print("  - æ ‡å‡†åŒ–è¯„åˆ¤æ ‡å‡†")
        return 0
    else:
        print("\nâŒ DriveMMå…¬å¹³æ¯”è¾ƒä½œä¸šæäº¤å¤±è´¥")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)