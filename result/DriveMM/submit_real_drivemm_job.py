#!/usr/bin/env python3
"""
æäº¤çœŸå®DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML
åœ¨GPUç¯å¢ƒä¸­ä¸‹è½½å’Œè¿è¡ŒçœŸå®DriveMMæ¨¡å‹
"""

import os
import sys
from azure.ai.ml import MLClient
from azure.ai.ml import command
from azure.ai.ml.entities import Environment
from azure.identity import DefaultAzureCredential
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def submit_real_drivemm_job():
    """æäº¤çœŸå®DriveMMæ¨ç†ä½œä¸š"""
    
    logger.info("ğŸš€ æäº¤çœŸå®DriveMMæ¨ç†ä½œä¸šåˆ°Azure ML")
    
    try:
        # Azure MLå®¢æˆ·ç«¯
        credential = DefaultAzureCredential()
        ml_client = MLClient.from_config(credential=credential)
        
        logger.info("âœ… Azure MLå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
        
        # ç›´æ¥ä½¿ç”¨Azureå®˜æ–¹ç¯å¢ƒï¼Œä¸å†è‡ªå®šä¹‰ç¯å¢ƒ
        official_env = "azureml:AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10"
        
        # åˆ›å»ºä½œä¸š
        logger.info("ğŸ¯ åˆ›å»ºçœŸå®DriveMMæ¨ç†ä½œä¸š...")
        
        job = command(
            display_name="DriveMM_Real_Inference_Ghost_Probing",
            description="ä½¿ç”¨çœŸå®DriveMMæ¨¡å‹(17GB)åœ¨GPUç¯å¢ƒä¸­è¿›è¡Œé¬¼æ¢å¤´æ£€æµ‹",
            code=".",
            command="pip install transformers>=4.35.0 huggingface_hub>=0.20.0 accelerate>=0.24.0 azure-storage-blob>=12.19.0 opencv-python>=4.8.0 && python azure_drivemm_real_inference.py",
            environment=official_env,
            compute="drivemm-a100-cluster",
            environment_variables={
                "AZURE_STORAGE_CONNECTION_STRING": "DefaultEndpointsProtocol=https;AccountName=drivelmmstorage2e932dad7;AccountKey=MniZTrPWLKwVg6XpJKpu+4Rv5fuvd0x+xq2smYW+yZn1IGVpf5OcMuGfLBmSuKyOWhAjOLGnbNIq+AStpd49zQ==;EndpointSuffix=core.windows.net",
                "HF_HOME": "/tmp/huggingface_cache",
                "TRANSFORMERS_CACHE": "/tmp/transformers_cache",
                "TORCH_HOME": "/tmp/torch_cache"
            },
            experiment_name="drivemm-real-inference",
            tags={
                "model": "DriveMM-Real-17GB",
                "task": "ghost-probing-detection", 
                "comparison": "vs-GPT41-balanced",
                "environment": "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu:10",
                "model_source": "huggingface.co/DriveMM/DriveMM"
            }
        )
        
        # æäº¤ä½œä¸š
        logger.info("ğŸ“¤ æäº¤ä½œä¸šåˆ°Azure ML...")
        returned_job = ml_client.create_or_update(job)
        
        logger.info("âœ… çœŸå®DriveMMä½œä¸šæäº¤æˆåŠŸ!")
        logger.info(f"ğŸ”— ä½œä¸šURL: {returned_job.services['Studio'].endpoint}")
        logger.info(f"ğŸ†” ä½œä¸šID: {returned_job.name}")
        
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ çœŸå®DriveMMæ¨ç†ä½œä¸šå·²å¯åŠ¨!")
        logger.info("ğŸ“‹ ä½œä¸šè¯¦æƒ…:")
        logger.info(f"   - æ¨¡å‹: DriveMM/DriveMM (çœŸå®17GBæ¨¡å‹)")
        logger.info(f"   - ç¯å¢ƒ: Azure ML GPU")
        logger.info(f"   - æ•°æ®æº: drivelmmstorage2e932dad7")
        logger.info(f"   - ä»»åŠ¡: 99ä¸ªè§†é¢‘é¬¼æ¢å¤´æ£€æµ‹")
        logger.info(f"   - å¯¹æ¯”åŸºå‡†: GPT-4.1 Balanced F1=0.712")
        logger.info("â³ ä½œä¸šå°†è‡ªåŠ¨ä¸‹è½½DriveMMæ¨¡å‹å¹¶å¼€å§‹æ¨ç†...")
        
        return returned_job.name
        
    except Exception as e:
        logger.error(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    job_id = submit_real_drivemm_job()
    if job_id:
        print(f"\nğŸŠ æˆåŠŸ! ä½œä¸šID: {job_id}")
        print("è¯·åœ¨Azure ML Studioä¸­ç›‘æ§ä½œä¸šè¿›åº¦")
    else:
        print("\nâŒ ä½œä¸šæäº¤å¤±è´¥")
        sys.exit(1)