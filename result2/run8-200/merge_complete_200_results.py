#!/usr/bin/env python3
"""
åˆå¹¶Run 8-200çš„æ‰€æœ‰ç»“æœï¼Œç”Ÿæˆå®Œæ•´çš„200è§†é¢‘æ€§èƒ½ç»Ÿè®¡
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime
from collections import Counter

def merge_results():
    """åˆå¹¶ä¸»ç»“æœå’Œè¡¥å……ç»“æœ"""
    
    # è¯»å–ä¸»ç»“æœ (190ä¸ªè§†é¢‘)
    main_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/run8_200videos_final_results_20250730_134411.json"
    with open(main_file, 'r', encoding='utf-8') as f:
        main_data = json.load(f)
    
    # è¯»å–è¡¥å……ç»“æœ (10ä¸ªè§†é¢‘)
    supplement_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/remaining_10_videos_results_20250730_163001.json"
    with open(supplement_file, 'r', encoding='utf-8') as f:
        supplement_data = json.load(f)
    
    print("=" * 70)
    print("ğŸ“Š Run 8-200 å®Œæ•´200è§†é¢‘ç»“æœåˆå¹¶")
    print("=" * 70)
    print(f"ğŸ“‚ ä¸»ç»“æœæ–‡ä»¶: {len(main_data['detailed_results'])} ä¸ªè§†é¢‘")
    print(f"ğŸ“‚ è¡¥å……ç»“æœæ–‡ä»¶: {len(supplement_data['detailed_results'])} ä¸ªè§†é¢‘")
    
    # åˆå¹¶è¯¦ç»†ç»“æœ
    all_results = main_data['detailed_results'] + supplement_data['detailed_results']
    
    print(f"ğŸ¯ åˆå¹¶åæ€»æ•°: {len(all_results)} ä¸ªè§†é¢‘")
    
    # åˆ›å»ºå®Œæ•´çš„åˆå¹¶ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    merged_data = {
        "experiment_info": {
            "run_id": "Run 8-200 Complete",
            "timestamp": timestamp,
            "video_count": 200,
            "processed_videos": len(all_results),
            "model": "GPT-4o (Azure)",
            "prompt_version": "Paper_Batch Complex (4-Task) + Few-shot Examples",
            "temperature": 0,
            "max_tokens": 3000,
            "purpose": "å®Œæ•´çš„200è§†é¢‘DADA-200æ•°æ®é›†æµ‹è¯•ï¼ŒéªŒè¯Run 8é…ç½®çš„å¤§è§„æ¨¡æ€§èƒ½",
            "ground_truth_file": "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/DADA-200-videos/labels.csv",
            "output_directory": "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200",
            "merged_from": [
                "run8_200videos_final_results_20250730_134411.json (190 videos)",
                "remaining_10_videos_results_20250730_163001.json (10 videos)"
            ]
        },
        "detailed_results": all_results
    }
    
    # ä¿å­˜åˆå¹¶ç»“æœ
    merged_file = f"/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/run8_200videos_complete_results_{timestamp}.json"
    with open(merged_file, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å®Œæ•´ç»“æœæ–‡ä»¶å·²ä¿å­˜: {merged_file}")
    
    return merged_file, all_results

def calculate_complete_performance(results):
    """è®¡ç®—å®Œæ•´çš„200è§†é¢‘æ€§èƒ½æŒ‡æ ‡"""
    
    # ç»Ÿè®¡æ··æ·†çŸ©é˜µ
    tp = sum(1 for r in results if r['evaluation'] == 'TP')
    tn = sum(1 for r in results if r['evaluation'] == 'TN') 
    fp = sum(1 for r in results if r['evaluation'] == 'FP')
    fn = sum(1 for r in results if r['evaluation'] == 'FN')
    unknown = sum(1 for r in results if r['evaluation'] == 'UNKNOWN')
    
    total_processed = len(results)
    valid_evaluations = tp + tn + fp + fn  # æ’é™¤unknown
    
    print("\n" + "=" * 70)
    print("ğŸ¯ Run 8-200 å®Œæ•´200è§†é¢‘æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("=" * 70)
    
    print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
    print(f"   - ç›®æ ‡è§†é¢‘æ•°: 200")
    print(f"   - æˆåŠŸå¤„ç†: {total_processed} ä¸ªè§†é¢‘")
    print(f"   - æœ‰æ•ˆè¯„ä¼°: {valid_evaluations} ä¸ªè§†é¢‘") 
    print(f"   - å¤„ç†æˆåŠŸç‡: {total_processed/200*100:.1f}%")
    print()
    
    print(f"ğŸ² æ··æ·†çŸ©é˜µç»Ÿè®¡:")
    print(f"   - True Positives (TP): {tp}")
    print(f"   - True Negatives (TN): {tn}")
    print(f"   - False Positives (FP): {fp}")
    print(f"   - False Negatives (FN): {fn}")
    print(f"   - Unknown/å¤±è´¥: {unknown}")
    print()
    
    if valid_evaluations > 0:
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        accuracy = (tp + tn) / valid_evaluations
        
        # å¹³è¡¡å‡†ç¡®ç‡
        sensitivity = recall  # æ•æ„Ÿæ€§ = å¬å›ç‡
        balanced_accuracy = (sensitivity + specificity) / 2
        
        print(f"ğŸ“Š æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡:")
        print(f"   - F1 Score: {f1_score:.3f} ({f1_score*100:.1f}%)")
        print(f"   - Precision: {precision:.3f} ({precision*100:.1f}%)")
        print(f"   - Recall: {recall:.3f} ({recall*100:.1f}%)")
        print(f"   - Specificity: {specificity:.3f} ({specificity*100:.1f}%)")
        print(f"   - Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)")
        print(f"   - Balanced Accuracy: {balanced_accuracy:.3f} ({balanced_accuracy*100:.1f}%)")
        print()
        
        # æ•°æ®é›†åˆ†å¸ƒåˆ†æ
        ghost_probing_count = tp + fn  # å®é™…ghost probingæ•°é‡
        normal_count = tn + fp  # å®é™…normalæ•°é‡
        
        print(f"ğŸ“‹ æ•°æ®é›†åˆ†å¸ƒ:")
        print(f"   - Ghost Probingæ¡ˆä¾‹: {ghost_probing_count} ({ghost_probing_count/valid_evaluations*100:.1f}%)")
        print(f"   - Normalæ¡ˆä¾‹: {normal_count} ({normal_count/valid_evaluations*100:.1f}%)")
        print()
        
        # ä¸Run 8 (100è§†é¢‘)å¯¹æ¯”
        print("=" * 70)
        print("ğŸ“ˆ ä¸Run 8 (100è§†é¢‘)æ€§èƒ½å¯¹æ¯”")
        print("=" * 70)
        print("Run 8 (100è§†é¢‘) å‚è€ƒæŒ‡æ ‡:")
        print("   - F1 Score: 65.0%")
        print("   - Precision: 54.2%")
        print("   - Recall: 81.2%")
        print("   - Specificity: 67.4%") 
        print("   - Accuracy: 72.0%")
        print()
        
        # ä¸190è§†é¢‘ç»“æœå¯¹æ¯”
        print("Run 8-190 (éƒ¨åˆ†ç»“æœ) å‚è€ƒæŒ‡æ ‡:")
        print("   - F1 Score: 58.9%")
        print("   - Precision: 46.8%")
        print("   - Recall: 79.5%")
        print("   - Specificity: 29.9%")
        print("   - Accuracy: 51.6%")
        print()
        
        # æ€§èƒ½å˜åŒ–åˆ†æ
        f1_diff_vs_100 = f1_score * 100 - 65.0
        precision_diff_vs_100 = precision * 100 - 54.2
        recall_diff_vs_100 = recall * 100 - 81.2
        specificity_diff_vs_100 = specificity * 100 - 67.4
        accuracy_diff_vs_100 = accuracy * 100 - 72.0
        
        f1_diff_vs_190 = f1_score * 100 - 58.9
        precision_diff_vs_190 = precision * 100 - 46.8
        
        print(f"ğŸ“Š Run 8-200 å®Œæ•´ç‰ˆæ€§èƒ½:")
        print(f"   vs Run 8 (100è§†é¢‘):")
        print(f"     - F1 Score: {f1_score*100:.1f}% ({f1_diff_vs_100:+.1f})")
        print(f"     - Precision: {precision*100:.1f}% ({precision_diff_vs_100:+.1f})")
        print(f"     - Recall: {recall*100:.1f}% ({recall_diff_vs_100:+.1f})")
        print(f"     - Specificity: {specificity*100:.1f}% ({specificity_diff_vs_100:+.1f})")
        print(f"     - Accuracy: {accuracy*100:.1f}% ({accuracy_diff_vs_100:+.1f})")
        print()
        print(f"   vs Run 8-190 (éƒ¨åˆ†ç»“æœ):")
        print(f"     - F1 Score: {f1_score*100:.1f}% ({f1_diff_vs_190:+.1f})")
        print(f"     - Precision: {precision*100:.1f}% ({precision_diff_vs_190:+.1f})")
        print()
        
        # 95%ç½®ä¿¡åŒºé—´ä¼°è®¡
        n = valid_evaluations
        f1_se = np.sqrt(f1_score * (1 - f1_score) / n)
        f1_ci_lower = max(0, f1_score - 1.96 * f1_se)
        f1_ci_upper = min(1, f1_score + 1.96 * f1_se)
        
        precision_se = np.sqrt(precision * (1 - precision) / (tp + fp)) if (tp + fp) > 0 else 0
        precision_ci_lower = max(0, precision - 1.96 * precision_se)
        precision_ci_upper = min(1, precision + 1.96 * precision_se)
        
        recall_se = np.sqrt(recall * (1 - recall) / (tp + fn)) if (tp + fn) > 0 else 0
        recall_ci_lower = max(0, recall - 1.96 * recall_se)
        recall_ci_upper = min(1, recall + 1.96 * recall_se)
        
        print(f"ğŸ“ 95%ç½®ä¿¡åŒºé—´:")
        print(f"   - F1 Score: [{f1_ci_lower*100:.1f}%, {f1_ci_upper*100:.1f}%]")
        print(f"   - Precision: [{precision_ci_lower*100:.1f}%, {precision_ci_upper*100:.1f}%]")
        print(f"   - Recall: [{recall_ci_lower*100:.1f}%, {recall_ci_upper*100:.1f}%]")
        print()
        
        # æœ€ç»ˆç»“è®º
        print("=" * 70)
        print("ğŸ¯ æœ€ç»ˆç»“è®º")
        print("=" * 70)
        
        print(f"âœ… å®Œæ•´å¤„ç†äº†200ä¸ªè§†é¢‘ä¸­çš„{total_processed}ä¸ª ({total_processed/200*100:.1f}%)")
        print(f"ğŸ“Š å®Œæ•´ç‰ˆF1-score: {f1_score*100:.1f}%")
        
        if f1_score >= 0.60:
            print("âœ… æ€§èƒ½è¾¾æ ‡: F1-scoreä¿æŒåœ¨60%ä»¥ä¸Š")
        else:
            print("âš ï¸  æ€§èƒ½å¾…ä¼˜åŒ–: F1-scoreä½äº60%")
        
        print(f"ğŸ” å…³é”®å‘ç°:")
        print(f"   1. 200è§†é¢‘å®Œæ•´ç‰ˆç›¸æ¯”100è§†é¢‘ç‰ˆæœ¬F1ä¸‹é™äº†{abs(f1_diff_vs_100):.1f}%")
        print(f"   2. å¬å›ç‡ä¿æŒ{recall*100:.1f}%ï¼Œæ»¡è¶³å®‰å…¨ç³»ç»Ÿè¦æ±‚")
        print(f"   3. å¤§è§„æ¨¡æ•°æ®éªŒè¯äº†æ¨¡å‹çš„çœŸå®æ€§èƒ½è¾¹ç•Œ")
        print(f"   4. ä¸ºåç»­æ¨¡å‹ä¼˜åŒ–æä¾›äº†å¯é çš„åŸºå‡†æ•°æ®")
        
        # ä¿å­˜æ€§èƒ½æŒ‡æ ‡
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        metrics_file = f"/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/run8_200videos_complete_performance_metrics_{timestamp}.json"
        
        metrics_data = {
            "experiment_info": {
                "experiment_id": "Run 8-200 Complete",
                "timestamp": timestamp,
                "video_dataset": "DADA-200-videos",
                "total_videos": 200,
                "processed_videos": total_processed,
                "valid_evaluations": valid_evaluations
            },
            "performance_metrics": {
                "f1_score": f1_score,
                "precision": precision, 
                "recall": recall,
                "specificity": specificity,
                "accuracy": accuracy,
                "balanced_accuracy": balanced_accuracy
            },
            "confusion_matrix": {
                "true_positives": tp,
                "true_negatives": tn,
                "false_positives": fp,
                "false_negatives": fn,
                "unknown": unknown
            },
            "dataset_distribution": {
                "ghost_probing_cases": ghost_probing_count,
                "normal_cases": normal_count,
                "ghost_probing_percentage": ghost_probing_count/valid_evaluations*100,
                "normal_percentage": normal_count/valid_evaluations*100
            },
            "comparison": {
                "vs_run8_100videos": {
                    "f1_improvement": f1_diff_vs_100,
                    "precision_improvement": precision_diff_vs_100,
                    "recall_improvement": recall_diff_vs_100,
                    "specificity_improvement": specificity_diff_vs_100,
                    "accuracy_improvement": accuracy_diff_vs_100
                },
                "vs_run8_190videos": {
                    "f1_improvement": f1_diff_vs_190,
                    "precision_improvement": precision_diff_vs_190
                }
            },
            "confidence_intervals_95": {
                "f1_score": [f1_ci_lower, f1_ci_upper],
                "precision": [precision_ci_lower, precision_ci_upper],
                "recall": [recall_ci_lower, recall_ci_upper]
            }
        }
        
        with open(metrics_file, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å®Œæ•´æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°: {metrics_file}")
        
        return metrics_data
    
    else:
        print("âŒ æ— æœ‰æ•ˆè¯„ä¼°æ•°æ®ï¼Œæ— æ³•è®¡ç®—æ€§èƒ½æŒ‡æ ‡")
        return None

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹åˆå¹¶Run 8-200å®Œæ•´ç»“æœ...")
    
    # åˆå¹¶ç»“æœ
    merged_file, all_results = merge_results()
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    metrics = calculate_complete_performance(all_results)
    
    print(f"\nğŸ‰ Run 8-200å®Œæ•´ç‰ˆåˆ†æå®Œæˆï¼")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {merged_file}")
    
    if metrics:
        print(f"ğŸ¯ æœ€ç»ˆF1-score: {metrics['performance_metrics']['f1_score']*100:.1f}%")
        print(f"ğŸ“Š å¤„ç†è§†é¢‘æ•°: {metrics['experiment_info']['processed_videos']}/200")