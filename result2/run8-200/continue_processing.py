#!/usr/bin/env python3
"""
æ£€æŸ¥å¹¶ç»§ç»­å¤„ç†å‰©ä½™çš„DADA-200è§†é¢‘
ç¡®ä¿å®Œæ•´å¤„ç†200ä¸ªè§†é¢‘
"""

import os
import json
import glob

def find_missing_videos():
    """æ‰¾å‡ºæœªå¤„ç†çš„è§†é¢‘"""
    
    # è·å–æ‰€æœ‰200ä¸ªè§†é¢‘æ–‡ä»¶
    video_dir = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/DADA-200-videos"
    all_videos = []
    for filename in os.listdir(video_dir):
        if filename.endswith('.avi'):
            video_id = filename.replace('.avi', '')
            all_videos.append(video_id)
    
    all_videos.sort()
    print(f"ğŸ“‚ DADA-200ç›®å½•ä¸‹æ€»è§†é¢‘æ•°: {len(all_videos)}")
    
    # è¯»å–å·²å¤„ç†çš„è§†é¢‘
    results_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/run8_200videos_final_results_20250730_134411.json"
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        processed_videos = set()
        for result in data['detailed_results']:
            video_id = result['video_id'].replace('.avi', '')
            processed_videos.add(video_id)
        
        print(f"âœ… å·²å¤„ç†çš„è§†é¢‘æ•°: {len(processed_videos)}")
        
        # æ‰¾å‡ºæœªå¤„ç†çš„è§†é¢‘
        missing_videos = []
        for video_id in all_videos:
            if video_id not in processed_videos:
                missing_videos.append(video_id)
        
        missing_videos.sort()
        print(f"âŒ æœªå¤„ç†çš„è§†é¢‘æ•°: {len(missing_videos)}")
        
        if missing_videos:
            print("\nğŸ“‹ æœªå¤„ç†çš„è§†é¢‘åˆ—è¡¨:")
            for i, video_id in enumerate(missing_videos, 1):
                print(f"   {i:2d}. {video_id}.avi")
        
        return missing_videos
        
    except Exception as e:
        print(f"âŒ è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        return []

def check_api_timeout_videos():
    """æ£€æŸ¥APIè¶…æ—¶å¤±è´¥çš„è§†é¢‘"""
    
    log_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/run8_200videos_output.log"
    
    timeout_videos = []
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # æŸ¥æ‰¾APIè¶…æ—¶çš„è§†é¢‘
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if "APIè¯·æ±‚å¼‚å¸¸" in line and "Read timed out" in line:
                # æŸ¥æ‰¾å‰é¢çš„å¼€å§‹åˆ†ææ—¥å¿—
                for j in range(i-1, max(0, i-10), -1):
                    if "ğŸ¬ å¼€å§‹åˆ†æè§†é¢‘:" in lines[j]:
                        video_id = lines[j].split("ğŸ¬ å¼€å§‹åˆ†æè§†é¢‘: ")[1].strip()
                        timeout_videos.append(video_id)
                        break
        
        timeout_videos = list(set(timeout_videos))  # å»é‡
        print(f"\nâ° APIè¶…æ—¶å¤±è´¥çš„è§†é¢‘æ•°: {len(timeout_videos)}")
        if timeout_videos:
            print("ğŸ“‹ è¶…æ—¶è§†é¢‘åˆ—è¡¨:")
            for i, video_id in enumerate(timeout_videos, 1):
                print(f"   {i:2d}. {video_id}.avi")
        
        return timeout_videos
        
    except Exception as e:
        print(f"âŒ è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        return []

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” Run 8-200è§†é¢‘å¤„ç†å®Œæ•´æ€§æ£€æŸ¥")
    print("=" * 60)
    
    missing_videos = find_missing_videos()
    timeout_videos = check_api_timeout_videos()
    
    # åˆå¹¶éœ€è¦é‡æ–°å¤„ç†çš„è§†é¢‘
    videos_to_process = list(set(missing_videos + timeout_videos))
    videos_to_process.sort()
    
    print(f"\nğŸ¯ éœ€è¦(é‡æ–°)å¤„ç†çš„è§†é¢‘æ€»æ•°: {len(videos_to_process)}")
    
    if videos_to_process:
        print("\nğŸ“ å»ºè®®æ“ä½œ:")
        print("   1. ä¿®æ”¹run8_gpt4o_200videos_fewshot.pyï¼Œè®¾ç½®åªå¤„ç†è¿™äº›è§†é¢‘")
        print("   2. æˆ–è€…åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„è¡¥å……å¤„ç†è„šæœ¬")
        print("   3. å¤„ç†å®Œæˆååˆå¹¶ç»“æœåˆ°ä¸»ç»“æœæ–‡ä»¶")
        
        # ä¿å­˜å¾…å¤„ç†è§†é¢‘åˆ—è¡¨
        todo_file = "/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run8-200/videos_to_process.json"
        todo_data = {
            "missing_videos": missing_videos,
            "timeout_videos": timeout_videos, 
            "videos_to_process": videos_to_process,
            "total_count": len(videos_to_process)
        }
        
        with open(todo_file, 'w', encoding='utf-8') as f:
            json.dump(todo_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å¾…å¤„ç†è§†é¢‘åˆ—è¡¨å·²ä¿å­˜åˆ°: {todo_file}")
    else:
        print("\nâœ… æ‰€æœ‰200ä¸ªè§†é¢‘å·²å®Œæˆå¤„ç†ï¼")