#!/usr/bin/env python3
"""
Calculate performance metrics for Run 11 Rerun3
"""
import json
from pathlib import Path

def calculate_metrics():
    results_file = Path("/Users/wanmeng/repository/GPT4Video-cobra-auto/result2/run11-rerun3/run11_gpt41_rerun3_final_results_20250730_102243.json")
    
    with open(results_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Count results
    tp = fp = tn = fn = 0
    
    for result in data['detailed_results']:
        evaluation = result['evaluation']
        if evaluation == 'TP':
            tp += 1
        elif evaluation == 'FP':
            fp += 1
        elif evaluation == 'TN':
            tn += 1
        elif evaluation == 'FN':
            fn += 1
    
    total = tp + fp + tn + fn
    
    # Calculate metrics
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    accuracy = (tp + tn) / total if total > 0 else 0
    balanced_accuracy = (recall + specificity) / 2
    
    print("ğŸš€ Run 11 Rerun3 Performance Metrics")
    print("="*50)
    print(f"ğŸ“Š Total Videos: {total}")
    print(f"ğŸ¯ True Positives (TP): {tp}")
    print(f"ğŸ”´ False Positives (FP): {fp}")
    print(f"âœ… True Negatives (TN): {tn}")
    print(f"ğŸŸ¡ False Negatives (FN): {fn}")
    print()
    print("ğŸ“ˆ Performance Metrics:")
    print(f"ğŸ¯ F1-Score: {f1:.3f}")
    print(f"ğŸ” Precision: {precision:.3f}")
    print(f"ğŸ“¡ Recall: {recall:.3f}")
    print(f"ğŸ›¡ï¸ Specificity: {specificity:.3f}")
    print(f"âœ… Accuracy: {accuracy:.3f}")
    print(f"âš–ï¸ Balanced Accuracy: {balanced_accuracy:.3f}")
    
    # Model info
    exp_info = data['experiment_info']
    print(f"\nğŸ”§ Model: {exp_info['model']}")
    print(f"ğŸ“ Prompt: {exp_info['prompt_version']}")
    print(f"ğŸ“… Timestamp: {exp_info['timestamp']}")
    
    return {
        'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,
        'f1_score': f1, 'precision': precision, 'recall': recall,
        'specificity': specificity, 'accuracy': accuracy,
        'balanced_accuracy': balanced_accuracy,
        'total_videos': total
    }

if __name__ == "__main__":
    metrics = calculate_metrics()