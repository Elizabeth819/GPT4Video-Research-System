#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt å®Œæ•´å®éªŒ (99ä¸ªè§†é¢‘)
åŸºäºå¿«é€Ÿæµ‹è¯•çš„æˆåŠŸç»“æœï¼Œæ‰©å±•åˆ°å…¨éƒ¨Ground Truthè§†é¢‘
"""

import os
import json
import cv2
from moviepy.editor import VideoFileClip
import google.generativeai as genai
from dotenv import load_dotenv
import time
import pandas as pd
from tqdm import tqdm
import traceback

def setup_gemini():
    """è®¾ç½®Gemini API"""
    load_dotenv()
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("âŒ è¯·è®¾ç½®GEMINI_API_KEYç¯å¢ƒå˜é‡")
        return None
    
    genai.configure(api_key=api_key)
    
    try:
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        print("âœ… Gemini 2.0 Flashæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        return model
    except Exception as e:
        print(f"âŒ Geminiæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return None

def get_balanced_prompt():
    """GPT-4.1å¹³è¡¡ç‰ˆprompt"""
    return """You are an expert AI system analyzing sequential video frames from autonomous driving scenarios. Your primary task is to detect "ghost probing" events using a balanced layered detection strategy.

**DEFINITION: Ghost Probing**
A dangerous traffic scenario where pedestrians, cyclists, or objects suddenly appear from concealed positions (behind parked cars, walls, blind spots) creating immediate collision risk requiring emergency braking or avoidance.

**LAYERED DETECTION STRATEGY:**

**1. HIGH-CONFIDENCE Ghost Probing (use "ghost probing" in key_actions)**:
- Object appears EXTREMELY close (within 1-2 vehicle lengths, <3 meters) 
- Appearance is SUDDEN and from blind spots (behind parked cars, walls, obstacles)
- Occurs in HIGH-RISK environments: highways, rural roads, parking lots
- Creates IMMEDIATE danger requiring emergency response
- Object was previously completely hidden and suddenly emerges

**2. POTENTIAL Ghost Probing (use "potential ghost probing" in key_actions)**:
- Object appears suddenly but at moderate distance (3-5 meters)
- Sudden movement in environments where some unpredictability exists
- Appears from partially concealed positions
- Creates heightened caution but not immediate emergency

**3. Normal Traffic (use "none" in key_actions)**:
- Predictable pedestrian crossings at crosswalks
- Cyclists in designated bike lanes
- Normal traffic flow and lane changes
- Expected movements in urban environments

**ANALYSIS FRAMEWORK:**
1. **Concealment Assessment**: Was the object previously hidden behind obstacles?
2. **Distance Evaluation**: How close is the object when first detected?
3. **Environment Context**: Is this a high-risk scenario location?
4. **Predictability**: Was this movement expected or sudden?
5. **Emergency Level**: Does this require immediate evasive action?

Always return a single JSON object with these fields:
- video_id: (extract from video filename)
- segment_id: (e.g., "segment_000")
- Start_Timestamp and End_Timestamp: derived from frame timing
- summary: detailed description of the scenario
- actions: current vehicle actions and reasoning
- key_objects: important objects affecting driving decisions
- key_actions: classification using layered strategy ("ghost probing", "potential ghost probing", or "none")
- next_action: JSON object with speed_control, direction_control, and lane_control

**IMPORTANT**: Use the layered detection strategy to maintain high recall (detect real dangers) while improving precision (reduce false positives). When in doubt between categories, prefer the more conservative classification.

All text must be in English. Return only valid JSON."""

def extract_frames(video_path, start_time, end_time, num_frames=10):
    """ä»è§†é¢‘ä¸­æå–å¸§"""
    try:
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        frames = []
        duration = end_time - start_time
        
        for i in range(num_frames):
            timestamp = start_time + (i * duration / num_frames)
            frame_number = int(timestamp * fps)
            
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            ret, frame = cap.read()
            
            if ret:
                # ç¡®ä¿framesç›®å½•å­˜åœ¨
                os.makedirs("frames", exist_ok=True)
                frame_path = f"frames/temp_frame_{i:03d}.jpg"
                cv2.imwrite(frame_path, frame)
                frames.append(frame_path)
        
        cap.release()
        return frames
        
    except Exception as e:
        print(f"âŒ å¸§æå–å¤±è´¥: {str(e)}")
        return []

def analyze_with_gemini(model, frames, video_id, segment_id):
    """ä½¿ç”¨Geminiåˆ†æå¸§"""
    try:
        prompt = get_balanced_prompt()
        
        # å‡†å¤‡å†…å®¹
        content = [prompt]
        content.append(f"\nAnalyzing video {video_id}, {segment_id}")
        content.append(f"Processing {len(frames)} frames:")
        
        # æ·»åŠ å›¾ç‰‡
        for i, frame_path in enumerate(frames):
            if os.path.exists(frame_path):
                with open(frame_path, 'rb') as f:
                    image_data = f.read()
                
                content.append({
                    'mime_type': 'image/jpeg',
                    'data': image_data
                })
                content.append(f"Frame {i+1}: {os.path.basename(frame_path)}")
        
        # APIè°ƒç”¨
        response = model.generate_content(
            content,
            generation_config={
                "temperature": 0.2,
                "top_p": 0.95,
                "max_output_tokens": 2048,
            }
        )
        
        if response.text:
            return response.text
        else:
            return None
            
    except Exception as e:
        print(f"âŒ Geminiåˆ†æå¤±è´¥: {str(e)}")
        return None

def parse_gemini_response(result_text):
    """è§£æGeminiå“åº”ä¸ºJSON"""
    try:
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
        clean_text = result_text.strip()
        if clean_text.startswith('```'):
            lines = clean_text.split('\n')
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª{å’Œæœ€åä¸€ä¸ª}
            json_start = -1
            json_end = -1
            for i, line in enumerate(lines):
                if line.strip().startswith('{') and json_start == -1:
                    json_start = i
                if line.strip().endswith('}'):
                    json_end = i
            
            if json_start != -1 and json_end != -1:
                clean_text = '\n'.join(lines[json_start:json_end+1])
        
        return json.loads(clean_text)
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æå¤±è´¥: {str(e)}")
        return None

def process_video(model, video_path, output_dir):
    """å¤„ç†å•ä¸ªè§†é¢‘"""
    video_name = os.path.basename(video_path)
    video_id = video_name.replace('.avi', '').replace('images_', 'dada_')
    
    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    output_file = os.path.join(output_dir, f"actionSummary_{video_id}.json")
    if os.path.exists(output_file):
        return "skipped"
    
    try:
        # è·å–è§†é¢‘ä¿¡æ¯
        with VideoFileClip(video_path) as clip:
            duration = clip.duration
        
        # è®¡ç®—ç‰‡æ®µæ•°é‡
        interval = 10  # 10ç§’é—´éš”
        num_segments = max(1, int(duration // interval))
        if duration % interval > 0:
            num_segments += 1
        
        results = []
        
        for seg_id in range(num_segments):
            start_time = seg_id * interval
            end_time = min((seg_id + 1) * interval, duration)
            
            # æå–å¸§
            frames = extract_frames(video_path, start_time, end_time, 10)
            
            if not frames:
                continue
            
            # Geminiåˆ†æ
            result_text = analyze_with_gemini(model, frames, video_id, f"segment_{seg_id:03d}")
            
            if result_text:
                result_json = parse_gemini_response(result_text)
                if result_json:
                    results.append(result_json)
            
            # æ¸…ç†ä¸´æ—¶å¸§
            for frame in frames:
                if os.path.exists(frame):
                    os.remove(frame)
            
            # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
            time.sleep(1)
        
        # ä¿å­˜ç»“æœ
        if results:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            return "success"
        else:
            return "failed"
            
    except Exception as e:
        print(f"âŒ å¤„ç†è§†é¢‘ {video_name} å¤±è´¥: {str(e)}")
        return "failed"

def get_ground_truth_videos():
    """è·å–Ground Truthè§†é¢‘åˆ—è¡¨"""
    try:
        df = pd.read_csv('result/groundtruth_labels.csv', sep='\t')
        video_ids = df['video_id'].str.replace('.avi', '').tolist()
        
        # è¿‡æ»¤æ‰ç©ºå€¼
        video_ids = [vid for vid in video_ids if vid and isinstance(vid, str)]
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        video_paths = []
        for vid in video_ids:
            video_path = f"DADA-2000-videos/{vid}.avi"
            if os.path.exists(video_path):
                video_paths.append(video_path)
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(video_paths)} ä¸ªGround Truthè§†é¢‘")
        return video_paths
        
    except Exception as e:
        print(f"âŒ è¯»å–Ground Truthå¤±è´¥: {str(e)}")
        return []

def main():
    print("ğŸš€ Gemini 2.0 Flash + å¹³è¡¡ç‰ˆPrompt å®Œæ•´å®éªŒ")
    print("=" * 60)
    print("ğŸ“‹ ç›®æ ‡: å¤„ç†99ä¸ªGround Truthè§†é¢‘ï¼Œä¸GPT-4.1è¿›è¡Œå…¬å¹³å¯¹æ¯”")
    
    # åˆå§‹åŒ–Gemini
    model = setup_gemini()
    if not model:
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "result/gemini-balanced-full"
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–è§†é¢‘åˆ—è¡¨
    video_paths = get_ground_truth_videos()
    if not video_paths:
        print("âŒ æœªæ‰¾åˆ°å¯å¤„ç†çš„è§†é¢‘")
        return
    
    print(f"ğŸ¬ å‡†å¤‡å¤„ç† {len(video_paths)} ä¸ªè§†é¢‘")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # å¤„ç†ç»Ÿè®¡
    successful = 0
    skipped = 0
    failed = 0
    
    # å¤„ç†è§†é¢‘
    with tqdm(video_paths, desc="å¤„ç†è§†é¢‘") as pbar:
        for video_path in pbar:
            video_name = os.path.basename(video_path)
            pbar.set_description(f"å¤„ç† {video_name}")
            
            try:
                result = process_video(model, video_path, output_dir)
                
                if result == "success":
                    successful += 1
                    pbar.write(f"âœ… {video_name}")
                elif result == "skipped":
                    skipped += 1
                    pbar.write(f"â­ï¸ {video_name} (å·²å¤„ç†)")
                else:
                    failed += 1
                    pbar.write(f"âŒ {video_name}")
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'æˆåŠŸ': successful,
                    'è·³è¿‡': skipped, 
                    'å¤±è´¥': failed
                })
                
            except Exception as e:
                failed += 1
                pbar.write(f"âŒ {video_name}: {str(e)}")
    
    # æœ€ç»ˆç»Ÿè®¡
    total_processed = successful + failed
    success_rate = (successful / total_processed * 100) if total_processed > 0 else 0
    
    print(f"\nğŸ¯ å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸ: {successful}")
    print(f"  â­ï¸ è·³è¿‡: {skipped}")
    print(f"  âŒ å¤±è´¥: {failed}")
    print(f"  ğŸ“Š æˆåŠŸç‡: {success_rate:.1f}%")
    
    if successful > 0:
        print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
        print(f"ğŸ“‹ ä¸‹ä¸€æ­¥: è¿è¡Œå…¬å¹³å¯¹æ¯”åˆ†æ")
    
    # ä¿å­˜å¤„ç†æ—¥å¿—
    log_file = f"{output_dir}/processing_log_{time.strftime('%Y%m%d_%H%M%S')}.json"
    log_data = {
        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
        'total_videos': len(video_paths),
        'successful': successful,
        'skipped': skipped,
        'failed': failed,
        'success_rate': success_rate,
        'output_directory': output_dir
    }
    
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ å¤„ç†æ—¥å¿—å·²ä¿å­˜: {log_file}")

if __name__ == "__main__":
    main()