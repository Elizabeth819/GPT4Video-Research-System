#!/usr/bin/env python
"""
è®¾ç½®DriveMMåœ¨Azure MLä¸Šçš„æ¨ç†ç¯å¢ƒå¹¶æäº¤ä½œä¸š
"""

import os
import json
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Environment, CommandJob, AmlCompute
from azure.identity import DefaultAzureCredential

def setup_drivemm_azure():
    """è®¾ç½®DriveMM Azure MLç¯å¢ƒå¹¶æäº¤ä½œä¸š"""
    
    # ä»config.jsonè¯»å–é…ç½®
    if not os.path.exists('config.json'):
        print("âŒ æ‰¾ä¸åˆ°config.jsonæ–‡ä»¶")
        print("ğŸ“ è¯·å¤åˆ¶ config.json.example ä¸º config.json å¹¶å¡«å…¥å®é™…é…ç½®")
        return None
    
    with open('config.json', 'r') as f:
        config = json.load(f)
    
    # åˆå§‹åŒ–Azure MLå®¢æˆ·ç«¯
    print("ğŸ”— è¿æ¥åˆ°Azure ML...")
    credential = DefaultAzureCredential()
    ml_client = MLClient(
        credential=credential,
        subscription_id=config['subscription_id'],
        resource_group_name=config['resource_group'],
        workspace_name=config['workspace_name']
    )
    
    print("âœ… Azure MLå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ")
    
    # 1. æ£€æŸ¥GPUè®¡ç®—é›†ç¾¤
    print("ğŸ–¥ï¸  æ£€æŸ¥GPUè®¡ç®—é›†ç¾¤...")
    
    try:
        compute = ml_client.compute.get(config.get('compute_target', 'drivemm-a100-cluster'))
        print(f"âœ… æ‰¾åˆ°ç°æœ‰é›†ç¾¤: {compute.name}")
        print(f"   ç±»å‹: {compute.size}")
        print(f"   çŠ¶æ€: {compute.provisioning_state}")
    except Exception as e:
        print(f"âš ï¸  é›†ç¾¤ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {e}")
        print("ğŸ’¡ ä½ å¯ä»¥åœ¨Azure ML Studioä¸­åˆ›å»ºé›†ç¾¤ï¼Œæˆ–ä½¿ç”¨ä»¥ä¸‹ä»£ç åˆ›å»º:")
        print("""
        compute_config = AmlCompute(
            name="drivemm-a100-cluster",
            type="amlcompute",
            size="Standard_NC24ads_A100_v4",  # A100 40GB GPU
            min_instances=0,
            max_instances=2,
            idle_time_before_scale_down=1800
        )
        compute = ml_client.compute.begin_create_or_update(compute_config).result()
        """)
        return None
    
    # 2. åˆ›å»ºæˆ–æ›´æ–°DriveMMç¯å¢ƒ
    print("ğŸ³ åˆ›å»ºDriveMMæ¨ç†ç¯å¢ƒ...")
    
    environment = Environment(
        name="drivemm-inference-env",
        description="DriveMMæ¨ç†ç¯å¢ƒï¼Œæ”¯æŒGPU",
        conda_file="azure_drivemm_environment.yml",
        image="mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.6-cudnn8-ubuntu20.04:latest"
    )
    
    try:
        env = ml_client.environments.create_or_update(environment)
        print(f"âœ… ç¯å¢ƒåˆ›å»º/æ›´æ–°æˆåŠŸ: {env.name}:{env.version}")
    except Exception as e:
        print(f"âš ï¸  ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        return None
    
    # 3. æäº¤DriveMMæ¨ç†ä½œä¸š
    print("ğŸš€ æäº¤DriveMMæ¨ç†ä½œä¸š...")
    
    # è·å–å­˜å‚¨è¿æ¥å­—ç¬¦ä¸²
    storage_connection = os.getenv("AZURE_STORAGE_CONNECTION_STRING", "")
    if not storage_connection:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½®AZURE_STORAGE_CONNECTION_STRINGç¯å¢ƒå˜é‡")
        print("   è¯·è¿è¡Œ: export AZURE_STORAGE_CONNECTION_STRING='ä½ çš„è¿æ¥å­—ç¬¦ä¸²'")
    
    job = CommandJob(
        experiment_name=config.get('experiment_name', 'drivemm-inference'),
        display_name="DriveMM_Real_GPU_Inference",
        description="ä½¿ç”¨çœŸå®DriveMMæ¨¡å‹åœ¨A100 GPUä¸Šå¯¹dada-videosè¿›è¡Œæ¨ç†",
        compute=config.get('compute_target', 'drivemm-a100-cluster'),
        environment=f"{env.name}:{env.version}",
        command="python azure_drivemm_real_inference.py",
        code="./",
        environment_variables={
            "AZURE_STORAGE_CONNECTION_STRING": storage_connection
        },
        resources={
            "instance_count": 1,
            "shm_size": "16g"
        },
        timeout=7200  # 2å°æ—¶
    )
    
    try:
        submitted_job = ml_client.jobs.create_or_update(job)
        print(f"âœ… ä½œä¸šæäº¤æˆåŠŸ!")
        print(f"ğŸ“Š ä½œä¸šåç§°: {submitted_job.name}")
        print(f"ğŸ”— ç›‘æ§é“¾æ¥: {submitted_job.studio_url}")
        print(f"\nğŸ’¡ ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ—¥å¿—:")
        print(f"   az ml job stream --name {submitted_job.name} \\")
        print(f"      --workspace-name {config['workspace_name']} \\")
        print(f"      --resource-group {config['resource_group']}")
        return submitted_job
    except Exception as e:
        print(f"âŒ ä½œä¸šæäº¤å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    print("ğŸ”§ Azure ML DriveMMæ¨ç†ç¯å¢ƒè®¾ç½®")
    print("=" * 60)
    setup_drivemm_azure()
